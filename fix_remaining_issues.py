#!/usr/bin/env python3
"""
CORRECCI√ìN DE PROBLEMAS RESTANTES EN EL NOTEBOOK
"""

import json
import re

def fix_remaining_issues():
    """Corrige los problemas restantes detectados en la validaci√≥n"""
    
    print("üîß CORRIGIENDO PROBLEMAS RESTANTES")
    print("=" * 80)
    
    # Cargar notebook
    with open('models/hybrid_models_GRU-w12.ipynb', 'r') as f:
        notebook = json.load(f)
    
    content = ''.join(notebook['cells'][0]['source'])
    
    # 1. CORREGIR LLAMADA INCONSISTENTE EN validate_data_flow
    print("üîß 1. Corrigiendo llamada inconsistente...")
    
    # Buscar y corregir la llamada problem√°tica en validate_data_flow
    content = content.replace(
        'result = build_dataloaders(exp_name, fold_name, ds_full, 8)',
        'result = build_dataloaders(exp_name, fold_name, dataset, 8)'
    )
    
    print("   ‚úÖ Llamada inconsistente corregida")
    
    # 2. VERIFICAR Y MEJORAR build_dataloaders SI ES NECESARIO
    print("üîß 2. Verificando build_dataloaders...")
    
    # Buscar la funci√≥n build_dataloaders actual
    build_match = re.search(
        r'def build_dataloaders\(exp_name, fold_name, dataset, batch_size=64\):(.*?)(?=\ndef [^_]|\Z)',
        content,
        re.DOTALL
    )
    
    if build_match:
        build_function = build_match.group(1)
        
        # Verificar si tiene la l√≥gica de iteraci√≥n de features
        if 'for feature in features:' not in build_function:
            print("   ‚ö†Ô∏è build_dataloaders parece ser versi√≥n simplificada")
            print("   üìã Verificando si es intencional o necesita correcci√≥n...")
            
            # Si no tiene iteraci√≥n pero s√≠ tiene return de datasets TensorFlow, est√° OK
            if 'tf.data.Dataset' in build_function and 'return {' in build_function:
                print("   ‚úÖ build_dataloaders es versi√≥n simplificada pero funcional")
            else:
                print("   ‚ùå build_dataloaders necesita correcci√≥n")
        else:
            print("   ‚úÖ build_dataloaders tiene l√≥gica completa")
    
    # 3. VERIFICAR Y CORREGIR CONFIGURACI√ìN DE EXPERIMENTS SI ES NECESARIO
    print("üîß 3. Verificando configuraci√≥n de EXPERIMENTS...")
    
    # Buscar la configuraci√≥n de EXPERIMENTS
    exp_match = re.search(r"EXPERIMENTS\s*=\s*{(.*?)^}", content, re.DOTALL | re.MULTILINE)
    
    if exp_match:
        experiments_section = exp_match.group(0)
        
        # Verificar si las feature_list est√°n bien formateadas
        if "'feature_list': [" in experiments_section:
            print("   ‚úÖ feature_list bien formateadas")
        else:
            print("   ‚ö†Ô∏è feature_list posiblemente mal formateadas")
    
    # 4. ASEGURAR QUE TODOS LOS EXPERIMENTOS TENGAN active: False POR DEFECTO (EXCEPTO CONVGRU-ED)
    print("üîß 4. Configurando estados activos de experimentos...")
    
    # Asegurar que solo ConvGRU-ED est√© activo por defecto para testing
    exp_names = ['ConvGRU-ED-KCE', 'ConvGRU-ED-KCE-PAFC', 'AE-FUSION-ConvGRU-ED-KCE-PAFC-MHA', 'AE-FUSION-ConvGRU-ED-KCE-PAFC-MHA-TopoMask']
    
    for exp_name in exp_names:
        # Buscar y cambiar active: True por active: False para experimentos complejos
        pattern = rf"('{exp_name}':[^}}]*'active':\s*)True"
        replacement = r"\1False"
        content = re.sub(pattern, replacement, content)
    
    # Asegurar que ConvGRU-ED est√© activo
    convgru_pattern = r"('ConvGRU-ED':[^}]*'active':\s*)False"
    convgru_replacement = r"\1True"
    content = re.sub(convgru_pattern, convgru_replacement, content)
    
    print("   ‚úÖ Estados de experimentos configurados")
    
    # 5. A√ëADIR FUNCI√ìN DE PRUEBA R√ÅPIDA MEJORADA AL FINAL DE LA PRIMERA CELDA
    print("üîß 5. A√±adiendo funci√≥n de prueba mejorada...")
    
    improved_test = '''

# ======================================================================
# FUNCI√ìN DE PRUEBA R√ÅPIDA MEJORADA
# ======================================================================

def test_complete_data_flow():
    """Prueba completa del flujo de datos"""
    
    print("üß™ PRUEBA COMPLETA DEL FLUJO DE DATOS")
    print("="*50)
    
    try:
        # 1. Verificar componentes b√°sicos
        components = ['ds_full', 'EXPERIMENTS', 'build_dataloaders', 'train_experiment_complete']
        for comp in components:
            if comp in globals():
                print(f"‚úÖ {comp} disponible")
            else:
                print(f"‚ùå {comp} NO disponible")
                return False
        
        # 2. Verificar experimentos activos
        active_experiments = [name for name, config in EXPERIMENTS.items() if config.get('active', False)]
        print(f"‚úÖ Experimentos activos: {active_experiments}")
        
        if not active_experiments:
            print("‚ö†Ô∏è No hay experimentos activos - activando ConvGRU-ED")
            EXPERIMENTS['ConvGRU-ED']['active'] = True
            active_experiments = ['ConvGRU-ED']
        
        # 3. Probar con primer experimento activo
        exp_name = active_experiments[0]
        exp_config = EXPERIMENTS[exp_name]
        features = exp_config['feature_list']
        print(f"‚úÖ {exp_name}: {len(features)} caracter√≠sticas")
        print(f"   üìã Modelo: {exp_config['model']}")
        
        # Verificar features en dataset
        available_vars = list(ds_full.data_vars.keys())
        missing_features = [f for f in features if f not in available_vars]
        
        if missing_features:
            print(f"‚ùå Features faltantes: {missing_features[:3]}...")
            print(f"   üìã Dataset tiene: {available_vars[:10]}...")
            return False
        else:
            print("‚úÖ Todas las features disponibles en dataset")
        
        # 4. Probar build_dataloaders
        print(f"üî¨ Probando build_dataloaders...")
        result = build_dataloaders(exp_name, 'F1', ds_full, 16)
        
        if result is None:
            print("‚ùå build_dataloaders retorn√≥ None")
            return False
        
        print("‚úÖ build_dataloaders exitoso")
        print(f"   üìä Keys: {list(result.keys())}")
        
        # 5. Verificar que pipeline principal sea ejecutable
        print("üß™ Verificando pipeline principal...")
        if 'run_complete_training_pipeline' in globals():
            print("‚úÖ run_complete_training_pipeline disponible")
        else:
            print("‚ùå run_complete_training_pipeline NO disponible")
            return False
        
        print("üéâ FLUJO DE DATOS COMPLETAMENTE VALIDADO")
        print("üöÄ Listo para ejecutar run_complete_training_pipeline()")
        return True
        
    except Exception as e:
        print(f"‚ùå Error en prueba: {e}")
        import traceback
        traceback.print_exc()
        return False

print("‚úÖ FUNCI√ìN DE PRUEBA COMPLETA A√ëADIDA")
print("üß™ Ejecutar: test_complete_data_flow()")'''
    
    # A√±adir al final de la primera celda (antes del √∫ltimo print)
    if 'test_complete_data_flow()' not in content:
        # Buscar un buen lugar para insertar (antes del √∫ltimo print de la celda)
        last_print_pos = content.rfind('print("üéâ TODO LISTO PARA EJECUTAR!")')
        if last_print_pos != -1:
            content = content[:last_print_pos] + improved_test + '\n\n' + content[last_print_pos:]
            print("   ‚úÖ Funci√≥n de prueba a√±adida")
        else:
            # Si no encuentra el lugar, a√±adir al final
            content = content + improved_test
            print("   ‚úÖ Funci√≥n de prueba a√±adida al final")
    else:
        print("   ‚úÖ Funci√≥n de prueba ya existe")
    
    # 6. ACTUALIZAR NOTEBOOK
    print("\nüíæ GUARDANDO CORRECCIONES...")
    
    # Actualizar contenido
    notebook['cells'][0]['source'] = content.split('\n')
    
    # Guardar
    with open('models/hybrid_models_GRU-w12.ipynb', 'w') as f:
        json.dump(notebook, f, indent=1)
    
    print("‚úÖ CORRECCIONES GUARDADAS")
    
    # 7. VERIFICACI√ìN FINAL
    print("\nüîç VERIFICACI√ìN FINAL...")
    
    # Recargar y verificar
    with open('models/hybrid_models_GRU-w12.ipynb', 'r') as f:
        final_notebook = json.load(f)
    
    final_content = ''.join([''.join(cell['source']) for cell in final_notebook['cells']])
    
    # Verificaciones finales
    final_checks = [
        ('build_dataloaders(exp_name, fold_name, dataset', 'Llamadas consistentes'),
        ('test_complete_data_flow', 'Funci√≥n de prueba disponible'),
        ("'ConvGRU-ED':", 'Configuraci√≥n de experimentos'),
        ('def run_complete_training_pipeline', 'Pipeline principal')
    ]
    
    all_good = True
    for check, description in final_checks:
        if check in final_content:
            print(f"   ‚úÖ {description}")
        else:
            print(f"   ‚ùå {description} - FALTA")
            all_good = False
    
    return all_good

if __name__ == "__main__":
    success = fix_remaining_issues()
    
    print(f"\n" + "=" * 80)
    print("üéØ RESULTADO DE LAS CORRECCIONES")
    print("=" * 80)
    
    if success:
        print("‚úÖ TODAS LAS CORRECCIONES APLICADAS EXITOSAMENTE")
        print("üìã Notebook completamente listo")
        print("\nüöÄ PR√ìXIMOS PASOS:")
        print("   1. Ejecutar test_complete_data_flow() en el notebook")
        print("   2. Si todo OK, ejecutar quick_demo()")
        print("   3. Luego run_complete_training_pipeline()")
    else:
        print("‚ö†Ô∏è ALGUNAS CORRECCIONES NECESITAN REVISI√ìN MANUAL")
        print("üìã Verificar notebook manualmente")
    
    print("\n" + "=" * 80) 