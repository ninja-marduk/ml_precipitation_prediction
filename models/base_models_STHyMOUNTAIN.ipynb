{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4e7925",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/main/models/base_models_STHyMOUNTAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3744f4",
   "metadata": {
    "id": "af3744f4"
   },
   "source": [
    "# üìò Entrenamiento de Modelos Baseline para Predicci√≥n Espaciotemporal de Precipitaci√≥n Mensual STHyMOUNTAIN\n",
    "\n",
    "Este notebook implementa modelos baseline para la predicci√≥n de precipitaciones usando datos espaciotemporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994be36",
   "metadata": {},
   "source": [
    "## üîç Implementaci√≥n de Modelos Avanzados y T√©cnicas de Validaci√≥n\n",
    "\n",
    "Adem√°s de los modelos tabulares baseline, implementaremos:\n",
    "\n",
    "1. **Optimizaci√≥n avanzada con Optuna** para los modelos tabulares XGBoost y LightGBM\n",
    "2. **Validaci√≥n robusta** mediante:\n",
    "   - Hold-Out Validation (ya implementada)\n",
    "   - Cross-Validation (k=5)\n",
    "   - Bootstrapping (100 muestras)\n",
    "3. **Modelos de Deep Learning** para capturar patrones espaciales y temporales:\n",
    "   - Redes CNN para patrones espaciales\n",
    "   - Redes ConvLSTM para patrones espaciotemporales\n",
    "\n",
    "El objetivo es proporcionar una evaluaci√≥n completa de diferentes enfoques de modelado para la predicci√≥n de precipitaci√≥n en regiones monta√±osas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06416284",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06416284",
    "outputId": "a8e4c864-34e9-41b2-d5c3-e6ccaaf3699e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno configurado. Usando ruta base: ..\n",
      "Directorio para salida de modelos creado: ../models/output\n",
      "Respaldo del DataFrame guardado en: ../data/output/temp/dataframe_backup.parquet\n",
      "Respaldo del DataFrame guardado en: ../data/output/temp/dataframe_backup.parquet\n",
      "Modelo RandomForest cargado desde: ../models/output/RandomForest.pkl\n",
      "Modelo XGBoost cargado desde: ../models/output/XGBoost.pkl\n",
      "Modelo LightGBM cargado desde: ../models/output/LightGBM.pkl\n",
      "No se encontr√≥ el archivo de respaldo en: ../models/output/cnn_model.h5\n",
      "No se encontr√≥ el archivo de respaldo en: ../models/output/convlstm_model.h5\n",
      "Modelo RandomForest cargado desde: ../models/output/RandomForest.pkl\n",
      "Modelo XGBoost cargado desde: ../models/output/XGBoost.pkl\n",
      "Modelo LightGBM cargado desde: ../models/output/LightGBM.pkl\n",
      "No se encontr√≥ el archivo de respaldo en: ../models/output/cnn_model.h5\n",
      "No se encontr√≥ el archivo de respaldo en: ../models/output/convlstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del entorno (compatible con Colab y local)\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Detectar si estamos en Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')   \n",
    "    # Si estamos en Colab, clonar el repositorio\n",
    "    !git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
    "    %cd ml_precipitation_prediction\n",
    "    # Instalar dependencias necesarias\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn\n",
    "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
    "else:\n",
    "    # Si estamos en local, usar la ruta actual\n",
    "    if '/models' in os.getcwd():\n",
    "        BASE_PATH = Path('..')\n",
    "    else:\n",
    "        BASE_PATH = Path('.')\n",
    "\n",
    "print(f\"Entorno configurado. Usando ruta base: {BASE_PATH}\")\n",
    "\n",
    "# Si BASE_PATH viene como string, lo convertimos\n",
    "BASE_PATH = Path(BASE_PATH)\n",
    "\n",
    "# Ahora puedes concatenar correctamente\n",
    "model_output_dir = BASE_PATH / 'models' / 'output'\n",
    "model_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directorio para salida de modelos creado: {model_output_dir}\")\n",
    "\n",
    "# Implementaci√≥n de resiliencia para interacci√≥n con Google Drive y restauraci√≥n de datos\n",
    "def backup_dataframe(df, backup_path):\n",
    "    \"\"\"Guarda un DataFrame como respaldo en formato Parquet.\"\"\"\n",
    "    try:\n",
    "        df.to_parquet(backup_path, index=False)\n",
    "        print(f\"Respaldo del DataFrame guardado en: {backup_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar respaldo del DataFrame: {e}\")\n",
    "\n",
    "def restore_dataframe(backup_path):\n",
    "    \"\"\"Restaura un DataFrame desde un archivo de respaldo en formato Parquet.\"\"\"\n",
    "    try:\n",
    "        if backup_path.exists():\n",
    "            df_restored = pd.read_parquet(backup_path)\n",
    "            print(f\"DataFrame restaurado desde: {backup_path}\")\n",
    "            return df_restored\n",
    "        else:\n",
    "            print(f\"No se encontr√≥ el archivo de respaldo en: {backup_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al restaurar el DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ruta para respaldo temporal del DataFrame\n",
    "temp_dir = BASE_PATH / 'data' / 'output' / 'temp'\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "temp_file_path = temp_dir / 'dataframe_backup.parquet'\n",
    "\n",
    "# Respaldo inicial del DataFrame principal\n",
    "if 'df' in locals() and df is not None:\n",
    "    backup_dataframe(df, temp_file_path)\n",
    "\n",
    "# Modificar interacci√≥n con Google Drive para reintentos\n",
    "max_retries = 3\n",
    "retry_delay = 5  # segundos\n",
    "\n",
    "def mount_google_drive():\n",
    "    \"\"\"Intenta montar Google Drive con reintentos.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"Google Drive montado exitosamente.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error al montar Google Drive (intento {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "    print(\"No se pudo montar Google Drive despu√©s de varios intentos.\")\n",
    "    return False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not mount_google_drive():\n",
    "        print(\"Usando datos en memoria o restaurando desde respaldo local.\")\n",
    "        df = restore_dataframe(temp_file_path)\n",
    "\n",
    "# Restaurar modelos guardados en caso de fallo\n",
    "model_files = {\n",
    "    'RandomForest': model_output_dir / 'RandomForest.pkl',\n",
    "    'XGBoost': model_output_dir / 'XGBoost.pkl',\n",
    "    'LightGBM': model_output_dir / 'LightGBM.pkl'\n",
    "}\n",
    "\n",
    "def load_saved_model(model_name, model_path):\n",
    "    \"\"\"Carga un modelo guardado desde disco.\"\"\"\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "            print(f\"Modelo {model_name} cargado desde: {model_path}\")\n",
    "            return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Inicializar `modelos_base` como un diccionario vac√≠o\n",
    "modelos_base = {}\n",
    "\n",
    "# Intentar cargar modelos guardados\n",
    "for model_name, model_path in model_files.items():\n",
    "    if model_name not in modelos_base:\n",
    "        modelos_base[model_name] = load_saved_model(model_name, model_path)\n",
    "\n",
    "# Implementaci√≥n de resiliencia para modelos CNN y ConvLSTM\n",
    "\n",
    "# Respaldo y restauraci√≥n de modelos CNN y ConvLSTM\n",
    "cnn_model_path = model_output_dir / 'cnn_model.h5'\n",
    "convlstm_model_path = model_output_dir / 'convlstm_model.h5'\n",
    "\n",
    "def backup_model(model, model_path):\n",
    "    \"\"\"Guarda un modelo de Keras como respaldo.\"\"\"\n",
    "    try:\n",
    "        model.save(model_path)\n",
    "        print(f\"Modelo respaldado en: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar respaldo del modelo: {e}\")\n",
    "\n",
    "def restore_model(model_path):\n",
    "    \"\"\"Restaura un modelo de Keras desde un archivo de respaldo.\"\"\"\n",
    "    try:\n",
    "        if model_path.exists():\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"Modelo restaurado desde: {model_path}\")\n",
    "            return model\n",
    "        else:\n",
    "            print(f\"No se encontr√≥ el archivo de respaldo en: {model_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al restaurar el modelo: {e}\")\n",
    "        return None\n",
    "\n",
    "# Respaldo inicial de modelos si existen\n",
    "if 'cnn_model' in locals() and cnn_model is not None:\n",
    "    backup_model(cnn_model, cnn_model_path)\n",
    "if 'convlstm_model' in locals() and convlstm_model is not None:\n",
    "    backup_model(convlstm_model, convlstm_model_path)\n",
    "\n",
    "# Restaurar modelos en caso de fallo\n",
    "if 'cnn_model' not in locals() or cnn_model is None:\n",
    "    cnn_model = restore_model(cnn_model_path)\n",
    "if 'convlstm_model' not in locals() or convlstm_model is None:\n",
    "    convlstm_model = restore_model(convlstm_model_path)\n",
    "\n",
    "# Modificar interacci√≥n con Google Drive para reintentos\n",
    "max_retries = 3\n",
    "retry_delay = 5  # segundos\n",
    "\n",
    "def mount_google_drive():\n",
    "    \"\"\"Intenta montar Google Drive con reintentos.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"Google Drive montado exitosamente.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error al montar Google Drive (intento {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "    print(\"No se pudo montar Google Drive despu√©s de varios intentos.\")\n",
    "    return False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not mount_google_drive():\n",
    "        print(\"Usando datos en memoria o restaurando desde respaldo local para modelos CNN y ConvLSTM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47fb555",
   "metadata": {
    "id": "e47fb555"
   },
   "outputs": [],
   "source": [
    "# 1. Importaciones necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import optuna\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importaciones para barras de progreso y mejora de visualizaci√≥n\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import time\n",
    "\n",
    "# Configurar visualizaci√≥n m√°s atractiva\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313434be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow versi√≥n: 2.18.0\n",
      "No se detect√≥ GPU. Usando CPU.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones adicionales para Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, save_model, load_model\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Conv2D, Conv3D, ConvLSTM2D, BatchNormalization, \n",
    "                                   MaxPooling2D, Flatten, Input, concatenate, Reshape, TimeDistributed, UpSampling2D)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"TensorFlow versi√≥n:\", tf.__version__)\n",
    "\n",
    "# Configurar GPU si est√° disponible\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(f\"GPU disponible: {physical_devices}\")\n",
    "    # Permitir crecimiento de memoria seg√∫n sea necesario\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    print(\"No se detect√≥ GPU. Usando CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26215d90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "26215d90",
    "outputId": "ccb06926-e151-453f-a306-999f15566bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando archivo en: ../data/output/complete_dataset_with_features.nc\n",
      "Intentando cargar el archivo: ../data/output/complete_dataset_with_features.nc\n",
      "Archivo cargado exitosamente con xarray\n",
      "\n",
      "Informaci√≥n del dataset:\n",
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\ttime = 530 ;\n",
      "\tlatitude = 62 ;\n",
      "\tlongitude = 66 ;\n",
      "\n",
      "variables:\n",
      "\tdatetime64[ns] time(time) ;\n",
      "\tfloat32 latitude(latitude) ;\n",
      "\tfloat32 longitude(longitude) ;\n",
      "\tfloat32 total_precipitation(time, latitude, longitude) ;\n",
      "\tfloat32 max_daily_precipitation(time, latitude, longitude) ;\n",
      "\tfloat32 min_daily_precipitation(time, latitude, longitude) ;\n",
      "\tfloat32 daily_precipitation_std(time, latitude, longitude) ;\n",
      "\tfloat32 month_sin(time, latitude, longitude) ;\n",
      "\tfloat32 month_cos(time, latitude, longitude) ;\n",
      "\tfloat32 doy_sin(time, latitude, longitude) ;\n",
      "\tfloat32 doy_cos(time, latitude, longitude) ;\n",
      "\tfloat64 elevation(latitude, longitude) ;\n",
      "\tfloat32 slope(latitude, longitude) ;\n",
      "\tfloat32 aspect(latitude, longitude) ;\n",
      "\n",
      "// global attributes:\n",
      "\t:description = ST-HyMOUNTAIN-Net ready dataset with CHIRPS monthly precipitation and DEM variables ;\n",
      "\t:source = CHIRPS v2.0 & DEM Boyac√° ;\n",
      "\t:created_at = 2025-04-27 19:02:24 ;\n",
      "}None\n",
      "\n",
      "Variables disponibles:\n",
      "- total_precipitation: (530, 62, 66)\n",
      "- max_daily_precipitation: (530, 62, 66)\n",
      "- min_daily_precipitation: (530, 62, 66)\n",
      "- daily_precipitation_std: (530, 62, 66)\n",
      "- month_sin: (530, 62, 66)\n",
      "- month_cos: (530, 62, 66)\n",
      "- doy_sin: (530, 62, 66)\n",
      "- doy_cos: (530, 62, 66)\n",
      "- elevation: (62, 66)\n",
      "- slope: (62, 66)\n",
      "- aspect: (62, 66)\n",
      "Dataset cargado con √©xito. Dimensiones: (2168760, 14)\n",
      "\n",
      "Primeras filas del DataFrame:\n",
      "Dataset cargado con √©xito. Dimensiones: (2168760, 14)\n",
      "\n",
      "Primeras filas del DataFrame:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "latitude",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "longitude",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "total_precipitation",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "max_daily_precipitation",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "min_daily_precipitation",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "daily_precipitation_std",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "month_sin",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "month_cos",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "doy_sin",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "doy_cos",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "elevation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "slope",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "aspect",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e8e9d7e7-1c3a-445f-a507-801b8f8555b6",
       "rows": [
        [
         "0",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.975006",
         "47.38105",
         "24.706928",
         "0.0",
         "5.8257756",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "493.78455182073014",
         "89.53955",
         "102.0445"
        ],
        [
         "1",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.925",
         "40.750824",
         "21.819195",
         "0.0",
         "5.0190454",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "519.7501066909579",
         "89.86702",
         "73.481674"
        ],
        [
         "2",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.87501",
         "46.338623",
         "26.092327",
         "0.0",
         "5.7402234",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "248.7760453427361",
         "89.72222",
         "65.91682"
        ],
        [
         "3",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.825005",
         "48.779938",
         "29.42145",
         "0.0",
         "5.611738",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "351.4157280671193",
         "86.98613",
         "140.916"
        ],
        [
         "4",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.775",
         "38.932945",
         "18.48306",
         "0.0",
         "3.7335742",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "278.2619223660964",
         "88.27329",
         "18.43994"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>max_daily_precipitation</th>\n",
       "      <th>min_daily_precipitation</th>\n",
       "      <th>daily_precipitation_std</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slope</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.975006</td>\n",
       "      <td>47.381050</td>\n",
       "      <td>24.706928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.825776</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>493.784552</td>\n",
       "      <td>89.539551</td>\n",
       "      <td>102.044502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.925003</td>\n",
       "      <td>40.750824</td>\n",
       "      <td>21.819195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.019045</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>519.750107</td>\n",
       "      <td>89.867020</td>\n",
       "      <td>73.481674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.875008</td>\n",
       "      <td>46.338623</td>\n",
       "      <td>26.092327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.740223</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>248.776045</td>\n",
       "      <td>89.722221</td>\n",
       "      <td>65.916817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.825005</td>\n",
       "      <td>48.779938</td>\n",
       "      <td>29.421450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.611738</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>351.415728</td>\n",
       "      <td>86.986130</td>\n",
       "      <td>140.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.775002</td>\n",
       "      <td>38.932945</td>\n",
       "      <td>18.483061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.733574</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>278.261922</td>\n",
       "      <td>88.273293</td>\n",
       "      <td>18.439939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  latitude  longitude  total_precipitation  \\\n",
       "0 1981-01-01  4.324997 -74.975006            47.381050   \n",
       "1 1981-01-01  4.324997 -74.925003            40.750824   \n",
       "2 1981-01-01  4.324997 -74.875008            46.338623   \n",
       "3 1981-01-01  4.324997 -74.825005            48.779938   \n",
       "4 1981-01-01  4.324997 -74.775002            38.932945   \n",
       "\n",
       "   max_daily_precipitation  min_daily_precipitation  daily_precipitation_std  \\\n",
       "0                24.706928                      0.0                 5.825776   \n",
       "1                21.819195                      0.0                 5.019045   \n",
       "2                26.092327                      0.0                 5.740223   \n",
       "3                29.421450                      0.0                 5.611738   \n",
       "4                18.483061                      0.0                 3.733574   \n",
       "\n",
       "   month_sin  month_cos   doy_sin   doy_cos   elevation      slope      aspect  \n",
       "0        0.5   0.866025  0.017202  0.999852  493.784552  89.539551  102.044502  \n",
       "1        0.5   0.866025  0.017202  0.999852  519.750107  89.867020   73.481674  \n",
       "2        0.5   0.866025  0.017202  0.999852  248.776045  89.722221   65.916817  \n",
       "3        0.5   0.866025  0.017202  0.999852  351.415728  86.986130  140.916000  \n",
       "4        0.5   0.866025  0.017202  0.999852  278.261922  88.273293   18.439939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Cargar el dataset NetCDF\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Carga un archivo NetCDF y lo convierte a pandas DataFrame\"\"\"\n",
    "    try:\n",
    "        # Cargar el archivo NetCDF con xarray\n",
    "        print(f\"Intentando cargar el archivo: {file_path}\")\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        print(\"Archivo cargado exitosamente con xarray\")\n",
    "\n",
    "        # Mostrar informaci√≥n del dataset cargado\n",
    "        print(\"\\nInformaci√≥n del dataset:\")\n",
    "        print(ds.info())\n",
    "        print(\"\\nVariables disponibles:\")\n",
    "        for var_name in ds.data_vars:\n",
    "            print(f\"- {var_name}: {ds[var_name].shape}\")\n",
    "\n",
    "        # Convertir a DataFrame\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "        return df, ds\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el archivo NetCDF: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Ruta al dataset\n",
    "data_file = BASE_PATH / 'data' / 'output' / 'complete_dataset_with_features.nc'\n",
    "print(f\"Buscando archivo en: {data_file}\")\n",
    "\n",
    "# Cargar el dataset\n",
    "df, ds_original = load_dataset(data_file)\n",
    "\n",
    "# Verificar si se carg√≥ correctamente\n",
    "if df is not None:\n",
    "    print(f\"Dataset cargado con √©xito. Dimensiones: {df.shape}\")\n",
    "    print(\"\\nPrimeras filas del DataFrame:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No se pudo cargar el dataset. Verificar la ruta y el formato del archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f0aebbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f0aebbc",
    "outputId": "48e82987-ff47-41e8-9f40-57e53cf90cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna objetivo identificada: total_precipitation\n",
      "Filas antes de eliminar NaN: 2168760\n",
      "Filas despu√©s de eliminar NaN: 2168760\n",
      "\n",
      "Features seleccionadas (12):\n",
      "['latitude', 'longitude', 'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos', 'elevation', 'slope', 'aspect']\n",
      "\n",
      "Variable objetivo: total_precipitation\n",
      "\n",
      "Features seleccionadas (12):\n",
      "['latitude', 'longitude', 'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos', 'elevation', 'slope', 'aspect']\n",
      "\n",
      "Variable objetivo: total_precipitation\n"
     ]
    }
   ],
   "source": [
    "# 3. Preparaci√≥n de los datos\n",
    "if df is not None:\n",
    "    # Identificar la columna objetivo (precipitaci√≥n)\n",
    "    target_column = 'total_precipitation'  # Ajustar si tiene otro nombre en tu dataset\n",
    "\n",
    "    # Ver si existe 'precip_target' o usar 'total_precipitation'\n",
    "    if 'total_precipitation' in df.columns:\n",
    "        target_column = 'total_precipitation'\n",
    "\n",
    "    print(f\"Columna objetivo identificada: {target_column}\")\n",
    "\n",
    "    # Separar variables predictoras y variable objetivo\n",
    "    feature_cols = [col for col in df.columns if col != target_column and not pd.isna(df[col]).all()]\n",
    "\n",
    "    # Eliminar columnas no num√©ricas para los modelos (como fechas o coordenadas si no se usan como features)\n",
    "    non_feature_cols = ['time', 'spatial_ref']\n",
    "    feature_cols = [col for col in feature_cols if col not in non_feature_cols]\n",
    "\n",
    "    # Eliminar filas con valores NaN\n",
    "    print(f\"Filas antes de eliminar NaN: {df.shape[0]}\")\n",
    "    df_clean = df.dropna(subset=[target_column] + feature_cols)\n",
    "    print(f\"Filas despu√©s de eliminar NaN: {df_clean.shape[0]}\")\n",
    "\n",
    "    # Separar features y target\n",
    "    X = df_clean[feature_cols]\n",
    "    y = df_clean[target_column]\n",
    "\n",
    "    print(f\"\\nFeatures seleccionadas ({len(feature_cols)}):\\n{feature_cols}\")\n",
    "    print(f\"\\nVariable objetivo: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da222af5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da222af5",
    "outputId": "579fbd57-a790-42dd-807a-e61fc1daacbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del conjunto de entrenamiento: (1735008, 12)\n",
      "Dimensiones del conjunto de prueba: (433752, 12)\n",
      "Escalador guardado en models/output/scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# 4. Divisi√≥n del conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dimensiones del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba: {X_test.shape}\")\n",
    "\n",
    "# 5. Estandarizaci√≥n de variables predictoras\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Guardar el scaler para uso futuro\n",
    "with open(model_output_dir / 'scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Escalador guardado en models/output/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5ba053b",
   "metadata": {
    "id": "c5ba053b"
   },
   "outputs": [],
   "source": [
    "# 6. Funciones de evaluaci√≥n y entrenamiento\n",
    "def evaluar_modelo(y_true, y_pred):\n",
    "    \"\"\"Eval√∫a el rendimiento de un modelo usando m√∫ltiples m√©tricas\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "def entrenar_y_evaluar_modelo(modelo, nombre, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Entrena un modelo y eval√∫a su rendimiento con visualizaci√≥n del progreso\"\"\"\n",
    "    # Crear widget para mostrar informaci√≥n del proceso\n",
    "    display(HTML(f'<div style=\"background-color:#f0f8ff; padding:10px; border-radius:5px;\">' +\n",
    "                 f'<h3>üîÑ Entrenando modelo: {nombre}</h3>' +\n",
    "                 f'<div id=\"status_{nombre}\">Estado: Iniciando entrenamiento...</div>' +\n",
    "                 f'</div>'))\n",
    "    \n",
    "    # Tiempo de inicio\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Entrenar el modelo con seguimiento visual seg√∫n el tipo\n",
    "    if hasattr(modelo, 'fit_generator') or nombre in ['XGBoost', 'XGBoost_Optuna', 'LightGBM', 'LightGBM_Optuna']:\n",
    "        # Para modelos que soportan entrenamiento por lotes como XGBoost, LightGBM\n",
    "        print(f\"Entrenando {nombre} con visualizaci√≥n de progreso...\")\n",
    "        if hasattr(modelo, 'n_estimators'):\n",
    "            n_estimators = modelo.n_estimators\n",
    "            for i in tqdm(range(n_estimators), desc=f\"Entrenando {nombre}\"):\n",
    "                if i == 0:\n",
    "                    # Primera iteraci√≥n, ajuste inicial\n",
    "                    if nombre.startswith('LightGBM'):\n",
    "                        # LightGBM tiene par√°metro verbose\n",
    "                        temp_modelo = type(modelo)(n_estimators=1, **{k:v for k,v in modelo.get_params().items() \n",
    "                                                                 if k != 'n_estimators' and k != 'verbose'}, verbose=-1)\n",
    "                    else:\n",
    "                        temp_modelo = type(modelo)(n_estimators=1, **{k:v for k,v in modelo.get_params().items() \n",
    "                                                                if k != 'n_estimators'})\n",
    "                    temp_modelo.fit(X_train, y_train)\n",
    "                elif i == n_estimators - 1:\n",
    "                    # √öltima iteraci√≥n, ajuste completo\n",
    "                    modelo.fit(X_train, y_train)\n",
    "                \n",
    "                # Actualizar progreso visual\n",
    "                if i % max(1, n_estimators // 10) == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    display(HTML(f'<div style=\"background-color:#f0f8ff; padding:10px; border-radius:5px;\">' +\n",
    "                                f'<h3>üîÑ Entrenando modelo: {nombre}</h3>' +\n",
    "                                f'<div id=\"status_{nombre}\">Estado: Progreso {i+1}/{n_estimators} estimadores ({((i+1)/n_estimators*100):.1f}%)</div>' +\n",
    "                                f'</div>'))\n",
    "                    time.sleep(0.1)  # Peque√±a pausa para actualizaci√≥n visual\n",
    "        else:\n",
    "            # Si no tiene n_estimators, entrenamiento directo\n",
    "            modelo.fit(X_train, y_train)\n",
    "    else:\n",
    "        # Para modelos est√°ndar como RandomForest\n",
    "        modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Tiempo de entrenamiento\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Visualizar tiempo de entrenamiento\n",
    "    display(HTML(f'<div style=\"background-color:#e6ffe6; padding:10px; border-radius:5px;\">' +\n",
    "                f'<h3>‚úÖ Entrenamiento completado: {nombre}</h3>' +\n",
    "                f'<div>Tiempo de entrenamiento: {training_time:.2f} segundos</div>' +\n",
    "                f'</div>'))\n",
    "    \n",
    "    print(f\"Evaluando rendimiento de {nombre}...\")\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    rmse, mae, r2 = evaluar_modelo(y_test, predicciones)\n",
    "    \n",
    "    # Visualizar m√©tricas con estilo\n",
    "    display(HTML(f'<div style=\"background-color:#f5f5dc; padding:10px; border-radius:5px; margin-top:10px;\">' +\n",
    "                f'<h3>üìä M√©tricas para {nombre}</h3>' +\n",
    "                f'<table style=\"width:100%; text-align:left;\">' +\n",
    "                f'<tr><th>M√©trica</th><th>Valor</th></tr>' +\n",
    "                f'<tr><td>RMSE</td><td>{rmse:.4f}</td></tr>' +\n",
    "                f'<tr><td>MAE</td><td>{mae:.4f}</td></tr>' +\n",
    "                f'<tr><td>R¬≤</td><td>{r2:.4f}</td></tr>' +\n",
    "                f'</table></div>'))\n",
    "    \n",
    "    return modelo, (rmse, mae, r2)\n",
    "\n",
    "def guardar_modelo(modelo, nombre):\n",
    "    \"\"\"Guarda un modelo entrenado en disco\"\"\"\n",
    "    # timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # filename = f\"{nombre}_{timestamp}.pkl\"\n",
    "    filename = f\"{nombre}.pkl\"\n",
    "    with open(model_output_dir / filename, 'wb') as f:\n",
    "        pickle.dump(modelo, f)\n",
    "    \n",
    "    # Visualizar confirmaci√≥n de guardado\n",
    "    display(HTML(f'<div style=\"background-color:#e6ffee; padding:10px; border-radius:5px; margin-top:10px;\">' +\n",
    "                f'<h3>üíæ Modelo guardado</h3>' +\n",
    "                f'<div>Modelo <b>{nombre}</b> guardado como: {filename}</div>' +\n",
    "                f'</div>'))\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e59f9865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo RandomForest encontrado en ../models/output/RandomForest.pkl. Cargando...\n",
      "‚úÖ RandomForest evaluado: RMSE=36.4174, MAE=24.8917, R2=0.9168\n",
      "Modelo XGBoost encontrado en ../models/output/XGBoost.pkl. Cargando...\n",
      "‚úÖ XGBoost evaluado: RMSE=37.8542, MAE=26.3499, R2=0.9101\n",
      "Modelo LightGBM encontrado en ../models/output/LightGBM.pkl. Cargando...\n",
      "‚úÖ RandomForest evaluado: RMSE=36.4174, MAE=24.8917, R2=0.9168\n",
      "Modelo XGBoost encontrado en ../models/output/XGBoost.pkl. Cargando...\n",
      "‚úÖ XGBoost evaluado: RMSE=37.8542, MAE=26.3499, R2=0.9101\n",
      "Modelo LightGBM encontrado en ../models/output/LightGBM.pkl. Cargando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LightGBM evaluado: RMSE=39.0589, MAE=27.3338, R2=0.9043\n",
      "\n",
      "üîç Comparaci√≥n de modelos base sin optimizaci√≥n:\n",
      "\n",
      "Ordenados por RMSE (menor es mejor):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "695dee79-49a8-453a-bac6-d40d137882d3",
       "rows": [
        [
         "RandomForest",
         "36.41736289362402",
         "24.891714593345927",
         "0.9167978029821752"
        ],
        [
         "XGBoost",
         "37.85420285553673",
         "26.349937438964844",
         "0.9101028442382812"
        ],
        [
         "LightGBM",
         "39.058929036670044",
         "27.333847085632623",
         "0.9042897459778831"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>36.417363</td>\n",
       "      <td>24.891715</td>\n",
       "      <td>0.916798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>37.854203</td>\n",
       "      <td>26.349937</td>\n",
       "      <td>0.910103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>39.058929</td>\n",
       "      <td>27.333847</td>\n",
       "      <td>0.904290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RMSE        MAE        R2\n",
       "RandomForest  36.417363  24.891715  0.916798\n",
       "XGBoost       37.854203  26.349937  0.910103\n",
       "LightGBM      39.058929  27.333847  0.904290"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/c6n8lktn4qx_fwp7ksllkkhn0dhtn2/T/ipykernel_41954/2491721647.py:68: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=temp_df.index, y=temp_df['RMSE'], palette='coolwarm')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üîÅ 1. Importaciones necesarias\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚öôÔ∏è 2. Diccionarios de almacenamiento\n",
    "resultados_base = {}\n",
    "modelos_base = {}\n",
    "modelos_guardados = {}\n",
    "\n",
    "# üìÅ 3. Rutas de modelos guardados\n",
    "cnn_model_path = model_output_dir / 'cnn_model.h5'\n",
    "convlstm_model_path = model_output_dir / 'convlstm_model.h5'\n",
    "\n",
    "model_paths = {\n",
    "    'RandomForest': model_output_dir / 'RandomForest.pkl',\n",
    "    'XGBoost': model_output_dir / 'XGBoost.pkl',\n",
    "    'LightGBM': model_output_dir / 'LightGBM.pkl',\n",
    "    'CNN': cnn_model_path,\n",
    "    'ConvLSTM': convlstm_model_path\n",
    "}\n",
    "\n",
    "# ‚úÖ 4. Carga y evaluaci√≥n de modelos\n",
    "for model_name, model_path in model_paths.items():\n",
    "    if model_path.exists():\n",
    "        print(f\"Modelo {model_name} encontrado en {model_path}. Cargando...\")\n",
    "        if model_name in ['RandomForest', 'XGBoost', 'LightGBM']:\n",
    "            with open(model_path, 'rb') as f:\n",
    "                modelo = pickle.load(f)\n",
    "                modelos_base[model_name] = modelo\n",
    "                y_pred = modelo.predict(X_test_scaled)\n",
    "        elif model_name == 'CNN':\n",
    "            cnn_model = tf.keras.models.load_model(model_path)\n",
    "            print(\"‚úÖ CNN cargado.\")\n",
    "            y_pred = cnn_model.predict(X_test_spatial).squeeze()\n",
    "        elif model_name == 'ConvLSTM':\n",
    "            convlstm_model = tf.keras.models.load_model(model_path)\n",
    "            print(\"‚úÖ ConvLSTM cargado.\")\n",
    "            y_pred = convlstm_model.predict(X_test_spatial).squeeze()\n",
    "\n",
    "        # Evaluar m√©tricas si hay predicci√≥n\n",
    "        if 'y_pred' in locals():\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            resultados_base[model_name] = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "            print(f\"‚úÖ {model_name} evaluado: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}\")\n",
    "            del y_pred\n",
    "\n",
    "# üìä 5. Visualizaci√≥n de resultados\n",
    "print(\"\\nüîç Comparaci√≥n de modelos base sin optimizaci√≥n:\")\n",
    "temp_df = pd.DataFrame(resultados_base, index=['RMSE', 'MAE', 'R2']).T\n",
    "\n",
    "# Mostrar tabla ordenada por RMSE\n",
    "print(\"\\nOrdenados por RMSE (menor es mejor):\")\n",
    "display(temp_df.sort_values('RMSE'))\n",
    "\n",
    "# Gr√°fico de comparaci√≥n de RMSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=temp_df.index, y=temp_df['RMSE'], palette='coolwarm')\n",
    "plt.title('Comparaci√≥n de RMSE - Modelos Base')\n",
    "plt.ylabel('RMSE (menor es mejor)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_output_dir / 'baseline_rmse_comparison_full.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:33:02,783] Using an existing study with name 'RandomForest_memory_optimized' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Ejecutando optimizaci√≥n para RandomForest...\n",
      "\n",
      "üìä Iniciando optimizaci√≥n adaptativa para RandomForest...\n",
      "Memoria RAM disponible: 2.68 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:34:17,036] Trial 71 finished with value: 43.0440408355221 and parameters: {'n_estimators': 236, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:35:50,192] Trial 72 finished with value: 41.654383989762835 and parameters: {'n_estimators': 283, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:35:50,192] Trial 72 finished with value: 41.654383989762835 and parameters: {'n_estimators': 283, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:36:53,665] Trial 73 finished with value: 51.355881691959375 and parameters: {'n_estimators': 278, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:36:53,665] Trial 73 finished with value: 51.355881691959375 and parameters: {'n_estimators': 278, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:38:23,684] Trial 74 finished with value: 41.64597096124543 and parameters: {'n_estimators': 273, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:38:23,684] Trial 74 finished with value: 41.64597096124543 and parameters: {'n_estimators': 273, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [RandomForest] Trials completados: 75/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:39:47,962] Trial 75 finished with value: 41.64772576154432 and parameters: {'n_estimators': 275, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:41:15,145] Trial 76 finished with value: 41.691880166992064 and parameters: {'n_estimators': 286, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:41:15,145] Trial 76 finished with value: 41.691880166992064 and parameters: {'n_estimators': 286, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:42:31,968] Trial 77 finished with value: 43.00608196630091 and parameters: {'n_estimators': 265, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:42:31,968] Trial 77 finished with value: 43.00608196630091 and parameters: {'n_estimators': 265, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:44:06,046] Trial 78 finished with value: 41.66513065078071 and parameters: {'n_estimators': 297, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:44:06,046] Trial 78 finished with value: 41.66513065078071 and parameters: {'n_estimators': 297, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:45:32,614] Trial 79 finished with value: 41.64772576154432 and parameters: {'n_estimators': 275, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:45:32,614] Trial 79 finished with value: 41.64772576154432 and parameters: {'n_estimators': 275, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [RandomForest] Trials completados: 80/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:46:54,227] Trial 80 finished with value: 43.04835989883482 and parameters: {'n_estimators': 282, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:48:19,357] Trial 81 finished with value: 41.69681251087568 and parameters: {'n_estimators': 270, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:48:19,357] Trial 81 finished with value: 41.69681251087568 and parameters: {'n_estimators': 270, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:49:30,819] Trial 82 finished with value: 43.030839861369635 and parameters: {'n_estimators': 250, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:49:30,819] Trial 82 finished with value: 43.030839861369635 and parameters: {'n_estimators': 250, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:50:57,558] Trial 83 finished with value: 41.68708476506717 and parameters: {'n_estimators': 292, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:50:57,558] Trial 83 finished with value: 41.68708476506717 and parameters: {'n_estimators': 292, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:52:15,295] Trial 84 finished with value: 42.975176982972094 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:52:15,295] Trial 84 finished with value: 42.975176982972094 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [RandomForest] Trials completados: 85/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:53:36,052] Trial 85 finished with value: 41.630928646181296 and parameters: {'n_estimators': 265, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:54:56,438] Trial 86 finished with value: 41.63236035252783 and parameters: {'n_estimators': 262, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:54:56,438] Trial 86 finished with value: 41.63236035252783 and parameters: {'n_estimators': 262, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:56:17,515] Trial 87 finished with value: 41.63168439572765 and parameters: {'n_estimators': 267, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:56:17,515] Trial 87 finished with value: 41.63168439572765 and parameters: {'n_estimators': 267, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:57:36,765] Trial 88 finished with value: 41.629667633906514 and parameters: {'n_estimators': 264, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 16:57:36,765] Trial 88 finished with value: 41.629667633906514 and parameters: {'n_estimators': 264, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 16:58:53,547] Trial 89 finished with value: 41.6719194415667 and parameters: {'n_estimators': 255, 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 16:58:53,547] Trial 89 finished with value: 41.6719194415667 and parameters: {'n_estimators': 255, 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [RandomForest] Trials completados: 90/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 17:00:16,124] Trial 90 finished with value: 41.63819224368401 and parameters: {'n_estimators': 271, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:01:52,929] Trial 91 finished with value: 43.02755147184142 and parameters: {'n_estimators': 265, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:01:52,929] Trial 91 finished with value: 43.02755147184142 and parameters: {'n_estimators': 265, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:03:13,422] Trial 92 finished with value: 41.670070498415335 and parameters: {'n_estimators': 269, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:03:13,422] Trial 92 finished with value: 41.670070498415335 and parameters: {'n_estimators': 269, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:08:03,084] Trial 93 finished with value: 41.09717031410784 and parameters: {'n_estimators': 292, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:08:03,084] Trial 93 finished with value: 41.09717031410784 and parameters: {'n_estimators': 292, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:12:57,181] Trial 94 finished with value: 41.09910965056824 and parameters: {'n_estimators': 291, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:12:57,181] Trial 94 finished with value: 41.09910965056824 and parameters: {'n_estimators': 291, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [RandomForest] Trials completados: 95/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 17:17:53,290] Trial 95 finished with value: 41.09841375209928 and parameters: {'n_estimators': 294, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:22:27,136] Trial 96 finished with value: 42.666457847822166 and parameters: {'n_estimators': 288, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:22:27,136] Trial 96 finished with value: 42.666457847822166 and parameters: {'n_estimators': 288, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:27:18,780] Trial 97 finished with value: 41.09796048819834 and parameters: {'n_estimators': 293, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:27:18,780] Trial 97 finished with value: 41.09796048819834 and parameters: {'n_estimators': 293, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:31:50,234] Trial 98 finished with value: 42.66508732314287 and parameters: {'n_estimators': 291, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:31:50,234] Trial 98 finished with value: 42.66508732314287 and parameters: {'n_estimators': 291, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:36:26,891] Trial 99 finished with value: 42.66425777061779 and parameters: {'n_estimators': 294, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:36:26,891] Trial 99 finished with value: 42.66425777061779 and parameters: {'n_estimators': 294, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [RandomForest] Trials completados: 100/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 17:41:09,715] Trial 100 finished with value: 41.10270157234539 and parameters: {'n_estimators': 282, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 18:15:57,855] Using an existing study with name 'XGBoost_memory_optimized' instead of creating a new one.\n",
      "[I 2025-04-29 18:15:57,855] Using an existing study with name 'XGBoost_memory_optimized' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ RandomForest optimizado:\n",
      "RMSE: 41.0972\n",
      "MAE: 28.4235\n",
      "R¬≤: 0.8940\n",
      "\n",
      "üöÄ Ejecutando optimizaci√≥n para XGBoost...\n",
      "\n",
      "üìä Iniciando optimizaci√≥n adaptativa para XGBoost...\n",
      "Memoria RAM disponible: 2.98 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:16:04,475] Trial 60 finished with value: 39.350894779177196 and parameters: {'n_estimators': 278, 'max_depth': 4, 'learning_rate': 0.09965645419053396, 'subsample': 0.6711679030463277, 'colsample_bytree': 0.9044181459811054, 'min_child_weight': 3, 'gamma': 2.4751802377230163}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:17,690] Trial 61 finished with value: 35.75791576754806 and parameters: {'n_estimators': 189, 'max_depth': 12, 'learning_rate': 0.05560460746814403, 'subsample': 0.6157528967223698, 'colsample_bytree': 0.9706361090180385, 'min_child_weight': 2, 'gamma': 4.795362732218826}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:17,690] Trial 61 finished with value: 35.75791576754806 and parameters: {'n_estimators': 189, 'max_depth': 12, 'learning_rate': 0.05560460746814403, 'subsample': 0.6157528967223698, 'colsample_bytree': 0.9706361090180385, 'min_child_weight': 2, 'gamma': 4.795362732218826}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:31,165] Trial 62 finished with value: 35.795111943706786 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.06776939940548235, 'subsample': 0.6081970709148381, 'colsample_bytree': 0.9827617835027945, 'min_child_weight': 1, 'gamma': 4.742136855991785}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:31,165] Trial 62 finished with value: 35.795111943706786 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.06776939940548235, 'subsample': 0.6081970709148381, 'colsample_bytree': 0.9827617835027945, 'min_child_weight': 1, 'gamma': 4.742136855991785}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:46,070] Trial 63 finished with value: 35.75274348902735 and parameters: {'n_estimators': 207, 'max_depth': 12, 'learning_rate': 0.04764763125268048, 'subsample': 0.5953512532391368, 'colsample_bytree': 0.9613507776391274, 'min_child_weight': 3, 'gamma': 4.074784414355741}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:46,070] Trial 63 finished with value: 35.75274348902735 and parameters: {'n_estimators': 207, 'max_depth': 12, 'learning_rate': 0.04764763125268048, 'subsample': 0.5953512532391368, 'colsample_bytree': 0.9613507776391274, 'min_child_weight': 3, 'gamma': 4.074784414355741}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:58,667] Trial 64 finished with value: 35.80188235656664 and parameters: {'n_estimators': 185, 'max_depth': 12, 'learning_rate': 0.05965706897677661, 'subsample': 0.5821045739428595, 'colsample_bytree': 0.9328178199742988, 'min_child_weight': 3, 'gamma': 4.991950027088655}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:58,667] Trial 64 finished with value: 35.80188235656664 and parameters: {'n_estimators': 185, 'max_depth': 12, 'learning_rate': 0.05965706897677661, 'subsample': 0.5821045739428595, 'colsample_bytree': 0.9328178199742988, 'min_child_weight': 3, 'gamma': 4.991950027088655}. Best is trial 22 with value: 35.711163960942415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [XGBoost] Trials completados: 65/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:17:12,363] Trial 65 finished with value: 35.93389418051657 and parameters: {'n_estimators': 246, 'max_depth': 11, 'learning_rate': 0.042380034888878704, 'subsample': 0.634546770187394, 'colsample_bytree': 0.9868323406552163, 'min_child_weight': 2, 'gamma': 3.529303523512869}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:27,468] Trial 66 finished with value: 35.7568318701563 and parameters: {'n_estimators': 233, 'max_depth': 12, 'learning_rate': 0.05218237651264639, 'subsample': 0.5661149485002318, 'colsample_bytree': 0.9439404052896394, 'min_child_weight': 4, 'gamma': 4.661850070951837}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:27,468] Trial 66 finished with value: 35.7568318701563 and parameters: {'n_estimators': 233, 'max_depth': 12, 'learning_rate': 0.05218237651264639, 'subsample': 0.5661149485002318, 'colsample_bytree': 0.9439404052896394, 'min_child_weight': 4, 'gamma': 4.661850070951837}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:37,743] Trial 67 finished with value: 35.935810082549445 and parameters: {'n_estimators': 178, 'max_depth': 11, 'learning_rate': 0.0725036052194289, 'subsample': 0.665286959871946, 'colsample_bytree': 0.923743547421571, 'min_child_weight': 5, 'gamma': 4.405657774993751}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:37,743] Trial 67 finished with value: 35.935810082549445 and parameters: {'n_estimators': 178, 'max_depth': 11, 'learning_rate': 0.0725036052194289, 'subsample': 0.665286959871946, 'colsample_bytree': 0.923743547421571, 'min_child_weight': 5, 'gamma': 4.405657774993751}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:49,391] Trial 68 finished with value: 35.783349760987825 and parameters: {'n_estimators': 156, 'max_depth': 12, 'learning_rate': 0.06042582462646498, 'subsample': 0.6470507236624621, 'colsample_bytree': 0.9656870757571148, 'min_child_weight': 1, 'gamma': 4.882247254549063}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:49,391] Trial 68 finished with value: 35.783349760987825 and parameters: {'n_estimators': 156, 'max_depth': 12, 'learning_rate': 0.06042582462646498, 'subsample': 0.6470507236624621, 'colsample_bytree': 0.9656870757571148, 'min_child_weight': 1, 'gamma': 4.882247254549063}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:02,154] Trial 69 finished with value: 36.20294797917447 and parameters: {'n_estimators': 196, 'max_depth': 11, 'learning_rate': 0.037695739036660555, 'subsample': 0.6545199299049221, 'colsample_bytree': 0.8622852986561991, 'min_child_weight': 2, 'gamma': 3.9140976084054904}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:02,154] Trial 69 finished with value: 36.20294797917447 and parameters: {'n_estimators': 196, 'max_depth': 11, 'learning_rate': 0.037695739036660555, 'subsample': 0.6545199299049221, 'colsample_bytree': 0.8622852986561991, 'min_child_weight': 2, 'gamma': 3.9140976084054904}. Best is trial 22 with value: 35.711163960942415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [XGBoost] Trials completados: 70/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:18:08,251] Trial 70 finished with value: 36.29877006191549 and parameters: {'n_estimators': 60, 'max_depth': 12, 'learning_rate': 0.07978866991243412, 'subsample': 0.6204252253199223, 'colsample_bytree': 0.9458081925372654, 'min_child_weight': 3, 'gamma': 4.230545493841141}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:25,009] Trial 71 finished with value: 35.74243083933558 and parameters: {'n_estimators': 237, 'max_depth': 12, 'learning_rate': 0.04515644294615783, 'subsample': 0.5798589296637613, 'colsample_bytree': 0.9285770570455675, 'min_child_weight': 10, 'gamma': 4.274402251955779}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:25,009] Trial 71 finished with value: 35.74243083933558 and parameters: {'n_estimators': 237, 'max_depth': 12, 'learning_rate': 0.04515644294615783, 'subsample': 0.5798589296637613, 'colsample_bytree': 0.9285770570455675, 'min_child_weight': 10, 'gamma': 4.274402251955779}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:40,230] Trial 72 finished with value: 35.74070266724533 and parameters: {'n_estimators': 221, 'max_depth': 12, 'learning_rate': 0.043439758875546346, 'subsample': 0.5958731143843986, 'colsample_bytree': 0.9997170618607031, 'min_child_weight': 10, 'gamma': 4.466800084999603}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:40,230] Trial 72 finished with value: 35.74070266724533 and parameters: {'n_estimators': 221, 'max_depth': 12, 'learning_rate': 0.043439758875546346, 'subsample': 0.5958731143843986, 'colsample_bytree': 0.9997170618607031, 'min_child_weight': 10, 'gamma': 4.466800084999603}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:56,545] Trial 73 finished with value: 35.728982362559144 and parameters: {'n_estimators': 238, 'max_depth': 12, 'learning_rate': 0.04364595907457629, 'subsample': 0.5908223888396833, 'colsample_bytree': 0.9960436440079988, 'min_child_weight': 10, 'gamma': 3.287696253530477}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:56,545] Trial 73 finished with value: 35.728982362559144 and parameters: {'n_estimators': 238, 'max_depth': 12, 'learning_rate': 0.04364595907457629, 'subsample': 0.5908223888396833, 'colsample_bytree': 0.9960436440079988, 'min_child_weight': 10, 'gamma': 3.287696253530477}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:19:10,933] Trial 74 finished with value: 36.33536722165902 and parameters: {'n_estimators': 222, 'max_depth': 11, 'learning_rate': 0.02603524973787783, 'subsample': 0.594055874615617, 'colsample_bytree': 0.9975790178469592, 'min_child_weight': 9, 'gamma': 3.3362307724595763}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:19:10,933] Trial 74 finished with value: 36.33536722165902 and parameters: {'n_estimators': 222, 'max_depth': 11, 'learning_rate': 0.02603524973787783, 'subsample': 0.594055874615617, 'colsample_bytree': 0.9975790178469592, 'min_child_weight': 9, 'gamma': 3.3362307724595763}. Best is trial 22 with value: 35.711163960942415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [XGBoost] Trials completados: 75/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:19:28,279] Trial 75 finished with value: 35.73431863517636 and parameters: {'n_estimators': 248, 'max_depth': 12, 'learning_rate': 0.03550587326367754, 'subsample': 0.5853810740267053, 'colsample_bytree': 0.9848024319125552, 'min_child_weight': 10, 'gamma': 3.2196387008894387}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:19:42,961] Trial 76 finished with value: 36.00257186179985 and parameters: {'n_estimators': 252, 'max_depth': 11, 'learning_rate': 0.034998807001642256, 'subsample': 0.5675217142538795, 'colsample_bytree': 0.9851899024509025, 'min_child_weight': 9, 'gamma': 3.093088683386659}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:19:42,961] Trial 76 finished with value: 36.00257186179985 and parameters: {'n_estimators': 252, 'max_depth': 11, 'learning_rate': 0.034998807001642256, 'subsample': 0.5675217142538795, 'colsample_bytree': 0.9851899024509025, 'min_child_weight': 9, 'gamma': 3.093088683386659}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:03,057] Trial 77 finished with value: 35.78028621791527 and parameters: {'n_estimators': 260, 'max_depth': 12, 'learning_rate': 0.029333135537184613, 'subsample': 0.584998640954983, 'colsample_bytree': 0.9630554414357289, 'min_child_weight': 9, 'gamma': 3.1819780642067585}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:03,057] Trial 77 finished with value: 35.78028621791527 and parameters: {'n_estimators': 260, 'max_depth': 12, 'learning_rate': 0.029333135537184613, 'subsample': 0.584998640954983, 'colsample_bytree': 0.9630554414357289, 'min_child_weight': 9, 'gamma': 3.1819780642067585}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:17,526] Trial 78 finished with value: 35.720880773606176 and parameters: {'n_estimators': 244, 'max_depth': 12, 'learning_rate': 0.06946592839415004, 'subsample': 0.6837612973061943, 'colsample_bytree': 0.951603281558706, 'min_child_weight': 10, 'gamma': 3.6898027690721156}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:17,526] Trial 78 finished with value: 35.720880773606176 and parameters: {'n_estimators': 244, 'max_depth': 12, 'learning_rate': 0.06946592839415004, 'subsample': 0.6837612973061943, 'colsample_bytree': 0.951603281558706, 'min_child_weight': 10, 'gamma': 3.6898027690721156}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:28,340] Trial 79 finished with value: 36.10057091935147 and parameters: {'n_estimators': 228, 'max_depth': 10, 'learning_rate': 0.07113410880752633, 'subsample': 0.684907993984314, 'colsample_bytree': 0.9832355778237944, 'min_child_weight': 10, 'gamma': 3.276513093373638}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:28,340] Trial 79 finished with value: 36.10057091935147 and parameters: {'n_estimators': 228, 'max_depth': 10, 'learning_rate': 0.07113410880752633, 'subsample': 0.684907993984314, 'colsample_bytree': 0.9832355778237944, 'min_child_weight': 10, 'gamma': 3.276513093373638}. Best is trial 22 with value: 35.711163960942415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [XGBoost] Trials completados: 80/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:20:45,812] Trial 80 finished with value: 36.342193176565615 and parameters: {'n_estimators': 246, 'max_depth': 11, 'learning_rate': 0.0222884772088816, 'subsample': 0.6932643683811397, 'colsample_bytree': 0.9526654313936672, 'min_child_weight': 8, 'gamma': 3.6105962388974575}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:58,031] Trial 81 finished with value: 38.18438478240729 and parameters: {'n_estimators': 240, 'max_depth': 12, 'learning_rate': 0.2909337937359037, 'subsample': 0.5878028466351641, 'colsample_bytree': 0.9061703640467523, 'min_child_weight': 10, 'gamma': 3.0007930472949615}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:58,031] Trial 81 finished with value: 38.18438478240729 and parameters: {'n_estimators': 240, 'max_depth': 12, 'learning_rate': 0.2909337937359037, 'subsample': 0.5878028466351641, 'colsample_bytree': 0.9061703640467523, 'min_child_weight': 10, 'gamma': 3.0007930472949615}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:21:11,394] Trial 82 finished with value: 35.73569527786171 and parameters: {'n_estimators': 215, 'max_depth': 12, 'learning_rate': 0.06497049816178255, 'subsample': 0.6698872035595534, 'colsample_bytree': 0.940993716773699, 'min_child_weight': 10, 'gamma': 3.496097852506801}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:21:11,394] Trial 82 finished with value: 35.73569527786171 and parameters: {'n_estimators': 215, 'max_depth': 12, 'learning_rate': 0.06497049816178255, 'subsample': 0.6698872035595534, 'colsample_bytree': 0.940993716773699, 'min_child_weight': 10, 'gamma': 3.496097852506801}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:21:27,955] Trial 83 finished with value: 35.68340538572342 and parameters: {'n_estimators': 249, 'max_depth': 12, 'learning_rate': 0.05044482284440222, 'subsample': 0.6759914585271085, 'colsample_bytree': 0.9555247021543137, 'min_child_weight': 9, 'gamma': 2.6951144283440804}. Best is trial 83 with value: 35.68340538572342.\n",
      "[I 2025-04-29 18:21:27,955] Trial 83 finished with value: 35.68340538572342 and parameters: {'n_estimators': 249, 'max_depth': 12, 'learning_rate': 0.05044482284440222, 'subsample': 0.6759914585271085, 'colsample_bytree': 0.9555247021543137, 'min_child_weight': 9, 'gamma': 2.6951144283440804}. Best is trial 83 with value: 35.68340538572342.\n",
      "[I 2025-04-29 18:21:46,148] Trial 84 finished with value: 35.69708817946063 and parameters: {'n_estimators': 264, 'max_depth': 12, 'learning_rate': 0.04958167858695335, 'subsample': 0.6760234407193454, 'colsample_bytree': 0.9778596004064802, 'min_child_weight': 9, 'gamma': 2.5286783378423427}. Best is trial 83 with value: 35.68340538572342.\n",
      "[I 2025-04-29 18:21:46,148] Trial 84 finished with value: 35.69708817946063 and parameters: {'n_estimators': 264, 'max_depth': 12, 'learning_rate': 0.04958167858695335, 'subsample': 0.6760234407193454, 'colsample_bytree': 0.9778596004064802, 'min_child_weight': 9, 'gamma': 2.5286783378423427}. Best is trial 83 with value: 35.68340538572342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [XGBoost] Trials completados: 85/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:22:05,241] Trial 85 finished with value: 35.65736947738679 and parameters: {'n_estimators': 278, 'max_depth': 12, 'learning_rate': 0.039820465006311104, 'subsample': 0.6851098826016436, 'colsample_bytree': 0.9806212460161695, 'min_child_weight': 9, 'gamma': 2.396802314871436}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:20,476] Trial 86 finished with value: 35.848257059161014 and parameters: {'n_estimators': 284, 'max_depth': 11, 'learning_rate': 0.05007009745059281, 'subsample': 0.6834848267189058, 'colsample_bytree': 0.9565882330975652, 'min_child_weight': 9, 'gamma': 2.058496403793079}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:20,476] Trial 86 finished with value: 35.848257059161014 and parameters: {'n_estimators': 284, 'max_depth': 11, 'learning_rate': 0.05007009745059281, 'subsample': 0.6834848267189058, 'colsample_bytree': 0.9565882330975652, 'min_child_weight': 9, 'gamma': 2.058496403793079}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:37,958] Trial 87 finished with value: 35.678097423239755 and parameters: {'n_estimators': 298, 'max_depth': 12, 'learning_rate': 0.05745403023060766, 'subsample': 0.6957296446891053, 'colsample_bytree': 0.9761923562099223, 'min_child_weight': 9, 'gamma': 2.4653015252914754}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:37,958] Trial 87 finished with value: 35.678097423239755 and parameters: {'n_estimators': 298, 'max_depth': 12, 'learning_rate': 0.05745403023060766, 'subsample': 0.6957296446891053, 'colsample_bytree': 0.9761923562099223, 'min_child_weight': 9, 'gamma': 2.4653015252914754}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:57,951] Trial 88 finished with value: 36.46297887069843 and parameters: {'n_estimators': 296, 'max_depth': 11, 'learning_rate': 0.016827752123288398, 'subsample': 0.675343374267482, 'colsample_bytree': 0.9740057447685834, 'min_child_weight': 9, 'gamma': 2.3538163419774913}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:57,951] Trial 88 finished with value: 36.46297887069843 and parameters: {'n_estimators': 296, 'max_depth': 11, 'learning_rate': 0.016827752123288398, 'subsample': 0.675343374267482, 'colsample_bytree': 0.9740057447685834, 'min_child_weight': 9, 'gamma': 2.3538163419774913}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:23:05,793] Trial 89 finished with value: 39.495589770607616 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03930649309648896, 'subsample': 0.6951847422318385, 'colsample_bytree': 0.9881318663772927, 'min_child_weight': 8, 'gamma': 2.5592011153426517}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:23:05,793] Trial 89 finished with value: 39.495589770607616 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03930649309648896, 'subsample': 0.6951847422318385, 'colsample_bytree': 0.9881318663772927, 'min_child_weight': 8, 'gamma': 2.5592011153426517}. Best is trial 85 with value: 35.65736947738679.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [XGBoost] Trials completados: 90/30\n",
      "\n",
      "‚úÖ XGBoost optimizado:\n",
      "RMSE: 35.6574\n",
      "MAE: 24.4894\n",
      "R¬≤: 0.9202\n",
      "\n",
      "‚úÖ XGBoost optimizado:\n",
      "RMSE: 35.6574\n",
      "MAE: 24.4894\n",
      "R¬≤: 0.9202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:23:26,252] Using an existing study with name 'LightGBM_memory_optimized' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Ejecutando optimizaci√≥n para LightGBM...\n",
      "\n",
      "üìä Iniciando optimizaci√≥n adaptativa para LightGBM...\n",
      "Memoria RAM disponible: 2.53 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:35,991] Trial 30 finished with value: 39.346963352381465 and parameters: {'n_estimators': 264, 'max_depth': 11, 'learning_rate': 0.030730292125606733, 'subsample': 0.6388874218385346, 'colsample_bytree': 0.7249078901559086, 'min_child_samples': 75, 'reg_alpha': 0.5606647973347033, 'reg_lambda': 0.31039256966243556}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:35,991] Trial 30 finished with value: 39.346963352381465 and parameters: {'n_estimators': 264, 'max_depth': 11, 'learning_rate': 0.030730292125606733, 'subsample': 0.6388874218385346, 'colsample_bytree': 0.7249078901559086, 'min_child_samples': 75, 'reg_alpha': 0.5606647973347033, 'reg_lambda': 0.31039256966243556}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:40,629] Trial 31 finished with value: 37.793341202883745 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.21490094613315583, 'subsample': 0.611704946155858, 'colsample_bytree': 0.7840039642440151, 'min_child_samples': 100, 'reg_alpha': 0.4818963296633298, 'reg_lambda': 0.5183100958505646}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:40,629] Trial 31 finished with value: 37.793341202883745 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.21490094613315583, 'subsample': 0.611704946155858, 'colsample_bytree': 0.7840039642440151, 'min_child_samples': 100, 'reg_alpha': 0.4818963296633298, 'reg_lambda': 0.5183100958505646}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:43,902] Trial 32 finished with value: 38.03928961725169 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.2339317086540356, 'subsample': 0.5818221049056246, 'colsample_bytree': 0.8230600338772611, 'min_child_samples': 87, 'reg_alpha': 0.36727369990139574, 'reg_lambda': 0.27448497328248095}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:43,902] Trial 32 finished with value: 38.03928961725169 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.2339317086540356, 'subsample': 0.5818221049056246, 'colsample_bytree': 0.8230600338772611, 'min_child_samples': 87, 'reg_alpha': 0.36727369990139574, 'reg_lambda': 0.27448497328248095}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:49,426] Trial 33 finished with value: 37.86421096993678 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.1381126935879355, 'subsample': 0.608695743656408, 'colsample_bytree': 0.7758820089953998, 'min_child_samples': 87, 'reg_alpha': 0.5013117800345992, 'reg_lambda': 0.4169246083275006}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:49,426] Trial 33 finished with value: 37.86421096993678 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.1381126935879355, 'subsample': 0.608695743656408, 'colsample_bytree': 0.7758820089953998, 'min_child_samples': 87, 'reg_alpha': 0.5013117800345992, 'reg_lambda': 0.4169246083275006}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:53,190] Trial 34 finished with value: 37.73340463406887 and parameters: {'n_estimators': 159, 'max_depth': 8, 'learning_rate': 0.2980910093494307, 'subsample': 0.5501014280277093, 'colsample_bytree': 0.8689105872525069, 'min_child_samples': 75, 'reg_alpha': 0.3155468145928801, 'reg_lambda': 0.6528078838383202}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:53,190] Trial 34 finished with value: 37.73340463406887 and parameters: {'n_estimators': 159, 'max_depth': 8, 'learning_rate': 0.2980910093494307, 'subsample': 0.5501014280277093, 'colsample_bytree': 0.8689105872525069, 'min_child_samples': 75, 'reg_alpha': 0.3155468145928801, 'reg_lambda': 0.6528078838383202}. Best is trial 28 with value: 37.34593941374425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [LightGBM] Trials completados: 35/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:58,440] Trial 35 finished with value: 37.71705705316589 and parameters: {'n_estimators': 237, 'max_depth': 10, 'learning_rate': 0.18188215906458088, 'subsample': 0.5965280731754736, 'colsample_bytree': 0.7304453570550351, 'min_child_samples': 96, 'reg_alpha': 0.5795660494660648, 'reg_lambda': 0.06150172334536236}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:58,440] Trial 35 finished with value: 37.71705705316589 and parameters: {'n_estimators': 237, 'max_depth': 10, 'learning_rate': 0.18188215906458088, 'subsample': 0.5965280731754736, 'colsample_bytree': 0.7304453570550351, 'min_child_samples': 96, 'reg_alpha': 0.5795660494660648, 'reg_lambda': 0.06150172334536236}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:04,827] Trial 36 finished with value: 38.42329485569517 and parameters: {'n_estimators': 193, 'max_depth': 12, 'learning_rate': 0.08201683111519001, 'subsample': 0.6330518358093288, 'colsample_bytree': 0.8072100436515645, 'min_child_samples': 58, 'reg_alpha': 0.6592500368269296, 'reg_lambda': 0.5612378395588242}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:04,827] Trial 36 finished with value: 38.42329485569517 and parameters: {'n_estimators': 193, 'max_depth': 12, 'learning_rate': 0.08201683111519001, 'subsample': 0.6330518358093288, 'colsample_bytree': 0.8072100436515645, 'min_child_samples': 58, 'reg_alpha': 0.6592500368269296, 'reg_lambda': 0.5612378395588242}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:12,114] Trial 37 finished with value: 38.60008123864629 and parameters: {'n_estimators': 260, 'max_depth': 10, 'learning_rate': 0.0507933148714028, 'subsample': 0.6818604445268122, 'colsample_bytree': 0.9379188944325803, 'min_child_samples': 86, 'reg_alpha': 0.39558650642564963, 'reg_lambda': 0.2365276257207428}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:12,114] Trial 37 finished with value: 38.60008123864629 and parameters: {'n_estimators': 260, 'max_depth': 10, 'learning_rate': 0.0507933148714028, 'subsample': 0.6818604445268122, 'colsample_bytree': 0.9379188944325803, 'min_child_samples': 86, 'reg_alpha': 0.39558650642564963, 'reg_lambda': 0.2365276257207428}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:15,521] Trial 38 finished with value: 38.015780525623484 and parameters: {'n_estimators': 136, 'max_depth': 8, 'learning_rate': 0.2489885482679734, 'subsample': 0.6116685568972761, 'colsample_bytree': 0.7947059747312301, 'min_child_samples': 72, 'reg_alpha': 0.256706938969428, 'reg_lambda': 0.39683899908068127}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:15,521] Trial 38 finished with value: 38.015780525623484 and parameters: {'n_estimators': 136, 'max_depth': 8, 'learning_rate': 0.2489885482679734, 'subsample': 0.6116685568972761, 'colsample_bytree': 0.7947059747312301, 'min_child_samples': 72, 'reg_alpha': 0.256706938969428, 'reg_lambda': 0.39683899908068127}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:18,723] Trial 39 finished with value: 38.60497346459299 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.1952593962966629, 'subsample': 0.5504521701520809, 'colsample_bytree': 0.6931720150087146, 'min_child_samples': 82, 'reg_alpha': 0.7036637835943387, 'reg_lambda': 0.48284864646139214}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:18,723] Trial 39 finished with value: 38.60497346459299 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.1952593962966629, 'subsample': 0.5504521701520809, 'colsample_bytree': 0.6931720150087146, 'min_child_samples': 82, 'reg_alpha': 0.7036637835943387, 'reg_lambda': 0.48284864646139214}. Best is trial 28 with value: 37.34593941374425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [LightGBM] Trials completados: 40/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:22,769] Trial 40 finished with value: 37.406313496849414 and parameters: {'n_estimators': 212, 'max_depth': 11, 'learning_rate': 0.2564730232409371, 'subsample': 0.5827193516669354, 'colsample_bytree': 0.9956385980717999, 'min_child_samples': 94, 'reg_alpha': 0.8561476253366959, 'reg_lambda': 0.6195514196763037}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:22,769] Trial 40 finished with value: 37.406313496849414 and parameters: {'n_estimators': 212, 'max_depth': 11, 'learning_rate': 0.2564730232409371, 'subsample': 0.5827193516669354, 'colsample_bytree': 0.9956385980717999, 'min_child_samples': 94, 'reg_alpha': 0.8561476253366959, 'reg_lambda': 0.6195514196763037}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:26,311] Trial 41 finished with value: 37.53840740542601 and parameters: {'n_estimators': 176, 'max_depth': 11, 'learning_rate': 0.25392144116721577, 'subsample': 0.5880941012479235, 'colsample_bytree': 0.9981126922026227, 'min_child_samples': 95, 'reg_alpha': 0.8916418092084106, 'reg_lambda': 0.6899747107475411}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:26,311] Trial 41 finished with value: 37.53840740542601 and parameters: {'n_estimators': 176, 'max_depth': 11, 'learning_rate': 0.25392144116721577, 'subsample': 0.5880941012479235, 'colsample_bytree': 0.9981126922026227, 'min_child_samples': 95, 'reg_alpha': 0.8916418092084106, 'reg_lambda': 0.6899747107475411}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:31,141] Trial 42 finished with value: 37.65438101325667 and parameters: {'n_estimators': 212, 'max_depth': 11, 'learning_rate': 0.15682664235498858, 'subsample': 0.5822830169629756, 'colsample_bytree': 0.9957609342277367, 'min_child_samples': 93, 'reg_alpha': 0.8741516408421189, 'reg_lambda': 0.7002878332497946}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:31,141] Trial 42 finished with value: 37.65438101325667 and parameters: {'n_estimators': 212, 'max_depth': 11, 'learning_rate': 0.15682664235498858, 'subsample': 0.5822830169629756, 'colsample_bytree': 0.9957609342277367, 'min_child_samples': 93, 'reg_alpha': 0.8741516408421189, 'reg_lambda': 0.7002878332497946}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:36,556] Trial 43 finished with value: 37.61955339762543 and parameters: {'n_estimators': 183, 'max_depth': 12, 'learning_rate': 0.22236033567090766, 'subsample': 0.5774315275203007, 'colsample_bytree': 0.9627992617292189, 'min_child_samples': 96, 'reg_alpha': 0.9639498604994475, 'reg_lambda': 0.5400292943033523}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:36,556] Trial 43 finished with value: 37.61955339762543 and parameters: {'n_estimators': 183, 'max_depth': 12, 'learning_rate': 0.22236033567090766, 'subsample': 0.5774315275203007, 'colsample_bytree': 0.9627992617292189, 'min_child_samples': 96, 'reg_alpha': 0.9639498604994475, 'reg_lambda': 0.5400292943033523}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:40,724] Trial 44 finished with value: 37.57206803551958 and parameters: {'n_estimators': 184, 'max_depth': 12, 'learning_rate': 0.24144941689016675, 'subsample': 0.5535466512110425, 'colsample_bytree': 0.9609057029928285, 'min_child_samples': 96, 'reg_alpha': 0.9658374309543468, 'reg_lambda': 0.772774605551797}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:40,724] Trial 44 finished with value: 37.57206803551958 and parameters: {'n_estimators': 184, 'max_depth': 12, 'learning_rate': 0.24144941689016675, 'subsample': 0.5535466512110425, 'colsample_bytree': 0.9609057029928285, 'min_child_samples': 96, 'reg_alpha': 0.9658374309543468, 'reg_lambda': 0.772774605551797}. Best is trial 28 with value: 37.34593941374425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [LightGBM] Trials completados: 45/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:44,321] Trial 45 finished with value: 37.72344154662176 and parameters: {'n_estimators': 155, 'max_depth': 12, 'learning_rate': 0.2530776546075986, 'subsample': 0.5595842637629191, 'colsample_bytree': 0.9895543668226564, 'min_child_samples': 96, 'reg_alpha': 0.876341014048042, 'reg_lambda': 0.8899315843787003}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:44,321] Trial 45 finished with value: 37.72344154662176 and parameters: {'n_estimators': 155, 'max_depth': 12, 'learning_rate': 0.2530776546075986, 'subsample': 0.5595842637629191, 'colsample_bytree': 0.9895543668226564, 'min_child_samples': 96, 'reg_alpha': 0.876341014048042, 'reg_lambda': 0.8899315843787003}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:51,457] Trial 46 finished with value: 38.01096833450631 and parameters: {'n_estimators': 198, 'max_depth': 11, 'learning_rate': 0.11591311319145577, 'subsample': 0.5482779848156909, 'colsample_bytree': 0.9505894682740698, 'min_child_samples': 100, 'reg_alpha': 0.9258528120040186, 'reg_lambda': 0.7677445923528958}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:51,457] Trial 46 finished with value: 38.01096833450631 and parameters: {'n_estimators': 198, 'max_depth': 11, 'learning_rate': 0.11591311319145577, 'subsample': 0.5482779848156909, 'colsample_bytree': 0.9505894682740698, 'min_child_samples': 100, 'reg_alpha': 0.9258528120040186, 'reg_lambda': 0.7677445923528958}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:55,194] Trial 47 finished with value: 38.22070582246875 and parameters: {'n_estimators': 143, 'max_depth': 12, 'learning_rate': 0.15183422653050682, 'subsample': 0.5192089324839947, 'colsample_bytree': 0.9145942595193255, 'min_child_samples': 89, 'reg_alpha': 0.8704405798563677, 'reg_lambda': 0.8074778058983992}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:55,194] Trial 47 finished with value: 38.22070582246875 and parameters: {'n_estimators': 143, 'max_depth': 12, 'learning_rate': 0.15183422653050682, 'subsample': 0.5192089324839947, 'colsample_bytree': 0.9145942595193255, 'min_child_samples': 89, 'reg_alpha': 0.8704405798563677, 'reg_lambda': 0.8074778058983992}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:01,093] Trial 48 finished with value: 37.11077711702346 and parameters: {'n_estimators': 280, 'max_depth': 11, 'learning_rate': 0.26056382367357184, 'subsample': 0.6699101334644922, 'colsample_bytree': 0.9772010883647662, 'min_child_samples': 93, 'reg_alpha': 0.8133003553542224, 'reg_lambda': 0.7155782928888794}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:01,093] Trial 48 finished with value: 37.11077711702346 and parameters: {'n_estimators': 280, 'max_depth': 11, 'learning_rate': 0.26056382367357184, 'subsample': 0.6699101334644922, 'colsample_bytree': 0.9772010883647662, 'min_child_samples': 93, 'reg_alpha': 0.8133003553542224, 'reg_lambda': 0.7155782928888794}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:09,769] Trial 49 finished with value: 39.538676424442045 and parameters: {'n_estimators': 285, 'max_depth': 11, 'learning_rate': 0.0261891307455606, 'subsample': 0.6729100738537408, 'colsample_bytree': 0.9283598067504141, 'min_child_samples': 5, 'reg_alpha': 0.795444474477224, 'reg_lambda': 0.7033544280431728}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:09,769] Trial 49 finished with value: 39.538676424442045 and parameters: {'n_estimators': 285, 'max_depth': 11, 'learning_rate': 0.0261891307455606, 'subsample': 0.6729100738537408, 'colsample_bytree': 0.9283598067504141, 'min_child_samples': 5, 'reg_alpha': 0.795444474477224, 'reg_lambda': 0.7033544280431728}. Best is trial 48 with value: 37.11077711702346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [LightGBM] Trials completados: 50/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:16,729] Trial 50 finished with value: 37.82833306131848 and parameters: {'n_estimators': 275, 'max_depth': 11, 'learning_rate': 0.09786691390401238, 'subsample': 0.6485689141374892, 'colsample_bytree': 0.8940592932171196, 'min_child_samples': 26, 'reg_alpha': 0.8116885110866364, 'reg_lambda': 0.46400922155888225}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:16,729] Trial 50 finished with value: 37.82833306131848 and parameters: {'n_estimators': 275, 'max_depth': 11, 'learning_rate': 0.09786691390401238, 'subsample': 0.6485689141374892, 'colsample_bytree': 0.8940592932171196, 'min_child_samples': 26, 'reg_alpha': 0.8116885110866364, 'reg_lambda': 0.46400922155888225}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:22,257] Trial 51 finished with value: 37.26128108154203 and parameters: {'n_estimators': 255, 'max_depth': 11, 'learning_rate': 0.24798332552298202, 'subsample': 0.6636729066697132, 'colsample_bytree': 0.9755672122133138, 'min_child_samples': 93, 'reg_alpha': 0.9131181055691796, 'reg_lambda': 0.621329938583348}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:22,257] Trial 51 finished with value: 37.26128108154203 and parameters: {'n_estimators': 255, 'max_depth': 11, 'learning_rate': 0.24798332552298202, 'subsample': 0.6636729066697132, 'colsample_bytree': 0.9755672122133138, 'min_child_samples': 93, 'reg_alpha': 0.9131181055691796, 'reg_lambda': 0.621329938583348}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:28,378] Trial 52 finished with value: 37.218773890129945 and parameters: {'n_estimators': 257, 'max_depth': 11, 'learning_rate': 0.2561577122639253, 'subsample': 0.6659782978957755, 'colsample_bytree': 0.9847147617209204, 'min_child_samples': 91, 'reg_alpha': 0.7550822405145999, 'reg_lambda': 0.6796769065229676}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:28,378] Trial 52 finished with value: 37.218773890129945 and parameters: {'n_estimators': 257, 'max_depth': 11, 'learning_rate': 0.2561577122639253, 'subsample': 0.6659782978957755, 'colsample_bytree': 0.9847147617209204, 'min_child_samples': 91, 'reg_alpha': 0.7550822405145999, 'reg_lambda': 0.6796769065229676}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:33,089] Trial 53 finished with value: 37.43684250151292 and parameters: {'n_estimators': 254, 'max_depth': 10, 'learning_rate': 0.18469963077123455, 'subsample': 0.6647100841039998, 'colsample_bytree': 0.9787993398958806, 'min_child_samples': 90, 'reg_alpha': 0.7543131599868798, 'reg_lambda': 0.6094880396886312}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:33,089] Trial 53 finished with value: 37.43684250151292 and parameters: {'n_estimators': 254, 'max_depth': 10, 'learning_rate': 0.18469963077123455, 'subsample': 0.6647100841039998, 'colsample_bytree': 0.9787993398958806, 'min_child_samples': 90, 'reg_alpha': 0.7543131599868798, 'reg_lambda': 0.6094880396886312}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:37,649] Trial 54 finished with value: 37.406646030399614 and parameters: {'n_estimators': 257, 'max_depth': 10, 'learning_rate': 0.18657516049282813, 'subsample': 0.6997851907775049, 'colsample_bytree': 0.9749099992212265, 'min_child_samples': 90, 'reg_alpha': 0.7518624457311625, 'reg_lambda': 0.626943507027824}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:37,649] Trial 54 finished with value: 37.406646030399614 and parameters: {'n_estimators': 257, 'max_depth': 10, 'learning_rate': 0.18657516049282813, 'subsample': 0.6997851907775049, 'colsample_bytree': 0.9749099992212265, 'min_child_samples': 90, 'reg_alpha': 0.7518624457311625, 'reg_lambda': 0.626943507027824}. Best is trial 48 with value: 37.11077711702346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [LightGBM] Trials completados: 55/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:42,599] Trial 55 finished with value: 37.385937843327525 and parameters: {'n_estimators': 283, 'max_depth': 11, 'learning_rate': 0.1588812395864361, 'subsample': 0.6998177129720142, 'colsample_bytree': 0.9760117343443714, 'min_child_samples': 86, 'reg_alpha': 0.8338821359211896, 'reg_lambda': 0.7384309113212614}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:42,599] Trial 55 finished with value: 37.385937843327525 and parameters: {'n_estimators': 283, 'max_depth': 11, 'learning_rate': 0.1588812395864361, 'subsample': 0.6998177129720142, 'colsample_bytree': 0.9760117343443714, 'min_child_samples': 86, 'reg_alpha': 0.8338821359211896, 'reg_lambda': 0.7384309113212614}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:48,930] Trial 56 finished with value: 37.42007189187652 and parameters: {'n_estimators': 283, 'max_depth': 12, 'learning_rate': 0.16315640399059922, 'subsample': 0.680641902309246, 'colsample_bytree': 0.9499823073838851, 'min_child_samples': 85, 'reg_alpha': 0.9237137333041137, 'reg_lambda': 0.7381701020985204}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:48,930] Trial 56 finished with value: 37.42007189187652 and parameters: {'n_estimators': 283, 'max_depth': 12, 'learning_rate': 0.16315640399059922, 'subsample': 0.680641902309246, 'colsample_bytree': 0.9499823073838851, 'min_child_samples': 85, 'reg_alpha': 0.9237137333041137, 'reg_lambda': 0.7381701020985204}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:55,288] Trial 57 finished with value: 37.23618441589915 and parameters: {'n_estimators': 299, 'max_depth': 11, 'learning_rate': 0.1995390832009045, 'subsample': 0.6904311903141167, 'colsample_bytree': 0.8982404139820834, 'min_child_samples': 40, 'reg_alpha': 0.8303352316903764, 'reg_lambda': 0.8606505195068073}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:55,288] Trial 57 finished with value: 37.23618441589915 and parameters: {'n_estimators': 299, 'max_depth': 11, 'learning_rate': 0.1995390832009045, 'subsample': 0.6904311903141167, 'colsample_bytree': 0.8982404139820834, 'min_child_samples': 40, 'reg_alpha': 0.8303352316903764, 'reg_lambda': 0.8606505195068073}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:26:05,612] Trial 58 finished with value: 41.91892710162173 and parameters: {'n_estimators': 298, 'max_depth': 11, 'learning_rate': 0.013359706377499819, 'subsample': 0.6910386077544506, 'colsample_bytree': 0.9045364271919647, 'min_child_samples': 43, 'reg_alpha': 0.8338114959942773, 'reg_lambda': 0.9353154671756975}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:26:05,612] Trial 58 finished with value: 41.91892710162173 and parameters: {'n_estimators': 298, 'max_depth': 11, 'learning_rate': 0.013359706377499819, 'subsample': 0.6910386077544506, 'colsample_bytree': 0.9045364271919647, 'min_child_samples': 43, 'reg_alpha': 0.8338114959942773, 'reg_lambda': 0.9353154671756975}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:26:12,396] Trial 59 finished with value: 37.59809830471343 and parameters: {'n_estimators': 276, 'max_depth': 12, 'learning_rate': 0.12974199103267098, 'subsample': 0.6700170122352743, 'colsample_bytree': 0.9399309949866732, 'min_child_samples': 37, 'reg_alpha': 0.7903477861649355, 'reg_lambda': 0.8092985788621441}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:26:12,396] Trial 59 finished with value: 37.59809830471343 and parameters: {'n_estimators': 276, 'max_depth': 12, 'learning_rate': 0.12974199103267098, 'subsample': 0.6700170122352743, 'colsample_bytree': 0.9399309949866732, 'min_child_samples': 37, 'reg_alpha': 0.7903477861649355, 'reg_lambda': 0.8092985788621441}. Best is trial 48 with value: 37.11077711702346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà [LightGBM] Trials completados: 60/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ LightGBM optimizado:\n",
      "RMSE: 37.1108\n",
      "MAE: 25.8193\n",
      "R¬≤: 0.9136\n",
      "\n",
      "üìä Comparaci√≥n de modelos optimizados:\n",
      "Modelo\t\tRMSE\t\tMAE\t\tR2\n",
      "RandomForest\t41.0972\t28.4235\t0.8940\n",
      "XGBoost    \t35.6574\t24.4894\t0.9202\n",
      "LightGBM   \t37.1108\t25.8193\t0.9136\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloque√≥ al ejecutar c√≥digo en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el c√≥digo de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqu√≠</a> para obtener m√°s informaci√≥n. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener m√°s detalles."
     ]
    }
   ],
   "source": [
    "# ‚úÖ Versi√≥n corregida y funcional de la optimizaci√≥n adaptativa con Optuna\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import warnings\n",
    "import pickle\n",
    "import optuna\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "resultados_base = {}\n",
    "model_paths = {}  # Para guardar rutas de modelos optimizados\n",
    "\n",
    "# Suprimir warnings de XGBoost innecesarios\n",
    "def suppress_specific_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\")\n",
    "    os.environ[\"XGBOOST_DISABLE_USE_LABEL_ENCODER\"] = \"1\"\n",
    "\n",
    "suppress_specific_warnings()\n",
    "\n",
    "def validate_database_path(db_path):\n",
    "    \"\"\"Valida que la base de datos SQLite tenga permisos de escritura.\"\"\"\n",
    "    try:\n",
    "        with open(db_path, 'a') as f:\n",
    "            pass\n",
    "        print(f\"‚úÖ Base de datos validada: {db_path}\")\n",
    "    except IOError as e:\n",
    "        print(f\"‚ùå Error de permisos en la base de datos: {db_path}. {e}\")\n",
    "        print(\"Usando base de datos en memoria como alternativa.\")\n",
    "        return ':memory:'\n",
    "    return db_path\n",
    "\n",
    "class OptimizationProgressCallback:\n",
    "    def __init__(self, total_trials, model_name=\"Modelo\"):\n",
    "        self.total_trials = total_trials\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        completed_trials = len(study.trials)\n",
    "        if completed_trials % 5 == 0 or completed_trials == self.total_trials:\n",
    "            print(f\"üìà [{self.model_name}] Trials completados: {completed_trials}/{self.total_trials}\")\n",
    "\n",
    "def run_memory_efficient_optimization(model_type, X_train, y_train, X_test, y_test):\n",
    "    print(f\"\\nüìä Iniciando optimizaci√≥n adaptativa para {model_type}...\")\n",
    "\n",
    "    # Verificar si el modelo ya existe\n",
    "    model_path = model_output_dir / f\"{model_type}_optimized.pkl\"\n",
    "    if model_path.exists():\n",
    "        print(f\"‚úÖ Modelo optimizado encontrado: {model_path}. Cargando...\")\n",
    "        with open(model_path, 'rb') as f:\n",
    "            best_model = pickle.load(f)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"\\n‚úÖ {model_type} cargado y evaluado:\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"R¬≤: {r2:.4f}\")\n",
    "        resultados_base[f\"{model_type}_Optuna\"] = (rmse, mae, r2)\n",
    "        model_paths[f\"{model_type}_Optuna\"] = model_path\n",
    "        return None, best_model, (rmse, mae, r2)\n",
    "\n",
    "    available_memory_gb = psutil.virtual_memory().available / (1024**3)\n",
    "    print(f\"Memoria RAM disponible: {available_memory_gb:.2f} GB\")\n",
    "\n",
    "    model_types = {\n",
    "        'RandomForest': RandomForestRegressor,\n",
    "        'XGBoost': XGBRegressor,\n",
    "        'LightGBM': LGBMRegressor\n",
    "    }\n",
    "\n",
    "    if model_type not in model_types:\n",
    "        raise ValueError(f\"Tipo de modelo no soportado: {model_type}.\")\n",
    "\n",
    "    if available_memory_gb < 2.0:\n",
    "        n_trials, max_estimators, max_depth, subsample = 10, 50, 6, 0.5\n",
    "    elif available_memory_gb < 8.0:\n",
    "        n_trials, max_estimators, max_depth, subsample = 30, 300, 12, 0.7\n",
    "    else:\n",
    "        n_trials, max_estimators, max_depth, subsample = 50, 500, 20, 0.9\n",
    "\n",
    "    def objective(trial):\n",
    "        common_params = {'random_state': 42}\n",
    "\n",
    "        if model_type == 'RandomForest':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, max_estimators),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, max_depth),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "                'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "        elif model_type == 'XGBoost':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, max_estimators),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, max_depth),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, subsample),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "                'tree_method': 'hist',\n",
    "                'n_jobs': -1,\n",
    "                'verbosity': 0\n",
    "            }\n",
    "        elif model_type == 'LightGBM':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, max_estimators),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, max_depth),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, subsample),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "                'boosting_type': 'gbdt',\n",
    "                'n_jobs': -1,\n",
    "                'verbose': -1\n",
    "            }\n",
    "\n",
    "        params.update(common_params)\n",
    "        gc.collect()\n",
    "        try:\n",
    "            model = model_types[model_type](**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            return rmse\n",
    "        except Exception as e:\n",
    "            print(f\"Error con par√°metros: {params}\\n{e}\")\n",
    "            return float('inf')\n",
    "\n",
    "    db_path = validate_database_path(model_output_dir / f\"{model_type}_study.db\")\n",
    "\n",
    "    try:\n",
    "        study = optuna.create_study(\n",
    "            study_name=f\"{model_type}_memory_optimized\",\n",
    "            storage=f\"sqlite:///{db_path}\",\n",
    "            direction='minimize',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            load_if_exists=True\n",
    "        )\n",
    "    except OperationalError as e:\n",
    "        print(f\"Error al acceder a la base de datos: {e}\")\n",
    "        print(\"Aseg√∫rate de que la base de datos no sea de solo lectura o verifica los permisos.\")\n",
    "        return None, None, None\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[OptimizationProgressCallback(n_trials, model_type)])\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params['random_state'] = 42\n",
    "    if model_type == 'XGBoost':\n",
    "        best_params['tree_method'] = 'hist'\n",
    "\n",
    "    best_model = model_types[model_type](**best_params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n‚úÖ {model_type} optimizado:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R¬≤: {r2:.4f}\")\n",
    "\n",
    "    resultados_base[f\"{model_type}_Optuna\"] = (rmse, mae, r2)\n",
    "\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    model_paths[f\"{model_type}_Optuna\"] = model_path\n",
    "\n",
    "    return best_params, best_model, (rmse, mae, r2)\n",
    "\n",
    "# ‚úÖ Ejecutar optimizaci√≥n adaptativa para todos los modelos base\n",
    "if 'X_train_scaled' in globals() and 'y_train' in globals() and 'X_test_scaled' in globals() and 'y_test' in globals():\n",
    "    print(\"\\nüöÄ Ejecutando optimizaci√≥n para RandomForest...\")\n",
    "    rf_params, rf_model, rf_metrics = run_memory_efficient_optimization('RandomForest', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "    print(\"\\nüöÄ Ejecutando optimizaci√≥n para XGBoost...\")\n",
    "    xgb_params, xgb_model, xgb_metrics = run_memory_efficient_optimization('XGBoost', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "    print(\"\\nüöÄ Ejecutando optimizaci√≥n para LightGBM...\")\n",
    "    lgb_params, lgb_model, lgb_metrics = run_memory_efficient_optimization('LightGBM', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "    # üìä Comparaci√≥n de m√©tricas\n",
    "    print(\"\\nüìä Comparaci√≥n de modelos optimizados:\")\n",
    "    print(\"Modelo\\t\\tRMSE\\t\\tMAE\\t\\tR2\")\n",
    "    print(f\"RandomForest\\t{rf_metrics[0]:.4f}\\t{rf_metrics[1]:.4f}\\t{rf_metrics[2]:.4f}\")\n",
    "    print(f\"XGBoost    \\t{xgb_metrics[0]:.4f}\\t{xgb_metrics[1]:.4f}\\t{xgb_metrics[2]:.4f}\")\n",
    "    print(f\"LightGBM   \\t{lgb_metrics[0]:.4f}\\t{lgb_metrics[1]:.4f}\\t{lgb_metrics[2]:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå No se encontraron las variables X_train_scaled, y_train, X_test_scaled o y_test en el entorno actual.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f81dd",
   "metadata": {},
   "source": [
    "## üß† Implementaci√≥n de Modelos de Deep Learning\n",
    "\n",
    "A continuaci√≥n implementaremos modelos basados en redes neuronales profundas para capturar patrones espaciales y temporales en los datos de precipitaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e57e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Preparando datos para modelos CNN...\n",
      "Columnas de coordenadas encontradas: ['latitude', 'longitude']\n",
      "Usando latitude y longitude como coordenadas para CNN\n",
      "Convirtiendo datos a formato espacial...\n"
     ]
    }
   ],
   "source": [
    "# Implementaci√≥n de modelo CNN para predicci√≥n espacial\n",
    "import gc  # Para liberar memoria\n",
    "\n",
    "print(\"\\nüîç Preparando datos para modelos CNN...\")\n",
    "\n",
    "# Verificar si tenemos columnas de coordenadas en nuestros datos\n",
    "coord_cols = [col for col in feature_cols if col in ['x', 'y', 'latitude', 'longitude', 'lat', 'lon']]\n",
    "\n",
    "if len(coord_cols) >= 2:\n",
    "    print(f\"Columnas de coordenadas encontradas: {coord_cols}\")\n",
    "    \n",
    "    # Mapeo de nombres de columnas comunes\n",
    "    lat_names = ['latitude', 'lat', 'y']\n",
    "    lon_names = ['longitude', 'lon', 'x']\n",
    "    \n",
    "    # Identificar columnas de latitud y longitud\n",
    "    lat_col = next((col for col in coord_cols if col in lat_names), None)\n",
    "    lon_col = next((col for col in coord_cols if col in lon_names), None)\n",
    "    \n",
    "    if lat_col and lon_col:\n",
    "        print(f\"Usando {lat_col} y {lon_col} como coordenadas para CNN\")\n",
    "        \n",
    "        # Convertir datos a formato espacial para CNN\n",
    "        def prepare_spatial_data(X_data, y_data, lat_col, lon_col):\n",
    "            \"\"\"Prepara datos espaciales para CNN\"\"\"\n",
    "            try:\n",
    "                # Extraer coordenadas √∫nicas en orden\n",
    "                lats = sorted(X_data[lat_col].unique())\n",
    "                lons = sorted(X_data[lon_col].unique())\n",
    "                \n",
    "                # Crear diccionarios de mapeo para √≠ndices\n",
    "                lat_to_idx = {lat: idx for idx, lat in enumerate(lats)}\n",
    "                lon_to_idx = {lon: idx for idx, lon in enumerate(lons)}\n",
    "                \n",
    "                # Dimensiones de la grilla\n",
    "                grid_height = len(lats)\n",
    "                grid_width = len(lons)\n",
    "                n_features = X_data.shape[1] - 2  # Restar las dos columnas de coordenadas\n",
    "                \n",
    "                # Inicializar arrays\n",
    "                X_grid = np.zeros((len(X_data), grid_height, grid_width, n_features), dtype=np.float32)\n",
    "                y_grid = np.zeros((len(y_data), grid_height, grid_width, 1), dtype=np.float32)\n",
    "                \n",
    "                # Recorrer todos los datos y ubicarlos en la grilla\n",
    "                non_coord_cols = [col for col in X_data.columns if col != lat_col and col != lon_col]\n",
    "                \n",
    "                for idx in range(len(X_data)):\n",
    "                    lat = X_data.iloc[idx][lat_col]\n",
    "                    lon = X_data.iloc[idx][lon_col]\n",
    "                    \n",
    "                    lat_idx = lat_to_idx[lat]\n",
    "                    lon_idx = lon_to_idx[lon]\n",
    "                    \n",
    "                    # Colocar caracter√≠sticas en la grilla\n",
    "                    for i, col in enumerate(non_coord_cols):\n",
    "                        X_grid[idx, lat_idx, lon_idx, i] = X_data.iloc[idx][col]\n",
    "                    \n",
    "                    # Colocar valor objetivo\n",
    "                    y_grid[idx, lat_idx, lon_idx, 0] = y_data.iloc[idx]\n",
    "                \n",
    "                return X_grid, y_grid\n",
    "            except Exception as e:\n",
    "                print(f\"Error preparando datos espaciales: {e}\")\n",
    "                return None, None\n",
    "        \n",
    "        # Convertir datos de entrenamiento a formato espacial\n",
    "        print(\"Convirtiendo datos a formato espacial...\")\n",
    "        try:\n",
    "            X_train_df = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "            X_test_df = pd.DataFrame(X_test_scaled, columns=feature_cols)\n",
    "            \n",
    "            X_train_spatial, y_train_spatial = prepare_spatial_data(X_train_df, y_train, lat_col, lon_col)\n",
    "            X_test_spatial, y_test_spatial = prepare_spatial_data(X_test_df, y_test, lat_col, lon_col)\n",
    "            \n",
    "            if X_train_spatial is None or X_test_spatial is None:\n",
    "                raise ValueError(\"Error al preparar datos espaciales para CNN.\")\n",
    "            \n",
    "            print(f\"Datos espaciales preparados:\")\n",
    "            print(f\"X_train_spatial: {X_train_spatial.shape}\")\n",
    "            print(f\"y_train_spatial: {y_train_spatial.shape}\")\n",
    "            print(f\"X_test_spatial: {X_test_spatial.shape}\")\n",
    "            print(f\"y_test_spatial: {y_test_spatial.shape}\")\n",
    "            \n",
    "            # Liberar memoria innecesaria\n",
    "            del X_train_df, X_test_df\n",
    "            gc.collect()\n",
    "            \n",
    "            # Modelo CNN para predicci√≥n de precipitaci√≥n\n",
    "            def create_cnn_model(input_shape):\n",
    "                \"\"\"Crea un modelo CNN para predicci√≥n espacial\"\"\"\n",
    "                inputs = Input(shape=input_shape)\n",
    "                x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "                x = BatchNormalization()(x)\n",
    "                x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "                x = Dropout(0.25)(x)\n",
    "                x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "                x = BatchNormalization()(x)\n",
    "                x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "                x = Dropout(0.25)(x)\n",
    "                outputs = Conv2D(1, kernel_size=(1, 1), activation='linear', padding='same')(x)\n",
    "                model = Model(inputs=inputs, outputs=outputs)\n",
    "                model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['mae'])\n",
    "                return model\n",
    "            \n",
    "            print(\"\\nüß† Creando y entrenando modelo CNN...\")\n",
    "            input_shape = X_train_spatial.shape[1:]\n",
    "            cnn_model = create_cnn_model(input_shape)\n",
    "            cnn_model.summary()\n",
    "            \n",
    "            callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "                ModelCheckpoint(filepath=model_output_dir / 'cnn_model_best.h5', save_best_only=True, monitor='val_loss')\n",
    "            ]\n",
    "            \n",
    "            history = cnn_model.fit(\n",
    "                X_train_spatial, y_train_spatial,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            print(\"\\nüìä Evaluando modelo CNN...\")\n",
    "            cnn_metrics = cnn_model.evaluate(X_test_spatial, y_test_spatial)\n",
    "            print(f\"Loss (MSE): {cnn_metrics[0]:.4f}\")\n",
    "            print(f\"MAE: {cnn_metrics[1]:.4f}\")\n",
    "            \n",
    "            cnn_model.save(model_output_dir / 'cnn_model_final.h5')\n",
    "            print(\"Modelo CNN guardado correctamente.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error preparando datos espaciales para CNN: {e}\")\n",
    "    else:\n",
    "        print(\"No se pudieron identificar columnas de latitud y longitud.\")\n",
    "else:\n",
    "    print(\"No se encontraron suficientes columnas de coordenadas para implementar CNN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementaci√≥n de modelo ConvLSTM para predicci√≥n espaciotemporal\n",
    "print(\"\\nüîç Preparando datos para modelo ConvLSTM...\")\n",
    "\n",
    "# Verificar si tenemos el DataFrame disponible\n",
    "if 'df' not in locals() or df is None:\n",
    "    print(\"DataFrame no disponible, intentando recargarlo...\")\n",
    "    try:\n",
    "        # Recargar el dataset si no est√° disponible\n",
    "        data_file = BASE_PATH / 'data' / 'output' / 'complete_dataset_with_features.nc'\n",
    "        print(f\"Recargando archivo desde: {data_file}\")\n",
    "        df, ds_original = load_dataset(data_file)\n",
    "        \n",
    "        if df is None:\n",
    "            print(\"Error: No se pudo recargar el DataFrame. Verificar la ruta del archivo.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al recargar el DataFrame: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Verificar si tenemos las variables necesarias\n",
    "if 'feature_cols' not in locals() or 'target_column' not in locals():\n",
    "    print(\"Variables necesarias no definidas, intentando redefinirlas...\")\n",
    "    if df is not None:\n",
    "        # Identificar la columna objetivo (precipitaci√≥n)\n",
    "        target_column = 'total_precipitation'  # Ajustar si tiene otro nombre en tu dataset\n",
    "        \n",
    "        # Ver si existe 'precip_target' o usar 'total_precipitation'\n",
    "        if 'total_precipitation' in df.columns:\n",
    "            target_column = 'total_precipitation'\n",
    "        \n",
    "        # Separar variables predictoras y variable objetivo\n",
    "        feature_cols = [col for col in df.columns if col != target_column and not pd.isna(df[col]).all()]\n",
    "        \n",
    "        # Eliminar columnas no num√©ricas para los modelos\n",
    "        non_feature_cols = ['time', 'spatial_ref']\n",
    "        feature_cols = [col for col in feature_cols if col not in non_feature_cols]\n",
    "\n",
    "# Si el DataFrame est√° disponible, continuar con la preparaci√≥n de datos\n",
    "if df is not None:\n",
    "    # Para ConvLSTM necesitamos datos con dimensi√≥n temporal\n",
    "    time_cols = [col for col in df.columns if col in ['time', 'date', 'month', 'year', 'day']]\n",
    "\n",
    "    if len(time_cols) > 0 and len(coord_cols) >= 2:\n",
    "        print(f\"Columnas temporales encontradas: {time_cols}\")\n",
    "        time_col = time_cols[0]\n",
    "        \n",
    "        # Funci√≥n para preparar datos espaciotemporales\n",
    "        def prepare_spatiotemporal_data(df, feature_cols, target_column, lat_col, lon_col, time_col, \n",
    "                                        sequence_length=3):\n",
    "            \"\"\"Prepara datos para ConvLSTM con dimensi√≥n espaciotemporal\"\"\"\n",
    "            print(\"Preparando datos espaciotemporales para ConvLSTM...\")\n",
    "            try:\n",
    "                # Asegurarnos que la columna temporal est√° ordenada\n",
    "                # Verificar el tipo de la columna temporal\n",
    "                time_dtype = df[time_col].dtype\n",
    "                print(f\"Tipo de dato de columna temporal: {time_dtype}\")\n",
    "                \n",
    "                if pd.api.types.is_datetime64_any_dtype(df[time_col]):\n",
    "                    # Ya es datetime, ordenamos\n",
    "                    df_sorted = df.sort_values(by=time_col)\n",
    "                else:\n",
    "                    # Intentar convertir a datetime\n",
    "                    try:\n",
    "                        df[time_col] = pd.to_datetime(df[time_col])\n",
    "                        df_sorted = df.sort_values(by=time_col)\n",
    "                    except Exception as e:\n",
    "                        print(f\"No se pudo convertir columna temporal a datetime: {e}\")\n",
    "                        # Si no podemos convertir, asumimos que ya est√° ordenado\n",
    "                        df_sorted = df\n",
    "                \n",
    "                # Extraer coordenadas √∫nicas\n",
    "                lats = sorted(df_sorted[lat_col].unique())\n",
    "                lons = sorted(df_sorted[lon_col].unique())\n",
    "                time_steps = sorted(df_sorted[time_col].unique())\n",
    "                \n",
    "                print(f\"Dimensiones espaciotemporales:\")\n",
    "                print(f\"- Latitudes (filas): {len(lats)}\")\n",
    "                print(f\"- Longitudes (columnas): {len(lons)}\")\n",
    "                print(f\"- Pasos temporales: {len(time_steps)}\")\n",
    "                \n",
    "                # Crear mapeos para √≠ndices\n",
    "                lat_to_idx = {lat: idx for idx, lat in enumerate(lats)}\n",
    "                lon_to_idx = {lon: idx for idx, lon in enumerate(lons)}\n",
    "                time_to_idx = {time: idx for idx, time in enumerate(time_steps)}\n",
    "                \n",
    "                # Filtrar columnas feature eliminando coordenadas y tiempo\n",
    "                feature_cols_filtered = [col for col in feature_cols if col != lat_col and col != lon_col and col != time_col]\n",
    "                n_features = len(feature_cols_filtered)\n",
    "                \n",
    "                # Dimensiones de la grilla espaciotemporal\n",
    "                grid_height = len(lats)\n",
    "                grid_width = len(lons)\n",
    "                n_timesteps = len(time_steps)\n",
    "                \n",
    "                print(f\"Caracter√≠sticas a usar: {n_features}\")\n",
    "                \n",
    "                # Crear un DataFrame indexado para acceso r√°pido\n",
    "                df_indexed = df_sorted.set_index([time_col, lat_col, lon_col])\n",
    "                \n",
    "                # Crear matrices 3D para cada paso temporal\n",
    "                # Las dimensiones son: [tiempo, altura, ancho, features]\n",
    "                X_spatiotemporal = np.zeros((n_timesteps, grid_height, grid_width, n_features))\n",
    "                y_spatiotemporal = np.zeros((n_timesteps, grid_height, grid_width, 1))\n",
    "                \n",
    "                # Llenar matrices con datos disponibles\n",
    "                for t_idx, t in enumerate(time_steps):\n",
    "                    for lat_idx, lat in enumerate(lats):\n",
    "                        for lon_idx, lon in enumerate(lons):\n",
    "                            try:\n",
    "                                # Obtener datos para esta coordenada y tiempo\n",
    "                                data = df_indexed.loc[(t, lat, lon)]\n",
    "                                \n",
    "                                # Llenar caracter√≠sticas\n",
    "                                for f_idx, feat in enumerate(feature_cols_filtered):\n",
    "                                    X_spatiotemporal[t_idx, lat_idx, lon_idx, f_idx] = data[feat]\n",
    "                                \n",
    "                                # Llenar target\n",
    "                                y_spatiotemporal[t_idx, lat_idx, lon_idx, 0] = data[target_column]\n",
    "                            except KeyError:\n",
    "                                # Este punto espaciotemporal no existe en los datos\n",
    "                                pass\n",
    "                \n",
    "                # Crear secuencias para ConvLSTM\n",
    "                # Para cada paso temporal t, usaremos t-sequence_length hasta t-1 para predecir t\n",
    "                n_sequences = n_timesteps - sequence_length\n",
    "                \n",
    "                if n_sequences <= 0:\n",
    "                    print(\"No hay suficientes pasos temporales para crear secuencias. Ajustando sequence_length.\")\n",
    "                    sequence_length = max(1, n_timesteps // 2)\n",
    "                    n_sequences = n_timesteps - sequence_length\n",
    "                    print(f\"Nuevo sequence_length: {sequence_length}, n_sequences: {n_sequences}\")\n",
    "                \n",
    "                # Crear arrays para secuencias\n",
    "                X_sequences = np.zeros((n_sequences, sequence_length, grid_height, grid_width, n_features))\n",
    "                y_sequences = np.zeros((n_sequences, grid_height, grid_width, 1))\n",
    "                \n",
    "                for i in range(n_sequences):\n",
    "                    X_sequences[i] = X_spatiotemporal[i:i+sequence_length]\n",
    "                    y_sequences[i] = y_spatiotemporal[i+sequence_length]\n",
    "                \n",
    "                print(f\"Secuencias creadas:\")\n",
    "                print(f\"X_sequences: {X_sequences.shape}\")\n",
    "                print(f\"y_sequences: {y_sequences.shape}\")\n",
    "                \n",
    "                # Dividir en train/test\n",
    "                train_size = int(0.8 * n_sequences)\n",
    "                X_train = X_sequences[:train_size]\n",
    "                y_train = y_sequences[:train_size]\n",
    "                X_test = X_sequences[train_size:]\n",
    "                y_test = y_sequences[train_size:]\n",
    "                \n",
    "                return X_train, y_train, X_test, y_test\n",
    "            except Exception as e:\n",
    "                print(f\"Error preparando datos espaciotemporales: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                return None, None, None, None\n",
    "        \n",
    "        # Intentar preparar datos espaciotemporales\n",
    "        try:\n",
    "            X_train_convlstm, y_train_convlstm, X_test_convlstm, y_test_convlstm = prepare_spatiotemporal_data(\n",
    "                df, feature_cols, target_column, lat_col, lon_col, time_col, sequence_length=3\n",
    "            )\n",
    "            \n",
    "            # Si los datos se preparan correctamente, crear y entrenar modelo ConvLSTM\n",
    "            if X_train_convlstm is not None:\n",
    "                print(\"\\nüß† Creando y entrenando modelo ConvLSTM...\")\n",
    "                \n",
    "                def create_convlstm_model(input_shape):\n",
    "                    \"\"\"Crea un modelo ConvLSTM para predicci√≥n espaciotemporal\"\"\"\n",
    "                    model = Sequential([\n",
    "                        # Capa ConvLSTM\n",
    "                        ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same',\n",
    "                                  return_sequences=True, activation='tanh',\n",
    "                                  input_shape=input_shape),\n",
    "                        BatchNormalization(),\n",
    "                        \n",
    "                        # Segunda capa ConvLSTM\n",
    "                        ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same',\n",
    "                                   return_sequences=False, activation='tanh'),\n",
    "                        BatchNormalization(),\n",
    "                        \n",
    "                        # Capa convolucional para reducir mapas de caracter√≠sticas\n",
    "                        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "                        BatchNormalization(),\n",
    "                        MaxPooling2D(pool_size=(2, 2)),\n",
    "                        \n",
    "                        # Capas finales\n",
    "                        Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "                        UpSampling2D(size=(2, 2)),  # Restaurar dimensi√≥n original\n",
    "                        Conv2D(filters=1, kernel_size=(3, 3), activation='linear', padding='same')\n",
    "                    ])\n",
    "                    \n",
    "                    # Compilar modelo\n",
    "                    model.compile(\n",
    "                        loss='mse',\n",
    "                        optimizer=Adam(learning_rate=0.001),\n",
    "                        metrics=['mae']\n",
    "                    )\n",
    "                    \n",
    "                    return model\n",
    "                \n",
    "                # Crear modelo ConvLSTM\n",
    "                input_shape = X_train_convlstm.shape[1:]  # (sequence_length, height, width, features)\n",
    "                convlstm_model = create_convlstm_model(input_shape)\n",
    "                \n",
    "                # Mostrar resumen del modelo\n",
    "                convlstm_model.summary()\n",
    "                \n",
    "                # Callbacks para entrenamiento\n",
    "                callbacks = [\n",
    "                    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "                    ModelCheckpoint(filepath=model_output_dir / 'convlstm_model_best.h5',\n",
    "                                  save_best_only=True, monitor='val_loss')\n",
    "                ]\n",
    "                \n",
    "                # Entrenar modelo\n",
    "                history = convlstm_model.fit(\n",
    "                    X_train_convlstm, y_train_convlstm,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                # Evaluar modelo\n",
    "                print(\"\\nüìä Evaluando modelo ConvLSTM...\")\n",
    "                convlstm_metrics = convlstm_model.evaluate(X_test_convlstm, y_test_convlstm)\n",
    "                print(f\"Loss (MSE): {convlstm_metrics[0]:.4f}\")\n",
    "                print(f\"MAE: {convlstm_metrics[1]:.4f}\")\n",
    "                \n",
    "                # Predecir con el modelo\n",
    "                y_pred_convlstm = convlstm_model.predict(X_test_convlstm)\n",
    "                \n",
    "                # Aplanar las predicciones para calcular m√©tricas\n",
    "                y_test_flat = y_test_convlstm.flatten()\n",
    "                y_pred_flat = y_pred_convlstm.flatten()\n",
    "                \n",
    "                # Filtrar valores donde y_test_flat > 0 (presumiblemente donde hay datos)\n",
    "                valid_indices = y_test_flat > 0\n",
    "                y_test_valid = y_test_flat[valid_indices]\n",
    "                y_pred_valid = y_pred_flat[valid_indices]\n",
    "                \n",
    "                # Calcular m√©tricas\n",
    "                convlstm_rmse = np.sqrt(mean_squared_error(y_test_valid, y_pred_valid))\n",
    "                convlstm_mae = mean_absolute_error(y_test_valid, y_pred_valid)\n",
    "                convlstm_r2 = r2_score(y_test_valid, y_pred_valid)\n",
    "                \n",
    "                print(f\"RMSE: {convlstm_rmse:.4f}\")\n",
    "                print(f\"MAE: {convlstm_mae:.4f}\")\n",
    "                print(f\"R¬≤: {convlstm_r2:.4f}\")\n",
    "                \n",
    "                # Guardar modelo\n",
    "                convlstm_model.save(model_output_dir / 'convlstm_model_final.h5')\n",
    "                print(\"Modelo ConvLSTM guardado como 'convlstm_model_final.h5'\")\n",
    "                \n",
    "                # Visualizar la historia del entrenamiento\n",
    "                plt.figure(figsize=(12, 5))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.plot(history.history['loss'])\n",
    "                plt.plot(history.history['val_loss'])\n",
    "                plt.title('P√©rdida del modelo ConvLSTM')\n",
    "                plt.ylabel('P√©rdida')\n",
    "                plt.xlabel('√âpoca')\n",
    "                plt.legend(['Entrenamiento', 'Validaci√≥n'], loc='upper right')\n",
    "                \n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot(history.history['mae'])\n",
    "                plt.plot(history.history['val_mae'])\n",
    "                plt.title('Error absoluto medio ConvLSTM')\n",
    "                plt.ylabel('MAE')\n",
    "                plt.xlabel('√âpoca')\n",
    "                plt.legend(['Entrenamiento', 'Validaci√≥n'], loc='upper right')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(model_output_dir / 'convlstm_training_history.png')\n",
    "                plt.show()\n",
    "                \n",
    "                # A√±adir resultados a nuestro diccionario de comparaci√≥n\n",
    "                resultados_base['ConvLSTM'] = (convlstm_rmse, convlstm_mae, convlstm_r2)\n",
    "            else:\n",
    "                print(\"No se pudieron preparar datos para ConvLSTM.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ejecutar preparaci√≥n de datos para ConvLSTM: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"No se encontraron columnas temporales o espaciales suficientes para implementar ConvLSTM.\")\n",
    "        print(\"El modelo ConvLSTM requiere al menos una columna temporal y dos columnas espaciales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87873507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar optimizaci√≥n adaptativa de memoria RAM para modelos base\n",
    "print(\"\\nüîç Ejecutando optimizaci√≥n adaptativa de memoria RAM para Random Forest...\")\n",
    "rf_params, rf_model_opt, rf_metrics_opt = run_memory_efficient_optimization('RandomForest', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(\"\\nüîç Ejecutando optimizaci√≥n adaptativa de memoria RAM para XGBoost...\")\n",
    "xgb_params, xgb_model_opt, xgb_metrics_opt = run_memory_efficient_optimization('XGBoost', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(\"\\nüîç Ejecutando optimizaci√≥n adaptativa de memoria RAM para LightGBM...\")\n",
    "lgbm_params, lgbm_model_opt, lgbm_metrics_opt = run_memory_efficient_optimization('LightGBM', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "# Resumen de par√°metros √≥ptimos encontrados\n",
    "print(\"\\nüìä Mejores par√°metros encontrados para cada modelo:\")\n",
    "print(f\"\\nRandom Forest: {rf_params}\")\n",
    "print(f\"\\nXGBoost: {xgb_params}\")\n",
    "print(f\"\\nLightGBM: {lgbm_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejora de visibilidad en el entrenamiento y errores para modelos CNN y ConvLSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Visualiza la historia del entrenamiento de un modelo.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # P√©rdida\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_loss'], label='Validaci√≥n')\n",
    "    plt.title(f'P√©rdida del modelo {model_name}')\n",
    "    plt.ylabel('P√©rdida')\n",
    "    plt.xlabel('√âpoca')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_mae'], label='Validaci√≥n')\n",
    "    plt.title(f'Error absoluto medio (MAE) - {model_name}')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('√âpoca')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_model_metrics(metrics, model_name):\n",
    "    \"\"\"Muestra las m√©tricas de evaluaci√≥n de un modelo de forma visual.\"\"\"\n",
    "    rmse, mae, r2 = metrics\n",
    "    display(HTML(f'<div style=\"background-color:#f5f5dc; padding:10px; border-radius:5px; margin-top:10px;\">' +\n",
    "                 f'<h3>üìä M√©tricas para {model_name}</h3>' +\n",
    "                 f'<table style=\"width:100%; text-align:left;\">' +\n",
    "                 f'<tr><th>M√©trica</th><th>Valor</th></tr>' +\n",
    "                 f'<tr><td>RMSE</td><td>{rmse:.4f}</td></tr>' +\n",
    "                 f'<tr><td>MAE</td><td>{mae:.4f}</td></tr>' +\n",
    "                 f'<tr><td>R¬≤</td><td>{r2:.4f}</td></tr>' +\n",
    "                 f'</table></div>'))\n",
    "\n",
    "# Aplicar mejoras de visibilidad al modelo CNN\n",
    "if 'cnn_model' in locals() and 'history' in locals():\n",
    "    print(\"\\nüìà Visualizando historia del entrenamiento para modelo CNN...\")\n",
    "    plot_training_history(history, 'CNN')\n",
    "\n",
    "if 'cnn_metrics' in locals():\n",
    "    print(\"\\nüìä Mostrando m√©tricas para modelo CNN...\")\n",
    "    display_model_metrics((cnn_rmse, cnn_mae, cnn_r2), 'CNN')\n",
    "\n",
    "# Aplicar mejoras de visibilidad al modelo ConvLSTM\n",
    "if 'convlstm_model' in locals() and 'history' in locals():\n",
    "    print(\"\\nüìà Visualizando historia del entrenamiento para modelo ConvLSTM...\")\n",
    "    plot_training_history(history, 'ConvLSTM')\n",
    "\n",
    "if 'convlstm_metrics' in locals():\n",
    "    print(\"\\nüìä Mostrando m√©tricas para modelo ConvLSTM...\")\n",
    "    display_model_metrics((convlstm_rmse, convlstm_mae, convlstm_r2), 'ConvLSTM')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
