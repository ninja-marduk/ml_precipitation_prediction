{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827c19f7",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/feature%2Fhybrid-models/models/hybrid_models_enconders_layering_w3_ST-HybridWaveStack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43abece5",
   "metadata": {},
   "source": [
    "# Meta-Modelo Convolucional: ElevClusConvPrecipMetaNet\n",
    "\n",
    "Este modelo implementa una arquitectura convolucional avanzada para la predicción espaciotemporal de precipitación con horizonte de 12 meses.\n",
    "\n",
    "## Arquitectura\n",
    "\n",
    "1. **Entradas**:\n",
    "   - Mapas de predicción de los modelos base (ConvBiGRU-AE y ConvLSTM-AE) para cada horizonte (12 meses)\n",
    "   - Información de elevación y clusters para condicionamiento (FiLM)\n",
    "\n",
    "2. **Reducción Temprana de Canales**:\n",
    "   - Reduce los 24 canales (2 modelos × 12 horizontes) a 16 para optimizar memoria\n",
    "   - Aplica Conv2D(1×1) para mezclar información sin perder resolución espacial\n",
    "\n",
    "3. **Bloques Residuales Multiescala**:\n",
    "   - Bloques depthwise-separables con distintas dilataciones (1,2,4)\n",
    "   - Captura patrones a diferentes escalas espaciales sin incrementar parámetros\n",
    "\n",
    "4. **Atención Espacial por Cluster**:\n",
    "   - FiLM (Feature-wise Linear Modulation): γ_cluster ⊗ F + β_cluster\n",
    "   - Adapta el comportamiento según el régimen orográfico\n",
    "\n",
    "5. **U-Net Compacto**:\n",
    "   - Arquitectura de encoder-decoder con skip connections\n",
    "   - Solo 2 niveles de downsampling para preservar detalle\n",
    "\n",
    "6. **Agrupamiento de Horizontes**:\n",
    "   - Conv3D para procesar conjuntamente la dimensión temporal de horizontes\n",
    "   - Permite aprender relaciones entre meses consecutivos\n",
    "\n",
    "7. **Salida Multi-Horizonte**:\n",
    "   - Genera los 12 mapas refinados de predicción\n",
    "\n",
    "8. **Estrategias Memory-Friendly**:\n",
    "   - Mixed precision (float16)\n",
    "   - Gradient checkpointing\n",
    "   - Acumulación de gradientes\n",
    "   - Entrenamiento por etapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción Espaciotemporal de Precipitación Mensual - Notebook Completo\n",
    "\n",
    "# 0) Configuración del entorno, rutas y dependencias\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import joblib  # Para persistir scalers\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def log_and_print(msg):\n",
    "    logger.info(msg)\n",
    "    print(msg)\n",
    "\n",
    "# Detectar entorno (Colab o local)\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "log_and_print(f\"Ejecutando en Colab: {IN_COLAB}\")\n",
    "\n",
    "# Definir rutas base\n",
    "desired_repo = 'ml_precipitation_prediction'\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_PATH = Path('/content/drive/MyDrive') / desired_repo\n",
    "    if not Path(desired_repo).exists():\n",
    "        log_and_print(\"Clonando repositorio...\")\n",
    "        get_ipython().system('git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git')\n",
    "    os.chdir(desired_repo)\n",
    "    get_ipython().system('pip install -q xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open cartopy geopandas joblib')\n",
    "else:\n",
    "    # Instalación más simple sin PyEMD\n",
    "    %pip install -q xarray netCDF4 scikit-image\n",
    "    current = Path.cwd()\n",
    "    for p in [current] + list(current.parents):\n",
    "        if (p / '.git').is_dir() or (p / 'requirements.txt').is_file() or (p / 'README.md').is_file():\n",
    "            BASE_PATH = p\n",
    "            break\n",
    "    else:\n",
    "        BASE_PATH = current\n",
    "    log_and_print(f\"Ejecutando en local. Base path: {BASE_PATH}\")\n",
    "\n",
    "# Rutas de datos y modelos\n",
    "DATA_OUTPUT   = BASE_PATH / 'data' / 'output'\n",
    "MODELS_OUTPUT = BASE_PATH / 'models' / 'output'\n",
    "PREDS_DIR     = MODELS_OUTPUT / 'base_model_predictions'\n",
    "SHP_PATH      = BASE_PATH / 'data' / 'input' / 'shapes' / 'MGN_Departamento.shp'\n",
    "\n",
    "# Crear directorios\n",
    "MODELS_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "PREDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parámetros generales\n",
    "INPUT_WINDOW   = 60\n",
    "OUTPUT_HORIZON = 12  # 12 meses\n",
    "BATCH_SIZE     = 16\n",
    "MAX_EPOCHS     = 300\n",
    "PATIENCE       = 50\n",
    "LR             = 1e-3\n",
    "\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log_and_print(f\"Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "\n",
    "# 1) Imports adicionales y utilidades\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature  # Añadido para características cartográficas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler # Mixed precision training\n",
    "from torch.utils.checkpoint import checkpoint # Gradient checkpointing\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  # Añadido para learning rate adaptativo\n",
    "from IPython.display import clear_output  # Para actualizar gráficos durante entrenamiento\n",
    "import pywt\n",
    "from scipy.signal import hilbert\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "# 2) Carga y preprocesamiento de datos - Versión simplificada\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    log_and_print(\"Cargando datos...\")\n",
    "    \n",
    "    # Cargar datos completos\n",
    "    ds_full = xr.open_dataset(DATA_OUTPUT / 'complete_dataset_with_features_with_clusters_elevation_with_windows.nc')\n",
    "    log_and_print(f\"Dataset completo cargado, dims: {ds_full.dims}\")\n",
    "    \n",
    "    # Cargar componentes directamente de archivos específicos\n",
    "    ds_ceemdan = xr.open_dataset(MODELS_OUTPUT / 'features_CEEMDAN.nc')\n",
    "    log_and_print(f\"Dataset CEEMDAN cargado, dims: {ds_ceemdan.dims}\")\n",
    "    log_and_print(f\"Variables disponibles en CEEMDAN: {list(ds_ceemdan.data_vars.keys())}\")\n",
    "    \n",
    "    ds_tvfemd = xr.open_dataset(MODELS_OUTPUT / 'features_TVFEMD.nc')\n",
    "    log_and_print(f\"Dataset TVF-EMD cargado, dims: {ds_tvfemd.dims}\")\n",
    "    log_and_print(f\"Variables disponibles en TVF-EMD: {list(ds_tvfemd.data_vars.keys())}\")\n",
    "    \n",
    "    # Cargar shapefile para visualizaciones\n",
    "    gdf = gpd.read_file(SHP_PATH)\n",
    "    if gdf.crs is None:\n",
    "        gdf = gdf.set_crs(epsg=4326)\n",
    "    elif gdf.crs.to_epsg() != 4326:\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "    log_and_print(\"Shapefile cargado y CRS validado.\")\n",
    "\n",
    "    # Extraer información temporal\n",
    "    times = ds_full.time.values.astype('datetime64[M]')\n",
    "    REF = np.datetime64('2024-02','M')\n",
    "    idx_ref = int(np.where(times==REF)[0][0])\n",
    "    log_and_print(f\"Referencia (REF) = {REF}, index={idx_ref}\")\n",
    "    \n",
    "    return ds_full, ds_ceemdan, ds_tvfemd, gdf, times, REF, idx_ref\n",
    "\n",
    "# Ejecutar carga/preproc con los archivos específicos\n",
    "ds_full, ds_ceemdan, ds_tvfemd, gdf, times, REF, idx_ref = load_and_preprocess_data()\n",
    "\n",
    "# Preparar datos para entrenamiento y evaluación\n",
    "def prepare_train_val_data(ds_full, input_window=INPUT_WINDOW, output_horizon=OUTPUT_HORIZON):\n",
    "    \"\"\"\n",
    "    Prepara los datos de entrenamiento y validación desde el dataset completo.\n",
    "    \n",
    "    Args:\n",
    "        ds_full: Dataset completo con variables\n",
    "        input_window: Tamaño de la ventana de entrada\n",
    "        output_horizon: Horizonte de predicción\n",
    "    \n",
    "    Returns:\n",
    "        X_train, y_train, X_val, y_val: Arrays de entrenamiento y validación\n",
    "    \"\"\"\n",
    "    print(\"Preparando datos para entrenamiento y validación...\")\n",
    "    \n",
    "    # Extraer precipitación como variable objetivo\n",
    "    # Check if 'precipitacion' exists in the dataset\n",
    "    if 'precipitacion' in ds_full.data_vars:\n",
    "        precip = ds_full.precipitacion.values\n",
    "        print(\"Using 'precipitacion' as target variable\")\n",
    "    # If not, check for 'total_precipitation'\n",
    "    elif 'total_precipitation' in ds_full.data_vars:\n",
    "        precip = ds_full.total_precipitation.values\n",
    "        print(\"Using 'total_precipitation' as target variable\")\n",
    "    else:\n",
    "        # If neither exists, raise an error\n",
    "        raise ValueError(\"Could not find precipitation variable in dataset. Available variables: \" + \n",
    "                        str(list(ds_full.data_vars.keys())))\n",
    "    \n",
    "    # Ensure precip has 3 dimensions (time, lat, lon)\n",
    "    if len(precip.shape) != 3:\n",
    "        raise ValueError(f\"Expected precipitation data to have 3 dimensions (time, lat, lon), got {precip.shape}\")\n",
    "    \n",
    "    n_times, height, width = precip.shape\n",
    "    print(f\"Precipitation data shape: {precip.shape}\")\n",
    "    \n",
    "    # Extraer features, por ejemplo cluster y elevación\n",
    "    features = []\n",
    "    \n",
    "    # Verificar si las features estáticas existen y expandirlas para todas las timesteps\n",
    "    if 'cluster' in ds_full.data_vars:\n",
    "        cluster_data = ds_full.cluster.values\n",
    "        # Si cluster es 2D (lat, lon), expandir a 3D (time, lat, lon)\n",
    "        if len(cluster_data.shape) == 2:\n",
    "            cluster_data = np.repeat(cluster_data[np.newaxis, :, :], n_times, axis=0)\n",
    "        features.append(cluster_data)\n",
    "        print(\"Añadida variable 'cluster', shape:\", cluster_data.shape)\n",
    "    \n",
    "    if 'elevation' in ds_full.data_vars:\n",
    "        elev_data = ds_full.elevation.values\n",
    "        # Si elevation es 2D (lat, lon), expandir a 3D (time, lat, lon)\n",
    "        if len(elev_data.shape) == 2:\n",
    "            elev_data = np.repeat(elev_data[np.newaxis, :, :], n_times, axis=0)\n",
    "        features.append(elev_data)\n",
    "        print(\"Añadida variable 'elevation', shape:\", elev_data.shape)\n",
    "    \n",
    "    # Si no hay features específicas, usar precipitación histórica como feature\n",
    "    if not features:\n",
    "        print(\"No se encontraron features específicas, usando precipitación histórica\")\n",
    "        # Usar precipitación como característica, añadiendo una dimensión de canal\n",
    "        features_array = precip.reshape(n_times, 1, height, width)\n",
    "        print(f\"Shape de features: {features_array.shape}\")\n",
    "    else:\n",
    "        # Concatenar features en un solo array a lo largo de una nueva dimensión (canal)\n",
    "        features_array = np.stack(features, axis=1)\n",
    "        print(f\"Shape de features combinadas: {features_array.shape}\")\n",
    "    \n",
    "    # Crear ventanas deslizantes de manera segura\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(n_times - input_window - output_horizon + 1):\n",
    "        # Input: ventana de datos\n",
    "        X.append(features_array[i:i+input_window].copy())\n",
    "        # Output: horizonte de predicción \n",
    "        y.append(precip[i+input_window:i+input_window+output_horizon].copy())\n",
    "    \n",
    "    # Verificar formas antes de convertir\n",
    "    if not X or not y:\n",
    "        raise ValueError(\"No se pudieron crear ventanas válidas. Verifique los datos de entrada.\")\n",
    "        \n",
    "    # Usar np.stack en lugar de np.array para garantizar arrays homogéneos\n",
    "    X = np.stack(X)\n",
    "    y = np.stack(y)\n",
    "    \n",
    "    print(f\"Datos preparados - X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    \n",
    "    # División train/val (80/20)\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    print(f\"Train shapes - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "    print(f\"Val shapes - X: {X_val.shape}, y: {y_val.shape}\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# Función para entrenar y comparar modelos\n",
    "def train_and_compare_models(X_train, y_train, X_val, y_val, force_retrain=False):\n",
    "    \"\"\"\n",
    "    Entrena y compara modelos simples y híbridos usando las mismas entradas.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Datos de entrenamiento\n",
    "        y_train: Etiquetas de entrenamiento\n",
    "        X_val: Datos de validación\n",
    "        y_val: Etiquetas de validación\n",
    "        force_retrain: Si reentrenar aunque existan modelos guardados\n",
    "    \n",
    "    Returns:\n",
    "        dict, DataLoader: Diccionario con modelos entrenados y sus métricas, y el DataLoader de validación\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ENTRENAMIENTO Y COMPARACIÓN DE MODELOS SIMPLES Y HÍBRIDOS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Directorios para guardar modelos\n",
    "    models_dir = MODELS_OUTPUT / 'comparison_models'\n",
    "    models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Parámetros comunes\n",
    "    input_channels = X_train.shape[1] if len(X_train.shape) > 3 else 1\n",
    "    hidden_dim = 128\n",
    "    output_channels = 1\n",
    "    seq_length = OUTPUT_HORIZON\n",
    "    \n",
    "    # Obtener shape de target si está disponible\n",
    "    if len(y_train.shape) >= 3:\n",
    "        target_shape = y_train.shape[-2:]\n",
    "    else:\n",
    "        target_shape = (61, 65)  # valores por defecto\n",
    "    \n",
    "    print(f\"Configuración común: input_channels={input_channels}, hidden_dim={hidden_dim}, output_channels={output_channels}\")\n",
    "    print(f\"Secuencia: {seq_length}, target_shape: {target_shape}\")\n",
    "    \n",
    "    # Definir los modelos a entrenar con sus rutas de guardado\n",
    "    models = {\n",
    "        'SimpleConvGRU': {\n",
    "            'class': SimpleConvGRU,\n",
    "            'path': models_dir / 'simple_convgru.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'SimpleConvLSTM': {\n",
    "            'class': SimpleConvLSTM,\n",
    "            'path': models_dir / 'simple_convlstm.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'ConvBiGRU-AE': {\n",
    "            'class': ConvBiGRU_AE,\n",
    "            'path': models_dir / 'convbigru_ae.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'num_layers': 3,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'ConvBiLSTM-AE': {\n",
    "            'class': ConvBiLSTM_AE,\n",
    "            'path': models_dir / 'convbilstm_ae.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'num_layers': 3,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Crear datasets y dataloaders\n",
    "    train_dataset = PrecipitationDataset(X_train, y_train, seq_length)\n",
    "    val_dataset = PrecipitationDataset(X_val, y_val, seq_length)\n",
    "    \n",
    "    batch_size = 16\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Iterar sobre cada modelo\n",
    "    for model_name, config in models.items():\n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(f\"PROCESANDO MODELO: {model_name}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        # Verificar si existe modelo guardado\n",
    "        if config['path'].exists() and not force_retrain:\n",
    "            print(f\"Modelo encontrado en {config['path']}, cargando...\")\n",
    "            try:\n",
    "                # Cargar modelo existente\n",
    "                model = config['class'](**config['params']).to(DEVICE)\n",
    "                checkpoint = torch.load(config['path'], map_location=DEVICE)\n",
    "                \n",
    "                # Verificar contenido del checkpoint\n",
    "                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "                    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                    config['train_losses'] = checkpoint.get('train_losses', [])\n",
    "                    config['val_losses'] = checkpoint.get('val_losses', [])\n",
    "                else:\n",
    "                    # Formato antiguo (solo state_dict)\n",
    "                    model.load_state_dict(checkpoint)\n",
    "                \n",
    "                print(f\"✅ Modelo {model_name} cargado correctamente\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error al cargar modelo: {str(e)}\")\n",
    "                print(\"Entrenando el modelo desde cero...\")\n",
    "                \n",
    "                # Instanciar modelo\n",
    "                model = config['class'](**config['params']).to(DEVICE)\n",
    "                \n",
    "                # Configurar entrenamiento\n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "                scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "                \n",
    "                # Entrenar modelo\n",
    "                model, train_losses, val_losses = train_hybrid_model(\n",
    "                    name=model_name,\n",
    "                    model=model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    epochs=100,\n",
    "                    patience=20,\n",
    "                    optimizer=optimizer,\n",
    "                    criterion=criterion,\n",
    "                    scheduler=scheduler\n",
    "                )\n",
    "                \n",
    "                # Guardar historial de pérdidas\n",
    "                config['train_losses'] = train_losses\n",
    "                config['val_losses'] = val_losses\n",
    "                \n",
    "                # Guardar modelo\n",
    "                save_data = {\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses\n",
    "                }\n",
    "                torch.save(save_data, config['path'])\n",
    "        else:\n",
    "            # Entrenar modelo\n",
    "            print(f\"Entrenando {model_name} desde cero...\")\n",
    "            \n",
    "            # Instanciar modelo\n",
    "            model = config['class'](**config['params']).to(DEVICE)\n",
    "            \n",
    "            # Configurar entrenamiento\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "            \n",
    "            # Entrenar modelo\n",
    "            model, train_losses, val_losses, learning_rates = train_hybrid_model(\n",
    "                name=model_name,\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                epochs=100,\n",
    "                patience=20,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                scheduler=scheduler,\n",
    "                generate_plots=True\n",
    "            )\n",
    "            \n",
    "            # Guardar historial de pérdidas\n",
    "            config['train_losses'] = train_losses\n",
    "            config['val_losses'] = val_losses\n",
    "            \n",
    "            # Guardar modelo\n",
    "            save_data = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses,\n",
    "                'learning_rates': learning_rates\n",
    "            }\n",
    "            torch.save(save_data, config['path'])\n",
    "        \n",
    "        # Evaluar modelo con métricas adicionales\n",
    "        print(f\"Evaluando {model_name} con métricas adicionales...\")\n",
    "        model.eval()\n",
    "        \n",
    "        all_targets = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Asegurar dimensión de canal si es necesario\n",
    "                if len(outputs.shape) == 5 and outputs.shape[2] == 1:\n",
    "                    outputs = outputs.squeeze(2)\n",
    "                \n",
    "                # NUEVO: Asegurar que outputs y targets tienen la misma forma antes de compararlos\n",
    "                # Aplicar las mismas transformaciones que en train_hybrid_model\n",
    "                if len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                    if outputs.shape[1] == targets.shape[1]:\n",
    "                        targets = targets[:, :, 0, :, :]\n",
    "                    else:\n",
    "                        # Seleccionar diagonal o promediar\n",
    "                        targets_reshaped = []\n",
    "                        for i in range(min(targets.shape[1], outputs.shape[1])):\n",
    "                            if i < targets.shape[2]:\n",
    "                                targets_reshaped.append(targets[:, i, i])\n",
    "                            else:\n",
    "                                targets_reshaped.append(targets[:, i, -1])\n",
    "                        targets = torch.stack(targets_reshaped, dim=1)\n",
    "                \n",
    "                # Ajustar longitud de secuencia si difiere\n",
    "                if len(outputs.shape) == 4 and len(targets.shape) == 4:\n",
    "                    output_seq_len = outputs.shape[1]\n",
    "                    target_seq_len = targets.shape[1]\n",
    "                    \n",
    "                    if output_seq_len > target_seq_len:\n",
    "                        outputs = outputs[:, :target_seq_len]\n",
    "                    elif output_seq_len < target_seq_len:\n",
    "                        targets = targets[:, :output_seq_len]\n",
    "                \n",
    "                # Manejar dimensiones incompatibles\n",
    "                if outputs.shape != targets.shape:\n",
    "                    # Encontrar dimensiones comunes\n",
    "                    if len(outputs.shape) == len(targets.shape):\n",
    "                        min_shape = [min(o, t) for o, t in zip(outputs.shape, targets.shape)]\n",
    "                        # Crear slices para cada dimensión\n",
    "                        slices_out = tuple(slice(0, m) for m in min_shape)\n",
    "                        slices_tgt = tuple(slice(0, m) for m in min_shape)\n",
    "                        \n",
    "                        outputs = outputs[slices_out]\n",
    "                        targets = targets[slices_tgt]\n",
    "                \n",
    "                # IMPORTANTE: Verificar que ahora tienen la misma forma\n",
    "                if outputs.shape != targets.shape:\n",
    "                    print(f\"⚠️ Advertencia: No se pudo ajustar dimensiones: outputs={outputs.shape}, targets={targets.shape}\")\n",
    "                    # En caso extremo, usar formas más simples\n",
    "                    if len(outputs.shape) > 2 and len(targets.shape) > 2:\n",
    "                        # Usar solo el primer elemento de cada secuencia/batch\n",
    "                        outputs = outputs[0:1, 0:1] if len(outputs.shape) >= 3 else outputs[0:1]\n",
    "                        targets = targets[0:1, 0:1] if len(targets.shape) >= 3 else targets[0:1]\n",
    "                        print(f\"   Usando formas simplificadas: outputs={outputs.shape}, targets={targets.shape}\")\n",
    "                \n",
    "                # Transformar a numpy para métricas\n",
    "                preds = outputs.cpu().numpy()\n",
    "                targets_np = targets.numpy()\n",
    "                \n",
    "                # Almacenar para métricas globales\n",
    "                all_targets.append(targets_np)\n",
    "                all_preds.append(preds)\n",
    "        \n",
    "        # Concatenar todas las predicciones y targets\n",
    "        try:\n",
    "            all_targets = np.concatenate(all_targets, axis=0)\n",
    "            all_preds = np.concatenate(all_preds, axis=0)\n",
    "        except ValueError as e:\n",
    "            print(f\"❌ Error al concatenar: {str(e)}\")\n",
    "            print(f\"Formas de datos: {[t.shape for t in all_targets]}\")\n",
    "            print(f\"Formas de predicciones: {[p.shape for p in all_preds]}\")\n",
    "            # Usar solo el primer batch para evitar errores de concatenación\n",
    "            all_targets = all_targets[0]\n",
    "            all_preds = all_preds[0]\n",
    "        \n",
    "        # Asegurar que las dimensiones son compatibles antes de aplanar\n",
    "        print(f\"Forma final: all_targets={all_targets.shape}, all_preds={all_preds.shape}\")\n",
    "        \n",
    "        # NUEVO: Asegurar que ambos arrays tengan la misma forma antes de aplanar\n",
    "        if all_targets.shape != all_preds.shape:\n",
    "            # Encontrar la forma más pequeña común\n",
    "            common_shape = []\n",
    "            for i in range(min(len(all_targets.shape), len(all_preds.shape))):\n",
    "                common_shape.append(min(all_targets.shape[i], all_preds.shape[i]))\n",
    "            \n",
    "            # Crear slices para recortar\n",
    "            slices = tuple(slice(0, dim) for dim in common_shape)\n",
    "            all_targets = all_targets[slices]\n",
    "            all_preds = all_preds[slices]\n",
    "            print(f\"⚠️ Ajustadas dimensiones a forma común: {all_targets.shape}\")\n",
    "        \n",
    "        # Calcular métricas\n",
    "        # Aplanar para métricas generales\n",
    "        flat_targets = all_targets.flatten()\n",
    "        flat_preds = all_preds.flatten()\n",
    "        \n",
    "        # Verificar que tengan la misma longitud\n",
    "        assert flat_targets.shape == flat_preds.shape, f\"Error: Las dimensiones siguen siendo diferentes: {flat_targets.shape} vs {flat_preds.shape}\"\n",
    "        \n",
    "        # Eliminar valores NaN si existen\n",
    "        mask = ~np.isnan(flat_targets) & ~np.isnan(flat_preds)\n",
    "        flat_targets = flat_targets[mask]\n",
    "        flat_preds = flat_preds[mask]\n",
    "        \n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(flat_targets, flat_preds)\n",
    "        rmse = np.sqrt(mean_squared_error(flat_targets, flat_preds))\n",
    "        r2 = r2_score(flat_targets, flat_preds)\n",
    "        corr = np.corrcoef(flat_targets, flat_preds)[0, 1]\n",
    "        \n",
    "        # Calcular MAPE evitando divisiones por cero\n",
    "        mask_nonzero = flat_targets != 0\n",
    "        mape = np.mean(np.abs((flat_targets[mask_nonzero] - flat_preds[mask_nonzero]) / flat_targets[mask_nonzero])) * 100\n",
    "        \n",
    "        # Almacenar métricas\n",
    "        config['metrics'] = {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape,\n",
    "            'r': corr,\n",
    "            'R²': r2\n",
    "        }\n",
    "        \n",
    "        # Almacenar modelo en el diccionario\n",
    "        config['model'] = model\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print(f\"\\nMétricas para {model_name}:\")\n",
    "        print(f\"  MAE: {mae:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  r (correlación): {corr:.4f}\")\n",
    "        print(f\"  R²: {r2:.4f}\")\n",
    "    \n",
    "    # Devolver diccionario con todos los modelos y resultados, así como el val_loader para visualizaciones\n",
    "    return models, val_loader\n",
    "\n",
    "# Función para generar visualizaciones comparativas\n",
    "def visualize_model_comparisons(models_dict, val_loader=None):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones comparativas para todos los modelos\n",
    "    \n",
    "    Args:\n",
    "        models_dict: Diccionario con modelos y sus métricas\n",
    "        val_loader: DataLoader de validación para generar predicciones\n",
    "    \n",
    "    Returns:\n",
    "        Path: Ruta al directorio con las visualizaciones\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERANDO VISUALIZACIONES COMPARATIVAS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Crear directorio para visualizaciones\n",
    "    vis_dir = MODELS_OUTPUT / 'visualization' / 'comparisons'\n",
    "    vis_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # 1. Tabla comparativa de métricas\n",
    "    model_names = list(models_dict.keys())\n",
    "    metrics = ['MAE', 'RMSE', 'MAPE (%)', 'r', 'R²']\n",
    "    \n",
    "    # Crear DataFrame para tabla\n",
    "    metrics_data = {metric: [] for metric in metrics}\n",
    "    metrics_data['Modelo'] = model_names\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        for metric in metrics:\n",
    "            value = models_dict[model_name]['metrics'].get(metric, np.nan)\n",
    "            metrics_data[metric].append(value)\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    # Mostrar tabla\n",
    "    print(\"\\n📊 TABLA COMPARATIVA DE MÉTRICAS\")\n",
    "    print(metrics_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "    \n",
    "    # Guardar como CSV\n",
    "    metrics_csv_path = vis_dir / 'metrics_comparison.csv'\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False, float_format='%.4f')\n",
    "    print(f\"\\nTabla guardada en {metrics_csv_path}\")\n",
    "    \n",
    "    # 2. Gráfico de barras comparativo de métricas\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Iterar sobre las métricas\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        values = [models_dict[model]['metrics'].get(metric, np.nan) for model in model_names]\n",
    "        \n",
    "        # Crear gráfico de barras\n",
    "        bars = plt.bar(model_names, values)\n",
    "        \n",
    "        # Añadir etiquetas de valor sobre cada barra\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{value:.4f}',\n",
    "                    ha='center', va='bottom', rotation=0, fontsize=9)\n",
    "        \n",
    "        plt.title(f'Comparación de {metric}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(alpha=0.3, axis='y')\n",
    "        \n",
    "        # Para métricas donde menor es mejor, destacar el mejor modelo\n",
    "        if metric in ['MAE', 'RMSE', 'MAPE (%)']:\n",
    "            best_idx = np.nanargmin(values)\n",
    "            bars[best_idx].set_color('green')\n",
    "        else:  # Para métricas donde mayor es mejor\n",
    "            best_idx = np.nanargmax(values)\n",
    "            bars[best_idx].set_color('green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    metrics_plot_path = vis_dir / 'metrics_comparison.png'\n",
    "    plt.savefig(metrics_plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico de métricas guardado en {metrics_plot_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Curvas de aprendizaje comparativas (mejorado con más información)\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # 3.1 Pérdidas de entrenamiento\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for model_name in model_names:\n",
    "        train_losses = models_dict[model_name].get('train_losses', [])\n",
    "        if train_losses:\n",
    "            plt.plot(train_losses, label=model_name)\n",
    "    \n",
    "    plt.title('Pérdidas de Entrenamiento')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3.2 Pérdidas de validación\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for model_name in model_names:\n",
    "        val_losses = models_dict[model_name].get('val_losses', [])\n",
    "        if val_losses:\n",
    "            plt.plot(val_losses, label=model_name)\n",
    "    \n",
    "    plt.title('Pérdidas de Validación')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3.3 Pérdidas de ambas en escala logarítmica\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for model_name in model_names:\n",
    "        train_losses = models_dict[model_name].get('train_losses', [])\n",
    "        val_losses = models_dict[model_name].get('val_losses', [])\n",
    "        if train_losses:\n",
    "            plt.semilogy(train_losses, linestyle='-', label=f'{model_name} (Train)')\n",
    "        if val_losses:\n",
    "            plt.semilogy(val_losses, linestyle='--', label=f'{model_name} (Val)')\n",
    "    \n",
    "    plt.title('Pérdidas de Entrenamiento y Validación (Log)')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida (log)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3.4 Comparación de convergencia (normalizada)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for model_name in model_names:\n",
    "        val_losses = models_dict[model_name].get('val_losses', [])\n",
    "        if val_losses and len(val_losses) > 1:\n",
    "            # Normalizar pérdidas para comparar velocidad de convergencia\n",
    "            norm_losses = [(loss - min(val_losses)) / (max(val_losses) - min(val_losses) + 1e-10) \n",
    "                          for loss in val_losses]\n",
    "            plt.plot(norm_losses, label=model_name)\n",
    "    \n",
    "    plt.title('Convergencia Normalizada (Validación)')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida Normalizada')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    learning_plot_path = vis_dir / 'learning_curves.png'\n",
    "    plt.savefig(learning_plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico de curvas de aprendizaje guardado en {learning_plot_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Si hay un DataLoader de validación, generar ejemplos de predicciones\n",
    "    if val_loader is not None and next(iter(models_dict.values())).get('model') is not None:\n",
    "        try:\n",
    "            # Obtener algunas muestras para visualizar\n",
    "            print(\"\\nGenerando ejemplos de predicciones...\")\n",
    "            \n",
    "            # Tomar un batch como ejemplo\n",
    "            sample_inputs, sample_targets = next(iter(val_loader))\n",
    "            \n",
    "            # Configurar figura para mostrar predicciones\n",
    "            fig = plt.figure(figsize=(20, 5 * len(model_names)))\n",
    "            \n",
    "            # Generar predicciones con cada modelo\n",
    "            for i, model_name in enumerate(model_names):\n",
    "                model = models_dict[model_name].get('model')\n",
    "                if model is None:\n",
    "                    continue\n",
    "                    \n",
    "                # Modo evaluación\n",
    "                model.eval()\n",
    "                \n",
    "                # Generar predicciones\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(sample_inputs.to(next(model.parameters()).device))\n",
    "                \n",
    "                # Seleccionar un ejemplo (primer item del batch)\n",
    "                if len(outputs.shape) == 5:  # [batch, seq, channel, H, W]\n",
    "                    pred = outputs[0, 0, 0].cpu().numpy()\n",
    "                elif len(outputs.shape) == 4:  # [batch, seq, H, W]\n",
    "                    pred = outputs[0, 0].cpu().numpy()\n",
    "                else:\n",
    "                    pred = outputs[0].cpu().numpy()\n",
    "                \n",
    "                # Obtener target correspondiente\n",
    "                if len(sample_targets.shape) == 5:  # [batch, seq, channel, H, W]\n",
    "                    target = sample_targets[0, 0, 0].numpy()\n",
    "                elif len(sample_targets.shape) == 4:  # [batch, seq, H, W]\n",
    "                    target = sample_targets[0, 0].numpy()\n",
    "                else:\n",
    "                    target = sample_targets[0].numpy()\n",
    "                \n",
    "                # Mostrar predicción vs real\n",
    "                plt.subplot(len(model_names), 3, i*3+1)\n",
    "                plt.imshow(target, cmap='viridis')\n",
    "                plt.colorbar(fraction=0.046, pad=0.04)\n",
    "                plt.title(f'{model_name} - Valor Real')\n",
    "                \n",
    "                plt.subplot(len(model_names), 3, i*3+2)\n",
    "                plt.imshow(pred, cmap='viridis')\n",
    "                plt.colorbar(fraction=0.046, pad=0.04)\n",
    "                plt.title(f'{model_name} - Predicción')\n",
    "                \n",
    "                plt.subplot(len(model_names), 3, i*3+3)\n",
    "                diff = target - pred\n",
    "                plt.imshow(diff, cmap='RdBu_r')\n",
    "                plt.colorbar(fraction=0.046, pad=0.04)\n",
    "                plt.title(f'{model_name} - Diferencia')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            pred_plot_path = vis_dir / 'prediction_examples.png'\n",
    "            plt.savefig(pred_plot_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Ejemplos de predicción guardados en {pred_plot_path}\")\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar ejemplos de predicción: {str(e)}\")\n",
    "    \n",
    "    return vis_dir\n",
    "\n",
    "# Verificación de datos\n",
    "try:\n",
    "    log_and_print(\"Verificando datos cargados...\")\n",
    "    \n",
    "    # Verificar que los datasets contienen los datos necesarios\n",
    "    if 'precipitacion' not in ds_full.data_vars and 'total_precipitation' not in ds_full.data_vars:\n",
    "        raise ValueError(f\"No se encontró variable de precipitación. Variables disponibles: {list(ds_full.data_vars.keys())}\")\n",
    "    \n",
    "    # Verificar que las dimensiones son las esperadas\n",
    "    if len(ds_full.dims) < 2:\n",
    "        raise ValueError(f\"Dataset con dimensiones insuficientes: {ds_full.dims}\")\n",
    "    \n",
    "    # Ejemplo de cómo examinar un punto de datos para verificar que no esté corrupto\n",
    "    sample_var = next(iter(ds_full.data_vars))\n",
    "    log_and_print(f\"Ejemplo de datos - Variable '{sample_var}', primeros valores: {ds_full[sample_var].values.flatten()[:5]}\")\n",
    "    \n",
    "    log_and_print(\"Los datos superaron las verificaciones iniciales.\")\n",
    "\n",
    "    # Preparación de datos con manejo de excepciones\n",
    "    try:\n",
    "        # Si los datos son muy grandes, podemos usar una muestra para pruebas\n",
    "        # Descomentar estas líneas para usar una muestra si hay problemas de memoria\n",
    "        # use_sample = True\n",
    "        # if use_sample:\n",
    "        #    log_and_print(\"Usando muestra de datos para pruebas...\")\n",
    "        #    ds_full = ds_full.isel(time=slice(0, min(200, len(ds_full.time))))\n",
    "        log_and_print(\"Preparando datos para entrenamiento...\")\n",
    "        X_train, y_train, X_val, y_val = prepare_train_val_data(ds_full)\n",
    "        \n",
    "        log_and_print(f\"Datos preparados exitosamente. Formas: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "        \n",
    "        # Entrenar y comparar modelos con los datos preparados\n",
    "        log_and_print(\"Iniciando entrenamiento de modelos...\")\n",
    "        comparison_models, val_loader = train_and_compare_models(X_train, y_train, X_val, y_val)\n",
    "        \n",
    "        # Generar visualizaciones\n",
    "        log_and_print(\"Generando visualizaciones comparativas...\")\n",
    "        vis_dir = visualize_model_comparisons(comparison_models, val_loader)\n",
    "        log_and_print(f\"Visualizaciones guardadas en {vis_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        log_and_print(f\"ERROR en la preparación de datos o entrenamiento: {str(e)}\")\n",
    "        log_and_print(traceback.format_exc())\n",
    "        \n",
    "        # Intentar ejecutar una versión simplificada si falla\n",
    "        log_and_print(\"Intentando ejecución con una muestra reducida...\")\n",
    "        try:\n",
    "            # Usar una muestra pequeña para diagnóstico\n",
    "            time_sample = min(100, len(ds_full.time))\n",
    "            log_and_print(f\"Usando muestra de {time_sample} puntos temporales\")\n",
    "            ds_sample = ds_full.isel(time=slice(0, time_sample))\n",
    "            \n",
    "            X_train, y_train, X_val, y_val = prepare_train_val_data(ds_sample, input_window=12, output_horizon=3)\n",
    "            log_and_print(\"Muestra de datos preparada correctamente. Probando modelo básico...\")\n",
    "            \n",
    "            # Probar solo un modelo pequeño\n",
    "            input_channels = X_train.shape[1] if len(X_train.shape) > 3 else 1\n",
    "            target_shape = y_train.shape[-2:] if len(y_train.shape) >= 3 else (61, 65)\n",
    "            \n",
    "            # Crear un modelo simple para pruebas\n",
    "            test_model = SimpleConvGRU(\n",
    "                input_channels=input_channels,\n",
    "                hidden_dim=64,  # Reducido para pruebas\n",
    "                output_channels=1,\n",
    "                seq_length=3,  # Reducido para pruebas\n",
    "                target_shape=target_shape\n",
    "            ).to(DEVICE)\n",
    "            \n",
    "            log_and_print(\"Modelo creado correctamente. Verificación completa.\")\n",
    "            \n",
    "        except Exception as nested_e:\n",
    "            log_and_print(f\"ERROR también en la ejecución simplificada: {str(nested_e)}\")\n",
    "            log_and_print(traceback.format_exc())\n",
    "            log_and_print(\"Recomendaciones para solucionar:\")\n",
    "            log_and_print(\"1. Verificar la estructura del dataset y variables disponibles\")\n",
    "            log_and_print(\"2. Revisar espacio en disco y memoria disponible\")\n",
    "            log_and_print(\"3. Comprobar que todos los archivos necesarios están presentes\")\n",
    "    \n",
    "except Exception as outer_e:\n",
    "    import traceback\n",
    "    log_and_print(f\"ERROR en verificación de datos: {str(outer_e)}\")\n",
    "    log_and_print(traceback.format_exc())\n",
    "    \n",
    "# Mantenemos sólo las funciones de preprocesamiento que aún se necesitan\n",
    "def calculate_afc(signal, lags=[1, 3, 6]):\n",
    "    \"\"\"Calcula la Función de Autocorrelación para los lags dados.\"\"\"\n",
    "    afc = [np.correlate(signal[lag:], signal[:-lag], mode='valid') for lag in lags]\n",
    "    return afc\n",
    "\n",
    "# Funciones de preprocesamiento adicionales\n",
    "def wavelet_denoise(data, wavelet='db4', level=3):\n",
    "    \"\"\"Aplica denoising wavelet a los datos.\"\"\"\n",
    "    try:\n",
    "        # API moderna de scikit-image (0.19+)\n",
    "        return denoise_wavelet(\n",
    "            data, \n",
    "            wavelet=wavelet, \n",
    "            mode='soft',\n",
    "            method='BayesShrink',\n",
    "            channel_axis=None\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en wavelet denoising: {str(e)}. Intentando método alternativo.\")\n",
    "        # Si falla, intentar solo con parámetros básicos\n",
    "        return denoise_wavelet(data, wavelet=wavelet)\n",
    "\n",
    "# 3) Definición de Datasets PyTorch\n",
    "class PrecipitationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para datos de precipitación que maneja la reducción\n",
    "    de dimensionalidad y garantiza la compatibilidad dimensional.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, target, seq_length):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).float()\n",
    "        self.seq_length = seq_length\n",
    "        self.target_shape = target.shape[1:]  # Guardar la forma objetivo (height, width)\n",
    "        \n",
    "        print(f\"Dataset inicializado - Forma de datos: {self.data.shape}\")\n",
    "        print(f\"Dataset inicializado - Forma de targets: {self.target.shape}\")\n",
    "        print(f\"Forma objetivo almacenada: {self.target_shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener secuencia de datos\n",
    "        inputs = self.data[idx:idx+self.seq_length]\n",
    "        labels = self.target[idx:idx+self.seq_length]\n",
    "        \n",
    "        # Para debugging, imprimir formas solo para el primer elemento\n",
    "        if idx == 0:\n",
    "            print(f\"Ejemplo de entrada - forma original: {inputs.shape}\")\n",
    "            \n",
    "        # Simplificar dimensiones si es posible\n",
    "        if len(inputs.shape) > 3 and inputs.shape[1] == 1:  # Si hay una sola ventana/característica\n",
    "            inputs = inputs.squeeze(1)  # Eliminar dimensión redundante \n",
    "            \n",
    "        # Para debugging\n",
    "        if idx == 0:\n",
    "            print(f\"Ejemplo de entrada - forma final: {inputs.shape}\")\n",
    "            print(f\"Ejemplo de etiqueta: {labels.shape}\")\n",
    "            \n",
    "        return inputs, labels\n",
    "\n",
    "# 4) Modelos Híbridos: ConvBiGRU-AE y ConvLSTM-AE\n",
    "class ConvBiGRU_AE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, num_layers, output_channels, seq_length, target_shape=(61, 65), kernel_size=3, padding=1):\n",
    "        super(ConvBiGRU_AE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.target_shape = target_shape  # Guardar la forma objetivo\n",
    "        \n",
    "        # Encoder - Convoluciones 2D para cada paso de tiempo\n",
    "        # En lugar de esperar múltiples canales, procesaremos cada paso de tiempo independientemente\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm2 = nn.InstanceNorm2d(hidden_dim)\n",
    "        \n",
    "        # GRU para procesar la secuencia comprimida\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.dnorm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_dim, output_channels * seq_length, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        # Usar la forma objetivo proporcionada o la predeterminada\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "        \n",
    "        # Manejar entradas con diferentes dimensiones\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = None\n",
    "        H = None\n",
    "        W = None\n",
    "        \n",
    "        # NUEVO: Manejar caso de 6 dimensiones [batch, seq, window, channel, H, W]\n",
    "        if len(x.shape) == 6:\n",
    "            batch_size, seq_len, window, channels, H, W = x.shape\n",
    "            # Combinar window y channels para simplificar\n",
    "            x = x.permute(0, 1, 3, 2, 4, 5).contiguous()  # [batch, seq, channel, window, H, W]\n",
    "            x = x.reshape(batch_size, seq_len, channels*window, H, W)\n",
    "            # Ahora x tiene forma [batch, seq, channel*window, H, W]\n",
    "            # Tomar solo el primer canal por simplicidad\n",
    "            x = x[:, :, 0, :, :]  # [batch, seq, H, W]\n",
    "            \n",
    "        elif len(x.shape) > 4:  # Manejar caso con más dimensiones (por ejemplo, dimensión de canal)\n",
    "            if len(x.shape) == 5:  # [batch, seq, channel, H, W]\n",
    "                seq_len = x.size(1)\n",
    "                # Combinar dimensión de canal con características (enfoque simplificado)\n",
    "                # Asumiendo canal=1 o permitiendo solo el primer canal\n",
    "                x = x[:, :, 0, :, :]  # Tomar primer canal\n",
    "            else:\n",
    "                raise ValueError(f\"Forma de entrada no soportada: {x.shape}\")\n",
    "                \n",
    "        elif len(x.shape) < 4:  # Manejar caso con menos dimensiones\n",
    "            # Añadir dimensiones faltantes\n",
    "            if len(x.shape) == 3:  # [batch, H, W]\n",
    "                # Añadir dimensión de secuencia (asumiendo seq_len=1)\n",
    "                x = x.unsqueeze(1)\n",
    "                seq_len = 1\n",
    "            else:\n",
    "                raise ValueError(f\"Forma de entrada no soportada: {x.shape}\")\n",
    "                \n",
    "        else:\n",
    "            # Forma esperada: [batch_size, seq_length, height, width]\n",
    "            batch_size, seq_len, H, W = x.size()\n",
    "        \n",
    "        # Obtener dimensiones espaciales después de la reorganización\n",
    "        if H is None or W is None:  # Si aún no se han establecido\n",
    "            _, _, H, W = x.size()\n",
    "\n",
    "        # Procesar cada paso de tiempo individualmente\n",
    "        processed_features = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Obtener el paso de tiempo actual y añadir dimensión de canal\n",
    "            x_t = x[:, t].unsqueeze(1)  # [batch_size, 1, height, width]\n",
    "            \n",
    "            # Aplicar convoluciones\n",
    "            x_t = F.relu(self.norm1(self.conv1(x_t)))\n",
    "            x_t = F.relu(self.norm2(self.conv2(x_t)))\n",
    "            \n",
    "            # Promedio espacial para reducir a [batch_size, hidden_dim]\n",
    "            x_t_features = x_t.mean(dim=(2, 3))\n",
    "            \n",
    "            # Almacenar características para este paso de tiempo\n",
    "            processed_features.append(x_t_features)\n",
    "        \n",
    "        # Concatenar características para todos los pasos de tiempo\n",
    "        sequence_features = torch.stack(processed_features, dim=1)  # [batch_size, seq_length, hidden_dim]\n",
    "        \n",
    "        # Aplicar GRU a la secuencia\n",
    "        output, _ = self.gru(sequence_features)  # [batch_size, seq_length, hidden_dim*2]\n",
    "        \n",
    "        # Tomar el último estado y preparar para deconv\n",
    "        output = output[:, -1, :].view(batch_size, self.hidden_dim*2, 1, 1)\n",
    "        output = F.interpolate(output, size=(H, W), mode='nearest')\n",
    "        \n",
    "        # Decoder\n",
    "        output = F.relu(self.dnorm1(self.deconv1(output)))\n",
    "        output = self.deconv2(output)  # [batch_size, seq_length*output_channels, H, W]\n",
    "        \n",
    "        # Reorganizar para obtener [batch_size, seq_length, output_channels, H, W]\n",
    "        output = output.view(batch_size, self.seq_length, self.output_channels, H, W)\n",
    "        \n",
    "        # Redimensionar a la forma objetivo usando interpolación bilineal\n",
    "        # Primero reorganizamos para [batch_size*seq_length, output_channels, H, W]\n",
    "        output_reshaped = output.view(batch_size * self.seq_length, self.output_channels, H, W)\n",
    "        output_resized = F.interpolate(output_reshaped, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Reorganizar de nuevo a [batch_size, seq_length, output_channels, target_H, target_W]\n",
    "        output = output_resized.view(batch_size, self.seq_length, self.output_channels, target_shape[0], target_shape[1])\n",
    "        \n",
    "        return output\n",
    "\n",
    "class ConvBiLSTM_AE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, num_layers, output_channels, seq_length, target_shape=(61, 65), kernel_size=3, padding=1):\n",
    "        super(ConvBiLSTM_AE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.target_shape = target_shape  # Guardar la forma objetivo\n",
    "        \n",
    "        # Encoder para procesar cada paso de tiempo individualmente\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm2 = nn.InstanceNorm2d(hidden_dim)\n",
    "        \n",
    "        # LSTM para procesar la secuencia\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.dnorm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_dim, output_channels * seq_length, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        # Usar la forma objetivo proporcionada o la predeterminada\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "            \n",
    "        # Manejar entradas con diferentes dimensiones\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = None\n",
    "        H = None\n",
    "        W = None\n",
    "        \n",
    "        # NUEVO: Manejar caso de 6 dimensiones [batch, seq, window, channel, H, W]\n",
    "        if len(x.shape) == 6:\n",
    "            batch_size, seq_len, window, channels, H, W = x.shape\n",
    "            # Combinar window y channels para simplificar\n",
    "            x = x.permute(0, 1, 3, 2, 4, 5).contiguous()  # [batch, seq, channel, window, H, W]\n",
    "            x = x.reshape(batch_size, seq_len, channels*window, H, W)\n",
    "            # Ahora x tiene forma [batch, seq, channel*window, H, W]\n",
    "            # Tomar solo el primer canal por simplicidad\n",
    "            x = x[:, :, 0, :, :]  # [batch, seq, H, W]\n",
    "            \n",
    "        elif len(x.shape) > 4:  # Manejar caso con más dimensiones (por ejemplo, dimensión de canal)\n",
    "            if len(x.shape) == 5:  # [batch, seq, channel, H, W]\n",
    "                seq_len = x.size(1)\n",
    "                # Combinar dimensión de canal con características (enfoque simplificado)\n",
    "                # Asumiendo canal=1 o permitiendo solo el primer canal\n",
    "                x = x[:, :, 0, :, :]  # Tomar primer canal\n",
    "            else:\n",
    "                raise ValueError(f\"Forma de entrada no soportada: {x.shape}\")\n",
    "                \n",
    "        elif len(x.shape) < 4:  # Manejar caso con menos dimensiones\n",
    "            # Añadir dimensiones faltantes\n",
    "            if len(x.shape) == 3:  # [batch, H, W]\n",
    "                # Añadir dimensión de secuencia (asumiendo seq_len=1)\n",
    "                x = x.unsqueeze(1)\n",
    "                seq_len = 1\n",
    "            else:\n",
    "                raise ValueError(f\"Forma de entrada no soportada: {x.shape}\")\n",
    "                \n",
    "        else:\n",
    "            # Forma esperada: [batch_size, seq_length, height, width]\n",
    "            batch_size, seq_len, H, W = x.size()\n",
    "        \n",
    "        # Obtener dimensiones espaciales después de la reorganización\n",
    "        if H is None or W is None:  # Si aún no se han establecido\n",
    "            _, _, H, W = x.size()\n",
    "\n",
    "        # Procesar cada paso de tiempo individualmente\n",
    "        processed_features = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Obtener el paso de tiempo actual y añadir dimensión de canal\n",
    "            x_t = x[:, t].unsqueeze(1)  # [batch_size, 1, height, width]\n",
    "            \n",
    "            # Aplicar convoluciones\n",
    "            x_t = F.relu(self.norm1(self.conv1(x_t)))\n",
    "            x_t = F.relu(self.norm2(self.conv2(x_t)))\n",
    "            \n",
    "            # Extraer características globales\n",
    "            # Promedio espacial para reducir a [batch_size, hidden_dim]\n",
    "            x_t_features = x_t.mean(dim=(2, 3))\n",
    "            \n",
    "            # Almacenar características para este paso de tiempo\n",
    "            processed_features.append(x_t_features)\n",
    "        \n",
    "        # Concatenar características para todos los pasos de tiempo\n",
    "        sequence_features = torch.stack(processed_features, dim=1)  # [batch_size, seq_length, hidden_dim]\n",
    "        \n",
    "        # Aplicar LSTM a la secuencia\n",
    "        output, _ = self.lstm(sequence_features)  # [batch_size, seq_length, hidden_dim*2]\n",
    "        \n",
    "        # Tomar el último estado y preparar para deconv\n",
    "        output = output[:, -1, :].view(batch_size, self.hidden_dim*2, 1, 1)\n",
    "        output = F.interpolate(output, size=(H, W), mode='nearest')\n",
    "        \n",
    "        # Decoder\n",
    "        output = F.relu(self.dnorm1(self.deconv1(output)))\n",
    "        output = self.deconv2(output)  # [batch_size, seq_length*output_channels, H, W]\n",
    "        \n",
    "        # Reorganizar para obtener [batch_size, seq_length, output_channels, H, W]\n",
    "        output = output.view(batch_size, self.seq_length, self.output_channels, H, W)\n",
    "        \n",
    "        # Redimensionar a la forma objetivo usando interpolación bilineal\n",
    "        output_reshaped = output.view(batch_size * self.seq_length, self.output_channels, H, W)\n",
    "        output_resized = F.interpolate(output_reshaped, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        output = output_resized.view(batch_size, self.seq_length, self.output_channels, target_shape[0], target_shape[1])\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 4.5) Modelos ConvGRU y ConvLSTM simples para comparación\n",
    "class SimpleConvGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo simple ConvGRU para comparar con los modelos híbridos.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_dim, output_channels, seq_length=12, target_shape=(61, 65)):\n",
    "        super(SimpleConvGRU, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.seq_length = seq_length\n",
    "        self.target_shape = target_shape\n",
    "        \n",
    "        # Capas convolucionales para procesar entrada\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_dim // 2, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_dim // 2)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim // 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        \n",
    "        # Capa GRU\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_dim * target_shape[0] * target_shape[1], \n",
    "            hidden_size=hidden_dim * 4, \n",
    "            num_layers=2, \n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Capas para generar salida\n",
    "        self.upconv1 = nn.Conv2d(hidden_dim * 4, hidden_dim * 2, kernel_size=3, padding=1)\n",
    "        self.upbn1 = nn.BatchNorm2d(hidden_dim * 2)\n",
    "        self.upconv2 = nn.Conv2d(hidden_dim * 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.upbn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        \n",
    "        # Capa final para generar múltiples horizontes de predicción\n",
    "        self.out_conv = nn.Conv2d(hidden_dim, output_channels * seq_length, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor de entrada que puede tener varias formas:\n",
    "               - [batch_size, seq_len, input_window, channels, height, width]\n",
    "               - [batch_size, seq_len, channels, height, width]\n",
    "               - [batch_size, channels, height, width]\n",
    "            target_shape: Forma objetivo para la salida\n",
    "        \"\"\"\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "        \n",
    "        # NUEVO: Manejar el caso de 6 dimensiones [batch, seq, window, channel, H, W]\n",
    "        if len(x.shape) == 6:  \n",
    "            batch_size, seq_len, window, channels, H, W = x.shape\n",
    "            \n",
    "            # Reorganizar a [batch, seq, channels*window, H, W] combinando window y channels\n",
    "            x = x.permute(0, 1, 3, 2, 4, 5).contiguous()  # [batch, seq, channel, window, H, W]\n",
    "            x = x.view(batch_size, seq_len, channels*window, H, W)  # [batch, seq, channel*window, H, W]\n",
    "            \n",
    "            # Procesar cada paso de tiempo independientemente\n",
    "            processed_features = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                # Extraer slice temporal: [batch, channels*window, H, W]\n",
    "                xt = x[:, t]\n",
    "                \n",
    "                # Aplicar convoluciones\n",
    "                xt = F.relu(self.bn1(self.conv1(xt)))\n",
    "                xt = F.relu(self.bn2(self.conv2(xt)))\n",
    "                \n",
    "                # Aplanar para GRU: [batch, hidden_dim*H*W]\n",
    "                xt = xt.view(batch_size, -1)\n",
    "                processed_features.append(xt)\n",
    "            \n",
    "            # Stack para secuencia: [batch, seq_len, features]\n",
    "            x_sequence = torch.stack(processed_features, dim=1)\n",
    "            \n",
    "            # Aplicar GRU\n",
    "            gru_out, _ = self.gru(x_sequence)\n",
    "            \n",
    "            # Tomar último estado\n",
    "            last_out = gru_out[:, -1]  # [batch, hidden_dim*4]\n",
    "            \n",
    "        # Verificar y manejar diferentes formas de entrada\n",
    "        elif len(x.shape) == 5:  # [batch, seq_len, channels, height, width]\n",
    "            batch_size = x.size(0)\n",
    "            seq_len = x.size(1)\n",
    "            \n",
    "            # Procesar cada paso de tiempo independientemente\n",
    "            processed_features = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                # Extraer slice temporal: [batch, channels, H, W]\n",
    "                xt = x[:, t]\n",
    "                \n",
    "                # Aplicar convoluciones\n",
    "                xt = F.relu(self.bn1(self.conv1(xt)))\n",
    "                xt = F.relu(self.bn2(self.conv2(xt)))\n",
    "                \n",
    "                # Aplanar para GRU: [batch, hidden_dim*H*W]\n",
    "                xt = xt.view(batch_size, -1)\n",
    "                processed_features.append(xt)\n",
    "            \n",
    "            # Stack para secuencia: [batch, seq_len, features]\n",
    "            x_sequence = torch.stack(processed_features, dim=1)\n",
    "            \n",
    "            # Aplicar GRU\n",
    "            gru_out, _ = self.gru(x_sequence)\n",
    "            \n",
    "            # Tomar último estado\n",
    "            last_out = gru_out[:, -1]  # [batch, hidden_dim*4]\n",
    "            \n",
    "        elif len(x.shape) == 4:  # [batch, channels, height, width] (sin dimensión de secuencia)\n",
    "            batch_size = x.size(0)\n",
    "            \n",
    "            # Aplicar convoluciones directamente\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = F.relu(self.bn2(self.conv2(x)))\n",
    "            \n",
    "            # Aplanar\n",
    "            x_flat = x.view(batch_size, -1)\n",
    "            \n",
    "            # Añadir dimensión de secuencia ficticia\n",
    "            x_sequence = x_flat.unsqueeze(1)  # [batch, 1, features]\n",
    "            \n",
    "            # Aplicar GRU\n",
    "            gru_out, _ = self.gru(x_sequence)\n",
    "            \n",
    "            # Tomar salida\n",
    "            last_out = gru_out[:, -1]  # [batch, hidden_dim*4]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Forma de entrada no soportada: {x.shape}\")\n",
    "        \n",
    "        # Reformar para procesamiento convolucional\n",
    "        last_out = last_out.view(batch_size, self.hidden_dim * 4, 1, 1)\n",
    "        last_out = F.interpolate(last_out, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Capas finales\n",
    "        out = F.relu(self.upbn1(self.upconv1(last_out)))\n",
    "        out = F.relu(self.upbn2(self.upconv2(out)))\n",
    "        out = self.out_conv(out)\n",
    "        \n",
    "        # Reorganizar para obtener [batch, seq_len, channels, H, W]\n",
    "        out = out.view(batch_size, self.seq_length, self.output_channels, *target_shape)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "class SimpleConvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo simple ConvLSTM para comparar con los modelos híbridos.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_dim, output_channels, seq_length=12, target_shape=(61, 65)):\n",
    "        super(SimpleConvLSTM, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.seq_length = seq_length\n",
    "        self.target_shape = target_shape\n",
    "        \n",
    "        # Capas convolucionales para procesar entrada\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_dim // 2, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_dim // 2)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim // 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        \n",
    "        # Capa LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim * target_shape[0] * target_shape[1], \n",
    "            hidden_size=hidden_dim * 4, \n",
    "            num_layers=2, \n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Capas para generar salida\n",
    "        self.upconv1 = nn.Conv2d(hidden_dim * 4, hidden_dim * 2, kernel_size=3, padding=1)\n",
    "        self.upbn1 = nn.BatchNorm2d(hidden_dim * 2)\n",
    "        self.upconv2 = nn.Conv2d(hidden_dim * 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.upbn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        \n",
    "        # Capa final para generar múltiples horizontes de predicción\n",
    "        self.out_conv = nn.Conv2d(hidden_dim, output_channels * seq_length, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor de entrada que puede tener varias formas:\n",
    "               - [batch_size, seq_len, input_window, channels, height, width]\n",
    "               - [batch_size, seq_len, channels, height, width]\n",
    "               - [batch_size, channels, height, width]\n",
    "            target_shape: Forma objetivo para la salida\n",
    "        \"\"\"\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "            \n",
    "        # NUEVO: Manejar el caso de 6 dimensiones [batch, seq, window, channel, H, W]\n",
    "        if len(x.shape) == 6:  \n",
    "            batch_size, seq_len, window, channels, H, W = x.shape\n",
    "            \n",
    "            # Reorganizar a [batch, seq, channels*window, H, W] combinando window y channels\n",
    "            x = x.permute(0, 1, 3, 2, 4, 5).contiguous()  # [batch, seq, channel, window, H, W]\n",
    "            x = x.view(batch_size, seq_len, channels*window, H, W)  # [batch, seq, channel*window, H, W]\n",
    "            \n",
    "            # Procesar cada paso de tiempo independientemente\n",
    "            processed_features = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                # Extraer slice temporal: [batch, channels*window, H, W]\n",
    "                xt = x[:, t]\n",
    "                \n",
    "                # Aplicar convoluciones\n",
    "                xt = F.relu(self.bn1(self.conv1(xt)))\n",
    "                xt = F.relu(self.bn2(self.conv2(xt)))\n",
    "                \n",
    "                # Aplanar para LSTM: [batch, hidden_dim*H*W]\n",
    "                xt = xt.view(batch_size, -1)\n",
    "                processed_features.append(xt)\n",
    "            \n",
    "            # Stack para secuencia: [batch, seq_len, features]\n",
    "            x_sequence = torch.stack(processed_features, dim=1)\n",
    "            \n",
    "            # Aplicar LSTM\n",
    "            lstm_out, _ = self.lstm(x_sequence)\n",
    "            \n",
    "            # Tomar último estado\n",
    "            last_out = lstm_out[:, -1]  # [batch, hidden_dim*4]\n",
    "            \n",
    "        # Verificar y manejar diferentes formas de entrada\n",
    "        elif len(x.shape) == 5:  # [batch, seq_len, channels, height, width]\n",
    "            batch_size = x.size(0)\n",
    "            seq_len = x.size(1)\n",
    "            \n",
    "            # Procesar cada paso de tiempo independientemente\n",
    "            processed_features = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                # Extraer slice temporal: [batch, channels, H, W]\n",
    "                xt = x[:, t]\n",
    "                \n",
    "                # Aplicar convoluciones\n",
    "                xt = F.relu(self.bn1(self.conv1(xt)))\n",
    "                xt = F.relu(self.bn2(self.conv2(xt)))\n",
    "                \n",
    "                # Aplanar para LSTM: [batch, hidden_dim*H*W]\n",
    "                xt = xt.view(batch_size, -1)\n",
    "                processed_features.append(xt)\n",
    "            \n",
    "            # Stack para secuencia: [batch, seq_len, features]\n",
    "            x_sequence = torch.stack(processed_features, dim=1)\n",
    "            \n",
    "            # Aplicar LSTM\n",
    "            lstm_out, _ = self.lstm(x_sequence)\n",
    "            \n",
    "            # Tomar último estado\n",
    "            last_out = lstm_out[:, -1]  # [batch, hidden_dim*4]\n",
    "            \n",
    "        elif len(x.shape) == 4:  # [batch, channels, height, width] (sin dimensión de secuencia)\n",
    "            batch_size = x.size(0)\n",
    "            \n",
    "            # Aplicar convoluciones directamente\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = F.relu(self.bn2(self.conv2(x)))\n",
    "            \n",
    "            # Aplanar\n",
    "            x_flat = x.view(batch_size, -1)\n",
    "            \n",
    "            # Añadir dimensión de secuencia ficticia\n",
    "            x_sequence = x_flat.unsqueeze(1)  # [batch, 1, features]\n",
    "            \n",
    "            # Aplicar LSTM\n",
    "            lstm_out, _ = self.lstm(x_sequence)\n",
    "            \n",
    "            # Tomar salida\n",
    "            last_out = lstm_out[:, -1]  # [batch, hidden_dim*4]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Forma de entrada no soportada: {x.shape}\")\n",
    "        \n",
    "        # Reformar para procesamiento convolucional\n",
    "        last_out = last_out.view(batch_size, self.hidden_dim * 4, 1, 1)\n",
    "        last_out = F.interpolate(last_out, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Capas finales\n",
    "        out = F.relu(self.upbn1(self.upconv1(last_out)))\n",
    "        out = F.relu(self.upbn2(self.upconv2(out)))\n",
    "        out = self.out_conv(out)\n",
    "        \n",
    "        # Reorganizar para obtener [batch, seq_len, channels, H, W]\n",
    "        out = out.view(batch_size, self.seq_length, self.output_channels, *target_shape)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Función para entrenar y evaluar todos los modelos disponibles\n",
    "def train_and_compare_models(X_train, y_train, X_val, y_val, force_retrain=False):\n",
    "    \"\"\"\n",
    "    Entrena y compara modelos simples y híbridos usando las mismas entradas.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Datos de entrenamiento\n",
    "        y_train: Etiquetas de entrenamiento\n",
    "        X_val: Datos de validación\n",
    "        y_val: Etiquetas de validación\n",
    "        force_retrain: Si reentrenar aunque existan modelos guardados\n",
    "    \n",
    "    Returns:\n",
    "        dict, DataLoader: Diccionario con modelos entrenados y sus métricas, y el DataLoader de validación\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ENTRENAMIENTO Y COMPARACIÓN DE MODELOS SIMPLES Y HÍBRIDOS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Directorios para guardar modelos\n",
    "    models_dir = MODELS_OUTPUT / 'comparison_models'\n",
    "    models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Parámetros comunes\n",
    "    input_channels = X_train.shape[1] if len(X_train.shape) > 3 else 1\n",
    "    hidden_dim = 128\n",
    "    output_channels = 1\n",
    "    seq_length = OUTPUT_HORIZON\n",
    "    \n",
    "    # Obtener shape de target si está disponible\n",
    "    if len(y_train.shape) >= 3:\n",
    "        target_shape = y_train.shape[-2:]\n",
    "    else:\n",
    "        target_shape = (61, 65)  # valores por defecto\n",
    "    \n",
    "    print(f\"Configuración común: input_channels={input_channels}, hidden_dim={hidden_dim}, output_channels={output_channels}\")\n",
    "    print(f\"Secuencia: {seq_length}, target_shape: {target_shape}\")\n",
    "    \n",
    "    # Definir los modelos a entrenar con sus rutas de guardado\n",
    "    models = {\n",
    "        'SimpleConvGRU': {\n",
    "            'class': SimpleConvGRU,\n",
    "            'path': models_dir / 'simple_convgru.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'SimpleConvLSTM': {\n",
    "            'class': SimpleConvLSTM,\n",
    "            'path': models_dir / 'simple_convlstm.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'ConvBiGRU-AE': {\n",
    "            'class': ConvBiGRU_AE,\n",
    "            'path': models_dir / 'convbigru_ae.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'num_layers': 3,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'ConvBiLSTM-AE': {\n",
    "            'class': ConvBiLSTM_AE,\n",
    "            'path': models_dir / 'convbilstm_ae.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'num_layers': 3,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Crear datasets y dataloaders\n",
    "    train_dataset = PrecipitationDataset(X_train, y_train, seq_length)\n",
    "    val_dataset = PrecipitationDataset(X_val, y_val, seq_length)\n",
    "    \n",
    "    batch_size = 16\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Iterar sobre cada modelo\n",
    "    for model_name, config in models.items():\n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(f\"PROCESANDO MODELO: {model_name}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        # Verificar si existe modelo guardado\n",
    "        if config['path'].exists() and not force_retrain:\n",
    "            print(f\"Modelo encontrado en {config['path']}, cargando...\")\n",
    "            try:\n",
    "                # Cargar modelo existente\n",
    "                model = config['class'](**config['params']).to(DEVICE)\n",
    "                checkpoint = torch.load(config['path'], map_location=DEVICE)\n",
    "                \n",
    "                # Verificar contenido del checkpoint\n",
    "                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "                    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                    config['train_losses'] = checkpoint.get('train_losses', [])\n",
    "                    config['val_losses'] = checkpoint.get('val_losses', [])\n",
    "                else:\n",
    "                    # Formato antiguo (solo state_dict)\n",
    "                    model.load_state_dict(checkpoint)\n",
    "                \n",
    "                print(f\"✅ Modelo {model_name} cargado correctamente\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error al cargar modelo: {str(e)}\")\n",
    "                print(\"Entrenando el modelo desde cero...\")\n",
    "                \n",
    "                # Instanciar modelo\n",
    "                model = config['class'](**config['params']).to(DEVICE)\n",
    "                \n",
    "                # Configurar entrenamiento\n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "                scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "                \n",
    "                # Entrenar modelo\n",
    "                model, train_losses, val_losses = train_hybrid_model(\n",
    "                    name=model_name,\n",
    "                    model=model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    epochs=100,\n",
    "                    patience=20,\n",
    "                    optimizer=optimizer,\n",
    "                    criterion=criterion,\n",
    "                    scheduler=scheduler\n",
    "                )\n",
    "                \n",
    "                # Guardar historial de pérdidas\n",
    "                config['train_losses'] = train_losses\n",
    "                config['val_losses'] = val_losses\n",
    "                \n",
    "                # Guardar modelo\n",
    "                save_data = {\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses\n",
    "                }\n",
    "                torch.save(save_data, config['path'])\n",
    "        else:\n",
    "            # Entrenar modelo\n",
    "            print(f\"Entrenando {model_name} desde cero...\")\n",
    "            \n",
    "            # Instanciar modelo\n",
    "            model = config['class'](**config['params']).to(DEVICE)\n",
    "            \n",
    "            # Configurar entrenamiento\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "            \n",
    "            # Entrenar modelo\n",
    "            model, train_losses, val_losses, learning_rates = train_hybrid_model(\n",
    "                name=model_name,\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                epochs=100,\n",
    "                patience=20,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                scheduler=scheduler,\n",
    "                generate_plots=True\n",
    "            )\n",
    "            \n",
    "            # Guardar historial de pérdidas\n",
    "            config['train_losses'] = train_losses\n",
    "            config['val_losses'] = val_losses\n",
    "            \n",
    "            # Guardar modelo\n",
    "            save_data = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses,\n",
    "                'learning_rates': learning_rates\n",
    "            }\n",
    "            torch.save(save_data, config['path'])\n",
    "        \n",
    "        # Evaluar modelo con métricas adicionales\n",
    "        print(f\"Evaluando {model_name} con métricas adicionales...\")\n",
    "        model.eval()\n",
    "        \n",
    "        all_targets = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Asegurar dimensión de canal si es necesario\n",
    "                if len(outputs.shape) == 5 and outputs.shape[2] == 1:\n",
    "                    outputs = outputs.squeeze(2)\n",
    "                \n",
    "                # NUEVO: Asegurar que outputs y targets tienen la misma forma antes de compararlos\n",
    "                # Aplicar las mismas transformaciones que en train_hybrid_model\n",
    "                if len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                    if outputs.shape[1] == targets.shape[1]:\n",
    "                        targets = targets[:, :, 0, :, :]\n",
    "                    else:\n",
    "                        # Seleccionar diagonal o promediar\n",
    "                        targets_reshaped = []\n",
    "                        for i in range(min(targets.shape[1], outputs.shape[1])):\n",
    "                            if i < targets.shape[2]:\n",
    "                                targets_reshaped.append(targets[:, i, i])\n",
    "                            else:\n",
    "                                targets_reshaped.append(targets[:, i, -1])\n",
    "                        targets = torch.stack(targets_reshaped, dim=1)\n",
    "                \n",
    "                # Ajustar longitud de secuencia si difiere\n",
    "                if len(outputs.shape) == 4 and len(targets.shape) == 4:\n",
    "                    output_seq_len = outputs.shape[1]\n",
    "                    target_seq_len = targets.shape[1]\n",
    "                    \n",
    "                    if output_seq_len > target_seq_len:\n",
    "                        outputs = outputs[:, :target_seq_len]\n",
    "                    elif output_seq_len < target_seq_len:\n",
    "                        targets = targets[:, :output_seq_len]\n",
    "                \n",
    "                # Manejar dimensiones incompatibles\n",
    "                if outputs.shape != targets.shape:\n",
    "                    # Encontrar dimensiones comunes\n",
    "                    if len(outputs.shape) == len(targets.shape):\n",
    "                        min_shape = [min(o, t) for o, t in zip(outputs.shape, targets.shape)]\n",
    "                        # Crear slices para cada dimensión\n",
    "                        slices_out = tuple(slice(0, m) for m in min_shape)\n",
    "                        slices_tgt = tuple(slice(0, m) for m in min_shape)\n",
    "                        \n",
    "                        outputs = outputs[slices_out]\n",
    "                        targets = targets[slices_tgt]\n",
    "                \n",
    "                # IMPORTANTE: Verificar que ahora tienen la misma forma\n",
    "                if outputs.shape != targets.shape:\n",
    "                    print(f\"⚠️ Advertencia: No se pudo ajustar dimensiones: outputs={outputs.shape}, targets={targets.shape}\")\n",
    "                    # En caso extremo, usar formas más simples\n",
    "                    if len(outputs.shape) > 2 and len(targets.shape) > 2:\n",
    "                        # Usar solo el primer elemento de cada secuencia/batch\n",
    "                        outputs = outputs[0:1, 0:1] if len(outputs.shape) >= 3 else outputs[0:1]\n",
    "                        targets = targets[0:1, 0:1] if len(targets.shape) >= 3 else targets[0:1]\n",
    "                        print(f\"   Usando formas simplificadas: outputs={outputs.shape}, targets={targets.shape}\")\n",
    "                \n",
    "                # Transformar a numpy para métricas\n",
    "                preds = outputs.cpu().numpy()\n",
    "                targets_np = targets.numpy()\n",
    "                \n",
    "                # Almacenar para métricas globales\n",
    "                all_targets.append(targets_np)\n",
    "                all_preds.append(preds)\n",
    "        \n",
    "        # Concatenar todas las predicciones y targets\n",
    "        try:\n",
    "            all_targets = np.concatenate(all_targets, axis=0)\n",
    "            all_preds = np.concatenate(all_preds, axis=0)\n",
    "        except ValueError as e:\n",
    "            print(f\"❌ Error al concatenar: {str(e)}\")\n",
    "            print(f\"Formas de datos: {[t.shape for t in all_targets]}\")\n",
    "            print(f\"Formas de predicciones: {[p.shape for p in all_preds]}\")\n",
    "            # Usar solo el primer batch para evitar errores de concatenación\n",
    "            all_targets = all_targets[0]\n",
    "            all_preds = all_preds[0]\n",
    "        \n",
    "        # Asegurar que las dimensiones son compatibles antes de aplanar\n",
    "        print(f\"Forma final: all_targets={all_targets.shape}, all_preds={all_preds.shape}\")\n",
    "        \n",
    "        # NUEVO: Asegurar que ambos arrays tengan la misma forma antes de aplanar\n",
    "        if all_targets.shape != all_preds.shape:\n",
    "            # Encontrar la forma más pequeña común\n",
    "            common_shape = []\n",
    "            for i in range(min(len(all_targets.shape), len(all_preds.shape))):\n",
    "                common_shape.append(min(all_targets.shape[i], all_preds.shape[i]))\n",
    "            \n",
    "            # Crear slices para recortar\n",
    "            slices = tuple(slice(0, dim) for dim in common_shape)\n",
    "            all_targets = all_targets[slices]\n",
    "            all_preds = all_preds[slices]\n",
    "            print(f\"⚠️ Ajustadas dimensiones a forma común: {all_targets.shape}\")\n",
    "        \n",
    "        # Calcular métricas\n",
    "        # Aplanar para métricas generales\n",
    "        flat_targets = all_targets.flatten()\n",
    "        flat_preds = all_preds.flatten()\n",
    "        \n",
    "        # Verificar que tengan la misma longitud\n",
    "        assert flat_targets.shape == flat_preds.shape, f\"Error: Las dimensiones siguen siendo diferentes: {flat_targets.shape} vs {flat_preds.shape}\"\n",
    "        \n",
    "        # Eliminar valores NaN si existen\n",
    "        mask = ~np.isnan(flat_targets) & ~np.isnan(flat_preds)\n",
    "        flat_targets = flat_targets[mask]\n",
    "        flat_preds = flat_preds[mask]\n",
    "        \n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(flat_targets, flat_preds)\n",
    "        rmse = np.sqrt(mean_squared_error(flat_targets, flat_preds))\n",
    "        r2 = r2_score(flat_targets, flat_preds)\n",
    "        corr = np.corrcoef(flat_targets, flat_preds)[0, 1]\n",
    "        \n",
    "        # Calcular MAPE evitando divisiones por cero\n",
    "        mask_nonzero = flat_targets != 0\n",
    "        mape = np.mean(np.abs((flat_targets[mask_nonzero] - flat_preds[mask_nonzero]) / flat_targets[mask_nonzero])) * 100\n",
    "        \n",
    "        # Almacenar métricas\n",
    "        config['metrics'] = {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape,\n",
    "            'r': corr,\n",
    "            'R²': r2\n",
    "        }\n",
    "        \n",
    "        # Almacenar modelo en el diccionario\n",
    "        config['model'] = model\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print(f\"\\nMétricas para {model_name}:\")\n",
    "        print(f\"  MAE: {mae:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  r (correlación): {corr:.4f}\")\n",
    "        print(f\"  R²: {r2:.4f}\")\n",
    "    \n",
    "    # Devolver diccionario con todos los modelos y resultados, así como el val_loader para visualizaciones\n",
    "    return models, val_loader\n",
    "\n",
    "# Función para generar visualizaciones comparativas\n",
    "def visualize_model_comparisons(models_dict, val_loader=None):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones comparativas para todos los modelos\n",
    "    \n",
    "    Args:\n",
    "        models_dict: Diccionario con modelos y sus métricas\n",
    "        val_loader: DataLoader de validación para generar predicciones\n",
    "    \n",
    "    Returns:\n",
    "        Path: Ruta al directorio con las visualizaciones\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERANDO VISUALIZACIONES COMPARATIVAS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Crear directorio para visualizaciones\n",
    "    vis_dir = MODELS_OUTPUT / 'visualization' / 'comparisons'\n",
    "    vis_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # 1. Tabla comparativa de métricas\n",
    "    model_names = list(models_dict.keys())\n",
    "    metrics = ['MAE', 'RMSE', 'MAPE (%)', 'r', 'R²']\n",
    "    \n",
    "    # Crear DataFrame para tabla\n",
    "    metrics_data = {metric: [] for metric in metrics}\n",
    "    metrics_data['Modelo'] = model_names\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        for metric in metrics:\n",
    "            value = models_dict[model_name]['metrics'].get(metric, np.nan)\n",
    "            metrics_data[metric].append(value)\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    # Mostrar tabla\n",
    "    print(\"\\n📊 TABLA COMPARATIVA DE MÉTRICAS\")\n",
    "    print(metrics_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "    \n",
    "    # Guardar como CSV\n",
    "    metrics_csv_path = vis_dir / 'metrics_comparison.csv'\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False, float_format='%.4f')\n",
    "    print(f\"\\nTabla guardada en {metrics_csv_path}\")\n",
    "    \n",
    "    # 2. Gráfico de barras comparativo de métricas\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Iterar sobre las métricas\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        values = [models_dict[model]['metrics'].get(metric, np.nan) for model in model_names]\n",
    "        \n",
    "        # Crear gráfico de barras\n",
    "        bars = plt.bar(model_names, values)\n",
    "        \n",
    "        # Añadir etiquetas de valor sobre cada barra\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{value:.4f}',\n",
    "                    ha='center', va='bottom', rotation=0, fontsize=9)\n",
    "        \n",
    "        plt.title(f'Comparación de {metric}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(alpha=0.3, axis='y')\n",
    "        \n",
    "        # Para métricas donde menor es mejor, destacar el mejor modelo\n",
    "        if metric in ['MAE', 'RMSE', 'MAPE (%)']:\n",
    "            best_idx = np.nanargmin(values)\n",
    "            bars[best_idx].set_color('green')\n",
    "        else:  # Para métricas donde mayor es mejor\n",
    "            best_idx = np.nanargmax(values)\n",
    "            bars[best_idx].set_color('green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    metrics_plot_path = vis_dir / 'metrics_comparison.png'\n",
    "    plt.savefig(metrics_plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico de métricas guardado en {metrics_plot_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Curvas de aprendizaje comparativas (mejorado con más información)\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # 3.1 Pérdidas de entrenamiento\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for model_name in model_names:\n",
    "        train_losses = models_dict[model_name].get('train_losses', [])\n",
    "        if train_losses:\n",
    "            plt.plot(train_losses, label=model_name)\n",
    "    \n",
    "    plt.title('Pérdidas de Entrenamiento')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3.2 Pérdidas de validación\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for model_name in model_names:\n",
    "        val_losses = models_dict[model_name].get('val_losses', [])\n",
    "        if val_losses:\n",
    "            plt.plot(val_losses, label=model_name)\n",
    "    \n",
    "    plt.title('Pérdidas de Validación')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3.3 Pérdidas de ambas en escala logarítmica\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for model_name in model_names:\n",
    "        train_losses = models_dict[model_name].get('train_losses', [])\n",
    "        val_losses = models_dict[model_name].get('val_losses', [])\n",
    "        if train_losses:\n",
    "            plt.semilogy(train_losses, linestyle='-', label=f'{model_name} (Train)')\n",
    "        if val_losses:\n",
    "            plt.semilogy(val_losses, linestyle='--', label=f'{model_name} (Val)')\n",
    "    \n",
    "    plt.title('Pérdidas de Entrenamiento y Validación (Log)')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida (log)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3.4 Comparación de convergencia (normalizada)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for model_name in model_names:\n",
    "        val_losses = models_dict[model_name].get('val_losses', [])\n",
    "        if val_losses and len(val_losses) > 1:\n",
    "            # Normalizar pérdidas para comparar velocidad de convergencia\n",
    "            norm_losses = [(loss - min(val_losses)) / (max(val_losses) - min(val_losses) + 1e-10) \n",
    "                          for loss in val_losses]\n",
    "            plt.plot(norm_losses, label=model_name)\n",
    "    \n",
    "    plt.title('Convergencia Normalizada (Validación)')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida Normalizada')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    learning_plot_path = vis_dir / 'learning_curves.png'\n",
    "    plt.savefig(learning_plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico de curvas de aprendizaje guardado en {learning_plot_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Si hay un DataLoader de validación, generar ejemplos de predicciones\n",
    "    if val_loader is not None and next(iter(models_dict.values())).get('model') is not None:\n",
    "        try:\n",
    "            # Obtener algunas muestras para visualizar\n",
    "            print(\"\\nGenerando ejemplos de predicciones...\")\n",
    "            \n",
    "            # Tomar un batch como ejemplo\n",
    "            sample_inputs, sample_targets = next(iter(val_loader))\n",
    "            \n",
    "            # Configurar figura para mostrar predicciones\n",
    "            fig = plt.figure(figsize=(20, 5 * len(model_names)))\n",
    "            \n",
    "            # Generar predicciones con cada modelo\n",
    "            for i, model_name in enumerate(model_names):\n",
    "                model = models_dict[model_name].get('model')\n",
    "                if model is None:\n",
    "                    continue\n",
    "                    \n",
    "                # Modo evaluación\n",
    "                model.eval()\n",
    "                \n",
    "                # Generar predicciones\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(sample_inputs.to(next(model.parameters()).device))\n",
    "                \n",
    "                # Seleccionar un ejemplo (primer item del batch)\n",
    "                if len(outputs.shape) == 5:  # [batch, seq, channel, H, W]\n",
    "                    pred = outputs[0, 0, 0].cpu().numpy()\n",
    "                elif len(outputs.shape) == 4:  # [batch, seq, H, W]\n",
    "                    pred = outputs[0, 0].cpu().numpy()\n",
    "                else:\n",
    "                    pred = outputs[0].cpu().numpy()\n",
    "                \n",
    "                # Obtener target correspondiente\n",
    "                if len(sample_targets.shape) == 5:  # [batch, seq, channel, H, W]\n",
    "                    target = sample_targets[0, 0, 0].numpy()\n",
    "                elif len(sample_targets.shape) == 4:  # [batch, seq, H, W]\n",
    "                    target = sample_targets[0, 0].numpy()\n",
    "                else:\n",
    "                    target = sample_targets[0].numpy()\n",
    "                \n",
    "                # Mostrar predicción vs real\n",
    "                plt.subplot(len(model_names), 3, i*3+1)\n",
    "                plt.imshow(target, cmap='viridis')\n",
    "                plt.colorbar(fraction=0.046, pad=0.04)\n",
    "                plt.title(f'{model_name} - Valor Real')\n",
    "                \n",
    "                plt.subplot(len(model_names), 3, i*3+2)\n",
    "                plt.imshow(pred, cmap='viridis')\n",
    "                plt.colorbar(fraction=0.046, pad=0.04)\n",
    "                plt.title(f'{model_name} - Predicción')\n",
    "                \n",
    "                plt.subplot(len(model_names), 3, i*3+3)\n",
    "                diff = target - pred\n",
    "                plt.imshow(diff, cmap='RdBu_r')\n",
    "                plt.colorbar(fraction=0.046, pad=0.04)\n",
    "                plt.title(f'{model_name} - Diferencia')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            pred_plot_path = vis_dir / 'prediction_examples.png'\n",
    "            plt.savefig(pred_plot_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Ejemplos de predicción guardados en {pred_plot_path}\")\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar ejemplos de predicción: {str(e)}\")\n",
    "    \n",
    "    return vis_dir\n",
    "# Añadir a la parte principal de ejecución - función ya definida previamente\n",
    "# Añadir a la parte principal de ejecución\n",
    "# Preparar datos para entrenamiento y evaluación\n",
    "def prepare_train_val_data(ds_full, input_window=INPUT_WINDOW, output_horizon=OUTPUT_HORIZON):\n",
    "    \"\"\"\n",
    "    Prepara los datos de entrenamiento y validación desde el dataset completo.\n",
    "    \n",
    "    Args:\n",
    "        ds_full: Dataset completo con variables\n",
    "        input_window: Tamaño de la ventana de entrada\n",
    "        output_horizon: Horizonte de predicción\n",
    "    \n",
    "    Returns:\n",
    "        X_train, y_train, X_val, y_val: Arrays de entrenamiento y validación\n",
    "    \"\"\"\n",
    "    print(\"Preparando datos para entrenamiento y validación...\")\n",
    "    \n",
    "    # Extraer precipitación como variable objetivo\n",
    "    # Check if 'precipitacion' exists in the dataset\n",
    "    if 'precipitacion' in ds_full.data_vars:\n",
    "        precip = ds_full.precipitacion.values\n",
    "        print(\"Using 'precipitacion' as target variable\")\n",
    "    # If not, check for 'total_precipitation'\n",
    "    elif 'total_precipitation' in ds_full.data_vars:\n",
    "        precip = ds_full.total_precipitation.values\n",
    "        print(\"Using 'total_precipitation' as target variable\")\n",
    "    else:\n",
    "        # If neither exists, raise an error\n",
    "        raise ValueError(\"Could not find precipitation variable in dataset. Available variables: \" + \n",
    "                        str(list(ds_full.data_vars.keys())))\n",
    "    \n",
    "    # Ensure precip has 3 dimensions (time, lat, lon)\n",
    "    if len(precip.shape) != 3:\n",
    "        raise ValueError(f\"Expected precipitation data to have 3 dimensions (time, lat, lon), got {precip.shape}\")\n",
    "    \n",
    "    n_times, height, width = precip.shape\n",
    "    print(f\"Precipitation data shape: {precip.shape}\")\n",
    "    \n",
    "    # Extraer features, por ejemplo cluster y elevación\n",
    "    features = []\n",
    "    \n",
    "    # Verificar si las features estáticas existen y expandirlas para todas las timesteps\n",
    "    if 'cluster' in ds_full.data_vars:\n",
    "        cluster_data = ds_full.cluster.values\n",
    "        # Si cluster es 2D (lat, lon), expandir a 3D (time, lat, lon)\n",
    "        if len(cluster_data.shape) == 2:\n",
    "            cluster_data = np.repeat(cluster_data[np.newaxis, :, :], n_times, axis=0)\n",
    "        features.append(cluster_data)\n",
    "        print(\"Añadida variable 'cluster', shape:\", cluster_data.shape)\n",
    "    \n",
    "    if 'elevation' in ds_full.data_vars:\n",
    "        elev_data = ds_full.elevation.values\n",
    "        # Si elevation es 2D (lat, lon), expandir a 3D (time, lat, lon)\n",
    "        if len(elev_data.shape) == 2:\n",
    "            elev_data = np.repeat(elev_data[np.newaxis, :, :], n_times, axis=0)\n",
    "        features.append(elev_data)\n",
    "        print(\"Añadida variable 'elevation', shape:\", elev_data.shape)\n",
    "    \n",
    "    # Si no hay features específicas, usar precipitación histórica como feature\n",
    "    if not features:\n",
    "        print(\"No se encontraron features específicas, usando precipitación histórica\")\n",
    "        # Usar precipitación como característica, añadiendo una dimensión de canal\n",
    "        features_array = precip.reshape(n_times, 1, height, width)\n",
    "        print(f\"Shape de features: {features_array.shape}\")\n",
    "    else:\n",
    "        # Concatenar features en un solo array a lo largo de una nueva dimensión (canal)\n",
    "        features_array = np.stack(features, axis=1)\n",
    "        print(f\"Shape de features combinadas: {features_array.shape}\")\n",
    "    \n",
    "    # Crear ventanas deslizantes de manera segura\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(n_times - input_window - output_horizon + 1):\n",
    "        # Input: ventana de datos\n",
    "        X.append(features_array[i:i+input_window].copy())\n",
    "        # Output: horizonte de predicción \n",
    "        y.append(precip[i+input_window:i+input_window+output_horizon].copy())\n",
    "    \n",
    "    # Verificar formas antes de convertir\n",
    "    if not X or not y:\n",
    "        raise ValueError(\"No se pudieron crear ventanas válidas. Verifique los datos de entrada.\")\n",
    "        \n",
    "    # Usar np.stack en lugar de np.array para garantizar arrays homogéneos\n",
    "    X = np.stack(X)\n",
    "    y = np.stack(y)\n",
    "    \n",
    "    print(f\"Datos preparados - X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    \n",
    "    # División train/val (80/20)\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    print(f\"Train shapes - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "    print(f\"Val shapes - X: {X_val.shape}, y: {y_val.shape}\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# Función para entrenar modelos híbridos\n",
    "def train_hybrid_model(name, model, train_loader, val_loader, epochs=100, patience=20, \n",
    "                      optimizer=None, criterion=None, scheduler=None, generate_plots=True):\n",
    "    \"\"\"\n",
    "    Train a hybrid model with advanced optimizations and evaluation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"TRAINING {name}\")\n",
    "    print(f\"{'='*30}\")\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Import tqdm if available\n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "    except ImportError:\n",
    "        # Define simple version if not installed\n",
    "        def tqdm(iterable, **kwargs):\n",
    "            print(kwargs.get('desc', ''))\n",
    "            return iterable\n",
    "    \n",
    "    # Use default optimizer and loss function if not provided\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        print(\"Using default Adam optimizer with lr=1e-3\")\n",
    "    \n",
    "    if criterion is None:\n",
    "        criterion = nn.MSELoss()\n",
    "        print(\"Using default MSELoss criterion\")\n",
    "    \n",
    "    if scheduler is None:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=10, verbose=True\n",
    "        )\n",
    "        print(\"Using default ReduceLROnPlateau scheduler\")\n",
    "    \n",
    "    # Metrics tracking\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    learning_rates = []  # Track learning rates\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Get data dimensions info\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    sample_inputs, sample_targets = sample_batch\n",
    "    input_seq_len = sample_inputs.shape[1] if len(sample_inputs.shape) >= 2 else 1\n",
    "    target_seq_len = sample_targets.shape[1] if len(sample_targets.shape) >= 2 else 1\n",
    "    print(f\"INPUT SEQ LEN: {input_seq_len}, TARGET SEQ LEN: {target_seq_len}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Track current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        batch_losses = []\n",
    "        \n",
    "        for batch_data in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train] LR: {current_lr:.1e}\", leave=False):\n",
    "            inputs, targets = batch_data\n",
    "            \n",
    "            # Debug shapes for first batch in initial epoch\n",
    "            if epoch == 0 and len(batch_losses) == 0:\n",
    "                print(f\"Train batch shapes - inputs: {inputs.shape}, targets: {targets.shape}\")\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Remove singleton dimension if present\n",
    "            if len(outputs.shape) == 5 and outputs.shape[2] == 1:  # [batch, seq, 1, H, W]\n",
    "                outputs = outputs.squeeze(2)  # [batch, seq, H, W]\n",
    "            \n",
    "            # Handle 5D targets with double sequence dimension\n",
    "            if len(targets.shape) == 5 and len(outputs.shape) == 4 and outputs.shape[1] == targets.shape[1]:\n",
    "                targets = targets[:, :, 0, :, :]  # Convert [batch, seq, seq, H, W] to [batch, seq, H, W]\n",
    "                print(f\"Converted targets from shape {targets.shape} by removing redundant dim\")\n",
    "\n",
    "            # Handle 5D targets with different sequence dimensions\n",
    "            elif len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                # Select diagonal or average across 3rd dimension\n",
    "                targets_reshaped = []\n",
    "                for i in range(min(targets.shape[1], outputs.shape[1])):\n",
    "                    # For each time step, keep first element or diagonal\n",
    "                    if i < targets.shape[2]:\n",
    "                        targets_reshaped.append(targets[:, i, i])\n",
    "                    else:\n",
    "                        targets_reshaped.append(targets[:, i, -1])\n",
    "                \n",
    "                # Stack to form [batch, seq, H, W]\n",
    "                targets = torch.stack(targets_reshaped, dim=1)\n",
    "                print(f\"Converted targets using diagonal selection: {targets.shape}\")\n",
    "            \n",
    "            # Adjust sequence length when output_seq_len != target_seq_len\n",
    "            if len(outputs.shape) == 4 and len(targets.shape) == 4:\n",
    "                output_seq_len = outputs.shape[1]\n",
    "                target_seq_len = targets.shape[1]\n",
    "                \n",
    "                if output_seq_len > target_seq_len:\n",
    "                    # If model produces longer sequence, use only the first target_seq_len elements\n",
    "                    outputs = outputs[:, :target_seq_len]\n",
    "                    print(f\"Trimming outputs from {output_seq_len} to {target_seq_len}\")\n",
    "                elif output_seq_len < target_seq_len:\n",
    "                    # If model produces shorter sequence, repeat last element\n",
    "                    padding = targets[:, output_seq_len:target_seq_len].shape[1]\n",
    "                    last_output = outputs[:, -1:].repeat(1, padding, 1, 1)\n",
    "                    outputs = torch.cat([outputs, last_output], dim=1)\n",
    "                    print(f\"Extending outputs from {output_seq_len} to {target_seq_len}\")\n",
    "            \n",
    "            # Handle different target formats\n",
    "            if len(targets.shape) == 3 and len(outputs.shape) == 4:  # targets: [batch, H, W], outputs: [batch, seq, H, W]\n",
    "                targets = targets.unsqueeze(1).repeat(1, outputs.shape[1], 1, 1)\n",
    "                \n",
    "            elif len(targets.shape) == 4 and len(outputs.shape) == 4 and targets.shape[1] == 1:\n",
    "                targets = targets.repeat(1, outputs.shape[1], 1, 1)\n",
    "            \n",
    "            # Ensure compatible dimensions before calculating loss\n",
    "            if outputs.shape != targets.shape:\n",
    "                print(f\"⚠️ Warning: Shapes still incompatible after adjustments:\")\n",
    "                print(f\"   outputs.shape: {outputs.shape}, targets.shape: {targets.shape}\")\n",
    "                \n",
    "                # Handle special case: [batch, seq, H, W] vs [batch, seq, seq, H, W]\n",
    "                if len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                    B, S1, S2, H, W = targets.shape\n",
    "                    targets = targets.view(B, S1*S2, H, W)[:, :outputs.shape[1]]\n",
    "                \n",
    "                # Generic case: adjust to common dimensions\n",
    "                if outputs.shape != targets.shape:\n",
    "                    try:\n",
    "                        min_shape = [min(o, t) for o, t in zip(outputs.shape, targets.shape) \n",
    "                                   if o is not None and t is not None]\n",
    "                        slices_out = tuple(slice(0, m) for m in min_shape)\n",
    "                        slices_tgt = tuple(slice(0, m) for m in min_shape)\n",
    "                        \n",
    "                        outputs = outputs[slices_out]\n",
    "                        targets = targets[slices_tgt]\n",
    "                    except:\n",
    "                        # Last resort: flatten and trim\n",
    "                        flat_out = outputs.flatten()[:10000]\n",
    "                        flat_tgt = targets.flatten()[:10000]\n",
    "                        outputs = flat_out.unsqueeze(0)\n",
    "                        targets = flat_tgt.unsqueeze(0)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "            \n",
    "        # Calculate average training loss\n",
    "        train_loss = sum(batch_losses) / len(batch_losses)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_batch_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False):\n",
    "                inputs, targets = batch_data\n",
    "                \n",
    "                if epoch == 0 and len(val_batch_losses) == 0:\n",
    "                    print(f\"Val batch shapes - inputs: {inputs.shape}, targets: {targets.shape}\")\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Remove singleton dimension if present\n",
    "                if len(outputs.shape) == 5 and outputs.shape[2] == 1:\n",
    "                    outputs = outputs.squeeze(2)\n",
    "                \n",
    "                # Apply same shape adjustments as in training\n",
    "                if len(targets.shape) == 5 and len(outputs.shape) == 4 and outputs.shape[1] == targets.shape[1]:\n",
    "                    targets = targets[:, :, 0, :, :]\n",
    "                \n",
    "                elif len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                    targets_reshaped = []\n",
    "                    for i in range(min(targets.shape[1], outputs.shape[1])):\n",
    "                        if i < targets.shape[2]:\n",
    "                            targets_reshaped.append(targets[:, i, i])\n",
    "                        else:\n",
    "                            targets_reshaped.append(targets[:, i, -1])\n",
    "                    targets = torch.stack(targets_reshaped, dim=1)\n",
    "                \n",
    "                # Adjust sequence length\n",
    "                if len(outputs.shape) == 4 and len(targets.shape) == 4:\n",
    "                    output_seq_len = outputs.shape[1]\n",
    "                    target_seq_len = targets.shape[1]\n",
    "                    \n",
    "                    if output_seq_len > target_seq_len:\n",
    "                        outputs = outputs[:, :target_seq_len]\n",
    "                    elif output_seq_len < target_seq_len:\n",
    "                        padding = targets[:, output_seq_len:target_seq_len].shape[1]\n",
    "                        last_output = outputs[:, -1:].repeat(1, padding, 1, 1)\n",
    "                        outputs = torch.cat([outputs, last_output], dim=1)\n",
    "                \n",
    "                # Handle different target formats\n",
    "                if len(targets.shape) == 3 and len(outputs.shape) == 4:\n",
    "                    targets = targets.unsqueeze(1).repeat(1, outputs.shape[1], 1, 1)\n",
    "                \n",
    "                elif len(targets.shape) == 4 and len(outputs.shape) == 4 and targets.shape[1] == 1:\n",
    "                    targets = targets.repeat(1, outputs.shape[1], 1, 1)\n",
    "                \n",
    "                # Ensure compatible dimensions\n",
    "                if outputs.shape != targets.shape:\n",
    "                    if len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                        B, S1, S2, H, W = targets.shape\n",
    "                        targets = targets.view(B, S1*S2, H, W)[:, :outputs.shape[1]]\n",
    "                    \n",
    "                    if outputs.shape != targets.shape:\n",
    "                        try:\n",
    "                            min_shape = [min(o, t) for o, t in zip(outputs.shape, targets.shape) \n",
    "                                      if o is not None and t is not None]\n",
    "                            slices_out = tuple(slice(0, m) for m in min_shape)\n",
    "                            slices_tgt = tuple(slice(0, m) for m in min_shape)\n",
    "                            \n",
    "                            outputs = outputs[slices_out]\n",
    "                            targets = targets[slices_tgt]\n",
    "                        except:\n",
    "                            flat_out = outputs.flatten()[:10000]\n",
    "                            flat_tgt = targets.flatten()[:10000]\n",
    "                            outputs = flat_out.unsqueeze(0)\n",
    "                            targets = flat_tgt.unsqueeze(0)\n",
    "                \n",
    "                # Calculate validation loss\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_batch_losses.append(loss.item())\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        val_loss = sum(val_batch_losses) / len(val_batch_losses)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Update learning rate if scheduler is provided\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f\"{name} - Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}, LR: {current_lr:.1e}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model state\n",
    "            best_model_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "                break\n",
    "    \n",
    "    # Restore best model state\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Generate detailed training metrics visualization if requested\n",
    "    if generate_plots:\n",
    "        visualize_training_metrics(name, train_losses, val_losses, learning_rates)\n",
    "    \n",
    "    print(f\"Training completed for {name}. Best validation loss: {best_val_loss:.6f}\")\n",
    "    return model, train_losses, val_losses, learning_rates\n",
    "\n",
    "# Nueva función para visualizar métricas de entrenamiento detalladas\n",
    "def visualize_training_metrics(model_name, train_losses, val_losses, learning_rates):\n",
    "    \"\"\"\n",
    "    Generate detailed visualizations for model training metrics.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model\n",
    "        train_losses: List of training losses per epoch\n",
    "        val_losses: List of validation losses per epoch\n",
    "        learning_rates: List of learning rates per epoch\n",
    "    \"\"\"\n",
    "    # Create figure with 2x2 subplots for comprehensive analysis\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    \n",
    "    # 1. Training and validation losses\n",
    "    plt.subplot(2, 2, 1)\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training loss')\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validation loss')\n",
    "    plt.title(f'{model_name} - Loss Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Log scale losses - better for visualizing small changes\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.semilogy(epochs, train_losses, 'b-', label='Training loss')\n",
    "    plt.semilogy(epochs, val_losses, 'r-', label='Validation loss')\n",
    "    plt.title(f'{model_name} - Loss Curves (Log Scale)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Loss difference (for overfitting detection)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    loss_diff = [val - train for train, val in zip(train_losses, val_losses)]\n",
    "    plt.plot(epochs, loss_diff, 'g-')\n",
    "    plt.fill_between(epochs, 0, loss_diff, alpha=0.3, color='g')\n",
    "    plt.title(f'{model_name} - Validation-Training Loss Gap')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Difference (Val - Train)')\n",
    "    plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Learning rate over time\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.semilogy(epochs, learning_rates, 'c-')\n",
    "    plt.title(f'{model_name} - Learning Rate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Learning Rate (log scale)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    save_dir = MODELS_OUTPUT / 'visualization' / 'training_metrics'\n",
    "    save_dir.mkdir(exist_ok=True, parents=True)\n",
    "    plt.savefig(save_dir / f'{model_name}_training_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"Training metrics visualization saved to {save_dir / f'{model_name}_training_metrics.png'}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
