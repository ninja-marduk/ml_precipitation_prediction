{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827c19f7",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/feature%2Fhybrid-models/models/hybrid_models_enconders_layering_w3_ST-HybridWaveStack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43abece5",
   "metadata": {},
   "source": [
    "# Meta-Modelo Convolucional: ElevClusConvPrecipMetaNet\n",
    "\n",
    "Este modelo implementa una arquitectura convolucional avanzada para la predicción espaciotemporal de precipitación con horizonte de 12 meses.\n",
    "\n",
    "## Arquitectura\n",
    "\n",
    "1. **Entradas**:\n",
    "   - Mapas de predicción de los modelos base (ConvBiGRU-AE y ConvLSTM-AE) para cada horizonte (12 meses)\n",
    "   - Información de elevación y clusters para condicionamiento (FiLM)\n",
    "\n",
    "2. **Reducción Temprana de Canales**:\n",
    "   - Reduce los 24 canales (2 modelos × 12 horizontes) a 16 para optimizar memoria\n",
    "   - Aplica Conv2D(1×1) para mezclar información sin perder resolución espacial\n",
    "\n",
    "3. **Bloques Residuales Multiescala**:\n",
    "   - Bloques depthwise-separables con distintas dilataciones (1,2,4)\n",
    "   - Captura patrones a diferentes escalas espaciales sin incrementar parámetros\n",
    "\n",
    "4. **Atención Espacial por Cluster**:\n",
    "   - FiLM (Feature-wise Linear Modulation): γ_cluster ⊗ F + β_cluster\n",
    "   - Adapta el comportamiento según el régimen orográfico\n",
    "\n",
    "5. **U-Net Compacto**:\n",
    "   - Arquitectura de encoder-decoder con skip connections\n",
    "   - Solo 2 niveles de downsampling para preservar detalle\n",
    "\n",
    "6. **Agrupamiento de Horizontes**:\n",
    "   - Conv3D para procesar conjuntamente la dimensión temporal de horizontes\n",
    "   - Permite aprender relaciones entre meses consecutivos\n",
    "\n",
    "7. **Salida Multi-Horizonte**:\n",
    "   - Genera los 12 mapas refinados de predicción\n",
    "\n",
    "8. **Estrategias Memory-Friendly**:\n",
    "   - Mixed precision (float16)\n",
    "   - Gradient checkpointing\n",
    "   - Acumulación de gradientes\n",
    "   - Entrenamiento por etapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción Espaciotemporal de Precipitación Mensual - Notebook Completo\n",
    "\n",
    "# 0) Configuración del entorno, rutas y dependencias\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import joblib  # Para persistir scalers\n",
    "import datetime\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def log_and_print(msg):\n",
    "    logger.info(msg)\n",
    "    print(msg)\n",
    "\n",
    "# Detectar entorno (Colab o local)\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "log_and_print(f\"Ejecutando en Colab: {IN_COLAB}\")\n",
    "\n",
    "# Definir rutas base\n",
    "desired_repo = 'ml_precipitation_prediction'\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_PATH = Path('/content/drive/MyDrive') / desired_repo\n",
    "    if not Path(desired_repo).exists():\n",
    "        log_and_print(\"Clonando repositorio...\")\n",
    "        get_ipython().system('git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git')\n",
    "    os.chdir(desired_repo)\n",
    "    get_ipython().system('pip install -q xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open cartopy geopandas joblib')\n",
    "else:\n",
    "    # Instalación más simple sin PyEMD\n",
    "    %pip install -q xarray netCDF4 scikit-image\n",
    "    current = Path.cwd()\n",
    "    for p in [current] + list(current.parents):\n",
    "        if (p / '.git').is_dir() or (p / 'requirements.txt').is_file() or (p / 'README.md').is_file():\n",
    "            BASE_PATH = p\n",
    "            break\n",
    "    else:\n",
    "        BASE_PATH = current\n",
    "    log_and_print(f\"Ejecutando en local. Base path: {BASE_PATH}\")\n",
    "\n",
    "# Rutas de datos y modelos\n",
    "DATA_OUTPUT   = BASE_PATH / 'data' / 'output'\n",
    "MODELS_OUTPUT = BASE_PATH / 'models' / 'output'\n",
    "PREDS_DIR     = MODELS_OUTPUT / 'base_model_predictions'\n",
    "SHP_PATH      = BASE_PATH / 'data' / 'input' / 'shapes' / 'MGN_Departamento.shp'\n",
    "\n",
    "# Crear directorios\n",
    "MODELS_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "PREDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parámetros generales\n",
    "INPUT_WINDOW   = 60\n",
    "OUTPUT_HORIZON = 12  # 12 meses\n",
    "BATCH_SIZE     = 16\n",
    "MAX_EPOCHS     = 300\n",
    "PATIENCE       = 50\n",
    "LR             = 1e-3\n",
    "\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log_and_print(f\"Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "\n",
    "# 1) Imports adicionales y utilidades\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature  # Añadido para características cartográficas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler # Mixed precision training\n",
    "from torch.utils.checkpoint import checkpoint # Gradient checkpointing\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  # Añadido para learning rate adaptativo\n",
    "from IPython.display import clear_output  # Para actualizar gráficos durante entrenamiento\n",
    "import pywt\n",
    "from scipy.signal import hilbert\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "# 2) Carga y preprocesamiento de datos - Versión simplificada\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    log_and_print(\"Cargando datos...\")\n",
    "    \n",
    "    # Cargar datos completos\n",
    "    ds_full = xr.open_dataset(DATA_OUTPUT / 'complete_dataset_with_features_with_clusters_elevation_with_windows.nc')\n",
    "    log_and_print(f\"Dataset completo cargado, dims: {ds_full.dims}\")\n",
    "    \n",
    "    # Cargar componentes directamente de archivos específicos\n",
    "    ds_ceemdan = xr.open_dataset(MODELS_OUTPUT / 'features_CEEMDAN.nc')\n",
    "    log_and_print(f\"Dataset CEEMDAN cargado, dims: {ds_ceemdan.dims}\")\n",
    "    log_and_print(f\"Variables disponibles en CEEMDAN: {list(ds_ceemdan.data_vars.keys())}\")\n",
    "    \n",
    "    ds_tvfemd = xr.open_dataset(MODELS_OUTPUT / 'features_TVFEMD.nc')\n",
    "    log_and_print(f\"Dataset TVF-EMD cargado, dims: {ds_tvfemd.dims}\")\n",
    "    log_and_print(f\"Variables disponibles en TVF-EMD: {list(ds_tvfemd.data_vars.keys())}\")\n",
    "    \n",
    "    # Cargar shapefile para visualizaciones\n",
    "    gdf = gpd.read_file(SHP_PATH)\n",
    "    if gdf.crs is None:\n",
    "        gdf = gdf.set_crs(epsg=4326)\n",
    "    elif gdf.crs.to_epsg() != 4326:\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "    log_and_print(\"Shapefile cargado y CRS validado.\")\n",
    "\n",
    "    # Extraer información temporal\n",
    "    times = ds_full.time.values.astype('datetime64[M]')\n",
    "    REF = np.datetime64('2024-02','M')\n",
    "    idx_ref = int(np.where(times==REF)[0][0])\n",
    "    log_and_print(f\"Referencia (REF) = {REF}, index={idx_ref}\")\n",
    "    \n",
    "    return ds_full, ds_ceemdan, ds_tvfemd, gdf, times, REF, idx_ref\n",
    "\n",
    "# Ejecutar carga/preproc con los archivos específicos\n",
    "ds_full, ds_ceemdan, ds_tvfemd, gdf, times, REF, idx_ref = load_and_preprocess_data()\n",
    "\n",
    "# Mantenemos sólo las funciones de preprocesamiento que aún se necesitan\n",
    "def calculate_afc(signal, lags=[1, 3, 6]):\n",
    "    \"\"\"Calcula la Función de Autocorrelación para los lags dados.\"\"\"\n",
    "    afc = [np.correlate(signal[lag:], signal[:-lag], mode='valid') for lag in lags]\n",
    "    return afc\n",
    "\n",
    "# Funciones de preprocesamiento adicionales\n",
    "def wavelet_denoise(data, wavelet='db4', level=3):\n",
    "    \"\"\"Aplica denoising wavelet a los datos.\"\"\"\n",
    "    try:\n",
    "        # API moderna de scikit-image (0.19+)\n",
    "        return denoise_wavelet(\n",
    "            data, \n",
    "            wavelet=wavelet, \n",
    "            mode='soft',\n",
    "            method='BayesShrink',\n",
    "            channel_axis=None\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en wavelet denoising: {str(e)}. Intentando método alternativo.\")\n",
    "        # Si falla, intentar solo con parámetros básicos\n",
    "        return denoise_wavelet(data, wavelet=wavelet)\n",
    "\n",
    "# 3) Definición de Datasets PyTorch\n",
    "class PrecipitationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para datos de precipitación que maneja la reducción\n",
    "    de dimensionalidad y garantiza la compatibilidad dimensional.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, target, seq_length):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).float()\n",
    "        self.seq_length = seq_length\n",
    "        self.target_shape = target.shape[1:]  # Guardar la forma objetivo (height, width)\n",
    "        \n",
    "        print(f\"Dataset inicializado - Forma de datos: {self.data.shape}\")\n",
    "        print(f\"Dataset inicializado - Forma de targets: {self.target.shape}\")\n",
    "        print(f\"Forma objetivo almacenada: {self.target_shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener secuencia de datos\n",
    "        inputs = self.data[idx:idx+self.seq_length]\n",
    "        labels = self.target[idx:idx+self.seq_length]\n",
    "        \n",
    "        # Para debugging, imprimir formas solo para el primer elemento\n",
    "        if idx == 0:\n",
    "            print(f\"Ejemplo de entrada - forma original: {inputs.shape}\")\n",
    "            \n",
    "        # Reducir dimensionalidad de las características y transformar a tensor 2D\n",
    "        if len(inputs.shape) == 2:  # [seq_length, features]\n",
    "            # Crear un tensor 3D con forma [channels, height, width] \n",
    "            # con dimensiones espaciales adecuadas para redes convolucionales\n",
    "            n_features = inputs.shape[1]\n",
    "            feature_dim = min(int(np.sqrt(n_features)), 16)  # Limitar a un tamaño razonable\n",
    "            \n",
    "            # Seleccionar primeros feature_dim² características para crear mapa 2D\n",
    "            n_features_to_use = min(feature_dim * feature_dim, n_features)\n",
    "            flattened_features = inputs.mean(dim=0)[:n_features_to_use]\n",
    "            \n",
    "            # Reshape a forma [1, feature_dim, feature_dim] para canal único\n",
    "            padding = torch.zeros(feature_dim * feature_dim - n_features_to_use) if n_features_to_use < feature_dim * feature_dim else None\n",
    "            if padding is not None:\n",
    "                flattened_features = torch.cat([flattened_features, padding])\n",
    "            \n",
    "            # Crear mapa 2D con canal único [1, H, W]\n",
    "            spatial_features = flattened_features.reshape(1, feature_dim, feature_dim)\n",
    "            inputs = spatial_features\n",
    "            \n",
    "        # Para debugging\n",
    "        if idx == 0:\n",
    "            print(f\"Ejemplo de entrada - forma final: {inputs.shape}\")\n",
    "            print(f\"Ejemplo de etiqueta: {labels.shape}\")\n",
    "            \n",
    "        # CORREGIDO: Devolver sólo inputs y labels, omitir target_shape para compatibilidad\n",
    "        return inputs, labels\n",
    "\n",
    "# 4) Modelos Híbridos: ConvBiGRU-AE y ConvLSTM-AE\n",
    "class ConvBiGRU_AE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, num_layers, output_channels, seq_length, target_shape=(61, 65), kernel_size=3, padding=1):\n",
    "        super(ConvBiGRU_AE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.target_shape = target_shape  # Guardar la forma objetivo\n",
    "        \n",
    "        # Encoder - Convoluciones 2D para cada paso de tiempo\n",
    "        # En lugar de esperar múltiples canales, procesaremos cada paso de tiempo independientemente\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm2 = nn.InstanceNorm2d(hidden_dim)\n",
    "        \n",
    "        # GRU para procesar la secuencia comprimida\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.dnorm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_dim, output_channels * seq_length, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        # Usar la forma objetivo proporcionada o la predeterminada\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "        \n",
    "        # x tiene forma [batch_size, seq_length, height, width]\n",
    "        batch_size, seq_len, H, W = x.size()\n",
    "        \n",
    "        # Procesar cada paso de tiempo individualmente\n",
    "        processed_features = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Obtener el paso de tiempo actual y añadir dimensión de canal\n",
    "            x_t = x[:, t].unsqueeze(1)  # [batch_size, 1, height, width]\n",
    "            \n",
    "            # Aplicar convoluciones\n",
    "            x_t = F.relu(self.norm1(self.conv1(x_t)))\n",
    "            x_t = F.relu(self.norm2(self.conv2(x_t)))\n",
    "            \n",
    "            # Extraer características globales\n",
    "            # Promedio espacial para reducir a [batch_size, hidden_dim]\n",
    "            x_t_features = x_t.mean(dim=(2, 3))\n",
    "            \n",
    "            # Almacenar características para este paso de tiempo\n",
    "            processed_features.append(x_t_features)\n",
    "        \n",
    "        # Concatenar características para todos los pasos de tiempo\n",
    "        sequence_features = torch.stack(processed_features, dim=1)  # [batch_size, seq_length, hidden_dim]\n",
    "        \n",
    "        # Aplicar GRU a la secuencia\n",
    "        output, _ = self.gru(sequence_features)  # [batch_size, seq_length, hidden_dim*2]\n",
    "        \n",
    "        # Tomar el último estado y preparar para deconv\n",
    "        output = output[:, -1, :].view(batch_size, self.hidden_dim*2, 1, 1)\n",
    "        output = F.interpolate(output, size=(H, W), mode='nearest')\n",
    "        \n",
    "        # Decoder\n",
    "        output = F.relu(self.dnorm1(self.deconv1(output)))\n",
    "        output = self.deconv2(output)  # [batch_size, seq_length*output_channels, H, W]\n",
    "        \n",
    "        # Reorganizar para obtener [batch_size, seq_length, output_channels, H, W]\n",
    "        output = output.view(batch_size, self.seq_length, self.output_channels, H, W)\n",
    "        \n",
    "        # Redimensionar a la forma objetivo usando interpolación bilineal\n",
    "        # Primero reorganizamos para [batch_size*seq_length, output_channels, H, W]\n",
    "        output_reshaped = output.view(batch_size * self.seq_length, self.output_channels, H, W)\n",
    "        output_resized = F.interpolate(output_reshaped, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Reorganizar de nuevo a [batch_size, seq_length, output_channels, target_H, target_W]\n",
    "        output = output_resized.view(batch_size, self.seq_length, self.output_channels, target_shape[0], target_shape[1])\n",
    "        \n",
    "        return output\n",
    "\n",
    "class ConvBiLSTM_AE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, num_layers, output_channels, seq_length, target_shape=(61, 65), kernel_size=3, padding=1):\n",
    "        super(ConvBiLSTM_AE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.target_shape = target_shape  # Guardar la forma objetivo\n",
    "        \n",
    "        # Encoder para procesar cada paso de tiempo individualmente\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm2 = nn.InstanceNorm2d(hidden_dim)\n",
    "        \n",
    "        # LSTM para procesar la secuencia\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.dnorm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_dim, output_channels * seq_length, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        # Usar la forma objetivo proporcionada o la predeterminada\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "            \n",
    "        # x tiene forma [batch_size, seq_length, height, width]\n",
    "        batch_size, seq_len, H, W = x.size()\n",
    "        \n",
    "        # Procesar cada paso de tiempo individualmente\n",
    "        processed_features = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Obtener el paso de tiempo actual y añadir dimensión de canal\n",
    "            x_t = x[:, t].unsqueeze(1)  # [batch_size, 1, height, width]\n",
    "            \n",
    "            # Aplicar convoluciones\n",
    "            x_t = F.relu(self.norm1(self.conv1(x_t)))\n",
    "            x_t = F.relu(self.norm2(self.conv2(x_t)))\n",
    "            \n",
    "            # Extraer características globales\n",
    "            # Promedio espacial para reducir a [batch_size, hidden_dim]\n",
    "            x_t_features = x_t.mean(dim=(2, 3))\n",
    "            \n",
    "            # Almacenar características para este paso de tiempo\n",
    "            processed_features.append(x_t_features)\n",
    "        \n",
    "        # Concatenar características para todos los pasos de tiempo\n",
    "        sequence_features = torch.stack(processed_features, dim=1)  # [batch_size, seq_length, hidden_dim]\n",
    "        \n",
    "        # Aplicar LSTM a la secuencia\n",
    "        output, _ = self.lstm(sequence_features)  # [batch_size, seq_length, hidden_dim*2]\n",
    "        \n",
    "        # Tomar el último estado y preparar para deconv\n",
    "        output = output[:, -1, :].view(batch_size, self.hidden_dim*2, 1, 1)\n",
    "        output = F.interpolate(output, size=(H, W), mode='nearest')\n",
    "        \n",
    "        # Decoder\n",
    "        output = F.relu(self.dnorm1(self.deconv1(output)))\n",
    "        output = self.deconv2(output)  # [batch_size, seq_length*output_channels, H, W]\n",
    "        \n",
    "        # Reorganizar para obtener [batch_size, seq_length, output_channels, H, W]\n",
    "        output = output.view(batch_size, self.seq_length, self.output_channels, H, W)\n",
    "        \n",
    "        # Redimensionar a la forma objetivo usando interpolación bilineal\n",
    "        output_reshaped = output.view(batch_size * self.seq_length, self.output_channels, H, W)\n",
    "        output_resized = F.interpolate(output_reshaped, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        output = output_resized.view(batch_size, self.seq_length, self.output_channels, target_shape[0], target_shape[1])\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 5) Funciones de entrenamiento y evaluación\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=500, patience=50):\n",
    "    \"\"\"\n",
    "    Entrena el modelo usando los loaders proporcionados, con soporte para scheduler y más métricas.\n",
    "    Compatible con diferentes versiones de PyTorch.\n",
    "    \"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    # Guardar ruta para el modelo\n",
    "    model_path = MODELS_OUTPUT / 'best_model_temp.pth'\n",
    "    \n",
    "    # Verificar la versión de PyTorch para usar los parámetros adecuados al guardar modelos\n",
    "    import torch\n",
    "    torch_version = torch.__version__\n",
    "    print(f\"Versión de PyTorch detectada: {torch_version}\")\n",
    "    \n",
    "    # Función para guardar modelo compatible con diferentes versiones de PyTorch\n",
    "    def save_model(model, path):\n",
    "        try:\n",
    "            torch.save(model.state_dict(), path, weights_only=True)\n",
    "            print(\"Modelo guardado con parámetro weights_only=True\")\n",
    "        except TypeError:\n",
    "            try:\n",
    "                torch.save(model.state_dict(), path, _use_new_zipfile_serialization=True)\n",
    "                print(\"Modelo guardado con parámetro _use_new_zipfile_serialization=True\")\n",
    "            except TypeError:\n",
    "                torch.save(model.state_dict(), path)\n",
    "                print(\"Modelo guardado sin parámetros adicionales\")\n",
    "    \n",
    "    # Función para cargar modelo compatible con diferentes versiones\n",
    "    def load_model(model, path):\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(path, weights_only=True))\n",
    "            print(\"Modelo cargado con parámetro weights_only=True\")\n",
    "        except TypeError:\n",
    "            try:\n",
    "                model.load_state_dict(torch.load(path, map_location=DEVICE))\n",
    "                print(\"Modelo cargado con parámetro map_location\")\n",
    "            except TypeError:\n",
    "                model.load_state_dict(torch.load(path))\n",
    "                print(\"Modelo cargado sin parámetros adicionales\")\n",
    "    \n",
    "    # Para graficar el progreso durante el entrenamiento\n",
    "    def plot_progress():\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.axhline(y=best_val_loss, color='r', linestyle='--', label=f'Best: {best_val_loss:.2f}')\n",
    "        plt.title(f'Loss vs. Epochs (Current: {val_losses[-1]:.2f})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        rel_loss = [l/train_losses[0] for l in train_losses]\n",
    "        rel_val_loss = [l/val_losses[0] for l in val_losses]\n",
    "        plt.plot(rel_loss, label='Train')\n",
    "        plt.plot(rel_val_loss, label='Val')\n",
    "        plt.title(f'Relative Loss (% of initial loss)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Relative Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        batch_train_losses = []\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            \n",
    "            # Debug info en primera iteración\n",
    "            if epoch == 0 and len(batch_train_losses) == 0:\n",
    "                print(f\"Batch entrenamiento - inputs: {inputs.shape}, targets: {targets.shape}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Asegurar que outputs y targets tienen formas comparables para calcular la pérdida\n",
    "            if len(outputs.shape) == 5 and len(targets.shape) <= 4:\n",
    "                outputs = outputs.squeeze(2)  # eliminar dim C si es 1\n",
    "                \n",
    "            if len(outputs.shape) != len(targets.shape):\n",
    "                if len(outputs.shape) == 5 and len(targets.shape) == 3:\n",
    "                    targets = targets.unsqueeze(1).unsqueeze(2).repeat(1, outputs.shape[1], 1, 1, 1)\n",
    "                elif len(outputs.shape) == 5 and len(targets.shape) == 4:\n",
    "                    targets = targets.unsqueeze(2)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            # Gradient clipping para estabilidad\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_train_losses.append(loss.item())\n",
    "        \n",
    "        train_loss = np.mean(batch_train_losses)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        batch_val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Ajustar dimensiones si es necesario\n",
    "                if len(outputs.shape) == 5 and len(targets.shape) <= 4:\n",
    "                    outputs = outputs.squeeze(2)\n",
    "                \n",
    "                if len(outputs.shape) != len(targets.shape):\n",
    "                    if len(outputs.shape) == 5 and len(targets.shape) == 3:\n",
    "                        targets = targets.unsqueeze(1).unsqueeze(2).repeat(1, outputs.shape[1], 1, 1, 1)\n",
    "                    elif len(outputs.shape) == 5 and len(targets.shape) == 4:\n",
    "                        targets = targets.unsqueeze(2)\n",
    "                \n",
    "                loss = criterion(outputs, targets)\n",
    "                batch_val_losses.append(loss.item())\n",
    "        \n",
    "        val_loss = np.mean(batch_val_losses)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Usar scheduler si está disponible\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # Mostrar progreso cada 10 épocas o en la última\n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            print(f'Epoca {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "            plot_progress()  # Actualizar el gráfico\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Usar la función save_model compatible con diferentes versiones\n",
    "            save_model(model, model_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print('Early stopping triggered')\n",
    "                break\n",
    "    \n",
    "    # Cargar el mejor modelo con la función load_model compatible\n",
    "    load_model(model, model_path)\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "# También necesitamos corregir la función al guardar los modelos finales al final del entrenamiento\n",
    "def save_model_compatible(model, path):\n",
    "    \"\"\"\n",
    "    Guarda un modelo de manera compatible con diferentes versiones de PyTorch.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        torch.save(model.state_dict(), path, weights_only=True)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            torch.save(model.state_dict(), path, _use_new_zipfile_serialization=True)\n",
    "        except TypeError:\n",
    "            torch.save(model.state_dict(), path)\n",
    "    print(f\"Modelo guardado en {path}\")\n",
    "\n",
    "def save_model(model, path, epoch=0, val_loss=0.0):\n",
    "    \"\"\"\n",
    "    Guarda un modelo PyTorch con metadatos, de forma compatible con diferentes versiones PyTorch.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo PyTorch a guardar\n",
    "        path: Ruta donde guardar el modelo\n",
    "        epoch: Número de época actual\n",
    "        val_loss: Pérdida de validación actual\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear directorio si no existe\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        \n",
    "        # Guardar modelo con metadatos\n",
    "        checkpoint = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss\n",
    "        }\n",
    "        \n",
    "        # Intentar diferentes métodos de guardado según compatibilidad de versión\n",
    "        try:\n",
    "            torch.save(checkpoint, path, weights_only=True)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                torch.save(checkpoint, path, _use_new_zipfile_serialization=True)\n",
    "            except TypeError:\n",
    "                torch.save(checkpoint, path)\n",
    "        \n",
    "        print(f\"Modelo guardado en {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar el modelo en {path}: {str(e)}\")\n",
    "\n",
    "# Visualización mejorada con coordenadas geográficas\n",
    "def visualize_predictions_with_geospatial_coords():\n",
    "    \"\"\"\n",
    "    Visualiza las predicciones usando coordenadas geoespaciales reales\n",
    "    y muestra un mapa con más detalle, incluyendo límites administrativos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import os\n",
    "        \n",
    "        # Determinar si tenemos archivos de predicciones\n",
    "        pred_file = PREDS_DIR / 'convbigru_predictions.npy'\n",
    "        if not os.path.exists(pred_file):\n",
    "            print(\"No se encontraron archivos de predicciones. Generando predicciones...\")\n",
    "            \n",
    "            # Generar predicciones si no existen archivos\n",
    "            model = convbigru_ae\n",
    "            model.eval()\n",
    "            \n",
    "            # Usar un solo batch del dataset de validación\n",
    "            val_batch = next(iter(val_loader))\n",
    "            inputs, targets = val_batch\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            \n",
    "            # Hacer predicción\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "            # Convertir a numpy\n",
    "            predictions = outputs.cpu().detach().numpy()\n",
    "            targets_np = targets.cpu().detach().numpy()\n",
    "            \n",
    "            # Guardar para uso futuro\n",
    "            np.save(PREDS_DIR / 'convbigru_predictions.npy', predictions)\n",
    "            np.save(PREDS_DIR / 'targets.npy', targets_np)\n",
    "            \n",
    "            print(f\"Predicciones generadas y guardadas con forma: {predictions.shape}\")\n",
    "            \n",
    "            # Usar las predicciones generadas\n",
    "            if len(predictions.shape) == 5:\n",
    "                # [B, seq, C, H, W]\n",
    "                sample_pred = predictions[0, 0, 0]  # Primer batch, primer elemento de secuencia, primer canal\n",
    "            elif len(predictions.shape) == 4:\n",
    "                # [B, seq, H, W]\n",
    "                sample_pred = predictions[0, 0]     # Primer batch, primer elemento de secuencia\n",
    "            else:\n",
    "                sample_pred = predictions\n",
    "                \n",
    "            # Mismo proceso para targets\n",
    "            if len(targets_np.shape) == 4:\n",
    "                sample_target = targets_np[0, 0]    # Primer batch, primer elemento de secuencia\n",
    "            elif len(targets_np.shape) == 3:\n",
    "                sample_target = targets_np[0]       # Primer batch\n",
    "            else:\n",
    "                sample_target = targets_np\n",
    "        else:\n",
    "            # Cargar predicciones existentes\n",
    "            predictions = np.load(PREDS_DIR / 'convbigru_predictions.npy')\n",
    "            targets = np.load(PREDS_DIR / 'targets.npy')\n",
    "            \n",
    "            # Extraer muestra para visualización\n",
    "            if len(predictions.shape) == 5:\n",
    "                sample_pred = predictions[0, 0, 0]  # [B, seq, C, H, W] -> [H, W]\n",
    "            elif len(predictions.shape) == 4:\n",
    "                sample_pred = predictions[0, 0]     # [B, seq, H, W] -> [H, W]\n",
    "            else:\n",
    "                sample_pred = predictions\n",
    "                \n",
    "            if len(targets.shape) == 4:\n",
    "                sample_target = targets[0, 0]       # [B, seq, H, W] -> [H, W]\n",
    "            elif len(targets.shape) == 3:\n",
    "                sample_target = targets[0]          # [B, H, W] -> [H, W]\n",
    "            else:\n",
    "                sample_target = targets\n",
    "        \n",
    "        # Extraer coordenadas lat/lon del dataset\n",
    "        latitudes = ds_full.latitude.values\n",
    "        longitudes = ds_full.longitude.values\n",
    "        \n",
    "        # Crear malla de coordenadas\n",
    "        lon_mesh, lat_mesh = np.meshgrid(longitudes, latitudes)\n",
    "        \n",
    "        # Crear figura con proyección de mapa\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # Definir proyección y límites del mapa para Colombia/región de interés\n",
    "        projection = ccrs.PlateCarree()\n",
    "        \n",
    "        # Crear tres subfiguras con la misma proyección\n",
    "        ax1 = fig.add_subplot(131, projection=projection)\n",
    "        ax2 = fig.add_subplot(132, projection=projection)\n",
    "        ax3 = fig.add_subplot(133, projection=projection)\n",
    "        \n",
    "        # Configurar cada subplot\n",
    "        for ax, data, title in zip([ax1, ax2, ax3], \n",
    "                                   [sample_target, sample_pred, sample_pred - sample_target], \n",
    "                                   ['Valores Reales', 'Predicción ConvBiGRU-AE', 'Error (Predicción - Real)']):\n",
    "            # Añadir características del mapa\n",
    "            ax.coastlines(resolution='10m', color='black', linewidth=1)\n",
    "            ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "            ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "            \n",
    "            # Añadir el shapefile de Colombia\n",
    "            ax.add_geometries(gdf.geometry, crs=ccrs.PlateCarree(), edgecolor='black',\n",
    "                             facecolor='none', alpha=0.8, linewidth=0.5)\n",
    "            \n",
    "            # Crear mapa de contorno con coordenadas reales\n",
    "            im = ax.pcolormesh(lon_mesh, lat_mesh, data, cmap='viridis', \n",
    "                              transform=ccrs.PlateCarree())\n",
    "            \n",
    "            # Añadir barra de color\n",
    "            cbar = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.05, fraction=0.05)\n",
    "            cbar.ax.tick_params(labelsize=8)\n",
    "            \n",
    "            # Añadir título y cuadrícula\n",
    "            ax.set_title(title, fontsize=14)\n",
    "            gl = ax.gridlines(draw_labels=True, linestyle='--', alpha=0.5)\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False\n",
    "            \n",
    "            # Establecer límites del mapa para la zona de Boyacá en Colombia\n",
    "            ax.set_extent([-75.5, -71.5, 4.0, 7.5], crs=ccrs.PlateCarree())\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(MODELS_OUTPUT / 'geospatial_predictions.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al visualizar predicciones geoespaciales: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# 6) Preparación de datos para modelos híbridos - Versión simplificada\n",
    "\n",
    "# Función para generar predicciones del modelo base en caso de que no existan\n",
    "def create_base_model_predictions(ds_full, idx_ref):\n",
    "    \"\"\"\n",
    "    Entrena un modelo ConvBiGRU básico y genera predicciones para usar como entrada\n",
    "    del meta-modelo, para evitar el uso de datos sintéticos.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERACIÓN DE PREDICCIONES CON MODELO BASE ConvBiGRU\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n🔄 Iniciando generación de predicciones del modelo base...\")\n",
    "    \n",
    "    # Verificar si ya existen las predicciones en el dataset\n",
    "    if 'convbigru_preds' in ds_full.data_vars:\n",
    "        print(\"✅ Las predicciones 'convbigru_preds' ya existen en el dataset.\")\n",
    "        return ds_full\n",
    "    \n",
    "    # 1. Seleccionar datos para entrenamiento y validación\n",
    "    print(\"1️⃣ Preparando datos para modelo base...\")\n",
    "    \n",
    "    # Usaremos precipitation como entrada y target\n",
    "    if 'total_precipitation' in ds_full:\n",
    "        precip_var = 'total_precipitation'\n",
    "    elif 'precip' in ds_full:\n",
    "        precip_var = 'precip'\n",
    "    else:\n",
    "        # Buscar cualquier variable que contenga 'precip' en el nombre\n",
    "        precip_vars = [var for var in ds_full.data_vars if 'precip' in var.lower()]\n",
    "        if precip_vars:\n",
    "            precip_var = precip_vars[0]\n",
    "        else:\n",
    "            print(\"❌ No se encontró ninguna variable de precipitación\")\n",
    "            return ds_full\n",
    "    \n",
    "    print(f\"   - Usando variable '{precip_var}' como entrada y objetivo\")\n",
    "    \n",
    "    # Separar en train y validación usando la fecha de referencia\n",
    "    ds_base_train = ds_full.sel(time=slice(None, ds_full.time.values[idx_ref-1]))\n",
    "    ds_base_val = ds_full.sel(time=slice(ds_full.time.values[idx_ref], None))\n",
    "    \n",
    "    # Convertir a arrays NumPy\n",
    "    X_base_train = ds_base_train[precip_var].values.astype(np.float32)\n",
    "    y_base_train = X_base_train.copy()  # Mismo input/output para el modelo base\n",
    "    \n",
    "    X_base_val = ds_base_val[precip_var].values.astype(np.float32)\n",
    "    y_base_val = X_base_val.copy()\n",
    "    \n",
    "    # Añadir dimensión de canal si es necesario\n",
    "    if len(X_base_train.shape) == 3:  # [tiempo, lat, lon]\n",
    "        X_base_train = X_base_train.reshape(X_base_train.shape[0], 1, X_base_train.shape[1], X_base_train.shape[2])\n",
    "        X_base_val = X_base_val.reshape(X_base_val.shape[0], 1, X_base_val.shape[1], X_base_val.shape[2])\n",
    "        \n",
    "    print(f\"   - Forma de datos de entrenamiento: {X_base_train.shape}\")\n",
    "    print(f\"   - Forma de datos de validación: {X_base_val.shape}\")\n",
    "    \n",
    "    # 2. Crear dataset de PyTorch\n",
    "    print(\"\\n2️⃣ Creando datasets y dataloaders...\")\n",
    "    \n",
    "    seq_length = min(12, X_base_train.shape[0] // 10)  # Secuencia más corta para modelo base\n",
    "    \n",
    "    # Convertir a tensores PyTorch\n",
    "    X_base_train_tensor = torch.from_numpy(X_base_train).float()\n",
    "    y_base_train_tensor = torch.from_numpy(y_base_train).float()\n",
    "    \n",
    "    X_base_val_tensor = torch.from_numpy(X_base_val).float()\n",
    "    y_base_val_tensor = torch.from_numpy(y_base_val).float()\n",
    "    \n",
    "    # Crear datasets personalizados para secuencias\n",
    "    class SimpleSeqDataset(Dataset):\n",
    "        def __init__(self, features, targets, seq_length=12):\n",
    "            self.features = features\n",
    "            self.targets = targets\n",
    "            self.seq_length = seq_length\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.features) - self.seq_length + 1\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            # Input: secuencia de 'seq_length' elementos\n",
    "            x = self.features[idx:idx + self.seq_length]\n",
    "            # Target: siguiente elemento después de la secuencia\n",
    "            # Si queremos predecir múltiples pasos, podemos usar:\n",
    "            y = self.targets[idx + self.seq_length - 1:idx + self.seq_length]\n",
    "            return x, y\n",
    "    \n",
    "    # Crear datasets\n",
    "    train_base_dataset = SimpleSeqDataset(X_base_train_tensor, y_base_train_tensor, seq_length)\n",
    "    val_base_dataset = SimpleSeqDataset(X_base_val_tensor, y_base_val_tensor, seq_length)\n",
    "    \n",
    "    # Crear dataloaders\n",
    "    batch_size_base = min(batch_size, len(train_base_dataset) // 10)  # Batch más pequeño si hay pocos datos\n",
    "    batch_size_base = max(1, batch_size_base)  # Asegurar batch_size mínimo 1\n",
    "    \n",
    "    train_base_loader = DataLoader(train_base_dataset, batch_size=batch_size_base, shuffle=True)\n",
    "    val_base_loader = DataLoader(val_base_dataset, batch_size=batch_size_base, shuffle=False)\n",
    "    \n",
    "    print(f\"   - Longitud de secuencia: {seq_length}\")\n",
    "    print(f\"   - Batch size: {batch_size_base}\")\n",
    "    print(f\"   - Batches por época: {len(train_base_loader)}\")\n",
    "    \n",
    "    # 3. Crear modelo base simplificado\n",
    "    print(\"\\n3️⃣ Creando modelo base ConvBiGRU simplificado...\")\n",
    "    \n",
    "    input_channels_base = X_base_train.shape[1]\n",
    "    hidden_dim_base = 64  # Más pequeño para modelo base\n",
    "    output_channels_base = 1\n",
    "    \n",
    "    # Modelo ConvBiGRU simplificado para generar predicciones base\n",
    "    class SimpleConvBiGRU(nn.Module):\n",
    "        def __init__(self, input_channels, hidden_dim, output_channels):\n",
    "            super(SimpleConvBiGRU, self).__init__()\n",
    "            self.conv = nn.Conv2d(input_channels, hidden_dim, kernel_size=3, padding=1)\n",
    "            self.bn = nn.BatchNorm2d(hidden_dim)\n",
    "            self.gru = nn.GRU(hidden_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "            self.output_conv = nn.Conv2d(hidden_dim*2, output_channels, kernel_size=3, padding=1)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            # x tiene forma [batch, sequence, channels, height, width]\n",
    "            batch_size, seq_len, C, H, W = x.shape\n",
    "            \n",
    "            # Procesar cada paso de tiempo\n",
    "            outputs = []\n",
    "            for t in range(seq_len):\n",
    "                # Obtener el frame actual\n",
    "                x_t = x[:, t]  # [batch, channels, height, width]\n",
    "                \n",
    "                # Aplicar convolución\n",
    "                x_t = F.relu(self.bn(self.conv(x_t)))\n",
    "                \n",
    "                # Extraer características para GRU (promedio espacial)\n",
    "                features = x_t.view(batch_size, -1, H*W)\n",
    "                features = features.mean(dim=2)  # [batch, hidden_dim]\n",
    "                \n",
    "                # Añadir dimensión de secuencia para GRU\n",
    "                features = features.unsqueeze(1)  # [batch, 1, hidden_dim]\n",
    "                \n",
    "                # Si es el primer paso, inicializar salida GRU\n",
    "                if t == 0:\n",
    "                    gru_out, h = self.gru(features)\n",
    "                else:\n",
    "                    gru_out, h = self.gru(features, h)\n",
    "                \n",
    "                # Reformar para conv final\n",
    "                gru_features = gru_out.view(batch_size, -1, 1, 1)  # [batch, hidden_dim*2, 1, 1]\n",
    "                gru_features = F.interpolate(gru_features, size=(H, W), mode='bilinear', align_corners=False)\n",
    "                \n",
    "                # Generar salida\n",
    "                out = self.output_conv(gru_features)  # [batch, output_channels, height, width]\n",
    "                outputs.append(out)\n",
    "            \n",
    "            # Concatenar todos los outputs\n",
    "            return torch.stack(outputs, dim=1)  # [batch, sequence, output_channels, height, width]\n",
    "    \n",
    "    # Instanciar modelo\n",
    "    base_model = SimpleConvBiGRU(input_channels_base, hidden_dim_base, output_channels_base).to(DEVICE)\n",
    "    print(f\"   - Modelo creado con {input_channels_base} canales de entrada, {hidden_dim_base} dimensiones ocultas\")\n",
    "    \n",
    "    # 4. Entrenar modelo\n",
    "    print(\"\\n4️⃣ Entrenando modelo base...\")\n",
    "    \n",
    "    # Hiperparámetros\n",
    "    lr_base = 1e-3\n",
    "    epochs_base = 30\n",
    "    patience_base = 10\n",
    "    \n",
    "    # Optimizador y función de pérdida\n",
    "    criterion_base = nn.MSELoss()\n",
    "    optimizer_base = optim.Adam(base_model.parameters(), lr=lr_base)\n",
    "    \n",
    "    # Entrenamiento\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs_base):\n",
    "        # Train\n",
    "        base_model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_base_loader):\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer_base.zero_grad()\n",
    "            output = base_model(data)\n",
    "            \n",
    "            # Ajustar dimensiones para calcular pérdida\n",
    "            if output.shape != target.shape:\n",
    "                if len(output.shape) == 5 and len(target.shape) == 4:\n",
    "                    output = output.squeeze(2)  # Eliminar dimensión de canal si es 1\n",
    "                elif len(output.shape) == 5 and len(target.shape) == 3:\n",
    "                    output = output[:, -1, 0]   # Tomar último elemento de secuencia y primer canal\n",
    "            \n",
    "            # Calcular pérdida\n",
    "            loss = criterion_base(output, target)\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer_base.step()\n",
    "        \n",
    "        # Validation\n",
    "        base_model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_base_loader:\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = base_model(data)\n",
    "                \n",
    "                # Ajustar dimensiones\n",
    "                if output.shape != target.shape:\n",
    "                    if len(output.shape) == 5 and len(target.shape) == 4:\n",
    "                        output = output.squeeze(2)\n",
    "                    elif len(output.shape) == 5 and len(target.shape) == 3:\n",
    "                        output = output[:, -1, 0]\n",
    "                \n",
    "                # Calcular pérdida\n",
    "                loss = criterion_base(output, target)\n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "        # Calculamos pérdidas promedio\n",
    "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        print(f\"   Época {epoch+1}/{epochs_base}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Guardar mejor modelo\n",
    "            torch.save(base_model.state_dict(), MODELS_OUTPUT / 'simple_convbigru_base.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= patience_base:\n",
    "            print(\"   Early stopping - No mejora en validación durante varias épocas\")\n",
    "            break\n",
    "    \n",
    "    # 5. Generar predicciones para todo el dataset\n",
    "    print(\"\\n5️⃣ Generando predicciones para todo el dataset...\")\n",
    "    \n",
    "    # Cargar mejor modelo\n",
    "    base_model.load_state_dict(torch.load(MODELS_OUTPUT / 'simple_convbigru_base.pth'))\n",
    "    base_model.eval()\n",
    "    \n",
    "    # Crear dataset para todas las fechas\n",
    "    all_data = torch.from_numpy(X_base_train).float()\n",
    "    if len(X_base_val) > 0:\n",
    "        all_data = torch.cat([all_data, torch.from_numpy(X_base_val).float()], dim=0)\n",
    "    \n",
    "    # Generar predicciones\n",
    "    all_predictions = []\n",
    "    seq_len = seq_length\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(all_data) - seq_len + 1):\n",
    "            # Obtener secuencia\n",
    "            seq = all_data[i:i+seq_len].unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "            \n",
    "            # Generar predicción\n",
    "            pred = base_model(seq)\n",
    "            \n",
    "            # Si estamos en el último paso, añadimos las últimas predicciones\n",
    "            if i == 0:\n",
    "                # Añadir todas las predicciones de la primera secuencia\n",
    "                for j in range(seq_len):\n",
    "                    if len(pred.shape) == 5:  # [B, seq, C, H, W]\n",
    "                        single_pred = pred[0, j, 0].cpu().numpy()  # Primera batch, paso j, canal 0\n",
    "                    else:\n",
    "                        single_pred = pred[0, j].cpu().numpy()  # Primera batch, paso j\n",
    "                    all_predictions.append(single_pred)\n",
    "            else:\n",
    "                # Para el resto, añadir solo la última predicción (paso a paso)\n",
    "                if len(pred.shape) == 5:  # [B, seq, C, H, W]\n",
    "                    single_pred = pred[0, -1, 0].cpu().numpy()  # Primera batch, último paso, canal 0\n",
    "                else:\n",
    "                    single_pred = pred[0, -1].cpu().numpy()  # Primera batch, último paso\n",
    "                all_predictions.append(single_pred)\n",
    "    \n",
    "    # Convertir lista de predicciones a array\n",
    "    predictions_array = np.array(all_predictions)\n",
    "    print(f\"   - Forma de predicciones generadas: {predictions_array.shape}\")\n",
    "    \n",
    "    # Verificar que tenemos predicciones para todas las fechas\n",
    "    if len(predictions_array) < len(ds_full.time):\n",
    "        print(f\"⚠️ No se generaron suficientes predicciones ({len(predictions_array)} vs {len(ds_full.time)} fechas)\")\n",
    "        missing = len(ds_full.time) - len(predictions_array)\n",
    "        # Rellenar con los últimos valores repetidos\n",
    "        last_pred = predictions_array[-1]\n",
    "        for _ in range(missing):\n",
    "            predictions_array = np.concatenate([predictions_array, last_pred[np.newaxis, ...]], axis=0)\n",
    "    \n",
    "    # 6. Guardar predicciones en el dataset\n",
    "    print(\"\\n6️⃣ Guardando predicciones en el dataset...\")\n",
    "    \n",
    "    # Añadir variable al dataset\n",
    "    ds_updated = ds_full.copy()\n",
    "    ds_updated['convbigru_preds'] = (('time', 'latitude', 'longitude'), predictions_array)\n",
    "    \n",
    "    # Guardar dataset actualizado\n",
    "    output_file = DATA_OUTPUT / 'dataset_with_convbigru_preds.nc'\n",
    "    ds_updated.to_netcdf(output_file)\n",
    "    print(f\"✅ Dataset con predicciones guardado en {output_file}\")\n",
    "    \n",
    "    print(\"\\n✅ Proceso completo: modelo entrenado y predicciones generadas\")\n",
    "    return ds_updated\n",
    "\n",
    "def prepare_data_for_hybrid_models(ds_full, ds_ceemdan, ds_tvfemd, idx_ref, horizon=12):\n",
    "    \"\"\"\n",
    "    Prepara los datos para el entrenamiento de los modelos híbridos ConvBiGRU-AE y ConvLSTM-AE.\n",
    "    Con verificación de límites para evitar IndexError y cálculos robustos de fechas.\n",
    "    \n",
    "    Args:\n",
    "        ds_full: Dataset completo con todas las características.\n",
    "        ds_ceemdan: Dataset con características de CEEMDAN.\n",
    "        ds_tvfemd: Dataset con características de TVF-EMD.\n",
    "        idx_ref: Índice de la fecha de referencia en el dataset.\n",
    "        horizon: Horizonte de predicción (número de meses).\n",
    "        \n",
    "    Returns:\n",
    "        X_train, y_train, X_val, y_val: Conjuntos de datos preparados para entrenamiento y validación.\n",
    "    \"\"\"\n",
    "    # Verificar límites y ajustar índices si es necesario\n",
    "    max_idx = len(ds_full.time.values) - 1\n",
    "    \n",
    "    # Verificar que hay suficientes datos para validación\n",
    "    if idx_ref + horizon > max_idx:\n",
    "        available_horizon = max_idx - idx_ref\n",
    "        print(f\"⚠️ Advertencia: No hay suficientes datos futuros. Ajustando horizonte de {horizon} a {available_horizon}.\")\n",
    "        horizon = available_horizon\n",
    "    \n",
    "    # Para datos de entrenamiento, usar todo hasta referencia (excepto último mes para tener targets disponibles)\n",
    "    # Asegurarnos de que idx_ref > 0 para evitar errores\n",
    "    if idx_ref <= 0:\n",
    "        raise ValueError(f\"El índice de referencia ({idx_ref}) debe ser mayor que 0.\")\n",
    "    \n",
    "    # Obtener las fechas para los conjuntos de entrenamiento y validación\n",
    "    train_end_date = ds_full.time.values[idx_ref]\n",
    "    val_end_idx = min(idx_ref + horizon, max_idx)\n",
    "    \n",
    "    print(f\"📅 Rango de fechas: entrenamiento hasta {train_end_date}, validación hasta {ds_full.time.values[val_end_idx]}\")\n",
    "    print(f\"📊 Horizonte efectivo: {horizon} meses\")\n",
    "    \n",
    "    # Para entrenamiento, usar datos históricos hasta la fecha de referencia (exclusive)\n",
    "    ds_train = ds_full.sel(time=slice(None, ds_full.time.values[idx_ref-1]))\n",
    "    \n",
    "    # Para validación, usar datos desde la fecha de referencia hasta el horizonte disponible\n",
    "    ds_val = ds_full.sel(time=slice(ds_full.time.values[idx_ref], ds_full.time.values[val_end_idx]))\n",
    "    \n",
    "    print(f\"📏 Tamaño conjunto de entrenamiento: {len(ds_train.time)}\")\n",
    "    print(f\"📏 Tamaño conjunto de validación: {len(ds_val.time)}\")\n",
    "    \n",
    "    # VALIDACIÓN DE DATOS:\n",
    "    # 1. Verificar si tenemos suficientes datos\n",
    "    if len(ds_train.time) < 12:\n",
    "        print(\"⚠️ ADVERTENCIA: Muy pocos datos para entrenamiento (<12 meses)!\")\n",
    "    if len(ds_val.time) < 3:\n",
    "        print(\"⚠️ ADVERTENCIA: Muy pocos datos para validación (<3 meses)!\")\n",
    "        \n",
    "    # 2. Verificar que los conjuntos no se superpongan\n",
    "    train_times = set(ds_train.time.values.astype('datetime64[M]').astype(str))\n",
    "    val_times = set(ds_val.time.values.astype('datetime64[M]').astype(str))\n",
    "    if train_times.intersection(val_times):\n",
    "        print(\"⚠️ ERROR: Superposición entre conjuntos de entrenamiento y validación!\")\n",
    "        \n",
    "    # 3. Verificar variables disponibles\n",
    "    available_vars = list(ds_train.data_vars.keys())\n",
    "    print(f\"📋 Variables disponibles: {available_vars[:5]}... (total: {len(available_vars)})\")\n",
    "    \n",
    "    # Extraer características y etiquetas\n",
    "    # Primero verificar si tenemos predictores precomputados\n",
    "    use_synthetic_data = False\n",
    "    if 'convbigru_preds' in ds_train:\n",
    "        print(\"✅ Usando predicciones precomputadas 'convbigru_preds'\")\n",
    "        X_train = ds_train['convbigru_preds'].values.astype(np.float32)\n",
    "        X_val = ds_val['convbigru_preds'].values.astype(np.float32)\n",
    "    else:\n",
    "        # No tenemos predicciones, usamos datos sintéticos\n",
    "        use_synthetic_data = True\n",
    "        print(\"ℹ️ Variable 'convbigru_preds' no encontrada. Preparando datos alternativos...\")\n",
    "        \n",
    "        # Intentar usar precipitación directamente\n",
    "        if 'total_precipitation' in ds_train:\n",
    "            print(\"✅ Usando 'total_precipitation' como característica principal\")\n",
    "            precipitation_var = 'total_precipitation'\n",
    "        elif 'precip' in ds_train:\n",
    "            print(\"✅ Usando 'precip' como característica principal\")\n",
    "            precipitation_var = 'precip'\n",
    "        else:\n",
    "            # Intentar encontrar algo relacionado con precipitación\n",
    "            precip_vars = [var for var in available_vars if 'precip' in var.lower()]\n",
    "            if precip_vars:\n",
    "                precipitation_var = precip_vars[0]\n",
    "                print(f\"✅ Usando '{precipitation_var}' como característica principal\")\n",
    "            else:\n",
    "                # Usar la primera variable disponible\n",
    "                precipitation_var = available_vars[0]\n",
    "                print(f\"⚠️ No se encontraron variables de precipitación. Usando '{precipitation_var}'\")\n",
    "        \n",
    "        # Preparar datos usando la variable seleccionada\n",
    "        X_train = ds_train[precipitation_var].values.astype(np.float32)\n",
    "        X_val = ds_val[precipitation_var].values.astype(np.float32)\n",
    "        \n",
    "        # Añadir dimensión de canal si es necesario [tiempo, lat, lon] -> [tiempo, 1, lat, lon]\n",
    "        if len(X_train.shape) == 3:\n",
    "            X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "            X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1], X_val.shape[2])\n",
    "    \n",
    "    # Target es siempre precipitación\n",
    "    if 'total_precipitation' in ds_train:\n",
    "        y_train = ds_train['total_precipitation'].values.astype(np.float32)\n",
    "        y_val = ds_val['total_precipitation'].values.astype(np.float32)\n",
    "    elif 'precip' in ds_train:\n",
    "        y_train = ds_train['precip'].values.astype(np.float32)\n",
    "        y_val = ds_val['precip'].values.astype(np.float32)\n",
    "    else:\n",
    "        # Si no encontramos precipitación, usar la misma variable que para las características\n",
    "        y_train = X_train.copy()\n",
    "        y_val = X_val.copy()\n",
    "        # Si tiene dimensión de canal, la quitamos para el target\n",
    "        if len(y_train.shape) == 4:\n",
    "            y_train = y_train.squeeze(1)\n",
    "            y_val = y_val.squeeze(1)\n",
    "    \n",
    "    # Imprimir información sobre los datos\n",
    "    print(f\"\\n📊 Resumen de los datos:\")\n",
    "    print(f\"  - X_train: {X_train.shape}, Rango: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
    "    print(f\"  - y_train: {y_train.shape}, Rango: [{y_train.min():.2f}, {y_train.max():.2f}]\")\n",
    "    print(f\"  - X_val: {X_val.shape}, Rango: [{X_val.min():.2f}, {X_val.max():.2f}]\")\n",
    "    print(f\"  - y_val: {y_val.shape}, Rango: [{y_val.min():.2f}, {y_val.max():.2f}]\")\n",
    "    \n",
    "    # Recordatorio final\n",
    "    if use_synthetic_data:\n",
    "        print(\"\\n⚠️ NOTA: Se están usando datos sintéticos porque no se encontró 'convbigru_preds'\")\n",
    "        print(\"   Si esto es inesperado, verifique que el dataset incluye las variables necesarias.\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# Verificar si necesitamos generar predicciones base\n",
    "if 'convbigru_preds' not in ds_full.data_vars:\n",
    "    print(\"\\n🚩 No se encontraron predicciones 'convbigru_preds'. Generando modelo base y predicciones...\")\n",
    "    ds_full = create_base_model_predictions(ds_full, idx_ref)\n",
    "    print(\"\\n✅ Ahora puede continuar con el entrenamiento del modelo meta usando las predicciones generadas.\")\n",
    "else:\n",
    "    print(\"\\n✅ El dataset ya contiene las predicciones 'convbigru_preds'. No es necesario generarlas.\")\n",
    "\n",
    "# Aplicar la función mejorada\n",
    "print(\"\\n🔄 Preparando datos con la función mejorada...\")\n",
    "X_train, y_train, X_val, y_val = prepare_data_for_hybrid_models(ds_full, ds_ceemdan, ds_tvfemd, idx_ref, horizon=OUTPUT_HORIZON)\n",
    "\n",
    "# Verificar formas de los conjuntos de datos\n",
    "print(f\"\\n✅ Formas finales de los conjuntos de datos:\")\n",
    "print(f\"  - Entrenamiento (X): {X_train.shape}\")\n",
    "print(f\"  - Entrenamiento (y): {y_train.shape}\")\n",
    "print(f\"  - Validación (X): {X_val.shape}\")\n",
    "print(f\"  - Validación (y): {y_val.shape}\")\n",
    "\n",
    "# Configuración de hiperparámetros mejorados para entrenamiento\n",
    "print(\"\\n\\n----- CONFIGURACIÓN DE HIPERPARÁMETROS MEJORADOS -----\")\n",
    "\n",
    "# Parámetros del modelo mejorados\n",
    "input_channels = X_train.shape[1]  # Número de características de entrada\n",
    "hidden_dim = 128  # Aumentado de 64 a 128 para mayor capacidad\n",
    "num_layers = 3    # Aumentado de 2 a 3 para mayor profundidad\n",
    "output_channels = 1\n",
    "seq_length = OUTPUT_HORIZON  # Definimos seq_length como igual al horizonte de predicción\n",
    "learning_rate = 0.0005  # Reducido para una convergencia más estable\n",
    "num_epochs = 500  # Aumentado sustancialmente de 200 a 500\n",
    "patience = 50     # Aumentado para permitir más intentos antes de early stopping\n",
    "batch_size = 16   # Mantenemos el mismo tamaño de batch\n",
    "\n",
    "# Inicializar modelos con arquitectura más potente\n",
    "print(f\"Inicializando modelos con input_channels={input_channels}, hidden_dim={hidden_dim}...\")\n",
    "convbigru_ae = ConvBiGRU_AE(input_channels, hidden_dim, num_layers, output_channels, seq_length).to(DEVICE)\n",
    "convbilstm_ae = ConvBiLSTM_AE(input_channels, hidden_dim, num_layers, output_channels, seq_length).to(DEVICE)\n",
    "\n",
    "# Optimizadores con decay para evitar sobreajuste\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_convbigru = optim.Adam(convbigru_ae.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "optimizer_convbilstm = optim.Adam(convbilstm_ae.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Añadir schedulers para reducir el learning rate cuando la pérdida se estanca\n",
    "scheduler_convbigru = ReduceLROnPlateau(optimizer_convbigru, mode='min', factor=0.5, patience=20, verbose=True)\n",
    "scheduler_convbilstm = ReduceLROnPlateau(optimizer_convbilstm, mode='min', factor=0.5, patience=20, verbose=True)\n",
    "\n",
    "# Create dataset objects with the prepared data\n",
    "train_dataset = PrecipitationDataset(X_train, y_train, seq_length)\n",
    "val_dataset = PrecipitationDataset(X_val, y_val, seq_length)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Configuración actualizada: {num_epochs} épocas, LR={learning_rate}, paciencia={patience}\")\n",
    "\n",
    "# Verificar compatibilidad con forward pass\n",
    "# Probar un forward pass con un batch del DataLoader\n",
    "try:\n",
    "    sample_inputs, sample_targets = next(iter(train_loader))\n",
    "    sample_inputs = sample_inputs.to(DEVICE)\n",
    "    sample_targets = sample_targets.to(DEVICE)\n",
    "    \n",
    "    # Probar con ambos modelos\n",
    "    with torch.no_grad():\n",
    "        sample_outputs_bigru = convbigru_ae(sample_inputs)\n",
    "        sample_outputs_bilstm = convbilstm_ae(sample_inputs)\n",
    "    \n",
    "    print(\"Forward pass exitoso. Formas de salida:\")\n",
    "    print(f\"  - ConvBiGRU-AE: {sample_outputs_bigru.shape}\")\n",
    "    print(f\"  - ConvBiLSTM-AE: {sample_outputs_bilstm.shape}\")\n",
    "    models_ready = True\n",
    "except Exception as e:\n",
    "    print(f\"Error durante el forward pass de prueba: {str(e)}\")\n",
    "    models_ready = False\n",
    "\n",
    "# Entrenamiento con las funciones mejoradas y mayor número de épocas\n",
    "if models_ready:\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ENTRENAMIENTO DE CONVBIGRU_AE\")\n",
    "        print(\"=\"*50)\n",
    "        convbigru_ae, train_losses_bigru, val_losses_bigru = train_model(\n",
    "            convbigru_ae, train_loader, val_loader, criterion, \n",
    "            optimizer_convbigru, scheduler_convbigru,\n",
    "            num_epochs, patience\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ENTRENAMIENTO DE CONVBILSTM_AE\")\n",
    "        print(\"=\"*50)\n",
    "        convbilstm_ae, train_losses_bilstm, val_losses_bilstm = train_model(\n",
    "            convbilstm_ae, train_loader, val_loader, criterion, \n",
    "            optimizer_convbilstm, scheduler_convbilstm,\n",
    "            num_epochs, patience\n",
    "        )\n",
    "        \n",
    "        print(\"\\n✅ Entrenamiento completado correctamente\")\n",
    "        \n",
    "        # Guardar modelos entrenados\n",
    "        save_model_compatible(convbigru_ae, MODELS_OUTPUT / 'convbigru_ae_model.pth')\n",
    "        save_model_compatible(convbilstm_ae, MODELS_OUTPUT / 'convbilstm_ae_model.pth')\n",
    "        print(f\"Modelos guardados en {MODELS_OUTPUT}\")\n",
    "        \n",
    "        # Evaluación y generación de visualizaciones geoespaciales\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"VISUALIZACIÓN DE PREDICCIONES CON COORDENADAS GEOESPACIALES\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Generar visualizaciones geoespaciales precisas\n",
    "        visualize_predictions_with_geospatial_coords()\n",
    "        \n",
    "        # También visualizar las curvas de aprendizaje detalladas\n",
    "        def plot_detailed_learning_curves():\n",
    "            \"\"\"\n",
    "            Crea visualizaciones detalladas de las curvas de aprendizaje para los modelos\n",
    "            ConvBiGRU-AE y ConvBiLSTM-AE, incluyendo análisis de convergencia y comparativa.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                plt.figure(figsize=(20, 12))\n",
    "                \n",
    "                # 1. Gráfico de pérdida absoluta para ambos modelos\n",
    "                plt.subplot(2, 2, 1)\n",
    "                plt.plot(train_losses_bigru, label='ConvBiGRU - Train', color='blue', linestyle='-')\n",
    "                plt.plot(val_losses_bigru, label='ConvBiGRU - Val', color='blue', linestyle='--')\n",
    "                plt.plot(train_losses_bilstm, label='ConvBiLSTM - Train', color='red', linestyle='-')\n",
    "                plt.plot(val_losses_bilstm, label='ConvBiLSTM - Val', color='red', linestyle='--')\n",
    "                plt.title('Curvas de Aprendizaje - Pérdida Absoluta', fontsize=14)\n",
    "                plt.xlabel('Época', fontsize=12)\n",
    "                plt.ylabel('Pérdida (MSE)', fontsize=12)\n",
    "                plt.legend(loc='upper right')\n",
    "                plt.grid(alpha=0.3)\n",
    "                \n",
    "                # 2. Gráfico de pérdida relativa (normalizada al valor inicial)\n",
    "                plt.subplot(2, 2, 2)\n",
    "                rel_train_bigru = [l/train_losses_bigru[0] for l in train_losses_bigru]\n",
    "                rel_val_bigru = [l/val_losses_bigru[0] for l in val_losses_bigru]\n",
    "                rel_train_bilstm = [l/train_losses_bilstm[0] for l in train_losses_bilstm]\n",
    "                rel_val_bilstm = [l/val_losses_bilstm[0] for l in val_losses_bilstm]\n",
    "                \n",
    "                plt.plot(rel_train_bigru, label='ConvBiGRU - Train', color='blue', alpha=0.7)\n",
    "                plt.plot(rel_val_bigru, label='ConvBiGRU - Val', color='blue', linestyle='--', alpha=0.7)\n",
    "                plt.plot(rel_train_bilstm, label='ConvBiLSTM - Train', color='red', alpha=0.7)\n",
    "                plt.plot(rel_val_bilstm, label='ConvBiLSTM - Val', color='red', linestyle='--', alpha=0.7)\n",
    "                plt.title(f'Curvas de Aprendizaje - Pérdida Relativa (% del valor inicial)', fontsize=14)\n",
    "                plt.xlabel('Época', fontsize=12)\n",
    "                plt.ylabel('Pérdida Relativa', fontsize=12)\n",
    "                plt.legend()\n",
    "                plt.grid(alpha=0.3)\n",
    "                \n",
    "                # 3. Comparación de diferencia entre train y validation\n",
    "                plt.subplot(2, 2, 3)\n",
    "                diff_bigru = [t-v for t, v in zip(train_losses_bigru, val_losses_bigru)]\n",
    "                diff_bilstm = [t-v for t, v in zip(train_losses_bilstm, val_losses_bilstm)]\n",
    "                \n",
    "                plt.plot(diff_bigru, label='ConvBiGRU (Train-Val)', color='blue')\n",
    "                plt.plot(diff_bilstm, label='ConvBiLSTM (Train-Val)', color='red')\n",
    "                plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "                plt.title('Diferencia entre Pérdidas de Train y Validación', fontsize=14)\n",
    "                plt.xlabel('Época', fontsize=12)\n",
    "                plt.ylabel('Train Loss - Val Loss', fontsize=12)\n",
    "                plt.legend()\n",
    "                plt.grid(alpha=0.3)\n",
    "                \n",
    "                # 4. Tasa de mejora (derivada de la pérdida)\n",
    "                plt.subplot(2, 2, 4)\n",
    "                # Calcular mejora por época (primera derivada de la pérdida)\n",
    "                improve_rate_bigru = [train_losses_bigru[i-1] - train_losses_bigru[i] for i in range(1, len(train_losses_bigru))]\n",
    "                improve_rate_bilstm = [train_losses_bilstm[i-1] - train_losses_bilstm[i] for i in range(1, len(train_losses_bilstm))]\n",
    "                \n",
    "                plt.plot(improve_rate_bigru, label='ConvBiGRU', color='blue')\n",
    "                plt.plot(improve_rate_bilstm, label='ConvBiLSTM', color='red')\n",
    "                plt.title('Tasa de Mejora por Época (Δ Pérdida)', fontsize=14)\n",
    "                plt.xlabel('Época', fontsize=12)\n",
    "                plt.ylabel('Mejora (Reducción de Pérdida)', fontsize=12)\n",
    "                plt.grid(alpha=0.3)\n",
    "                plt.legend()\n",
    "                \n",
    "                # Ajustar diseño y guardar figura\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(MODELS_OUTPUT / 'detailed_learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                \n",
    "                # Resumen final de métricas\n",
    "                best_val_bigru = min(val_losses_bigru)\n",
    "                best_val_bilstm = min(val_losses_bilstm)\n",
    "                best_epoch_bigru = val_losses_bigru.index(best_val_bigru)\n",
    "                best_epoch_bilstm = val_losses_bilstm.index(best_val_bilstm)\n",
    "                \n",
    "                print(\"\\n==== RESUMEN DE MÉTRICAS DE ENTRENAMIENTO ====\")\n",
    "                print(f\"ConvBiGRU-AE:\")\n",
    "                print(f\"  - Mejor pérdida de validación: {best_val_bigru:.2f} (Época {best_epoch_bigru})\")\n",
    "                print(f\"  - Reducción total de pérdida: {train_losses_bigru[0] - train_losses_bigru[-1]:.2f} ({(1 - train_losses_bigru[-1]/train_losses_bigru[0])*100:.1f}%)\")\n",
    "                \n",
    "                print(f\"\\nConvBiLSTM-AE:\")\n",
    "                print(f\"  - Mejor pérdida de validación: {best_val_bilstm:.2f} (Época {best_epoch_bilstm})\")\n",
    "                print(f\"  - Reducción total de pérdida: {train_losses_bilstm[0] - train_losses_bilstm[-1]:.2f} ({(1 - train_losses_bilstm[-1]/train_losses_bilstm[0])*100:.1f}%)\")\n",
    "                \n",
    "                if best_val_bigru < best_val_bilstm:\n",
    "                    print(f\"\\n✅ ConvBiGRU-AE tiene mejor rendimiento con {(best_val_bilstm - best_val_bigru)/best_val_bilstm*100:.1f}% menor pérdida de validación\")\n",
    "                else:\n",
    "                    print(f\"\\n✅ ConvBiLSTM-AE tiene mejor rendimiento con {(best_val_bigru - best_val_bilstm)/best_val_bigru*100:.1f}% menor pérdida de validación\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error al visualizar curvas de aprendizaje: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                \n",
    "        plot_detailed_learning_curves()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error durante el entrenamiento: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\n❌ Entrenamiento cancelado debido a problemas con los modelos.\")\n",
    "\n",
    "# Implementación de Modelos Híbridos Avanzados\n",
    "\n",
    "## TopoClus-CEEMDAN-TVF-AFC-ConvBiGRU‐AE y TopoClus-CEEMDAN-TVF-AFC-ConvLSTM‐AE\n",
    "\"\"\"\n",
    "Estos modelos representan una arquitectura avanzada que combina:\n",
    "\n",
    "1. **Técnicas de descomposición de señales**:\n",
    "   - CEEMDAN (Complete Ensemble Empirical Mode Decomposition with Adaptive Noise)\n",
    "   - TVF-EMD (Time-Varying Filter Empirical Mode Decomposition)\n",
    "   \n",
    "2. **Características de autocorrelación (AFC)** en diferentes lags temporales\n",
    "\n",
    "3. **Información topográfica y orográfica**:\n",
    "   - Clusters basados en elevación (TopoClus)\n",
    "   - Embeddings específicos por cluster\n",
    "\n",
    "4. **Arquitecturas neuronales avanzadas**:\n",
    "   - Encoder-Decoder Convolucional con BiGRU o BiLSTM\n",
    "   - Atención topográfica para modular características por tipo de terreno\n",
    "\n",
    "# Preparación de datos y extracción de características para modelos híbridos\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import math\n",
    "\n",
    "class FiLMLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Feature-wise Linear Modulation para adaptar las características según el cluster orográfico\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters, n_features):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_clusters, n_features * 2)\n",
    "        \n",
    "        # Inicializar con valores razonables (gamma cercano a 1, beta cercano a 0)\n",
    "        nn.init.normal_(self.embedding.weight[:, :n_features], 1.0, 0.1)\n",
    "        nn.init.zeros_(self.embedding.weight[:, n_features:])\n",
    "    \n",
    "    def forward(self, x, cluster_idx):\n",
    "        # x: [batch, channels, height, width]\n",
    "        # cluster_idx: [batch]\n",
    "        batch_size, channels = x.shape[0], x.shape[1]\n",
    "        \n",
    "        # Obtener parámetros gamma y beta del embedding\n",
    "        params = self.embedding(cluster_idx)  # [batch, channels*2]\n",
    "        gamma, beta = params.chunk(2, dim=1)  # [batch, channels], [batch, channels]\n",
    "        \n",
    "        # Reshape para permitir broadcasting\n",
    "        gamma = gamma.view(batch_size, channels, 1, 1)\n",
    "        beta = beta.view(batch_size, channels, 1, 1)\n",
    "        \n",
    "        # Aplicar modulación: γ ⊗ x + β\n",
    "        return gamma * x + beta\n",
    "\n",
    "class MultiResBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    Rama de procesamiento multi-resolución con dilataciones variables\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dilations=(1, 2, 4)):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList()\n",
    "        \n",
    "        # Crear una rama para cada dilatación\n",
    "        for dilation in dilations:\n",
    "            branch = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, \n",
    "                    out_channels, \n",
    "                    kernel_size=3, \n",
    "                    padding=dilation, \n",
    "                    dilation=dilation\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            self.branches.append(branch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for branch in self.branches:\n",
    "            outputs.append(branch(x))\n",
    "        \n",
    "        # Concatenar resultados de todas las ramas\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "class TopoClus_CEEMDAN_TVF_AFC_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder compartido para ambos modelos que integra todas las fuentes de datos\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_dim, n_clusters, use_checkpoint=True):\n",
    "        super().__init__()\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        \n",
    "        # Reducción inicial de canales\n",
    "        self.channel_reduction = nn.Conv2d(input_channels, hidden_dim, kernel_size=1)\n",
    "        \n",
    "        # Procesamiento multi-resolución\n",
    "        self.multi_res = MultiResBranch(hidden_dim, hidden_dim//2)\n",
    "        merged_channels = hidden_dim//2 * 3  # 3 ramas con dilaciones diferentes\n",
    "        \n",
    "        # Adaptación por cluster (FiLM)\n",
    "        self.film = FiLMLayer(n_clusters, merged_channels)\n",
    "        \n",
    "        # Codificador principal (estructura tipo U-Net)\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(merged_channels, hidden_dim, 3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim, hidden_dim*2, 3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim*2, hidden_dim*2, 3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim*2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim*2, hidden_dim*4, 3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim*4, hidden_dim*4, 3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, cluster_idx):\n",
    "        # x: [batch, channels, height, width]\n",
    "        \n",
    "        # Reducción de canales\n",
    "        x = self.channel_reduction(x)\n",
    "        \n",
    "        # Procesamiento multiresolución\n",
    "        if self.use_checkpoint and self.training:\n",
    "            x = checkpoint(self.multi_res, x)\n",
    "        else:\n",
    "            x = self.multi_res(x)\n",
    "        \n",
    "        # Adaptación por cluster\n",
    "        x = self.film(x, cluster_idx)\n",
    "        \n",
    "        # Codificador U-Net\n",
    "        # Guardar para conexiones skip\n",
    "        if self.use_checkpoint and self.training:\n",
    "            x1 = checkpoint(self.down1, x)\n",
    "        else:\n",
    "            x1 = self.down1(x)\n",
    "        \n",
    "        x = self.pool1(x1)\n",
    "        \n",
    "        if self.use_checkpoint and self.training:\n",
    "            x2 = checkpoint(self.down2, x)\n",
    "        else:\n",
    "            x2 = self.down2(x)\n",
    "        \n",
    "        x = self.pool2(x2)\n",
    "        \n",
    "        if self.use_checkpoint and self.training:\n",
    "            x = checkpoint(self.bottleneck, x)\n",
    "        else:\n",
    "            x = self.bottleneck(x)\n",
    "        \n",
    "        return x, x1, x2  # Retornar también activaciones intermedias para skip connections\n",
    "\n",
    "class TopoClus_CEEMDAN_TVF_AFC_ConvBiGRU_AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo completo que integra codificador compartido con BiGRU para procesamiento temporal\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_dim, n_clusters, seq_length=12, output_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_horizon = seq_length  # Guardar el horizonte de salida\n",
    "        \n",
    "        self.encoder = TopoClus_CEEMDAN_TVF_AFC_Encoder(\n",
    "            input_channels, hidden_dim, n_clusters\n",
    "        )\n",
    "        \n",
    "        # BiGRU para procesamiento secuencial\n",
    "        self.bigru = nn.GRU(\n",
    "            hidden_dim*4*4*4,  # Tamaño del bottleneck (asumiendo 2 maxpoolings)\n",
    "            hidden_dim*4,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            num_layers=2\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(hidden_dim*8, hidden_dim*2, 2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim*4, hidden_dim*2, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim*2, hidden_dim*2, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "        self.up2 = nn.ConvTranspose2d(hidden_dim*2, hidden_dim, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim*2, hidden_dim, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=False), \n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 7. Capa de salida multi-horizonte\n",
    "        out_channels = self.output_horizon * output_channels\n",
    "        self.output_conv = nn.Conv2d(hidden_dim, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, cluster_idx, target_shape=None):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Codificar\n",
    "        bottleneck, skip1, skip2 = self.encoder(x, cluster_idx)\n",
    "        \n",
    "        # Aplanar el bottleneck para el GRU\n",
    "        flattened = bottleneck.view(batch_size, -1)\n",
    "        \n",
    "        # Reshape para BiGRU (añadir dim de secuencia)\n",
    "        gru_in = flattened.unsqueeze(1)\n",
    "        \n",
    "        # Procesar con BiGRU\n",
    "        gru_out, _ = self.bigru(gru_in)\n",
    "        \n",
    "        # Tomar salida y reshape para decodificador\n",
    "        gru_features = gru_out.view(batch_size, -1, 1, 1)\n",
    "        \n",
    "        # Redimensionar para que coincida con el bottleneck\n",
    "        h, w = bottleneck.shape[2], bottleneck.shape[3]\n",
    "        gru_features = F.interpolate(gru_features, size=(h, w), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Decodificar\n",
    "        x = self.up1(gru_features)\n",
    "        \n",
    "        # Skip connection 1\n",
    "        x = torch.cat([x, skip2], dim=1)\n",
    "        x = self.dec1(x)\n",
    "        \n",
    "        x = self.up2(x)\n",
    "        \n",
    "        # Skip connection 2\n",
    "        x = torch.cat([x, skip1], dim=1)\n",
    "        x = self.dec2(x)\n",
    "        \n",
    "        # Salida multi-horizonte\n",
    "        x = self.output_conv(x)\n",
    "        \n",
    "        # Si no se proporciona target_shape, usar la forma de x\n",
    "        if target_shape is None:\n",
    "            height, width = x.shape[2], x.shape[3]  # Usar forma de la salida actual\n",
    "            # Ajustar para output_channels y output_horizon\n",
    "            target_height = height // self.output_horizon\n",
    "            target_width = width // output_channels\n",
    "            target_shape = (target_height, target_width)\n",
    "        \n",
    "        # Reorganizar para obtener [batch, seq, channels, height, width]\n",
    "        output = x.reshape(batch_size, self.output_horizon, output_channels, target_shape[0], target_shape[1])\n",
    "        \n",
    "        return output\n",
    "        \n",
    "class TopoClus_CEEMDAN_TVF_AFC_ConvBiLSTM_AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Versión con BiLSTM en lugar de BiGRU\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_dim, n_clusters, seq_length=12, output_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_horizon = seq_length  # Guardar el horizonte de predicción\n",
    "        \n",
    "        self.encoder = TopoClus_CEEMDAN_TVF_AFC_Encoder(\n",
    "            input_channels, hidden_dim, n_clusters\n",
    "        )\n",
    "        \n",
    "        # BiLSTM para procesamiento secuencial\n",
    "        self.bilstm = nn.LSTM(\n",
    "            hidden_dim*4*4*4,  # Tamaño del bottleneck (asumiendo 2 maxpoolings)\n",
    "            hidden_dim*4,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            num_layers=2\n",
    "        )\n",
    "        \n",
    "        # Decodificador (mismo que en versión BiGRU)\n",
    "        self.up1 = nn.ConvTranspose2d(hidden_dim*8, hidden_dim*2, 2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim*4, hidden_dim*2, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim*2, hidden_dim*2, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(hidden_dim*2, hidden_dim, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim*2, hidden_dim, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=False), \n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 7. Capa de salida multi-horizonte\n",
    "        out_channels = self.output_horizon * output_channels\n",
    "        self.output_conv = nn.Conv2d(hidden_dim, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, cluster_idx, target_shape=None):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Codificar\n",
    "        bottleneck, skip1, skip2 = self.encoder(x, cluster_idx)\n",
    "        \n",
    "        # Aplanar el bottleneck para el LSTM\n",
    "        flattened = bottleneck.view(batch_size, -1)\n",
    "        \n",
    "        # Reshape para BiLSTM (añadir dim de secuencia)\n",
    "        lstm_in = flattened.unsqueeze(1)\n",
    "        \n",
    "        # Procesar con BiLSTM\n",
    "        lstm_out, _ = self.bilstm(lstm_in)\n",
    "        \n",
    "        # Tomar salida y reshape para decodificador\n",
    "        lstm_features = lstm_out.view(batch_size, -1, 1, 1)\n",
    "        \n",
    "        # Redimensionar para que coincida con el bottleneck\n",
    "        h, w = bottleneck.shape[2], bottleneck.shape[3]\n",
    "        lstm_features = F.interpolate(lstm_features, size=(h, w), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Decodificar (mismo proceso que BiGRU)\n",
    "        x = self.up1(lstm_features)\n",
    "        x = torch.cat([x, skip2], dim=1)\n",
    "        x = self.dec1(x)\n",
    "        \n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, skip1], dim=1)\n",
    "        x = self.dec2(x)\n",
    "        \n",
    "        # Salida multi-horizonte\n",
    "        x = self.output_conv(x)\n",
    "        \n",
    "        # Si no se proporciona target_shape, usar la forma de x\n",
    "        if target_shape is None:\n",
    "            height, width = x.shape[2], x.shape[3]  # Usar forma de la salida actual\n",
    "            # Ajustar para output_channels y output_horizon\n",
    "            target_height = height // self.output_horizon\n",
    "            target_width = width // output_channels\n",
    "            target_shape = (target_height, target_width)\n",
    "            \n",
    "        # Reorganizar para obtener [batch, seq, channels, height, width]\n",
    "        output = x.reshape(batch_size, self.output_horizon, output_channels, target_shape[0], target_shape[1])\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Dataset para manejar las múltiples fuentes de características\n",
    "class MultiSourceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para manejar múltiples fuentes de características\n",
    "    \"\"\"\n",
    "    def __init__(self, X_list, y, seq_length=12):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_list: Lista de arrays de características\n",
    "            y: Array de targets\n",
    "            seq_length: Longitud de la secuencia\n",
    "        \"\"\"\n",
    "        self.X_list = [torch.FloatTensor(x) for x in X_list]\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # Definir nombres de características basados en la estructura de X_list\n",
    "        feature_names = ['precipitation', 'temperature', 'elevation', 'clusters']\n",
    "        \n",
    "        # Determinar qué fuente contiene los clusters para FiLM\n",
    "        for i, x in enumerate(self.X_list):\n",
    "            if 'clusters' in x:\n",
    "                self.cluster_idx = i\n",
    "                break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_list[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Combinar todas las fuentes en un solo tensor\n",
    "        # Cada fuente: [batch_size, input_window, height, width]\n",
    "        batch_inputs = []\n",
    "        for x in self.X_list:\n",
    "            # Tomar ventana completa para esta característica\n",
    "            feature = x[idx]\n",
    "            batch_inputs.append(feature)\n",
    "        \n",
    "        # Concatenar en dimensión de canal: [input_window, num_sources, height, width]\n",
    "        combined_input = torch.cat([x.unsqueeze(1) for x in batch_inputs], dim=1)\n",
    "        \n",
    "        # Target: [output_horizon, height, width]\n",
    "        target = self.y[idx]\n",
    "        \n",
    "        # Extraer el índice de cluster si está disponible\n",
    "        if self.cluster_idx >= 0:\n",
    "            # Tomar el primer índice de tiempo y la moda de los clusters en el mapa\n",
    "            cluster_map = batch_inputs[self.cluster_idx][0]\n",
    "            cluster_idx = int(torch.mode(cluster_map.flatten())[0])\n",
    "        else:\n",
    "            # Si no hay datos de cluster, usar 0 como fallback\n",
    "            cluster_idx = 0\n",
    "        \n",
    "        return combined_input, target, cluster_idx\n",
    "\n",
    "print(\"Definiendo modelos y dataset...\")\n",
    "\n",
    "# Inicializar el dataset\n",
    "train_dataset = MultiSourceDataset(X_train, y_train, seq_length=OUTPUT_HORIZON)\n",
    "val_dataset = MultiSourceDataset(X_val, y_val, seq_length=OUTPUT_HORIZON)\n",
    "\n",
    "# Parámetros de modelo\n",
    "if isinstance(X_train, list) and len(X_train) > 0:\n",
    "    combined_channels = sum(x.shape[1] for x in X_train[0])\n",
    "    print(f\"Canales de entrada combinados: {combined_channels}\")\n",
    "else:\n",
    "    combined_channels = X_train.shape[1]\n",
    "    print(f\"Canales de entrada: {combined_channels}\")\n",
    "\n",
    "# Definir cluster_ids basados en los datos disponibles\n",
    "# Si tenemos datos de clusters, obtener valores únicos, sino usar un valor predeterminado\n",
    "cluster_ids = list(range(10))  # Default: suponemos 10 clusters\n",
    "# Definir target_shape basado en los datos\n",
    "if isinstance(X_train, list) and len(X_train) > 0:\n",
    "    # Si X_train es una lista, tomar las dimensiones del primer elemento\n",
    "    if len(X_train[0].shape) >= 3:\n",
    "        target_shape = X_train[0].shape[-2:]  # Últimas dos dimensiones (altura, anchura)\n",
    "    else:\n",
    "        # Dimensiones por defecto si no podemos determinarlas\n",
    "        target_shape = (61, 65)\n",
    "else:\n",
    "    # Si X_train no es una lista, tomar sus dimensiones directamente\n",
    "    if len(X_train.shape) >= 3:\n",
    "        target_shape = X_train.shape[-2:]\n",
    "    else:\n",
    "        target_shape = (61, 65)\n",
    "\n",
    "print(f\"Target shape para la salida del modelo: {target_shape}\")\n",
    "\n",
    "# Instanciar modelos\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "convbigru_model = TopoClus_CEEMDAN_TVF_AFC_ConvBiGRU_AE(\n",
    "    combined_channels, hidden_dim, n_clusters, OUTPUT_HORIZON\n",
    ").to(device)\n",
    "\n",
    "convbilstm_model = TopoClus_CEEMDAN_TVF_AFC_ConvBiLSTM_AE(\n",
    "    combined_channels, hidden_dim, n_clusters, OUTPUT_HORIZON\n",
    ").to(device)\n",
    "\n",
    "def calculate_spatial_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula métricas espaciales entre valores verdaderos y predichos.\n",
    "    \"\"\"\n",
    "    # Implementación pendiente\n",
    "    pass\n",
    "\n",
    "# Función para mostrar progreso sin borrar salidas previas\n",
    "def plot_progress_without_clearing(train_losses, val_losses, best_val_loss=None):\n",
    "    \"\"\"\n",
    "    Plotea el progreso del entrenamiento sin borrar la salida anterior.\n",
    "    Similar a plot_progress pero sin el clear_output().\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    if best_val_loss is not None:\n",
    "        plt.axhline(y=best_val_loss, color='r', linestyle='--', label=f'Best: {best_val_loss:.2f}')\n",
    "    plt.title(f'Loss vs. Epochs (Current: {val_losses[-1]:.2f})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    rel_loss = [l/train_losses[0] for l in train_losses]\n",
    "    rel_val_loss = [l/val_losses[0] for l in val_losses]\n",
    "    plt.plot(rel_loss, label='Train')\n",
    "    plt.plot(rel_val_loss, label='Val')\n",
    "    plt.title(f'Relative Loss (% of initial loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Relative Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_hybrid_model(name, model, train_loader, val_loader, epochs=100, patience=20):\n",
    "    \"\"\"\n",
    "    Entrena un modelo híbrido con optimizaciones avanzadas y realiza evaluación\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"ENTRENAMIENTO DE {name}\")\n",
    "    print(f\"{'='*30}\")\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Importar tqdm si no está disponible\n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "    except ImportError:\n",
    "        # Definir una versión simple si no está instalado\n",
    "        def tqdm(iterable, **kwargs):\n",
    "            print(kwargs.get('desc', ''))\n",
    "            return iterable\n",
    "    \n",
    "    # Optimizador y función de pérdida\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=patience//2, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Mixed precision\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Tracking de métricas\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    current_lr = optimizer.param_groups[0]['lr']  # Guardar LR inicial\n",
    "    \n",
    "    # Para guardar mejor modelo\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    start_time = time.time()\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = name  # Asegurar que tenemos model_name definido\n",
    "    save_dir = MODELS_OUTPUT  # Usar el directorio de modelos definido globalmente\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model_path = save_dir / f'{name}_{timestamp}.pt'\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # ===== ENTRENAMIENTO =====\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        batch_metrics = []\n",
    "        \n",
    "        # Barra de progreso para entrenamiento\n",
    "        train_progress = tqdm(train_loader, desc=f\"Época {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "        \n",
    "        for inputs, targets in train_progress:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Asegurar compatibilidad de dimensiones\n",
    "            if len(outputs.shape) == 5 and len(targets.shape) <= 4:\n",
    "                outputs = outputs.squeeze(2)  # eliminar dim C si es 1\n",
    "                \n",
    "            if len(outputs.shape) != len(targets.shape):\n",
    "                if len(outputs.shape) == 5 and len(targets.shape) == 3:\n",
    "                    targets = targets.unsqueeze(1).unsqueeze(2).repeat(1, outputs.shape[1], 1, 1, 1)\n",
    "                elif len(outputs.shape) == 5 and len(targets.shape) == 4:\n",
    "                    targets = targets.unsqueeze(2)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping para estabilidad\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Actualizar barra de progreso con pérdida actual\n",
    "            train_progress.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "            batch_metrics.append(loss.item())\n",
    "        \n",
    "        train_loss = np.mean(batch_metrics)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # ===== VALIDACIÓN =====\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_outputs = []\n",
    "        val_targets = []\n",
    "        \n",
    "        # Barra de progreso para validación\n",
    "        val_progress = tqdm(val_loader, desc=f\"Época {epoch+1}/{epochs} [Val]\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_progress:\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Ajustar dimensiones si es necesario\n",
    "                if len(outputs.shape) == 5 and len(targets.shape) <= 4:\n",
    "                    outputs = outputs.squeeze(2)\n",
    "                \n",
    "                if len(outputs.shape) != len(targets.shape):\n",
    "                    if len(outputs.shape) == 5 and len(targets.shape) == 3:\n",
    "                        targets = targets.unsqueeze(1).unsqueeze(2).repeat(1, outputs.shape[1], 1, 1, 1)\n",
    "                    elif len(outputs.shape) == 5 and len(targets.shape) == 4:\n",
    "                        targets = targets.unsqueeze(2)\n",
    "                \n",
    "                loss = criterion(outputs, targets)\n",
    "                val_progress.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Guardar para métricas\n",
    "                val_outputs.append(outputs.cpu())\n",
    "                val_targets.append(targets.cpu())\n",
    "        \n",
    "        # Calcular pérdida promedio\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Calcular tiempo de la época\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Actualizar scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Comprobar si el LR ha cambiado\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        lr_updated = new_lr != current_lr\n",
    "        old_lr = current_lr\n",
    "        current_lr = new_lr  # Actualizar para próxima comparación\n",
    "        \n",
    "        # Mostrar gráfico de progreso cada 5 épocas o en la última\n",
    "        if epoch % 5 == 0 or epoch == epochs - 1 or epochs_no_improve == patience:\n",
    "            try:\n",
    "                plot_progress_without_clearing(train_losses, val_losses, best_val_loss)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al mostrar gráfico: {str(e)}\")\n",
    "        \n",
    "        # Imprimir resumen de la época\n",
    "        print(f\"\\n📊 Época {epoch+1}/{epochs} completada en {epoch_time:.1f}s\")\n",
    "        print(f\"   Train Loss: {train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | \" + \n",
    "              (f\"LR reducido: {old_lr:.6f} → {new_lr:.6f}\" if lr_updated else f\"LR: {new_lr:.6f}\"))\n",
    "        \n",
    "        # Early stopping y guardado del mejor modelo\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            improvement = (best_val_loss - avg_val_loss) / best_val_loss * 100 if best_val_loss != float('inf') else 100\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            \n",
    "            # Guardar mejor modelo\n",
    "            save_model(model, model_path, epoch, avg_val_loss)\n",
    "            print(f\"   ⭐ ¡Nuevo mejor modelo! Mejora: {improvement:.2f}%\")\n",
    "            \n",
    "            # También guardar checkpoint específico de esta época\n",
    "            epoch_path = save_dir / f'checkpoint_{model_name}_epoch_{epoch+1}.pth'\n",
    "            save_model(model, epoch_path, epoch, avg_val_loss)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"   ❌ Sin mejora durante {epochs_no_improve}/{patience} épocas. Mejor: {best_val_loss:.4f}\")\n",
    "            \n",
    "            # Guardar checkpoint regular cada 10 épocas\n",
    "            if epoch % 10 == 0:\n",
    "                checkpoint_path = save_dir / f'regular_checkpoint_{model_name}_epoch_{epoch+1}.pth'\n",
    "                save_model(model, checkpoint_path, epoch, avg_val_loss)\n",
    "                \n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"\\n⚠️ Early stopping activado después de {patience} épocas sin mejora\")\n",
    "                break\n",
    "    \n",
    "    # Tiempo total de entrenamiento\n",
    "    total_time = time.time() - start_time\n",
    "    hours, rem = divmod(total_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ENTRENAMIENTO FINALIZADO: {model_name}\")\n",
    "    print(f\"Tiempo total: {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n",
    "    print(f\"Mejor pérdida de validación: {best_val_loss:.4f}\")\n",
    "    print(f\"Modelos guardados en: {save_dir}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Cargar el mejor modelo\n",
    "    try:\n",
    "        checkpoint = torch.load(model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"✅ Mejor modelo cargado de la época {checkpoint['epoch']+1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al cargar el mejor modelo: {str(e)}\")\n",
    "    \n",
    "    # Tiempo total de entrenamiento\n",
    "    total_time = time.time() - start_time\n",
    "    hours, rem = divmod(total_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ENTRENAMIENTO FINALIZADO: {model_name}\")\n",
    "    print(f\"Tiempo total: {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n",
    "    print(f\"Mejor pérdida de validación: {best_val_loss:.4f}\")\n",
    "    print(f\"Modelos guardados en: {save_dir}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "# Función para verificar si un modelo existe y mostrar información sobre él\n",
    "def check_model_exists(model_path):\n",
    "    \"\"\"Verifica si un modelo existe y muestra información sobre él.\"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "            print(f\"✅ Modelo encontrado en: {model_path}\")\n",
    "            if isinstance(checkpoint, dict) and 'epoch' in checkpoint:\n",
    "                print(f\"   Guardado en época: {checkpoint['epoch']+1}\")\n",
    "                print(f\"   Pérdida validación: {checkpoint['val_loss']:.4f}\")\n",
    "            else:\n",
    "                print(\"   (Formato antiguo - solo state_dict)\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error al cargar modelo {model_path}: {str(e)}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"❌ Modelo no encontrado: {model_path}\")\n",
    "        return False\n",
    "\n",
    "# Función para visualizar métricas de entrenamiento almacenadas\n",
    "def visualize_training_metrics(train_losses, val_losses, model_name=\"modelo\"):\n",
    "    \"\"\"\n",
    "    Visualiza las métricas de entrenamiento con gráficos detallados y estadísticas.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # 1. Curva de pérdida básica\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(train_losses, label='Entrenamiento', color='blue', linestyle='-', marker='.', alpha=0.7)\n",
    "    plt.plot(val_losses, label='Validación', color='red', linestyle='-', marker='.', alpha=0.7)\n",
    "    \n",
    "    best_val_idx = np.argmin(val_losses)\n",
    "    best_val_loss = val_losses[best_val_idx]\n",
    "    plt.axvline(x=best_val_idx, color='green', linestyle='--', alpha=0.7, \n",
    "                label=f'Mejor época: {best_val_idx+1}')\n",
    "    plt.axhline(y=best_val_loss, color='green', linestyle=':', alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Curva de Aprendizaje - {model_name}', fontsize=14)\n",
    "    plt.xlabel('Época', fontsize=12)\n",
    "    plt.ylabel('Pérdida', fontsize=12)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Pérdida relativa (%)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    rel_train = [t/train_losses[0]*100 for t in train_losses]\n",
    "    rel_val = [v/val_losses[0]*100 for v in val_losses]\n",
    "    \n",
    "    plt.plot(rel_train, label='Entrenamiento', color='blue', alpha=0.7)\n",
    "    plt.plot(rel_val, label='Validación', color='red', alpha=0.7)\n",
    "    plt.axvline(x=best_val_idx, color='green', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Pérdida Relativa (% del valor inicial)', fontsize=14)\n",
    "    plt.xlabel('Época', fontsize=12)\n",
    "    plt.ylabel('Porcentaje (%)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Diferencia Train-Val (sobreajuste)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    diff = [t-v for t, v in zip(train_losses, val_losses)]\n",
    "    \n",
    "    plt.plot(diff, color='purple', alpha=0.7)\n",
    "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.axvline(x=best_val_idx, color='green', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Sombreado para zona de sobreajuste potencial\n",
    "    plt.fill_between(range(len(diff)), [0]*len(diff), diff, \n",
    "                     where=[d < 0 for d in diff], color='red', alpha=0.2,\n",
    "                     label='Posible subajuste')\n",
    "    plt.fill_between(range(len(diff)), [0]*len(diff), diff, \n",
    "                     where=[d > 0 for d in diff], color='orange', alpha=0.2,\n",
    "                     label='Posible sobreajuste')\n",
    "    \n",
    "    plt.title('Diferencia Train-Validación (Indicador de Sobreajuste)', fontsize=14)\n",
    "    plt.xlabel('Época', fontsize=12)\n",
    "    plt.ylabel('Train Loss - Val Loss', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Velocidad de convergencia (derivada de la pérdida)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if len(val_losses) > 1:\n",
    "        val_improvement = [val_losses[i-1] - val_losses[i] for i in range(1, len(val_losses))]\n",
    "        improving = [i > 0 for i in val_improvement]\n",
    "        colors = ['green' if imp else 'red' for imp in improving]\n",
    "        \n",
    "        plt.bar(range(1, len(val_losses)), val_improvement, color=colors, alpha=0.7)\n",
    "        plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        if best_val_idx > 0:\n",
    "            plt.axvline(x=best_val_idx, color='green', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.title('Velocidad de Mejora por Época', fontsize=14)\n",
    "        plt.xlabel('Época', fontsize=12)\n",
    "        plt.ylabel('Mejora (reducción de pérdida)', fontsize=12)\n",
    "        plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Estadísticas adicionales\n",
    "    print(f\"\\n{'='*40} ESTADÍSTICAS DE ENTRENAMIENTO {'='*40}\")\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    print(f\"Total de épocas: {len(train_losses)}\")\n",
    "    print(f\"Mejor época: {best_val_idx+1}\")\n",
    "    print(f\"Mejor pérdida validación: {best_val_loss:.4f}\")\n",
    "    print(f\"Pérdida inicial (val): {val_losses[0]:.4f}\")\n",
    "    print(f\"Pérdida final (val): {val_losses[-1]:.4f}\")\n",
    "    print(f\"Mejora total: {(1 - best_val_loss/val_losses[0])*100:.2f}%\")\n",
    "    \n",
    "    # Calcular tendencias\n",
    "    last_epochs = min(10, len(val_losses))\n",
    "    if last_epochs > 1:\n",
    "        recent_trend = val_losses[-last_epochs:][0] - val_losses[-1]\n",
    "        print(f\"Tendencia últimas {last_epochs} épocas: {recent_trend:.4f} \" +\n",
    "              (\"📉 mejorando\" if recent_trend > 0 else \"📈 empeorando\"))\n",
    "    \n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Reemplazar el código de entrenamiento con la versión mejorada\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENTRENAMIENTO DE MODELOS CON VISUALIZACIÓN MEJORADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar que los modelos estén listos\n",
    "if models_ready:\n",
    "    try:\n",
    "        # Verificar directorios de salida y rutas de modelos\n",
    "        print(\"\\n📂 Configuración de directorios y rutas:\")\n",
    "        print(f\"Directorio de salida: {MODELS_OUTPUT}\")\n",
    "        \n",
    "        # Comprobar si hay modelos guardados previamente\n",
    "        convbigru_output_path = MODELS_OUTPUT / 'convbigru_ae_model.pth'\n",
    "        convbilstm_output_path = MODELS_OUTPUT / 'convbilstm_ae_model.pth'\n",
    "        \n",
    "        print(\"\\n🔍 Verificando modelos guardados previamente:\")\n",
    "        bigru_exists = check_model_exists(convbigru_output_path)\n",
    "        bilstm_exists = check_model_exists(convbilstm_output_path)\n",
    "        \n",
    "        # Iniciar entrenamiento con seguimiento detallado\n",
    "        if not bigru_exists or input(\"¿Volver a entrenar ConvBiGRU-AE? (s/n): \").lower() == 's':\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"ENTRENAMIENTO DE CONVBIGRU_AE CON VISUALIZACIÓN MEJORADA\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # Entrenar con versión mejorada\n",
    "            convbigru_ae, train_losses_bigru, val_losses_bigru = improved_train_model(\n",
    "                convbigru_ae, train_loader, val_loader, \n",
    "                criterion, optimizer_convbigru, scheduler_convbigru,\n",
    "                num_epochs, patience, model_name=\"ConvBiGRU-AE\"\n",
    "            )\n",
    "            \n",
    "            # Guardar modelo final con mensaje claro\n",
    "            torch.save({\n",
    "                'model_state_dict': convbigru_ae.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_convbigru.state_dict(),\n",
    "                'train_losses': train_losses_bigru,\n",
    "                'val_losses': val_losses_bigru\n",
    "            }, convbigru_output_path)\n",
    "            print(f\"\\n✅ Modelo final ConvBiGRU-AE guardado en {convbigru_output_path}\")\n",
    "            \n",
    "            # Visualizar métricas detalladas\n",
    "            print(\"\\n📊 Visualización detallada de métricas de ConvBiGRU-AE:\")\n",
    "            visualize_training_metrics(train_losses_bigru, val_losses_bigru, \"ConvBiGRU-AE\")\n",
    "        \n",
    "        if not bilstm_exists or input(\"¿Volver a entrenar ConvBiLSTM-AE? (s/n): \").lower() == 's':\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"ENTRENAMIENTO DE CONVBILSTM_AE CON VISUALIZACIÓN MEJORADA\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # Entrenar con versión mejorada\n",
    "            convbilstm_ae, train_losses_bilstm, val_losses_bilstm = improved_train_model(\n",
    "                convbilstm_ae, train_loader, val_loader, \n",
    "                criterion, optimizer_convbilstm, scheduler_convbilstm,\n",
    "                num_epochs, patience, model_name=\"ConvBiLSTM-AE\"\n",
    "            )\n",
    "            \n",
    "            # Guardar modelo final con mensaje claro\n",
    "            torch.save({\n",
    "                'model_state_dict': convbilstm_ae.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_convbilstm.state_dict(),\n",
    "                'train_losses': train_losses_bilstm,\n",
    "                'val_losses': val_losses_bilstm\n",
    "            }, convbilstm_output_path)\n",
    "            print(f\"\\n✅ Modelo final ConvBiLSTM-AE guardado en {convbilstm_output_path}\")\n",
    "            \n",
    "            # Visualizar métricas detalladas\n",
    "            print(\"\\n📊 Visualización detallada de métricas de ConvBiLSTM-AE:\")\n",
    "            visualize_training_metrics(train_losses_bilstm, val_losses_bilstm, \"ConvBiLSTM-AE\")\n",
    "        \n",
    "        print(\"\\n✅ Proceso de entrenamiento mejorado completado\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error durante el entrenamiento mejorado: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\n❌ Los modelos no están listos para entrenar. Verifica la configuración.\")\n",
    "\n",
    "# Función para analizar y visualizar modelos guardados\n",
    "def analyze_saved_models(model_dir=MODELS_OUTPUT, pattern=\"*_ae_model.pth\"):\n",
    "    \"\"\"\n",
    "    Analiza y visualiza información sobre los modelos guardados\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Encontrar todos los archivos que coinciden con el patrón\n",
    "    model_files = list(Path(model_dir).glob(pattern))\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"❌ No se encontraron modelos con el patrón '{pattern}' en {model_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📊 Modelos encontrados: {len(model_files)}\")\n",
    "    for i, model_path in enumerate(model_files, 1):\n",
    "        print(f\"\\n{i}. {model_path.name}:\")\n",
    "        \n",
    "        # Obtener información del archivo\n",
    "        size_mb = os.path.getsize(model_path) / (1024*1024)\n",
    "        modified_time = datetime.fromtimestamp(os.path.getmtime(model_path))\n",
    "        \n",
    "        print(f\"   📁 Tamaño: {size_mb:.2f} MB\")\n",
    "        print(f\"   🕒 Última modificación: {modified_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        # Intentar cargar el modelo para obtener más información\n",
    "        try:\n",
    "            checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "            if isinstance(checkpoint, dict):\n",
    "                print(\"   📋 Contenido del checkpoint:\")\n",
    "                for key, value in checkpoint.items():\n",
    "                    if key == 'model_state_dict':\n",
    "                        n_params = sum(p.numel() for p in value.values())\n",
    "                        print(f\"      - model_state_dict: {n_params:,} parámetros\")\n",
    "                    elif key == 'optimizer_state_dict':\n",
    "                        print(f\"      - optimizer_state_dict: incluido\")\n",
    "                    elif isinstance(value, list):\n",
    "                        print(f\"      - {key}: lista de {len(value)} elementos\")\n",
    "                    elif isinstance(value, (int, float)):\n",
    "                        print(f\"      - {key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"      - {key}: {type(value).__name__}\")\n",
    "                        \n",
    "                # Si contiene historial de pérdidas, visualizarlo\n",
    "                if 'train_losses' in checkpoint and 'val_losses' in checkpoint:\n",
    "                    train_losses = checkpoint['train_losses']\n",
    "                    val_losses = checkpoint['val_losses']\n",
    "                    \n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.plot(train_losses, label='Train')\n",
    "                    plt.plot(val_losses, label='Validation')\n",
    "                    plt.title(f'Historial de entrenamiento - {model_path.stem}')\n",
    "                    plt.xlabel('Época')\n",
    "                    plt.ylabel('Pérdida')\n",
    "                    plt.legend()\n",
    "                    plt.grid(alpha=0.3)\n",
    "                    plt.show()\n",
    "                    \n",
    "                    print(f\"      - Épocas entrenadas: {len(train_losses)}\")\n",
    "                    print(f\"      - Pérdida inicial: {train_losses[0]:.4f} (train), {val_losses[0]:.4f} (val)\")\n",
    "                    print(f\"      - Pérdida final: {train_losses[-1]:.4f} (train), {val_losses[-1]:.4f} (val)\")\n",
    "                    print(f\"      - Mejor pérdida val: {min(val_losses):.4f} (época {np.argmin(val_losses)+1})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error al analizar el modelo: {str(e)}\")\n",
    "    \n",
    "    return model_files\n",
    "\n",
    "# Ejecutar análisis de modelos guardados\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANÁLISIS DE MODELOS GUARDADOS\")\n",
    "print(\"=\"*50)\n",
    "saved_models = analyze_saved_models()\n",
    "# Ejecutar análisis de modelos guardados\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANÁLISIS DE MODELOS GUARDADOS\")\n",
    "print(\"=\"*50)\n",
    "saved_models = analyze_saved_models()\n",
    "print(f\"\\n📂 Directorio de modelos guardados: {MODELS_OUTPUT}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
