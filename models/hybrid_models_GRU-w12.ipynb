{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, ConvLSTM2D, GRU, Flatten, RepeatVector, Reshape, TimeDistributed,\n",
    "    Dense, MultiHeadAttention, Add, LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "## ╭─────────────────────────── Rutas ──────────────────────────╮\n",
    "# ▶️ Path configuration\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
    "    # Instalar dependencias necesarias\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open cartopy geopandas\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    for p in [BASE_PATH, *BASE_PATH.parents]:\n",
    "        if (p / '.git').exists():\n",
    "            BASE_PATH = p; break\n",
    "\n",
    "print('BASE_PATH =', BASE_PATH)\n",
    "\n",
    "# Dataset paths\n",
    "DATA_DIR = BASE_PATH/'data'/'output'\n",
    "MODEL_OUTPUT_DIR = BASE_PATH/'models'/'output'\n",
    "MODEL_DIR = BASE_PATH/'models'/'output'/'HybridLSTMModels'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_INPUT_DIR = BASE_PATH/'data'/'input'/'shapes'\n",
    "MODEL_INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "IMAGE_DIR = MODEL_DIR/'images'\n",
    "IMAGE_DIR.mkdir(exist_ok=True)\n",
    "FULL_NC = DATA_DIR/'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation.nc'\n",
    "dept_gdf = gpd.read_file(MODEL_INPUT_DIR/'MGN_Departamento.shp')\n",
    "\n",
    "BASE_MODEL_DIR = MODEL_DIR\n",
    "GIF_DIR        = MODEL_DIR / \"gifs\"\n",
    "GIF_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────────── Dataset & Shapes ──────────────────╮\n",
    "ds          = xr.open_dataset(FULL_NC)\n",
    "lat, lon    = len(ds.latitude), len(ds.longitude)\n",
    "cells       = lat * lon\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────── Hyper‑parámetros globales ─────────────╮\n",
    "INPUT_WINDOW   = 60\n",
    "HORIZON        = 3\n",
    "TARGET_VAR     = 'total_precipitation'\n",
    "EPOCHS         = 100\n",
    "BATCH_SIZE     = 4           # tamaño pequeño → menor RAM GPU\n",
    "PATIENCE       = 10\n",
    "LR             = 1e-3\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "\n",
    "# ╭────────────────────── Modelo base ConvLSTM ────────────────╮\n",
    "\n",
    "def _build_convlstm_ed(*,input_window: int,output_horizon: int,spatial_height: int,spatial_width: int,n_features: int,n_filters: int = 64,n_heads: int = 4,use_attention: bool = True,lr: float = LR) -> Model:\n",
    "    \"\"\"Construye un Encoder‑Decoder ConvLSTM.\n",
    "\n",
    "    Si `use_attention=False` se omite la capa Multi‑Head Attention.\n",
    "    La salida es `(B, T_out, H, W, 1)`.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(input_window, spatial_height, spatial_width, n_features), name=\"enc_input\")\n",
    "\n",
    "    # ── Encoder ────────────────────────────────────────────\n",
    "    x = ConvLSTM2D(n_filters,   (3, 3), padding='same', return_sequences=True,  name=\"enc_lstm_1\")(inputs)\n",
    "    x = ConvLSTM2D(n_filters//2,(3, 3), padding='same', return_sequences=False, name=\"enc_lstm_2\")(x)\n",
    "\n",
    "    # ── Flatten + contexto temporal ────────────────────────\n",
    "    flat = Flatten(name=\"flatten_spatial\")(x)\n",
    "    ctx  = RepeatVector(output_horizon, name=\"context\")(flat)  # (B, T_out, H·W·C)\n",
    "\n",
    "    # ── Decoder GRU (temporal) ─────────────────────────────\n",
    "    dec = GRU(2*n_filters, return_sequences=True, name=\"dec_gru\")(ctx)\n",
    "\n",
    "    if use_attention:\n",
    "        attn = MultiHeadAttention(num_heads=n_heads, key_dim=n_filters, dropout=0.1, name=\"mha\")(dec, dec)\n",
    "        dec  = LayerNormalization(name=\"mha_norm\")(Add(name=\"mha_add\")([dec, attn]))\n",
    "\n",
    "    # ── Proyección + reshape a grid ───────────────────────\n",
    "    proj = TimeDistributed(Dense(spatial_height*spatial_width, activation='linear'), name=\"dense_proj\")(dec)\n",
    "    out  = Reshape((output_horizon, spatial_height, spatial_width, 1), name=\"reshape_out\")(proj)\n",
    "\n",
    "    model = Model(inputs, out, name=\"ConvLSTM_ED_Attn\" if use_attention else \"ConvLSTM_ED\")\n",
    "    model.compile(optimizer=Adam(lr), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Factories ---------------------------------------------------\n",
    "\n",
    "def factory_no_attn(**kw):\n",
    "    return _build_convlstm_ed(use_attention=False, **kw)\n",
    "\n",
    "def factory_attn(**kw):\n",
    "    return _build_convlstm_ed(use_attention=True, **kw)\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────────────── Métricas ────────────────────────╮\n",
    "\n",
    "def evaluate(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, mape, r2\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────────── Quick‑plot ────────────────────────╮\n",
    "\n",
    "def quick_plot(ax, data, cmap, title, date_label, vmin=None, vmax=None):\n",
    "    mesh = ax.pcolormesh(ds.longitude, ds.latitude, data, cmap=cmap, shading='nearest', vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree())\n",
    "    ax.coastlines(); ax.add_geometries(dept_gdf.geometry, ccrs.PlateCarree(), edgecolor='black', facecolor='none', linewidth=1)\n",
    "    gl = ax.gridlines(draw_labels=True); gl.top_labels=False; gl.right_labels=False\n",
    "    ax.set_title(f\"{title}\\n{date_label}\", pad=12)\n",
    "    return mesh\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────────── Experiments & Folds ─────────────────╮\n",
    "# ╭────────────────────── Experiments & Folds ─────────────────╮\n",
    "# ▸ Solo mostramos los tres primeros niveles; añade los demás igual\n",
    "BASE_FEATURES = [\n",
    "    'year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
    "    'max_daily_precipitation','min_daily_precipitation','daily_precipitation_std',\n",
    "    'elevation','slope','aspect'\n",
    "]\n",
    "ELEV_CLUSTER = ['elev_high','elev_med','elev_low']\n",
    "KCE_FEATURES = BASE_FEATURES + ELEV_CLUSTER\n",
    "PAFC_FEATURES= KCE_FEATURES + ['total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag12']\n",
    "\n",
    "FOLDS = {'F1': {'year': 2018,'active': True}}\n",
    "\n",
    "EXPERIMENTS: Dict[str, Dict[str, Any]] = {\n",
    "    'ConvLSTM-ED': {\n",
    "        'active': True,\n",
    "        'feature_list': BASE_FEATURES,\n",
    "        'builder': factory_attn, #factory_no_attn,\n",
    "        'n_filters': 64,\n",
    "        'n_heads'  : 4\n",
    "    },\n",
    "    'ConvLSTM-ED-KCE': {\n",
    "        'active': True,\n",
    "        'feature_list': KCE_FEATURES,\n",
    "        'builder': factory_attn,\n",
    "        'n_filters': 64,\n",
    "        'n_heads'  : 4,\n",
    "    },\n",
    "    'ConvLSTM-ED-KCE-PAFC': {\n",
    "        'active': True,\n",
    "        'feature_list': PAFC_FEATURES,\n",
    "        'builder': factory_attn,\n",
    "        'n_filters': 96,\n",
    "        'n_heads'  : 6,\n",
    "    },\n",
    "}\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────────── Bucle principal ────────────────────╮\n",
    "\n",
    "# ╭────────────────────── Experiments & Folds ─────────────────╮\n",
    "# (… definiciones de EXPERIMENTS y FOLDS sin cambios …)\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────── Ventanas deslizadas ───────────────────╮\n",
    "def make_windows(mask: np.ndarray, allow_past_context: bool) -> tuple[np.ndarray, np.ndarray]:\n",
    "    seq_X, seq_y = [], []\n",
    "    limit = len(mask) - INPUT_WINDOW - HORIZON + 1\n",
    "    for start in range(limit):\n",
    "        end_w = start + INPUT_WINDOW\n",
    "        end_y = end_w + HORIZON\n",
    "        if allow_past_context:\n",
    "            if not mask[end_w:end_y].all():\n",
    "                continue\n",
    "        else:\n",
    "            if not mask[start:end_y].all():\n",
    "                continue\n",
    "        seq_X.append(Xarr[start:end_w])\n",
    "        seq_y.append(yarr[end_w:end_y])\n",
    "    return np.array(seq_X), np.array(seq_y)\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────── Bucle principal de entrenamiento ────────╮\n",
    "RESULTS: List[Dict[str, Any]] = []\n",
    "# ╭────────────────── Bucle principal de entrenamiento ────────╮\n",
    "RESULTS: List[Dict[str, Any]] = []\n",
    "\n",
    "def run_all_experiments():\n",
    "    times = pd.to_datetime(ds.time.values)\n",
    "    total = sum(e['active'] for e in EXPERIMENTS.values()) * sum(f['active'] for f in FOLDS.values())\n",
    "    cnt   = 0\n",
    "\n",
    "    for exp_name, exp_cfg in EXPERIMENTS.items():\n",
    "        if not exp_cfg['active']:\n",
    "            continue\n",
    "        vars_     = exp_cfg['feature_list']\n",
    "        builder   = exp_cfg['builder']      # fábrica específica\n",
    "        n_filters = exp_cfg.get('n_filters',64)\n",
    "        n_heads   = exp_cfg.get('n_heads',4)\n",
    "\n",
    "        # ─ Pre‑load features por experimento ─────────────────────\n",
    "        global Xarr, yarr\n",
    "        Xarr = ds[vars_].to_array().transpose('time','latitude','longitude','variable').values.astype(np.float32)\n",
    "        yarr = ds[TARGET_VAR].values.astype(np.float32)\n",
    "        feats = Xarr.shape[-1]\n",
    "\n",
    "        for fold_name, fold_cfg in FOLDS.items():\n",
    "            if not fold_cfg['active']:\n",
    "                continue\n",
    "            cnt += 1\n",
    "            year_val = fold_cfg['year']\n",
    "            print(f\"\\n▶️  [{cnt}/{total}] {exp_name} – {fold_name} (val={year_val})\")\n",
    "\n",
    "            mask_val = times.year == year_val\n",
    "            mask_tr  = ~mask_val\n",
    "            if mask_val.sum() < HORIZON:\n",
    "                print(\"⚠️ Año sin pasos suficientes → skip\"); continue\n",
    "\n",
    "            X_tr, y_tr = make_windows(mask_tr,  allow_past_context=False)\n",
    "            X_va, y_va = make_windows(mask_val, allow_past_context=True)\n",
    "            print(f\"Ventanas train: {len(X_tr)} · val: {len(X_va)}\")\n",
    "            if len(X_tr)==0 or len(X_va)==0:\n",
    "                print(\"⚠️ Sin ventanas válidas → skip\"); continue\n",
    "\n",
    "            # ─ Scaling (fit solo en train) ─────────────────────\n",
    "            sx = StandardScaler().fit(X_tr.reshape(-1, feats))\n",
    "            sy = StandardScaler().fit(y_tr.reshape(-1, 1))\n",
    "            X_tr_sc = sx.transform(X_tr.reshape(-1, feats)).reshape(X_tr.shape)\n",
    "            X_va_sc = sx.transform(X_va.reshape(-1, feats)).reshape(X_va.shape)\n",
    "            y_tr_sc = sy.transform(y_tr.reshape(-1, 1)).reshape(y_tr.shape)[..., None]\n",
    "            y_va_sc = sy.transform(y_va.reshape(-1, 1)).reshape(y_va.shape)[..., None]\n",
    "\n",
    "            # ─ Build & train model (factory) ───────────────────\n",
    "            tag        = f\"{exp_name.replace('+','_')}_{fold_name}\"\n",
    "            model_path = BASE_MODEL_DIR / f\"{tag}.keras\"\n",
    "            if model_path.exists():\n",
    "                print(f\"⏩ {tag} ya existe → skip\"); continue\n",
    "\n",
    "            model = builder(\n",
    "                input_window=INPUT_WINDOW,\n",
    "                output_horizon=HORIZON,\n",
    "                spatial_height=lat,\n",
    "                spatial_width=lon,\n",
    "                n_features=feats,\n",
    "                n_filters=n_filters,\n",
    "                n_heads=n_heads,\n",
    "                lr=LR\n",
    "            )\n",
    "\n",
    "            es   = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "            hist = model.fit(X_tr_sc, y_tr_sc, validation_data=(X_va_sc, y_va_sc), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
    "\n",
    "            # ─ Evaluación ─────────────────────────────────────\n",
    "            y_hat_sc = model.predict(X_va_sc, verbose=0)\n",
    "            y_hat    = sy.inverse_transform(y_hat_sc.reshape(-1,1)).reshape(y_hat_sc.shape)\n",
    "            y_true   = sy.inverse_transform(y_va_sc.reshape(-1,1)).reshape(y_va_sc.shape)\n",
    "\n",
    "            rmse, mae, mape, r2 = evaluate(y_true.ravel(), y_hat.ravel())\n",
    "            RESULTS.append(dict(experiment=exp_name, fold=fold_name, RMSE=rmse, MAE=mae, MAPE=mape, R2=r2, epochs=len(hist.history['loss'])))\n",
    "\n",
    "            # ─ Guardado artefactos ────────────────────────────\n",
    "            model.save(model_path)\n",
    "            plt.figure(); plt.plot(hist.history['loss'], label='train'); plt.plot(hist.history['val_loss'], label='val'); plt.legend(); plt.title(tag); plt.savefig(CURVES_DIR/f\"{tag}.png\"); plt.close()\n",
    "\n",
    "            _generate_gif(y_true[0], y_hat[0], tag)\n",
    "            print(f\"✅ Guardado {model_path.name}\")\n",
    "\n",
    "    # ─ Métricas globales ────────────────────────────────────\n",
    "    df = pd.DataFrame(RESULTS)\n",
    "    out_csv = BASE_MODEL_DIR / \"metrics_experiments_folds.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\n📑 Tabla de métricas en {out_csv}\")\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────── Generador de GIF ─────────────────────╮\n",
    "\n",
    "def _generate_gif(y_true_sample, y_pred_sample, tag):\n",
    "    pcm_min, pcm_max = 0, np.max(y_pred_sample)\n",
    "    frames = []\n",
    "    for h in range(HORIZON):\n",
    "        pmap = y_pred_sample[h, ..., 0]\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,5), subplot_kw={'projection':ccrs.PlateCarree()})\n",
    "        mesh = ax.pcolormesh(ds.longitude, ds.latitude, pmap, cmap='Blues', shading='nearest', vmin=pcm_min, vmax=pcm_max, transform=ccrs.PlateCarree())\n",
    "        ax.coastlines(); ax.gridlines(draw_labels=True)\n",
    "        ax.set_title(f\"{tag} – H{h+1}\")\n",
    "        fig.colorbar(mesh, ax=ax, fraction=0.046, pad=0.04)\n",
    "        tmp = GIF_DIR/f\"tmp_{tag}_h{h}.png\"\n",
    "        fig.savefig(tmp, bbox_inches='tight'); plt.close(fig)\n",
    "        frames.append(imageio.imread(tmp)); tmp.unlink(missing_ok=True)\n",
    "    gif_path = GIF_DIR/f\"{tag}.gif\"\n",
    "    imageio.mimsave(gif_path, frames, fps=0.5)\n",
    "    print(f\"💾 GIF {gif_path.name} listo\")\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────────── Bucle principal ────────────────────╮\n",
    "run_all_experiments()\n",
    "# ╰────────────────────────────────────────────────────────────╯\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
