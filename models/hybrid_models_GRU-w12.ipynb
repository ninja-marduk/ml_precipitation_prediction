{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, ConvLSTM2D, GRU, Flatten, RepeatVector, Reshape, TimeDistributed,\n",
    "    Dense, MultiHeadAttention, Add, LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "## â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â RutasÂ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â–¶ï¸ Path configuration\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
    "    # Instalar dependencias necesarias\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open cartopy geopandas\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    for p in [BASE_PATH, *BASE_PATH.parents]:\n",
    "        if (p / '.git').exists():\n",
    "            BASE_PATH = p; break\n",
    "\n",
    "print('BASE_PATH =', BASE_PATH)\n",
    "\n",
    "# Dataset paths\n",
    "DATA_DIR = BASE_PATH/'data'/'output'\n",
    "MODEL_OUTPUT_DIR = BASE_PATH/'models'/'output'\n",
    "MODEL_DIR = BASE_PATH/'models'/'output'/'HybridLSTMModels'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_INPUT_DIR = BASE_PATH/'data'/'input'/'shapes'\n",
    "MODEL_INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "IMAGE_DIR = MODEL_DIR/'images'\n",
    "IMAGE_DIR.mkdir(exist_ok=True)\n",
    "FULL_NC = DATA_DIR/'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation.nc'\n",
    "dept_gdf = gpd.read_file(MODEL_INPUT_DIR/'MGN_Departamento.shp')\n",
    "\n",
    "BASE_MODEL_DIR = MODEL_DIR\n",
    "GIF_DIR        = MODEL_DIR / \"gifs\"\n",
    "GIF_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Dataset & Shapes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "ds          = xr.open_dataset(FULL_NC)\n",
    "lat, lon    = len(ds.latitude), len(ds.longitude)\n",
    "cells       = lat * lon\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hyperâ€‘parÃ¡metros globales â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "INPUT_WINDOW   = 60\n",
    "HORIZON        = 3\n",
    "TARGET_VAR     = 'total_precipitation'\n",
    "EPOCHS         = 100\n",
    "BATCH_SIZE     = 4           # tamaÃ±o pequeÃ±oÂ â†’Â menor RAMÂ GPU\n",
    "PATIENCE       = 10\n",
    "LR             = 1e-3\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â Modelo ConvLSTMÂ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "\n",
    "def build_model(\n",
    "        input_window: int,\n",
    "        output_horizon: int,\n",
    "        spatial_height: int,\n",
    "        spatial_width: int,\n",
    "        n_features: int,\n",
    "        n_filters: int = 64,\n",
    "        n_heads: int = 4,\n",
    "        lr: float = LR\n",
    ") -> Model:\n",
    "    \"\"\"ConvLSTMÂ Encoderâ€‘Decoder con Selfâ€‘Attention.\n",
    "\n",
    "    Produce salida `(batch,Â output_horizon,Â H,Â W,Â 1)`.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(input_window, spatial_height, spatial_width, n_features),name=\"enc_input\")\n",
    "\n",
    "    # â”€â”€ Encoder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    x = ConvLSTM2D(n_filters, (3, 3), padding='same', return_sequences=True,name=\"enc_lstm_1\")(inputs)\n",
    "    x = ConvLSTM2D(n_filters // 2, (3, 3), padding='same', return_sequences=False,name=\"enc_lstm_2\")(x)  # (B, H, W, C)\n",
    "\n",
    "    # â”€â”€ Flatten + contexto temporal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    flat = Flatten(name=\"flatten_spatial\")(x)                # (B, HÂ·WÂ·C)\n",
    "    ctx  = RepeatVector(output_horizon, name=\"context\")(flat)  # (B, T_out, HÂ·WÂ·C)\n",
    "\n",
    "    # â”€â”€ DecoderÂ GRU (temporal) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    dec = GRU(2 * n_filters, return_sequences=True, name=\"dec_gru\")(ctx)\n",
    "\n",
    "    # â”€â”€ Selfâ€‘Attention (temporal) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    attn = MultiHeadAttention(num_heads=n_heads, key_dim=n_filters, dropout=0.1, name=\"mha\")(dec, dec)\n",
    "    attn = Add(name=\"mha_add\")([dec, attn])\n",
    "    attn = LayerNormalization(name=\"mha_norm\")(attn)\n",
    "\n",
    "    # â”€â”€ ProyecciÃ³n + reshape a grid â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    proj = TimeDistributed(Dense(spatial_height * spatial_width, activation='linear'),name=\"dense_proj\")(attn)\n",
    "    out = Reshape((output_horizon, spatial_height, spatial_width, 1),name=\"reshape_out\")(proj)\n",
    "\n",
    "    model = Model(inputs, out, name=\"ConvLSTM_ED_Attn\")\n",
    "    model.compile(optimizer=Adam(lr), loss='mse')\n",
    "    return model\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â MÃ©tricasÂ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "\n",
    "def evaluate(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, mape, r2\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Quickâ€‘plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "\n",
    "def quick_plot(ax, data, cmap, title, date_label, vmin=None, vmax=None):\n",
    "    mesh = ax.pcolormesh(ds.longitude, ds.latitude, data, cmap=cmap, shading='nearest', vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    ax.add_geometries(dept_gdf.geometry,  ccrs.PlateCarree(), edgecolor='black', facecolor='none', linewidth=1)\n",
    "    ax.add_geometries(mpio_gdf.geometry,  ccrs.PlateCarree(), edgecolor='gray',  facecolor='none', linewidth=0.1)\n",
    "    gl = ax.gridlines(draw_labels=True); gl.top_labels = False; gl.right_labels = False\n",
    "    ax.set_title(f\"{title}\\n{date_label}\", pad=12)\n",
    "    return mesh\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Experiments & Folds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "ENABLED_MODELS      = ['GRU']          # â¬…ï¸Â puedes cambiarlo a ['LSTM',â€¦]\n",
    "RESULTS: list[dict[str, Any]] = []\n",
    "\n",
    "# â–¶ï¸ Fold configuration with activation/deactivation control\n",
    "FOLDS = {\n",
    "    'F1': {'year': 2018, 'active': True},\n",
    "    'F2': {'year': 2017, 'active': False},\n",
    "    'F3': {'year': 2016, 'active': False},\n",
    "    'F4': {'year': 2015, 'active': False},\n",
    "    'F5': {'year': 2014, 'active': False},\n",
    "    'F6': {'year': 2010, 'active': False},\n",
    "    'F7': {'year': 2000, 'active': False},\n",
    "}\n",
    "\n",
    "# Stats BASE FEATURES (12) - ConvGRU-ED foundation (WITHOUT cluster_elevation)\n",
    "BASE_FEATURES = [\n",
    "    # Temporal features\n",
    "    'year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos',\n",
    "    # Precipitation statistics  \n",
    "    'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std',\n",
    "    # Topographic features con rejilla espacial completa\n",
    "    'elevation', 'slope', 'aspect'\n",
    "]\n",
    "\n",
    "# Se usa directamente los nombres de las caracterÃ­sticas one-hot encoding\n",
    "ELEVATION_CLUSTER_FEATURES = [\n",
    "    'elev_high',      # ElevaciÃ³n alta (one-hot)\n",
    "    'elev_med',       # ElevaciÃ³n media (one-hot)\n",
    "    'elev_low'        # ElevaciÃ³n baja (one-hot)\n",
    "]\n",
    "\n",
    "# Stats KCE FEATURES (15) - ConvGRU-ED-KCE (Base + K-means Cluster Elevation one-hot)\n",
    "KCE_FEATURES = BASE_FEATURES + ELEVATION_CLUSTER_FEATURES\n",
    "\n",
    "# Verificar que todas las caracterÃ­sticas mantengan la estructura espacial completa\n",
    "REQUIRE_FULL_GRID_FOR_ALL_FEATURES = True  # Asegurar consistencia espacial en todo el grid\n",
    "\n",
    "# Stats PAFC FEATURES (18) - ConvGRU-ED-KCE-PAFC (KCE + Position-Aware Feature Calibration)\n",
    "PAFC_FEATURES = KCE_FEATURES + [\n",
    "    'total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag12'  # Correct naming\n",
    "]\n",
    "\n",
    "# Stats FUSION FEATURES (34) - AE-FUSION-ConvGRU-ED-KCE-PAFC (PAFC + 16 IMFs)\n",
    "FUSION_FEATURES = PAFC_FEATURES + [\n",
    "    # CEEMDAN IMFs (8) - correct uppercase naming\n",
    "    'CEEMDAN_imf_1', 'CEEMDAN_imf_2', 'CEEMDAN_imf_3', 'CEEMDAN_imf_4', \n",
    "    'CEEMDAN_imf_5', 'CEEMDAN_imf_6', 'CEEMDAN_imf_7', 'CEEMDAN_imf_8',\n",
    "    # TVFEMD IMFs (8) - correct uppercase naming \n",
    "    'TVFEMD_imf_1', 'TVFEMD_imf_2', 'TVFEMD_imf_3', 'TVFEMD_imf_4',\n",
    "    'TVFEMD_imf_5', 'TVFEMD_imf_6', 'TVFEMD_imf_7', 'TVFEMD_imf_8'\n",
    "]\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    # ğŸ—ï¸ HIERARCHICAL CONVGRU ARCHITECTURE\n",
    "    # =====================================\n",
    "    \n",
    "    'ConvGRU-ED': {\n",
    "        'active': True,\n",
    "        'description': 'ğŸ”¹ BASE: ConvGRU Encoder-Decoder (NO cluster_elevation)',\n",
    "        'model': 'conv_gru_ed',\n",
    "        'features': 'Base features (12)',\n",
    "        'feature_list': BASE_FEATURES,\n",
    "        'architecture': 'ConvGRU2D + Encoder-Decoder',\n",
    "        'use_lags': False,\n",
    "        'use_cluster_elevation': False,\n",
    "        'level': 1\n",
    "    },\n",
    "    \n",
    "    'ConvGRU-ED-KCE': {\n",
    "        'active': True,\n",
    "        'description': 'ğŸ”¸ LEVEL 2: ConvGRU-ED + K-means Cluster Elevation',\n",
    "        'model': 'conv_gru_ed_kce',\n",
    "        'features': 'Base + KCE features (15)',\n",
    "        'feature_list': KCE_FEATURES,\n",
    "        'architecture': 'ConvGRU2D + Encoder-Decoder + K-means Cluster Elevation',\n",
    "        'use_lags': False,\n",
    "        'use_cluster_elevation': True,\n",
    "        'level': 2\n",
    "    },\n",
    "    \n",
    "    'ConvGRU-ED-KCE-PAFC': {\n",
    "        'active': True,\n",
    "        'description': 'ğŸ”¸ LEVEL 3: ConvGRU-ED-KCE + Parcial Autocorretion Function (PAFC)',\n",
    "        'model': 'conv_gru_ed_kce_pafc',\n",
    "        'features': 'KCE + PAFC features (18)',\n",
    "        'feature_list': PAFC_FEATURES,\n",
    "        'architecture': 'ConvGRU2D + Encoder-Decoder + KCE + Lag Features {1,2,12}',\n",
    "        'use_lags': True,\n",
    "        'use_cluster_elevation': True,\n",
    "        'level': 3\n",
    "    },\n",
    "    \n",
    "    'AE-FUSION-ConvGRU-ED-KCE-PAFC-MHA': {\n",
    "        'active': False,\n",
    "        'description': 'ğŸ”¶ LEVEL 4: AE-FUSION + ConvGRU-ED-KCE-PAFC + Multi-Head Attention',\n",
    "        'model': 'ae_fusion_conv_gru_ed_kce_pafc_mha',\n",
    "        'features': 'PAFC + 16 IMFs + MHA (34 total)',\n",
    "        'feature_list': FUSION_FEATURES,\n",
    "        'architecture': 'Conv3D-AE + ConvGRU2D-ED-KCE-PAFC + Multi-Head Attention (4Ã—64d)',\n",
    "        'use_lags': True,\n",
    "        'use_cluster_elevation': True,\n",
    "        'level': 4\n",
    "    },\n",
    "    \n",
    "    'AE-FUSION-ConvGRU-ED-KCE-PAFC-MHA-TopoMask': {\n",
    "        'active': False,\n",
    "        'description': 'ğŸ”· LEVEL 5: Full Pipeline + Topographic Mask-Attention',\n",
    "        'model': 'ae_fusion_conv_gru_ed_kce_pafc_mha_topomask',\n",
    "        'features': 'All previous + Topographic Mask Attention (34 total)',\n",
    "        'feature_list': FUSION_FEATURES,\n",
    "        'architecture': 'Full Pipeline: Conv3D-AE + ConvGRU2D-ED-KCE-PAFC + MHA + TopoMask',\n",
    "        'use_lags': True,\n",
    "        'use_cluster_elevation': True,\n",
    "        'level': 5\n",
    "    }\n",
    "}\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â Bucle principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "\n",
    "RESULTS: List[Dict[str, Any]] = []\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Experiments & Folds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "#Â (â€¦ definiciones de EXPERIMENTS yÂ FOLDS sin cambios â€¦)\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ventanas deslizadas (FIX) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "\n",
    "def make_windows(mask: np.ndarray, *, allow_past_context: bool) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Genera pares (X,y).\n",
    "\n",
    "    * **Entrenamiento**Â â†’Â `allow_past_context=False`: exige que toda la\n",
    "      ventana (inputÂ +Â target) estÃ© dentro del `mask`.\n",
    "    * **ValidaciÃ³n**Â â†’Â `allow_past_context=True`: solo los `HORIZON` pasos\n",
    "      objetivo (`y`) deben estar dentro del `mask`; la ventana de entrada\n",
    "      puede comenzar antes.\n",
    "    \"\"\"\n",
    "    seq_X, seq_y = [], []\n",
    "    limit = len(mask) - INPUT_WINDOW - HORIZON + 1\n",
    "    for start in range(limit):\n",
    "        end_w = start + INPUT_WINDOW\n",
    "        end_y = end_w + HORIZON\n",
    "        if allow_past_context:\n",
    "            # solo comprobamos los targets\n",
    "            if not mask[end_w:end_y].all():\n",
    "                continue\n",
    "        else:\n",
    "            # todo debe pertenecer al mask\n",
    "            if not mask[start:end_y].all():\n",
    "                continue\n",
    "        seq_X.append(Xarr[start:end_w])\n",
    "        seq_y.append(yarr[end_w:end_y])\n",
    "    return np.array(seq_X), np.array(seq_y)\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Bucle principal de entrenamiento â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "RESULTS: List[Dict[str, Any]] = []\n",
    "\n",
    "def run_all_experiments():\n",
    "    times = pd.to_datetime(ds.time.values)\n",
    "    total = sum(e['active'] for e in EXPERIMENTS.values()) * sum(f['active'] for f in FOLDS.values())\n",
    "    cnt   = 0\n",
    "\n",
    "    for exp_name, exp_cfg in EXPERIMENTS.items():\n",
    "        if not exp_cfg['active']:\n",
    "            continue\n",
    "        vars_ = exp_cfg['feature_list']\n",
    "\n",
    "        # â”€ Preâ€‘load features (independiente del fold) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        global Xarr, yarr  # usado dentro de make_windows\n",
    "        Xarr = ds[vars_].to_array().transpose('time','latitude','longitude','variable').values.astype(np.float32)\n",
    "        yarr = ds[TARGET_VAR].values.astype(np.float32)\n",
    "        feats = Xarr.shape[-1]\n",
    "\n",
    "        if 'cluster_elevation' in vars_:\n",
    "            idx = vars_.index('cluster_elevation')\n",
    "            Xarr[..., idx] = LabelEncoder().fit_transform(Xarr[..., idx].ravel()).reshape(Xarr[..., idx].shape)\n",
    "\n",
    "        for fold_name, fold_cfg in FOLDS.items():\n",
    "            if not fold_cfg['active']:\n",
    "                continue\n",
    "            cnt += 1\n",
    "            year_val = fold_cfg['year']\n",
    "            print(f\"\\nâ–¶ï¸  [{cnt}/{total}] {exp_name} â€“ {fold_name} (val={year_val})\")\n",
    "\n",
    "            mask_val = times.year == year_val\n",
    "            mask_tr  = ~mask_val\n",
    "            if mask_val.sum() < HORIZON:\n",
    "                print(\"âš ï¸Â AÃ±o sin pasos suficientes para los targets â†’Â skip\"); continue\n",
    "\n",
    "            X_tr, y_tr = make_windows(mask_tr,  allow_past_context=False)\n",
    "            X_va, y_va = make_windows(mask_val, allow_past_context=True)\n",
    "            print(f\"VentanasÂ train: {len(X_tr)} Â· val: {len(X_va)}\")\n",
    "            if len(X_tr)==0 or len(X_va)==0:\n",
    "                print(\"âš ï¸Â Sin ventanas vÃ¡lidas â†’Â skip\"); continue\n",
    "\n",
    "            # â”€ Scaling (fit solo en train) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            sx = StandardScaler().fit(X_tr.reshape(-1, feats))\n",
    "            sy = StandardScaler().fit(y_tr.reshape(-1, 1))\n",
    "            X_tr_sc = sx.transform(X_tr.reshape(-1, feats)).reshape(X_tr.shape)\n",
    "            X_va_sc = sx.transform(X_va.reshape(-1, feats)).reshape(X_va.shape)\n",
    "            y_tr_sc = sy.transform(y_tr.reshape(-1, 1)).reshape(y_tr.shape)[..., None]\n",
    "            y_va_sc = sy.transform(y_va.reshape(-1, 1)).reshape(y_va.shape)[..., None]\n",
    "\n",
    "            # â”€ Build & train model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            tag        = f\"{exp_name.replace('+','_')}_{fold_name}\"\n",
    "            model_path = BASE_MODEL_DIR / f\"{tag}.keras\"\n",
    "            if model_path.exists():\n",
    "                print(f\"â©Â {tag} ya existe â†’Â skip\"); continue\n",
    "\n",
    "            model = build_model(INPUT_WINDOW, HORIZON, lat, lon, feats)\n",
    "            es     = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "            hist   = model.fit(X_tr_sc, y_tr_sc, validation_data=(X_va_sc, y_va_sc), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
    "\n",
    "            # â”€ EvaluaciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            y_hat_sc = model.predict(X_va_sc, verbose=0)\n",
    "            y_hat    = sy.inverse_transform(y_hat_sc.reshape(-1,1)).reshape(y_hat_sc.shape)\n",
    "            y_true   = sy.inverse_transform(y_va_sc.reshape(-1,1)).reshape(y_va_sc.shape)\n",
    "\n",
    "            rmse, mae, mape, r2 = evaluate(y_true.ravel(), y_hat.ravel())\n",
    "            RESULTS.append(dict(experiment=exp_name, fold=fold_name, RMSE=rmse, MAE=mae, MAPE=mape, R2=r2, epochs=len(hist.history['loss'])))\n",
    "\n",
    "            # â”€ Guardado artefactos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            model.save(model_path)\n",
    "            plt.figure(); plt.plot(hist.history['loss'], label='train'); plt.plot(hist.history['val_loss'], label='val'); plt.legend(); plt.title(tag); plt.savefig(BASE_MODEL_DIR/f\"{tag}.png\"); plt.close()\n",
    "\n",
    "            generate_gif(y_true[0], y_hat[0], tag)\n",
    "            print(f\"âœ…Â Guardado {model_path.name}\")\n",
    "\n",
    "    # â”€ MÃ©tricas globales â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    df = pd.DataFrame(RESULTS)\n",
    "    out_csv = BASE_MODEL_DIR / \"metrics_experiments_folds.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nğŸ“‘Â Tabla de mÃ©tricas en {out_csv}\")\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Generador de GIF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "\n",
    "def generate_gif(y_true_sample, y_pred_sample, tag):\n",
    "    pcm_min, pcm_max = 0, np.max(y_pred_sample)\n",
    "    frames = []\n",
    "    for h in range(HORIZON):\n",
    "        pmap = y_pred_sample[h, ..., 0]\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,5), subplot_kw={'projection':ccrs.PlateCarree()})\n",
    "        mesh = ax.pcolormesh(ds.longitude, ds.latitude, pmap, cmap='Blues', shading='nearest', vmin=pcm_min, vmax=pcm_max, transform=ccrs.PlateCarree())\n",
    "        ax.coastlines(); ax.gridlines(draw_labels=True)\n",
    "        ax.set_title(f\"{tag} â€“ H{h+1}\")\n",
    "        fig.colorbar(mesh, ax=ax, fraction=0.046, pad=0.04)\n",
    "        tmp = GIF_DIR/f\"tmp_{tag}_h{h}.png\"\n",
    "        fig.savefig(tmp, bbox_inches='tight'); plt.close(fig)\n",
    "        frames.append(imageio.imread(tmp)); tmp.unlink(missing_ok=True)\n",
    "    gif_path = GIF_DIR/f\"{tag}.gif\"\n",
    "    imageio.mimsave(gif_path, frames, fps=0.5)\n",
    "    print(f\"ğŸ’¾Â GIF {gif_path.name} listo\")\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "run_all_experiments()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
