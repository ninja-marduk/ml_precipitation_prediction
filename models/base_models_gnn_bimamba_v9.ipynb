{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/feature%2Fhybrid-models/models/base_models_gnn_bimamba_v9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V9: Bidirectional GNN-Mamba for Monthly Precipitation Prediction\n",
    "\n",
    "## Advanced State Space Models with Geographic Encoding and Frequency Tuning\n",
    "\n",
    "**Key Innovations from Literature Review:**\n",
    "- **BidirectionalMamba** (RiverMamba, NeurIPS 2025): Bidirectional SSM processing\n",
    "- **FrequencyTuning** (S4D-FT, WRR 2025): Learnable frequency domain filtering\n",
    "- **GeographicEncoding** (WSSM, arXiv 2025): Spatial position embeddings\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "| Component | V8 (Baseline) | V9 (This Model) |\n",
    "|-----------|---------------|------------------|\n",
    "| Spatial Encoder | GNN (GAT) | GNN (GAT) + **GeographicEncoding** |\n",
    "| Temporal Encoder | Bidirectional Mamba | **BidirectionalMamba** (improved) |\n",
    "| Signal Processing | None | **FrequencyTuning** |\n",
    "| Fusion | Cross-Attention | Cross-Attention |\n",
    "\n",
    "### Expected Improvements\n",
    "- Better capture of seasonal cycles via frequency tuning\n",
    "- Improved spatial awareness via geographic encoding\n",
    "- Enhanced bidirectional temporal modeling\n",
    "\n",
    "### Target Metrics\n",
    "| Metric | V8 Baseline | V9 Target |\n",
    "|--------|-------------|----------|\n",
    "| R2 | 0.60 | > 0.62 |\n",
    "| RMSE | 82 mm | < 78 mm |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 1: ENVIRONMENT SETUP\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "SEED = 42\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
    "\n",
    "    # Install dependencies\n",
    "    import torch\n",
    "    TORCH_VERSION = torch.__version__.split('+')[0]\n",
    "    CUDA_VERSION = torch.version.cuda\n",
    "    if CUDA_VERSION:\n",
    "        CUDA_TAG = f\"cu{CUDA_VERSION.replace('.', '')}\"\n",
    "    else:\n",
    "        CUDA_TAG = 'cpu'\n",
    "\n",
    "    print(f\"PyTorch: {TORCH_VERSION}\")\n",
    "    print(f\"CUDA: {CUDA_VERSION}\")\n",
    "\n",
    "    # Install torch_geometric\n",
    "    try:\n",
    "        import torch_geometric\n",
    "        print(f\"PyG already installed: {torch_geometric.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"Installing PyTorch Geometric...\")\n",
    "        pyg_url = f\"https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_TAG}.html\"\n",
    "        !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f $pyg_url\n",
    "        !pip install torch-geometric\n",
    "\n",
    "    # Install Mamba\n",
    "    print(\"\\nInstalling Mamba SSM...\")\n",
    "    !pip install mamba-ssm causal-conv1d>=1.1.0 --quiet\n",
    "\n",
    "    # Other dependencies\n",
    "    !pip install netCDF4 xarray dask h5netcdf --quiet\n",
    "\n",
    "    print(\"\\nEnvironment versions:\")\n",
    "    print(sys.version)\n",
    "    print(torch.__version__)\n",
    "    print(torch.version.cuda)\n",
    "\n",
    "    env_info = {\n",
    "        'python': sys.version,\n",
    "        'torch': torch.__version__,\n",
    "        'cuda': torch.version.cuda\n",
    "    }\n",
    "    try:\n",
    "        import torch_geometric\n",
    "        env_info['torch_geometric'] = torch_geometric.__version__\n",
    "        print(f\"PyG: {torch_geometric.__version__}\")\n",
    "    except Exception:\n",
    "        print(\"PyG: not available\")\n",
    "    try:\n",
    "        import mamba_ssm\n",
    "        env_info['mamba_ssm'] = mamba_ssm.__version__\n",
    "        print(f\"Mamba-SSM: {mamba_ssm.__version__}\")\n",
    "    except Exception:\n",
    "        print(\"Mamba-SSM: not available\")\n",
    "\n",
    "    env_dir = BASE_PATH / 'models' / 'output' / 'env_versions'\n",
    "    env_dir.mkdir(parents=True, exist_ok=True)\n",
    "    env_path = env_dir / 'v9_env_versions.json'\n",
    "    with open(env_path, 'w') as f:\n",
    "        json.dump(env_info, f, indent=2)\n",
    "    print(f\"Saved environment versions to: {env_path}\")\n",
    "\n",
    "else:\n",
    "    # Local environment\n",
    "    BASE_PATH = Path(r'd:\\github.com\\ninja-marduk\\ml_precipitation_prediction')\n",
    "    print(f\"Running locally, BASE_PATH: {BASE_PATH}\")\n",
    "\n",
    "print(f\"\\nBase path: {BASE_PATH}\")\n",
    "print(f\"Base path exists: {BASE_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 1.1: IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import gc\n",
    "import copy\n",
    "import warnings\n",
    "import math\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Matplotlib setup\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "\n",
    "# Mamba SSM\n",
    "PREFER_OFFICIAL_MAMBA = True\n",
    "REQUIRE_OFFICIAL_MAMBA = False\n",
    "USE_OFFICIAL_MAMBA = False\n",
    "MAMBA_BACKEND = \"custom\"\n",
    "try:\n",
    "    from mamba_ssm import Mamba\n",
    "    if PREFER_OFFICIAL_MAMBA:\n",
    "        USE_OFFICIAL_MAMBA = True\n",
    "        MAMBA_BACKEND = \"official\"\n",
    "        print(\"Using official mamba-ssm package for Mamba blocks\")\n",
    "    else:\n",
    "        print(\"Official mamba-ssm available but disabled; using custom implementation\")\n",
    "except ImportError as e:\n",
    "    if REQUIRE_OFFICIAL_MAMBA:\n",
    "        raise RuntimeError(\n",
    "            \"mamba-ssm not available but REQUIRE_OFFICIAL_MAMBA=True. \"\n",
    "            \"Install mamba-ssm or set REQUIRE_OFFICIAL_MAMBA=False.\"\n",
    "        ) from e\n",
    "    print(\"Official mamba-ssm not available, using custom implementation (slower; may trigger CUDA timeout on Windows)\")\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nDevice: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 2: V9 CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class V9Config:\n",
    "    \"\"\"V9 Bidirectional GNN-Mamba Configuration.\n",
    "    \n",
    "    Key additions from literature review:\n",
    "    - BidirectionalMamba (RiverMamba NeurIPS 2025)\n",
    "    - FrequencyTuning (S4D-FT WRR 2025)\n",
    "    - GeographicEncoding (WSSM arXiv 2025)\n",
    "    \"\"\"\n",
    "\n",
    "    # === Model Dimensions ===\n",
    "    hidden_dim: int = 64\n",
    "    d_state: int = 16\n",
    "    n_gnn_layers: int = 2\n",
    "    n_mamba_layers: int = 2\n",
    "    n_attention_heads: int = 4\n",
    "    dropout: float = 0.1\n",
    "    n_features: int = 5\n",
    "\n",
    "    # === Bidirectional Mamba (RiverMamba) ===\n",
    "    bidirectional: bool = True\n",
    "    combine_method: str = 'concat_linear'  # 'concat_linear', 'add', 'gate'\n",
    "    mamba_d_conv: int = 4\n",
    "    mamba_expand: int = 2\n",
    "\n",
    "    # === Frequency Tuning (S4D-FT) ===\n",
    "    use_frequency_tuning: bool = True\n",
    "    n_freq_bands: int = 4\n",
    "\n",
    "    # === Geographic Encoding (WSSM) ===\n",
    "    use_geographic_encoding: bool = True\n",
    "    n_lat: int = 61\n",
    "    n_lon: int = 65\n",
    "    n_nodes: int = 61 * 65\n",
    "\n",
    "    # === GNN Configuration ===\n",
    "    gnn_type: str = 'GAT'\n",
    "    gnn_num_heads: int = 4\n",
    "    gnn_dropout: float = 0.1\n",
    "\n",
    "    # === Cross-Modal Attention ===\n",
    "    cross_attn_heads: int = 4\n",
    "    cross_attn_dropout: float = 0.1\n",
    "\n",
    "    # === Training ===\n",
    "    epochs: int = 200\n",
    "    batch_size: int = 4\n",
    "    learning_rate: float = 0.0003\n",
    "    patience: int = 60\n",
    "    weight_decay: float = 1e-4\n",
    "    gradient_clip: float = 1.0\n",
    "\n",
    "    # === Physics Loss ===\n",
    "    use_physics_loss: bool = True\n",
    "    lambda_mass_conservation: float = 0.05\n",
    "    lambda_orographic: float = 0.1\n",
    "    high_elev_threshold: float = 3000.0\n",
    "\n",
    "    # === Data ===\n",
    "    input_window: int = 60\n",
    "    horizon: int = 12\n",
    "    train_val_split: float = 0.8\n",
    "    light_mode: bool = True\n",
    "    light_grid_size: int = 10\n",
    "    enabled_horizons: List[int] = field(default_factory=lambda: [12])\n",
    "\n",
    "    # === Scheduler ===\n",
    "    scheduler_type: str = 'cosine'\n",
    "    cosine_T0: int = 20\n",
    "    cosine_T_mult: int = 2\n",
    "\n",
    "    # === Chunking for memory ===\n",
    "    mamba_node_chunk: int = 256\n",
    "\n",
    "    # === Output ===\n",
    "    output_dir: str = 'V9_GNN_BiMamba'\n",
    "    save_checkpoints: bool = True\n",
    "\n",
    "    # === Data handling ===\n",
    "    allow_missing_features: bool = True\n",
    "\n",
    "    # === Outputs / Diagnostics ===\n",
    "    export_predictions: bool = True\n",
    "    export_history: bool = True\n",
    "    plot_graph_diagnostics: bool = True\n",
    "    plot_results_summary: bool = True\n",
    "    plot_metrics_table: bool = True\n",
    "    generate_map_plots: bool = True\n",
    "    map_export_horizon: int = 1\n",
    "    map_export_max_samples: int = 3\n",
    "\n",
    "    # === Quality checks ===\n",
    "    enforce_quality_gates: bool = False\n",
    "    quality_neg_pred_max: float = 0.01\n",
    "    quality_nan_max: float = 0.0\n",
    "    quality_bias_pct_max: float = 25.0\n",
    "\n",
    "    # === Expected performance ===\n",
    "    target_r2: float = 0.62\n",
    "    target_rmse: float = 78.0\n",
    "\n",
    "\n",
    "# Feature sets\n",
    "FEATURE_SETS = {\n",
    "    'BASIC': ['total_precipitation'],\n",
    "    'KCE': ['total_precipitation', 'elev_low', 'elev_med', 'elev_high'],\n",
    "    'FULL': ['total_precipitation', 'elevation', 'slope', 'aspect',\n",
    "             'elev_low', 'elev_med', 'elev_high']\n",
    "}\n",
    "\n",
    "# Initialize config\n",
    "CONFIG = V9Config()\n",
    "\n",
    "# Adjust for Colab memory constraints\n",
    "if IN_COLAB:\n",
    "    CONFIG.batch_size = 2\n",
    "    CONFIG.hidden_dim = 48\n",
    "    CONFIG.d_state = 12\n",
    "    CONFIG.gnn_num_heads = 2\n",
    "    print(\"Adjusted config for Colab memory constraints\")\n",
    "\n",
    "print(\"\\n=== V9 Bidirectional GNN-Mamba Configuration ===\")\n",
    "print(f\"  Input window: {CONFIG.input_window} months\")\n",
    "print(f\"  Horizon: {CONFIG.horizon} months\")\n",
    "print(f\"  Hidden dim: {CONFIG.hidden_dim}\")\n",
    "print(f\"  d_state: {CONFIG.d_state}\")\n",
    "print(f\"  Bidirectional: {CONFIG.bidirectional}\")\n",
    "print(f\"  Frequency Tuning: {CONFIG.use_frequency_tuning}\")\n",
    "print(f\"  Geographic Encoding: {CONFIG.use_geographic_encoding}\")\n",
    "print(f\"  GNN type: {CONFIG.gnn_type}\")\n",
    "print(f\"  Batch size: {CONFIG.batch_size}\")\n",
    "print(f\"  Learning rate: {CONFIG.learning_rate}\")\n",
    "print(f\"  Target R2: {CONFIG.target_r2}\")\n",
    "print(f\"  Target RMSE: {CONFIG.target_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. New V9 Modules\n",
    "\n",
    "### 3.1 BidirectionalMamba (RiverMamba NeurIPS 2025)\n",
    "### 3.2 FrequencyTuning (S4D-FT WRR 2025)\n",
    "### 3.3 GeographicEncoding (WSSM arXiv 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 3: V9 NEW MODULES\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3.1 Custom Mamba Block (fallback when official not available)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Selective State Space Model Block.\n",
    "    Based on: \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        d_state: int = 16,\n",
    "        d_conv: int = 4,\n",
    "        expand: int = 2,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_state = d_state\n",
    "        self.d_conv = d_conv\n",
    "        self.d_inner = d_model * expand\n",
    "\n",
    "        self.in_proj = nn.Linear(d_model, self.d_inner * 2, bias=False)\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=self.d_inner,\n",
    "            out_channels=self.d_inner,\n",
    "            kernel_size=d_conv,\n",
    "            padding=d_conv - 1,\n",
    "            groups=self.d_inner\n",
    "        )\n",
    "        self.x_proj = nn.Linear(self.d_inner, d_state * 2 + 1, bias=False)\n",
    "        A = torch.arange(1, d_state + 1, dtype=torch.float32)\n",
    "        self.A_log = nn.Parameter(torch.log(A))\n",
    "        self.D = nn.Parameter(torch.ones(self.d_inner))\n",
    "        self.out_proj = nn.Linear(self.d_inner, d_model, bias=False)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch, seq_len, _ = x.shape\n",
    "        residual = x\n",
    "\n",
    "        xz = self.in_proj(x)\n",
    "        x_branch, z = xz.chunk(2, dim=-1)\n",
    "\n",
    "        x_conv = x_branch.transpose(1, 2)\n",
    "        x_conv = self.conv1d(x_conv)[:, :, :seq_len]\n",
    "        x_conv = x_conv.transpose(1, 2)\n",
    "        x_conv = F.silu(x_conv)\n",
    "\n",
    "        y = self.ssm(x_conv)\n",
    "        z = F.silu(z)\n",
    "        output = y * z\n",
    "\n",
    "        output = self.out_proj(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.norm(output + residual)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def ssm(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch, seq_len, d_inner = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        x_proj = self.x_proj(x)\n",
    "        B = x_proj[:, :, :self.d_state]\n",
    "        C = x_proj[:, :, self.d_state:2*self.d_state]\n",
    "        dt = F.softplus(x_proj[:, :, -1:])\n",
    "\n",
    "        A = -torch.exp(self.A_log.float())\n",
    "        A_bar = torch.exp(A.view(1, 1, self.d_state) * dt)\n",
    "        B_bar = B * dt\n",
    "\n",
    "        h = torch.zeros(batch, d_inner, self.d_state, device=device)\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            h = h * A_bar[:, t, :].unsqueeze(1) + \\\n",
    "                x[:, t, :].unsqueeze(-1) * B_bar[:, t, :].unsqueeze(1)\n",
    "            y_t = (h * C[:, t, :].unsqueeze(1)).sum(dim=-1)\n",
    "            outputs.append(y_t)\n",
    "\n",
    "        y = torch.stack(outputs, dim=1)\n",
    "        y = y + x * self.D.view(1, 1, -1)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class OfficialMambaBlock(nn.Module):\n",
    "    '''\n",
    "    Wrapper around the official mamba-ssm Mamba module with residual + norm.\n",
    "\n",
    "    Uses the official CUDA kernels when available.\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        d_state: int = 16,\n",
    "        d_conv: int = 4,\n",
    "        expand: int = 2,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mamba = Mamba(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "        y = self.mamba(x)\n",
    "        y = self.dropout(y)\n",
    "        return self.norm(y + residual)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3.2 BidirectionalMamba (RiverMamba NeurIPS 2025)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "class BidirectionalMamba(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional Mamba block from RiverMamba (NeurIPS 2025).\n",
    "    \n",
    "    Processes sequences in both forward and backward directions,\n",
    "    then combines the representations for improved temporal modeling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, d_state: int = 16, d_conv: int = 4, expand: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Use official Mamba if available, otherwise custom\n",
    "        block_cls = OfficialMambaBlock if USE_OFFICIAL_MAMBA else MambaBlock\n",
    "        self.mamba_fwd = block_cls(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand, dropout=dropout)\n",
    "        self.mamba_bwd = block_cls(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand, dropout=dropout)\n",
    "        \n",
    "        # Combination layer\n",
    "        self.combine = nn.Linear(d_model * 2, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, seq_len, d_model)\n",
    "        Returns:\n",
    "            output: (batch, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Forward direction\n",
    "        x_fwd = self.mamba_fwd(x)\n",
    "        \n",
    "        # Backward direction (flip, process, flip back)\n",
    "        x_bwd = self.mamba_bwd(torch.flip(x, dims=[1]))\n",
    "        x_bwd = torch.flip(x_bwd, dims=[1])\n",
    "        \n",
    "        # Combine forward and backward\n",
    "        combined = self.combine(torch.cat([x_fwd, x_bwd], dim=-1))\n",
    "        combined = self.dropout(combined)\n",
    "        \n",
    "        # Residual connection and normalization\n",
    "        return self.norm(combined + x)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3.3 FrequencyTuning (S4D-FT WRR 2025)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "class FrequencyTuning(nn.Module):\n",
    "    \"\"\"\n",
    "    Frequency-domain tuning module from S4D-FT (WRR 2025).\n",
    "    \n",
    "    Learns to filter signals in the frequency domain to better\n",
    "    capture seasonal and periodic patterns in precipitation data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, n_freq_bands: int = 4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_freq_bands = n_freq_bands\n",
    "        \n",
    "        # Learnable frequency filter\n",
    "        self.freq_filter = nn.Conv1d(d_model, d_model, kernel_size=1)\n",
    "        \n",
    "        # Learnable mixing coefficient\n",
    "        self.alpha = nn.Parameter(torch.ones(1) * 0.5)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, seq_len, d_model)\n",
    "        Returns:\n",
    "            output: (batch, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        B, T, D = x.shape\n",
    "        \n",
    "        # Time domain representation\n",
    "        x_time = x\n",
    "        \n",
    "        # Transform to frequency domain\n",
    "        x_freq = torch.fft.rfft(x, dim=1)\n",
    "        \n",
    "        # Apply learnable filter to real part\n",
    "        x_freq_real = self.freq_filter(x_freq.real.transpose(1, 2)).transpose(1, 2)\n",
    "        \n",
    "        # Reconstruct complex tensor\n",
    "        x_freq_filtered = torch.complex(x_freq_real, x_freq.imag)\n",
    "        \n",
    "        # Transform back to time domain\n",
    "        x_freq_out = torch.fft.irfft(x_freq_filtered, n=T, dim=1)\n",
    "        \n",
    "        # Learnable mix of time and frequency representations\n",
    "        alpha = torch.sigmoid(self.alpha)\n",
    "        return alpha * x_time + (1 - alpha) * x_freq_out\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3.4 GeographicEncoding (WSSM arXiv 2025)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "class GeographicEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Geographic position encoding from WSSM (arXiv 2025).\n",
    "    \n",
    "    Encodes spatial position (latitude, longitude, elevation) to\n",
    "    provide the model with geographic awareness.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, n_lat: int = 61, n_lon: int = 65):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_lat = n_lat\n",
    "        self.n_lon = n_lon\n",
    "        \n",
    "        # Latitude and longitude embeddings\n",
    "        lat_dim = d_model // 3\n",
    "        lon_dim = d_model // 3\n",
    "        elev_dim = d_model - lat_dim - lon_dim\n",
    "        \n",
    "        self.lat_embed = nn.Embedding(n_lat, lat_dim)\n",
    "        self.lon_embed = nn.Embedding(n_lon, lon_dim)\n",
    "        self.elev_proj = nn.Linear(1, elev_dim)\n",
    "        \n",
    "        # Output projection to ensure dimension match\n",
    "        self.output_proj = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        lat_idx: torch.Tensor,\n",
    "        lon_idx: torch.Tensor,\n",
    "        elevation: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, n_nodes, d_model) or (batch, seq_len, n_nodes, d_model)\n",
    "            lat_idx: (n_nodes,) latitude indices\n",
    "            lon_idx: (n_nodes,) longitude indices  \n",
    "            elevation: (n_nodes,) elevation values\n",
    "        Returns:\n",
    "            output: same shape as x\n",
    "        \"\"\"\n",
    "        # Get geographic embeddings\n",
    "        lat_emb = self.lat_embed(lat_idx)  # (n_nodes, lat_dim)\n",
    "        lon_emb = self.lon_embed(lon_idx)  # (n_nodes, lon_dim)\n",
    "        elev_emb = self.elev_proj(elevation.unsqueeze(-1))  # (n_nodes, elev_dim)\n",
    "        \n",
    "        # Concatenate geographic features\n",
    "        geo = torch.cat([lat_emb, lon_emb, elev_emb], dim=-1)  # (n_nodes, d_model)\n",
    "        geo = self.output_proj(geo)  # (n_nodes, d_model)\n",
    "        \n",
    "        # Add to input (broadcast across batch and optionally time)\n",
    "        if x.dim() == 3:  # (batch, n_nodes, d_model)\n",
    "            geo = geo.unsqueeze(0)  # (1, n_nodes, d_model)\n",
    "        elif x.dim() == 4:  # (batch, seq_len, n_nodes, d_model)\n",
    "            geo = geo.unsqueeze(0).unsqueeze(0)  # (1, 1, n_nodes, d_model)\n",
    "        \n",
    "        return self.norm(x + geo)\n",
    "\n",
    "\n",
    "# Test new modules\n",
    "print(f\"Testing V9 modules ({MAMBA_BACKEND})...\")\n",
    "\n",
    "# Test BidirectionalMamba\n",
    "test_bimamba = BidirectionalMamba(d_model=64, d_state=16).to(device)\n",
    "test_input = torch.randn(2, 60, 64).to(device)\n",
    "test_output = test_bimamba(test_input)\n",
    "print(f\"BidirectionalMamba: {test_input.shape} -> {test_output.shape}\")\n",
    "\n",
    "# Test FrequencyTuning\n",
    "test_freq = FrequencyTuning(d_model=64, n_freq_bands=4).to(device)\n",
    "test_output = test_freq(test_input)\n",
    "print(f\"FrequencyTuning: {test_input.shape} -> {test_output.shape}\")\n",
    "\n",
    "# Test GeographicEncoding\n",
    "test_geo = GeographicEncoding(d_model=64, n_lat=61, n_lon=65).to(device)\n",
    "test_x = torch.randn(2, 100, 64).to(device)\n",
    "test_lat = torch.randint(0, 61, (100,)).to(device)\n",
    "test_lon = torch.randint(0, 65, (100,)).to(device)\n",
    "test_elev = torch.randn(100).to(device)\n",
    "test_output = test_geo(test_x, test_lat, test_lon, test_elev)\n",
    "print(f\"GeographicEncoding: {test_x.shape} -> {test_output.shape}\")\n",
    "\n",
    "del test_bimamba, test_freq, test_geo, test_input, test_x, test_output\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "print(\"\\nAll V9 modules tested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial GNN Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 4: SPATIAL GNN ENCODER\n",
    "# ============================================================\n",
    "\n",
    "class SpatialGNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Neural Network for spatial encoding.\n",
    "    Supports GAT, GraphSAGE, and GCN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_layers: int = 3,\n",
    "        gnn_type: str = 'GAT',\n",
    "        num_heads: int = 4,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gnn_type = gnn_type\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        self.gnn_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            if gnn_type == 'GAT':\n",
    "                self.gnn_layers.append(\n",
    "                    GATConv(\n",
    "                        in_channels=hidden_dim,\n",
    "                        out_channels=hidden_dim // num_heads,\n",
    "                        heads=num_heads,\n",
    "                        dropout=dropout,\n",
    "                        concat=True\n",
    "                    )\n",
    "                )\n",
    "            elif gnn_type == 'SAGE':\n",
    "                self.gnn_layers.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "            else:\n",
    "                self.gnn_layers.append(GCNConv(hidden_dim, hidden_dim))\n",
    "\n",
    "            self.norms.append(nn.LayerNorm(hidden_dim))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        edge_index: torch.Tensor,\n",
    "        edge_weight: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        h = self.input_proj(x)\n",
    "\n",
    "        for i, (gnn, norm) in enumerate(zip(self.gnn_layers, self.norms)):\n",
    "            h_res = h\n",
    "\n",
    "            if self.gnn_type == 'GAT':\n",
    "                h = gnn(h, edge_index)\n",
    "            elif edge_weight is not None and self.gnn_type == 'GCN':\n",
    "                h = gnn(h, edge_index, edge_weight)\n",
    "            else:\n",
    "                h = gnn(h, edge_index)\n",
    "\n",
    "            h = F.gelu(h)\n",
    "            h = norm(h)\n",
    "            h = self.dropout(h)\n",
    "            h = h + h_res\n",
    "\n",
    "        return self.output_norm(h)\n",
    "\n",
    "\n",
    "print(\"SpatialGNNEncoder defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GNN-BiMamba V9 Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 5: GNN-BIMAMBA V9 MAIN MODEL\n",
    "# ============================================================\n",
    "\n",
    "class CrossModalAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Cross-attention between spatial (GNN) and temporal (Mamba) representations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, num_heads: int = 4, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key_value: torch.Tensor) -> torch.Tensor:\n",
    "        attn_out, _ = self.attn(query, key_value, key_value)\n",
    "        x = self.norm1(query + attn_out)\n",
    "        x = self.norm2(x + self.ffn(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNN_BiMamba_V9(nn.Module):\n",
    "    \"\"\"\n",
    "    V9: Bidirectional GNN-Mamba with Frequency Tuning and Geographic Encoding.\n",
    "\n",
    "    Architecture:\n",
    "    1. Input projection\n",
    "    2. Geographic Encoding (WSSM)\n",
    "    3. Parallel branches:\n",
    "       - GNN: spatial encoding per timestep\n",
    "       - BidirectionalMamba + FrequencyTuning: temporal encoding per node\n",
    "    4. Cross-modal attention fusion\n",
    "    5. Prediction head\n",
    "\n",
    "    Improvements over V8:\n",
    "    - BidirectionalMamba from RiverMamba (NeurIPS 2025)\n",
    "    - FrequencyTuning from S4D-FT (WRR 2025)\n",
    "    - GeographicEncoding from WSSM (arXiv 2025)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: V9Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        # === Input Projection ===\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(config.n_features, config.hidden_dim),\n",
    "            nn.LayerNorm(config.hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config.dropout)\n",
    "        )\n",
    "\n",
    "        # === Geographic Encoding (WSSM) ===\n",
    "        if config.use_geographic_encoding:\n",
    "            self.geo_encoding = GeographicEncoding(\n",
    "                d_model=config.hidden_dim,\n",
    "                n_lat=config.n_lat,\n",
    "                n_lon=config.n_lon\n",
    "            )\n",
    "        else:\n",
    "            self.geo_encoding = None\n",
    "\n",
    "        # === Spatial Branch: GNN ===\n",
    "        self.gnn_encoder = SpatialGNNEncoder(\n",
    "            input_dim=config.hidden_dim,\n",
    "            hidden_dim=config.hidden_dim,\n",
    "            num_layers=config.n_gnn_layers,\n",
    "            gnn_type=config.gnn_type,\n",
    "            num_heads=config.gnn_num_heads,\n",
    "            dropout=config.gnn_dropout\n",
    "        )\n",
    "\n",
    "        # === Temporal Branch: BidirectionalMamba + FrequencyTuning ===\n",
    "        self.mamba_layers = nn.ModuleList([\n",
    "            BidirectionalMamba(\n",
    "                d_model=config.hidden_dim,\n",
    "                d_state=config.d_state,\n",
    "                d_conv=config.mamba_d_conv,\n",
    "                expand=config.mamba_expand,\n",
    "                dropout=config.dropout\n",
    "            )\n",
    "            for _ in range(config.n_mamba_layers)\n",
    "        ])\n",
    "\n",
    "        # === Frequency Tuning (S4D-FT) ===\n",
    "        if config.use_frequency_tuning:\n",
    "            self.freq_tuning = FrequencyTuning(\n",
    "                d_model=config.hidden_dim,\n",
    "                n_freq_bands=config.n_freq_bands\n",
    "            )\n",
    "        else:\n",
    "            self.freq_tuning = None\n",
    "\n",
    "        # === Cross-Modal Fusion ===\n",
    "        self.cross_attention = CrossModalAttention(\n",
    "            d_model=config.hidden_dim,\n",
    "            num_heads=config.cross_attn_heads,\n",
    "            dropout=config.cross_attn_dropout\n",
    "        )\n",
    "\n",
    "        # === Prediction Head ===\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(config.hidden_dim, config.hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.hidden_dim, config.hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.hidden_dim // 2, config.horizon)\n",
    "        )\n",
    "\n",
    "        # Store dimensions\n",
    "        self.n_lat = config.n_lat\n",
    "        self.n_lon = config.n_lon\n",
    "        self.n_nodes = config.n_nodes\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and param.dim() >= 2:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        edge_index: torch.Tensor,\n",
    "        edge_weight: Optional[torch.Tensor] = None,\n",
    "        lat_idx: Optional[torch.Tensor] = None,\n",
    "        lon_idx: Optional[torch.Tensor] = None,\n",
    "        elevation: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: (batch, seq_len, n_nodes, n_features)\n",
    "            edge_index: (2, num_edges)\n",
    "            edge_weight: (num_edges,) optional\n",
    "            lat_idx: (n_nodes,) latitude indices for geo encoding\n",
    "            lon_idx: (n_nodes,) longitude indices for geo encoding\n",
    "            elevation: (n_nodes,) elevation values for geo encoding\n",
    "\n",
    "        Returns:\n",
    "            pred: (batch, n_nodes, horizon)\n",
    "            info: dict with intermediate representations\n",
    "        \"\"\"\n",
    "        if x.dim() == 5:  # (B, T, lat, lon, F)\n",
    "            batch_size, seq_len, n_lat, n_lon, n_features = x.shape\n",
    "            n_nodes = n_lat * n_lon\n",
    "            x = x.view(batch_size, seq_len, n_nodes, n_features)\n",
    "        else:\n",
    "            batch_size, seq_len, n_nodes, n_features = x.shape\n",
    "\n",
    "        # 1. Input projection\n",
    "        x = self.input_proj(x)  # (B, T, N, H)\n",
    "\n",
    "        # 2. Geographic encoding (optional)\n",
    "        if self.geo_encoding is not None and lat_idx is not None:\n",
    "            x = self.geo_encoding(x, lat_idx, lon_idx, elevation)\n",
    "\n",
    "        # 3. Spatial encoding (GNN per timestep)\n",
    "        h_spatial = self._encode_spatial(x, edge_index, edge_weight)\n",
    "\n",
    "        # 4. Temporal encoding (BidirectionalMamba per node)\n",
    "        h_temporal = self._encode_temporal(x)\n",
    "\n",
    "        # 5. Cross-modal fusion\n",
    "        h_fused = self._fuse_representations(h_spatial, h_temporal)\n",
    "\n",
    "        # 6. Prediction\n",
    "        pred = self.predictor(h_fused)\n",
    "\n",
    "        info = {\n",
    "            'h_spatial': h_spatial[:, -1, :, :],\n",
    "            'h_temporal': h_temporal[:, -1, :, :],\n",
    "            'h_fused': h_fused\n",
    "        }\n",
    "\n",
    "        return pred, info\n",
    "\n",
    "    def _encode_spatial(self, x, edge_index, edge_weight):\n",
    "        \"\"\"Apply GNN to each timestep.\"\"\"\n",
    "        batch_size, seq_len, n_nodes, hidden_dim = x.shape\n",
    "\n",
    "        chunk_size = 10\n",
    "        outputs = []\n",
    "\n",
    "        for t_start in range(0, seq_len, chunk_size):\n",
    "            t_end = min(t_start + chunk_size, seq_len)\n",
    "            x_chunk = x[:, t_start:t_end, :, :]\n",
    "\n",
    "            chunk_len = t_end - t_start\n",
    "            x_flat = x_chunk.reshape(batch_size * chunk_len, n_nodes, hidden_dim)\n",
    "\n",
    "            h_list = []\n",
    "            for i in range(x_flat.shape[0]):\n",
    "                h_i = self.gnn_encoder(x_flat[i], edge_index, edge_weight)\n",
    "                h_list.append(h_i)\n",
    "\n",
    "            h_chunk = torch.stack(h_list, dim=0)\n",
    "            h_chunk = h_chunk.view(batch_size, chunk_len, n_nodes, hidden_dim)\n",
    "            outputs.append(h_chunk)\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "    def _encode_temporal(self, x):\n",
    "        \"\"\"Apply BidirectionalMamba + FrequencyTuning to each node's temporal sequence.\"\"\"\n",
    "        batch_size, seq_len, n_nodes, hidden_dim = x.shape\n",
    "\n",
    "        chunk_size = getattr(self.config, 'mamba_node_chunk', 0) or n_nodes\n",
    "        outputs = []\n",
    "\n",
    "        for n_start in range(0, n_nodes, chunk_size):\n",
    "            n_end = min(n_start + chunk_size, n_nodes)\n",
    "            x_chunk = x[:, :, n_start:n_end, :]\n",
    "\n",
    "            # Reshape: (B, T, chunk, H) -> (B*chunk, T, H)\n",
    "            x_temporal = x_chunk.permute(0, 2, 1, 3)\n",
    "            x_temporal = x_temporal.reshape(batch_size * (n_end - n_start), seq_len, hidden_dim)\n",
    "\n",
    "            # Apply BidirectionalMamba layers\n",
    "            h_temporal = x_temporal\n",
    "            for mamba_layer in self.mamba_layers:\n",
    "                h_temporal = mamba_layer(h_temporal)\n",
    "\n",
    "            # Apply FrequencyTuning (optional)\n",
    "            if self.freq_tuning is not None:\n",
    "                h_temporal = self.freq_tuning(h_temporal)\n",
    "\n",
    "            # Reshape back: (B*chunk, T, H) -> (B, T, chunk, H)\n",
    "            h_temporal = h_temporal.view(batch_size, n_end - n_start, seq_len, hidden_dim)\n",
    "            h_temporal = h_temporal.permute(0, 2, 1, 3)\n",
    "            outputs.append(h_temporal)\n",
    "\n",
    "        return torch.cat(outputs, dim=2)\n",
    "\n",
    "    def _fuse_representations(self, h_spatial, h_temporal):\n",
    "        \"\"\"Fuse spatial and temporal representations at final timestep.\"\"\"\n",
    "        h_spatial_final = h_spatial[:, -1, :, :]\n",
    "        h_temporal_final = h_temporal[:, -1, :, :]\n",
    "        h_fused = self.cross_attention(h_spatial_final, h_temporal_final)\n",
    "        return h_fused\n",
    "\n",
    "\n",
    "# Test model\n",
    "print(\"\\nTesting GNN_BiMamba_V9...\")\n",
    "test_config = V9Config(\n",
    "    n_features=4,\n",
    "    n_lat=10,\n",
    "    n_lon=10,\n",
    "    n_nodes=100,\n",
    "    hidden_dim=32,\n",
    "    d_state=8,\n",
    "    input_window=12,\n",
    "    horizon=6\n",
    ")\n",
    "\n",
    "test_model = GNN_BiMamba_V9(test_config).to(device)\n",
    "test_x = torch.randn(2, 12, 100, 4).to(device)\n",
    "test_edge_index = torch.randint(0, 100, (2, 500)).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_pred, test_info = test_model(test_x, test_edge_index)\n",
    "\n",
    "print(f\"  Input shape: {test_x.shape}\")\n",
    "print(f\"  Output shape: {test_pred.shape}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
    "\n",
    "del test_model, test_x, test_pred, test_info\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "print(\"\\nGNN_BiMamba_V9 test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 6: DATA LOADING\n",
    "# ============================================================\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = BASE_PATH / 'data' / 'output' / 'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation_clean.nc'\n",
    "OUTPUT_ROOT = BASE_PATH / 'models' / 'output' / CONFIG.output_dir\n",
    "DATA_OUT_DIR = OUTPUT_ROOT / 'data'\n",
    "FIG_OUT_DIR = OUTPUT_ROOT / 'figures'\n",
    "COMP_DIR = OUTPUT_ROOT / 'comparisons'\n",
    "TRAIN_LOG_DIR = OUTPUT_ROOT / 'training_metrics'\n",
    "MAP_OUT_DIR = OUTPUT_ROOT / 'map_exports'\n",
    "\n",
    "for d in [OUTPUT_ROOT, DATA_OUT_DIR, FIG_OUT_DIR, COMP_DIR, TRAIN_LOG_DIR, MAP_OUT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_ROOT}\")\n",
    "print(f\"Data exists: {DATA_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 6.1: DATA FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def validate_dataset(ds: xr.Dataset, config: V9Config) -> Tuple[str, str]:\n",
    "    \"\"\"Validate dataset dimensions.\"\"\"\n",
    "    lat_candidates = ['latitude', 'lat', 'y']\n",
    "    lon_candidates = ['longitude', 'lon', 'x']\n",
    "\n",
    "    lat_dim = next((d for d in lat_candidates if d in ds.dims), None)\n",
    "    lon_dim = next((d for d in lon_candidates if d in ds.dims), None)\n",
    "\n",
    "    if lat_dim is None or lon_dim is None:\n",
    "        raise ValueError(f\"Cannot find lat/lon dims in {list(ds.dims.keys())}\")\n",
    "\n",
    "    if 'time' not in ds.dims:\n",
    "        raise ValueError(\"Dataset must have 'time' dimension\")\n",
    "\n",
    "    config.n_lat = ds.dims[lat_dim]\n",
    "    config.n_lon = ds.dims[lon_dim]\n",
    "    config.n_nodes = config.n_lat * config.n_lon\n",
    "\n",
    "    return lat_dim, lon_dim\n",
    "\n",
    "\n",
    "def load_dataset(data_path: Path, config: V9Config) -> xr.Dataset:\n",
    "    \"\"\"Load and validate NetCDF dataset.\"\"\"\n",
    "    print(f\"Loading dataset from: {data_path}\")\n",
    "    ds = xr.open_dataset(data_path)\n",
    "\n",
    "    lat_dim, lon_dim = validate_dataset(ds, config)\n",
    "\n",
    "    print(f\"Dataset dimensions:\")\n",
    "    for dim, size in ds.dims.items():\n",
    "        print(f\"  - {dim}: {size}\")\n",
    "\n",
    "    print(f\"Available variables: {list(ds.data_vars)}\")\n",
    "\n",
    "    if config.light_mode:\n",
    "        ds = ds.isel({\n",
    "            lat_dim: slice(0, config.light_grid_size),\n",
    "            lon_dim: slice(0, config.light_grid_size)\n",
    "        })\n",
    "        config.n_lat = config.light_grid_size\n",
    "        config.n_lon = config.light_grid_size\n",
    "        config.n_nodes = config.n_lat * config.n_lon\n",
    "        print(f\"Light mode: using {config.light_grid_size}x{config.light_grid_size} grid\")\n",
    "\n",
    "    return ds, lat_dim, lon_dim\n",
    "\n",
    "\n",
    "def create_elevation_clusters(ds: xr.Dataset, n_clusters: int = 3) -> xr.Dataset:\n",
    "    \"\"\"Add elevation cluster features (KCE).\"\"\"\n",
    "    if 'elevation' not in ds:\n",
    "        print(\"Warning: No elevation data, skipping clustering\")\n",
    "        return ds\n",
    "\n",
    "    elevation = ds['elevation'].values\n",
    "    elev_dims = ds['elevation'].dims\n",
    "\n",
    "    if elevation.ndim == 3:\n",
    "        elevation = elevation[0]\n",
    "        elev_dims = elev_dims[-2:]\n",
    "\n",
    "    valid_mask = ~np.isnan(elevation)\n",
    "    elev_flat = elevation[valid_mask].reshape(-1, 1)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=SEED, n_init=10)\n",
    "    labels = np.full(elevation.shape, -1)\n",
    "    labels[valid_mask] = kmeans.fit_predict(elev_flat)\n",
    "\n",
    "    for i, name in enumerate(['elev_low', 'elev_med', 'elev_high']):\n",
    "        cluster_data = np.zeros_like(elevation)\n",
    "        cluster_data[labels == i] = 1.0\n",
    "        ds[name] = xr.DataArray(data=cluster_data, dims=elev_dims)\n",
    "\n",
    "    print(\"Added elevation clusters: elev_low, elev_med, elev_high\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def build_spatial_graph(\n",
    "    ds: xr.Dataset,\n",
    "    lat_dim: str,\n",
    "    lon_dim: str,\n",
    "    k_neighbors: int = 8,\n",
    "    max_edges: int = 500000\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Build spatial graph based on geographic proximity.\"\"\"\n",
    "    lat_vals = ds[lat_dim].values\n",
    "    lon_vals = ds[lon_dim].values\n",
    "\n",
    "    n_lat, n_lon = len(lat_vals), len(lon_vals)\n",
    "    n_nodes = n_lat * n_lon\n",
    "\n",
    "    edges = []\n",
    "    weights = []\n",
    "\n",
    "    for i in range(n_lat):\n",
    "        for j in range(n_lon):\n",
    "            node_idx = i * n_lon + j\n",
    "\n",
    "            neighbors = [\n",
    "                (i-1, j-1), (i-1, j), (i-1, j+1),\n",
    "                (i, j-1),             (i, j+1),\n",
    "                (i+1, j-1), (i+1, j), (i+1, j+1)\n",
    "            ]\n",
    "\n",
    "            for ni, nj in neighbors:\n",
    "                if 0 <= ni < n_lat and 0 <= nj < n_lon:\n",
    "                    neighbor_idx = ni * n_lon + nj\n",
    "\n",
    "                    dist = np.sqrt(\n",
    "                        (lat_vals[i] - lat_vals[ni])**2 +\n",
    "                        (lon_vals[j] - lon_vals[nj])**2\n",
    "                    )\n",
    "                    weight = 1.0 / (dist + 1e-6)\n",
    "\n",
    "                    edges.append([node_idx, neighbor_idx])\n",
    "                    weights.append(weight)\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    edge_weight = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "    edge_weight = edge_weight / edge_weight.max()\n",
    "\n",
    "    if edge_index.shape[1] > max_edges:\n",
    "        top_k = torch.topk(edge_weight, max_edges).indices\n",
    "        edge_index = edge_index[:, top_k]\n",
    "        edge_weight = edge_weight[top_k]\n",
    "\n",
    "    print(f\"Graph built: {n_nodes} nodes, {edge_index.shape[1]} edges\")\n",
    "\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "\n",
    "def create_geo_indices(n_lat: int, n_lon: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Create latitude and longitude indices for geographic encoding.\"\"\"\n",
    "    lat_idx = []\n",
    "    lon_idx = []\n",
    "    for i in range(n_lat):\n",
    "        for j in range(n_lon):\n",
    "            lat_idx.append(i)\n",
    "            lon_idx.append(j)\n",
    "    return torch.tensor(lat_idx, dtype=torch.long), torch.tensor(lon_idx, dtype=torch.long)\n",
    "\n",
    "\n",
    "def plot_graph_diagnostics(\n",
    "    edge_index: torch.Tensor,\n",
    "    edge_weight: torch.Tensor,\n",
    "    output_dir: Path,\n",
    "    config: V9Config\n",
    ") -> None:\n",
    "    \"\"\"Plot simple graph diagnostics.\"\"\"\n",
    "    if edge_index is None or edge_weight is None:\n",
    "        print('Graph diagnostics skipped: missing edge data')\n",
    "        return\n",
    "\n",
    "    src = edge_index[0].cpu().numpy() if torch.is_tensor(edge_index) else np.asarray(edge_index[0])\n",
    "    weights = edge_weight.cpu().numpy() if torch.is_tensor(edge_weight) else np.asarray(edge_weight)\n",
    "    degrees = np.bincount(src, minlength=config.n_nodes)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].hist(degrees, bins=30, color='steelblue', edgecolor='black')\n",
    "    axes[0].set_title('Node Degree Distribution')\n",
    "    axes[0].set_xlabel('Degree')\n",
    "    axes[0].set_ylabel('Count')\n",
    "\n",
    "    axes[1].hist(weights, bins=30, color='darkorange', edgecolor='black')\n",
    "    axes[1].set_title('Edge Weight Distribution')\n",
    "    axes[1].set_xlabel('Weight')\n",
    "    axes[1].set_ylabel('Count')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig_path = output_dir / 'v9_graph_diagnostics.png'\n",
    "    fig.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Graph diagnostics saved to: {fig_path}\")\n",
    "\n",
    "\n",
    "def extract_features(\n",
    "    ds: xr.Dataset,\n",
    "    feature_names: List[str],\n",
    "    config: V9Config\n",
    ") -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"Extract features from dataset.\"\"\"\n",
    "    features = []\n",
    "    missing = []\n",
    "\n",
    "    for name in feature_names:\n",
    "        if name in ds.data_vars:\n",
    "            data = ds[name].values\n",
    "            if data.ndim == 2:\n",
    "                data = np.broadcast_to(data, (ds.dims['time'], *data.shape))\n",
    "            features.append(data)\n",
    "        elif config.allow_missing_features:\n",
    "            print(f\"Warning: Missing feature {name}\")\n",
    "            missing.append(name)\n",
    "        else:\n",
    "            raise ValueError(f\"Missing feature: {name}\")\n",
    "\n",
    "    if not features:\n",
    "        raise ValueError(\"No features extracted\")\n",
    "\n",
    "    features = np.stack(features, axis=-1)\n",
    "    features = np.nan_to_num(features, nan=0.0)\n",
    "\n",
    "    config.n_features = features.shape[-1]\n",
    "    print(f\"Extracted features shape: {features.shape}\")\n",
    "\n",
    "    return features.astype(np.float32), missing\n",
    "\n",
    "\n",
    "def extract_elevation_vector(ds: xr.Dataset) -> Optional[np.ndarray]:\n",
    "    \"\"\"Extract elevation as a flat vector if available.\"\"\"\n",
    "    if 'elevation' not in ds:\n",
    "        return None\n",
    "\n",
    "    elevation = ds['elevation'].values\n",
    "    if elevation.ndim == 3:\n",
    "        elevation = elevation[0]\n",
    "\n",
    "    elevation = np.nan_to_num(elevation, nan=0.0).astype(np.float32)\n",
    "    return elevation.reshape(-1)\n",
    "\n",
    "\n",
    "print(\"Data functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 6.2: DATASET CLASS\n",
    "# ============================================================\n",
    "\n",
    "class V9Dataset(Dataset):\n",
    "    \"\"\"Dataset for V9 GNN-BiMamba model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        features: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        input_window: int,\n",
    "        horizon: int,\n",
    "        edge_index: torch.Tensor,\n",
    "        edge_weight: torch.Tensor,\n",
    "        start_idx: int,\n",
    "        end_idx: int,\n",
    "        elevation: Optional[torch.Tensor] = None,\n",
    "        lat_idx: Optional[torch.Tensor] = None,\n",
    "        lon_idx: Optional[torch.Tensor] = None\n",
    "    ):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.input_window = input_window\n",
    "        self.horizon = horizon\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_weight = edge_weight\n",
    "        self.start_idx = start_idx\n",
    "        self.end_idx = end_idx\n",
    "        self.elevation = elevation\n",
    "        self.lat_idx = lat_idx\n",
    "        self.lon_idx = lon_idx\n",
    "\n",
    "        self.n_lat = features.shape[1]\n",
    "        self.n_lon = features.shape[2]\n",
    "        self.n_nodes = self.n_lat * self.n_lon\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.end_idx - self.start_idx\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.start_idx + idx\n",
    "\n",
    "        x = self.features[i:i+self.input_window]\n",
    "        x = x.reshape(self.input_window, self.n_nodes, -1)\n",
    "\n",
    "        y = self.target[i+self.input_window:i+self.input_window+self.horizon]\n",
    "        y = y.reshape(self.horizon, self.n_nodes)\n",
    "        y = y.permute(1, 0)\n",
    "\n",
    "        sample = {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'edge_index': self.edge_index,\n",
    "            'edge_weight': self.edge_weight\n",
    "        }\n",
    "\n",
    "        if self.elevation is not None:\n",
    "            sample['elevation'] = self.elevation\n",
    "        if self.lat_idx is not None:\n",
    "            sample['lat_idx'] = self.lat_idx\n",
    "        if self.lon_idx is not None:\n",
    "            sample['lon_idx'] = self.lon_idx\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "def prepare_data(ds: xr.Dataset, config: V9Config, lat_dim: str, lon_dim: str, output_dir: Path):\n",
    "    \"\"\"Prepare train/val datasets.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Preparing data for V9 GNN-BiMamba\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    ds = create_elevation_clusters(ds)\n",
    "\n",
    "    features, missing_features = extract_features(ds, FEATURE_SETS['KCE'], config)\n",
    "\n",
    "    target = ds['total_precipitation'].values.astype(np.float32)\n",
    "    target = np.nan_to_num(target, nan=0.0)\n",
    "    print(f\"Target shape: {target.shape}\")\n",
    "\n",
    "    edge_index, edge_weight = build_spatial_graph(ds, lat_dim, lon_dim)\n",
    "\n",
    "    if getattr(config, 'plot_graph_diagnostics', True):\n",
    "        plot_graph_diagnostics(edge_index, edge_weight, output_dir, config)\n",
    "\n",
    "    features = torch.from_numpy(features)\n",
    "    target = torch.from_numpy(target)\n",
    "\n",
    "    elevation_vec = extract_elevation_vector(ds)\n",
    "    elevation = torch.from_numpy(elevation_vec) if elevation_vec is not None else None\n",
    "\n",
    "    lat_idx, lon_idx = create_geo_indices(config.n_lat, config.n_lon)\n",
    "\n",
    "    n_time = features.shape[0]\n",
    "    max_start = n_time - config.input_window - config.horizon\n",
    "\n",
    "    split_idx = int(max_start * config.train_val_split)\n",
    "\n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"  Total samples: {max_start + 1}\")\n",
    "    print(f\"  Train: 0 to {split_idx}\")\n",
    "    print(f\"  Val: {split_idx} to {max_start + 1}\")\n",
    "\n",
    "    train_dataset = V9Dataset(\n",
    "        features, target,\n",
    "        config.input_window, config.horizon,\n",
    "        edge_index, edge_weight,\n",
    "        start_idx=0, end_idx=split_idx,\n",
    "        elevation=elevation,\n",
    "        lat_idx=lat_idx,\n",
    "        lon_idx=lon_idx\n",
    "    )\n",
    "\n",
    "    val_dataset = V9Dataset(\n",
    "        features, target,\n",
    "        config.input_window, config.horizon,\n",
    "        edge_index, edge_weight,\n",
    "        start_idx=split_idx, end_idx=max_start + 1,\n",
    "        elevation=elevation,\n",
    "        lat_idx=lat_idx,\n",
    "        lon_idx=lon_idx\n",
    "    )\n",
    "\n",
    "    overlap_leakage = bool(split_idx < config.input_window)\n",
    "    data_report = {\n",
    "        'n_time': int(n_time),\n",
    "        'n_lat': int(config.n_lat),\n",
    "        'n_lon': int(config.n_lon),\n",
    "        'n_nodes': int(config.n_nodes),\n",
    "        'input_window': int(config.input_window),\n",
    "        'horizon': int(config.horizon),\n",
    "        'train_val_split': float(config.train_val_split),\n",
    "        'train_start_idx': 0,\n",
    "        'train_end_idx': int(split_idx - 1),\n",
    "        'val_start_idx': int(split_idx),\n",
    "        'val_end_idx': int(max_start),\n",
    "        'missing_features': missing_features,\n",
    "        'feature_set': FEATURE_SETS['KCE'],\n",
    "        'has_elevation': bool(elevation is not None),\n",
    "        'overlap_leakage': overlap_leakage,\n",
    "        'target_stats': {\n",
    "            'min': float(target.min().item()),\n",
    "            'max': float(target.max().item()),\n",
    "            'mean': float(target.mean().item()),\n",
    "            'std': float(target.std().item())\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return train_dataset, val_dataset, edge_index, edge_weight, lat_idx, lon_idx, elevation, data_report\n",
    "\n",
    "\n",
    "print(\"Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 6.3: LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "# Load dataset\n",
    "ds, lat_dim, lon_dim = load_dataset(DATA_PATH, CONFIG)\n",
    "\n",
    "# Prepare data\n",
    "train_dataset, val_dataset, edge_index, edge_weight, lat_idx, lon_idx, elevation, data_report = prepare_data(\n",
    "    ds, CONFIG, lat_dim, lon_dim, OUTPUT_ROOT\n",
    ")\n",
    "\n",
    "print(\"\\nData report summary:\")\n",
    "print(f\"  Missing features: {data_report.get('missing_features', [])}\")\n",
    "print(f\"  Overlap leakage: {data_report.get('overlap_leakage', False)}\")\n",
    "print(f\"  Target mean: {data_report['target_stats']['mean']:.3f}\")\n",
    "\n",
    "# Move graph and geo indices to device\n",
    "edge_index = edge_index.to(device)\n",
    "edge_weight = edge_weight.to(device)\n",
    "lat_idx = lat_idx.to(device)\n",
    "lon_idx = lon_idx.to(device)\n",
    "if elevation is not None:\n",
    "    elevation = elevation.to(device)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nData loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Test batch\n",
    "test_batch = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  x: {test_batch['x'].shape}\")\n",
    "print(f\"  y: {test_batch['y'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 7: LOSS FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def physics_informed_loss(\n",
    "    pred: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    elevation: Optional[torch.Tensor] = None,\n",
    "    config: V9Config = None\n",
    ") -> Tuple[torch.Tensor, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Physics-informed loss with mass conservation and orographic constraints.\n",
    "    \"\"\"\n",
    "    mse_loss = F.mse_loss(pred, target)\n",
    "\n",
    "    components = {'mse': mse_loss.item()}\n",
    "    total_loss = mse_loss\n",
    "\n",
    "    if config and config.use_physics_loss:\n",
    "        pred_sum = pred.sum(dim=1)\n",
    "        target_sum = target.sum(dim=1)\n",
    "        mass_loss = torch.abs(pred_sum - target_sum) / (target_sum.abs() + 1e-6)\n",
    "        mass_loss = mass_loss.mean()\n",
    "\n",
    "        total_loss = total_loss + config.lambda_mass_conservation * mass_loss\n",
    "        components['mass'] = mass_loss.item()\n",
    "\n",
    "        if elevation is not None:\n",
    "            elev = elevation\n",
    "            if elev.dim() == 2:\n",
    "                elev = elev[0]\n",
    "            high_elev_mask = elev > config.high_elev_threshold\n",
    "            if high_elev_mask.sum() > 0:\n",
    "                pred_high = pred[:, high_elev_mask, :].mean()\n",
    "                target_high = target[:, high_elev_mask, :].mean()\n",
    "                oro_loss = F.relu(target_high - pred_high)\n",
    "\n",
    "                total_loss = total_loss + config.lambda_orographic * oro_loss\n",
    "                components['orographic'] = oro_loss.item()\n",
    "\n",
    "    return total_loss, components\n",
    "\n",
    "\n",
    "print(\"Loss functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 7.1: TRAINING LOOP\n",
    "# ============================================================\n",
    "\n",
    "def train_v9(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    config: V9Config,\n",
    "    output_dir: Path,\n",
    "    lat_idx: torch.Tensor,\n",
    "    lon_idx: torch.Tensor,\n",
    "    elevation: torch.Tensor\n",
    ") -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Training loop for V9 GNN-BiMamba.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "\n",
    "    if config.scheduler_type == 'cosine':\n",
    "        scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=config.cosine_T0,\n",
    "            T_mult=config.cosine_T_mult\n",
    "        )\n",
    "    else:\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5\n",
    "        )\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_mse': [],\n",
    "        'val_mse': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Starting V9 GNN-BiMamba Training\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        # === Training ===\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        train_mse_sum = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            x = batch['x'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            edge_idx = batch['edge_index'][0].to(device)\n",
    "            edge_wt = batch['edge_weight'][0].to(device)\n",
    "            batch_elevation = batch['elevation'].to(device) if 'elevation' in batch else elevation\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred, info = model(\n",
    "                x, edge_idx, edge_wt,\n",
    "                lat_idx=lat_idx,\n",
    "                lon_idx=lon_idx,\n",
    "                elevation=elevation\n",
    "            )\n",
    "\n",
    "            loss, components = physics_informed_loss(\n",
    "                pred, y, elevation=batch_elevation, config=config\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if config.gradient_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    model.parameters(),\n",
    "                    config.gradient_clip\n",
    "                )\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_sum += loss.item()\n",
    "            train_mse_sum += components['mse']\n",
    "            n_batches += 1\n",
    "\n",
    "        avg_train_loss = train_loss_sum / n_batches\n",
    "        avg_train_mse = train_mse_sum / n_batches\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        val_mse_sum = 0.0\n",
    "        val_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x = batch['x'].to(device)\n",
    "                y = batch['y'].to(device)\n",
    "                edge_idx = batch['edge_index'][0].to(device)\n",
    "                edge_wt = batch['edge_weight'][0].to(device)\n",
    "                batch_elevation = batch['elevation'].to(device) if 'elevation' in batch else elevation\n",
    "\n",
    "                pred, info = model(\n",
    "                    x, edge_idx, edge_wt,\n",
    "                    lat_idx=lat_idx,\n",
    "                    lon_idx=lon_idx,\n",
    "                    elevation=elevation\n",
    "                )\n",
    "                loss, components = physics_informed_loss(\n",
    "                    pred, y, elevation=batch_elevation, config=config\n",
    "                )\n",
    "\n",
    "                val_loss_sum += loss.item()\n",
    "                val_mse_sum += components['mse']\n",
    "                val_batches += 1\n",
    "\n",
    "        avg_val_loss = val_loss_sum / val_batches\n",
    "        avg_val_mse = val_mse_sum / val_batches\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        if config.scheduler_type == 'cosine':\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['train_mse'].append(avg_train_mse)\n",
    "        history['val_mse'].append(avg_val_mse)\n",
    "        history['lr'].append(current_lr)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch+1:3d}/{config.epochs}: \"\n",
    "                f\"Train={avg_train_loss:.4f} Val={avg_val_loss:.4f} \"\n",
    "                f\"MSE={avg_val_mse:.4f} LR={current_lr:.2e}\"\n",
    "            )\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "\n",
    "            if config.save_checkpoints:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'config': asdict(config)\n",
    "                }\n",
    "                torch.save(checkpoint, output_dir / 'v9_best.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config.patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\nTraining complete. Best val loss: {best_val_loss:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "print(\"Training loop defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 7.2: RUN TRAINING\n",
    "# ============================================================\n",
    "\n",
    "# Initialize model\n",
    "model = GNN_BiMamba_V9(CONFIG)\n",
    "print(f\"\\nModel initialized:\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Trainable: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Train\n",
    "history = train_v9(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=CONFIG,\n",
    "    output_dir=OUTPUT_ROOT,\n",
    "    lat_idx=lat_idx,\n",
    "    lon_idx=lon_idx,\n",
    "    elevation=elevation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 8: EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    config: V9Config,\n",
    "    lat_idx: torch.Tensor,\n",
    "    lon_idx: torch.Tensor,\n",
    "    elevation: torch.Tensor\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate model and compute metrics per horizon.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            x = batch['x'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            edge_idx = batch['edge_index'][0].to(device)\n",
    "            edge_wt = batch['edge_weight'][0].to(device)\n",
    "\n",
    "            pred, _ = model(\n",
    "                x, edge_idx, edge_wt,\n",
    "                lat_idx=lat_idx,\n",
    "                lon_idx=lon_idx,\n",
    "                elevation=elevation\n",
    "            )\n",
    "\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(all_preds, axis=0)\n",
    "    targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    results = []\n",
    "    for h in range(config.horizon):\n",
    "        pred_h = preds[:, :, h].flatten()\n",
    "        target_h = targets[:, :, h].flatten()\n",
    "\n",
    "        rmse = np.sqrt(np.mean((pred_h - target_h) ** 2))\n",
    "        mae = np.mean(np.abs(pred_h - target_h))\n",
    "\n",
    "        ss_res = np.sum((target_h - pred_h) ** 2)\n",
    "        ss_tot = np.sum((target_h - target_h.mean()) ** 2)\n",
    "        r2 = 1 - (ss_res / (ss_tot + 1e-8))\n",
    "\n",
    "        bias = np.mean(pred_h - target_h)\n",
    "\n",
    "        results.append({\n",
    "            'H': h + 1,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R^2': r2,\n",
    "            'Bias': bias\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'metrics': results,\n",
    "        'predictions': preds,\n",
    "        'targets': targets\n",
    "    }\n",
    "\n",
    "\n",
    "# Load best model\n",
    "if 'model' not in globals():\n",
    "    model = GNN_BiMamba_V9(CONFIG)\n",
    "    print('Model not initialized; created new model for evaluation.')\n",
    "model = model.to(device)\n",
    "best_checkpoint = OUTPUT_ROOT / 'v9_best.pt'\n",
    "if best_checkpoint.exists():\n",
    "    checkpoint = torch.load(best_checkpoint, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"V9 GNN-BiMamba Evaluation Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "eval_results = evaluate_model(model, val_loader, CONFIG, lat_idx, lon_idx, elevation)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nMetrics by Horizon:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'H':>3} {'RMSE':>10} {'MAE':>10} {'R^2':>10} {'Bias':>10}\")\n",
    "print(\"-\" * 50)\n",
    "for m in eval_results['metrics']:\n",
    "    print(f\"{m['H']:>3} {m['RMSE']:>10.2f} {m['MAE']:>10.2f} {m['R^2']:>10.4f} {m['Bias']:>10.2f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Summary metrics\n",
    "avg_rmse = float(np.mean([m['RMSE'] for m in eval_results['metrics']]))\n",
    "avg_mae = float(np.mean([m['MAE'] for m in eval_results['metrics']]))\n",
    "avg_r2 = float(np.mean([m['R^2'] for m in eval_results['metrics']]))\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Avg RMSE: {avg_rmse:.2f} mm (target: {CONFIG.target_rmse})\")\n",
    "print(f\"  Avg R2: {avg_r2:.4f} (target: {CONFIG.target_r2})\")\n",
    "print(f\"  Avg MAE: {avg_mae:.2f} mm\")\n",
    "\n",
    "# Compare with baselines\n",
    "print(f\"\\nComparison with baselines:\")\n",
    "print(f\"  V4 R2: 0.596 -> V9 R2: {avg_r2:.4f} ({(avg_r2 - 0.596) / 0.596 * 100:+.1f}%)\")\n",
    "print(f\"  V4 RMSE: 84.37 -> V9 RMSE: {avg_rmse:.2f} ({(84.37 - avg_rmse) / 84.37 * 100:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 8.1: VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Training curves\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(history['train_loss'], label='Train Loss', alpha=0.8)\n",
    "ax1.plot(history['val_loss'], label='Val Loss', alpha=0.8)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Curves')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. RMSE by horizon\n",
    "ax2 = axes[0, 1]\n",
    "horizons = [m['H'] for m in eval_results['metrics']]\n",
    "rmses = [m['RMSE'] for m in eval_results['metrics']]\n",
    "ax2.bar(horizons, rmses, color='steelblue', edgecolor='black')\n",
    "ax2.axhline(y=84.37, color='red', linestyle='--', label='V4 Baseline')\n",
    "ax2.axhline(y=CONFIG.target_rmse, color='green', linestyle=':', label='V9 Target')\n",
    "ax2.set_xlabel('Forecast Horizon (months)')\n",
    "ax2.set_ylabel('RMSE (mm)')\n",
    "ax2.set_title('RMSE by Forecast Horizon')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. R2 by horizon\n",
    "ax3 = axes[1, 0]\n",
    "r2s = [m['R^2'] for m in eval_results['metrics']]\n",
    "ax3.bar(horizons, r2s, color='forestgreen', edgecolor='black')\n",
    "ax3.axhline(y=0.596, color='red', linestyle='--', label='V4 Baseline')\n",
    "ax3.axhline(y=CONFIG.target_r2, color='green', linestyle=':', label='V9 Target')\n",
    "ax3.set_xlabel('Forecast Horizon (months)')\n",
    "ax3.set_ylabel('R2')\n",
    "ax3.set_title('R2 by Forecast Horizon')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Learning rate schedule\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(history['lr'], color='orange')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Learning Rate')\n",
    "ax4.set_title('Learning Rate Schedule')\n",
    "ax4.set_yscale('log')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('V9 Bidirectional GNN-Mamba Training Results', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = FIG_OUT_DIR / 'v9_training_results.png'\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"Figure saved to: {fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 8.2: SAVE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(eval_results['metrics'])\n",
    "metrics_df.to_csv(COMP_DIR / 'v9_metrics.csv', index=False)\n",
    "print(f\"Metrics saved to: {COMP_DIR / 'v9_metrics.csv'}\")\n",
    "\n",
    "# Save training history\n",
    "if getattr(CONFIG, 'export_history', True):\n",
    "    history_df = pd.DataFrame({\n",
    "        'epoch': np.arange(1, len(history['train_loss']) + 1),\n",
    "        'train_loss': history['train_loss'],\n",
    "        'val_loss': history['val_loss'],\n",
    "        'train_mse': history['train_mse'],\n",
    "        'val_mse': history['val_mse'],\n",
    "        'lr': history['lr']\n",
    "    })\n",
    "    history_df.to_csv(TRAIN_LOG_DIR / 'v9_training_log.csv', index=False)\n",
    "    print(f\"Training history saved to: {TRAIN_LOG_DIR / 'v9_training_log.csv'}\")\n",
    "\n",
    "# Save predictions and targets\n",
    "if getattr(CONFIG, 'export_predictions', True):\n",
    "    np.save(DATA_OUT_DIR / 'predictions.npy', eval_results['predictions'])\n",
    "    np.save(DATA_OUT_DIR / 'targets.npy', eval_results['targets'])\n",
    "\n",
    "    meta = {\n",
    "        'n_samples': int(eval_results['predictions'].shape[0]),\n",
    "        'n_nodes': int(eval_results['predictions'].shape[1]),\n",
    "        'horizon': int(CONFIG.horizon),\n",
    "        'n_lat': int(CONFIG.n_lat),\n",
    "        'n_lon': int(CONFIG.n_lon)\n",
    "    }\n",
    "    with open(DATA_OUT_DIR / 'metadata.json', 'w') as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "    print(f\"Predictions saved to: {DATA_OUT_DIR}\")\n",
    "\n",
    "# Save data report\n",
    "if 'data_report' in globals():\n",
    "    with open(OUTPUT_ROOT / 'v9_data_report.json', 'w') as f:\n",
    "        json.dump(data_report, f, indent=2)\n",
    "    print(f\"Data report saved to: {OUTPUT_ROOT / 'v9_data_report.json'}\")\n",
    "\n",
    "# Save config\n",
    "with open(OUTPUT_ROOT / 'v9_config.json', 'w') as f:\n",
    "    json.dump(asdict(CONFIG), f, indent=2)\n",
    "print(f\"Config saved to: {OUTPUT_ROOT / 'v9_config.json'}\")\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 8.3: COLAB DISCONNECT\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import runtime\n",
    "        runtime.unassign()\n",
    "        print('Colab runtime disconnected.')\n",
    "    except Exception as exc:\n",
    "        print(f\"Colab runtime disconnect failed: {exc}\")\n",
    "else:\n",
    "    print('Not running in Colab; skip disconnect.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusions\n",
    "\n",
    "### V9 Bidirectional GNN-Mamba Summary\n",
    "\n",
    "**Key Innovations:**\n",
    "1. **BidirectionalMamba** (RiverMamba NeurIPS 2025): Improved bidirectional temporal processing\n",
    "2. **FrequencyTuning** (S4D-FT WRR 2025): Learnable frequency domain filtering for seasonal patterns\n",
    "3. **GeographicEncoding** (WSSM arXiv 2025): Spatial position embeddings for geographic awareness\n",
    "\n",
    "**Architecture:**\n",
    "- Input: 60 months of precipitation data\n",
    "- Output: 12-month ahead predictions\n",
    "- Spatial: GNN with GAT layers + Geographic Encoding\n",
    "- Temporal: BidirectionalMamba + FrequencyTuning\n",
    "- Fusion: Cross-modal attention\n",
    "\n",
    "**Expected Performance:**\n",
    "- Target R2: > 0.62 (vs V4 baseline 0.596)\n",
    "- Target RMSE: < 78 mm (vs V4 baseline 84.37 mm)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
