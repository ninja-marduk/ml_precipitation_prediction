{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, ConvLSTM2D, GRU, Flatten, RepeatVector, Reshape, TimeDistributed,\n",
    "    Dense, MultiHeadAttention, Add, LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "## ╭─────────────────────────── Rutas ──────────────────────────╮\n",
    "# ▶️ Path configuration\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
    "    # Instalar dependencias necesarias\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open cartopy geopandas\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    for p in [BASE_PATH, *BASE_PATH.parents]:\n",
    "        if (p / '.git').exists():\n",
    "            BASE_PATH = p; break\n",
    "\n",
    "print('BASE_PATH =', BASE_PATH)\n",
    "\n",
    "# Dataset paths\n",
    "DATA_DIR = BASE_PATH/'data'/'output'\n",
    "MODEL_OUTPUT_DIR = BASE_PATH/'models'/'output'\n",
    "MODEL_DIR = BASE_PATH/'models'/'output'/'HybridLSTMModels'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_INPUT_DIR = BASE_PATH/'data'/'input'/'shapes'\n",
    "MODEL_INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "IMAGE_DIR = MODEL_DIR/'images'\n",
    "IMAGE_DIR.mkdir(exist_ok=True)\n",
    "FULL_NC = DATA_DIR/'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation.nc'\n",
    "dept_gdf = gpd.read_file(MODEL_INPUT_DIR/'MGN_Departamento.shp')\n",
    "\n",
    "BASE_MODEL_DIR = MODEL_DIR\n",
    "GIF_DIR        = MODEL_DIR / \"gifs\"\n",
    "GIF_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────────── Dataset & Shapes ──────────────────╮\n",
    "ds          = xr.open_dataset(FULL_NC)\n",
    "lat, lon    = len(ds.latitude), len(ds.longitude)\n",
    "cells       = lat * lon\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────── Hyper‑parámetros globales ─────────────╮\n",
    "INPUT_WINDOW   = 60\n",
    "HORIZON        = 3\n",
    "TARGET_VAR     = 'total_precipitation'\n",
    "EPOCHS         = 100\n",
    "BATCH_SIZE     = 4           # tamaño pequeño → menor RAM GPU\n",
    "PATIENCE       = 10\n",
    "LR             = 1e-3\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "\n",
    "# ╭────────────────────── Modelo ConvLSTM ─────────────────────╮\n",
    "\n",
    "def build_model(\n",
    "        input_window: int,\n",
    "        output_horizon: int,\n",
    "        spatial_height: int,\n",
    "        spatial_width: int,\n",
    "        n_features: int,\n",
    "        n_filters: int = 64,\n",
    "        n_heads: int = 4,\n",
    "        lr: float = LR\n",
    ") -> Model:\n",
    "    \"\"\"ConvLSTM Encoder‑Decoder con Self‑Attention.\n",
    "\n",
    "    Produce salida `(batch, output_horizon, H, W, 1)`.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(input_window, spatial_height, spatial_width, n_features),name=\"enc_input\")\n",
    "\n",
    "    # ── Encoder ───────────────────────────────────────────────\n",
    "    x = ConvLSTM2D(n_filters, (3, 3), padding='same', return_sequences=True,name=\"enc_lstm_1\")(inputs)\n",
    "    x = ConvLSTM2D(n_filters // 2, (3, 3), padding='same', return_sequences=False,name=\"enc_lstm_2\")(x)  # (B, H, W, C)\n",
    "\n",
    "    # ── Flatten + contexto temporal ──────────────────────────\n",
    "    flat = Flatten(name=\"flatten_spatial\")(x)                # (B, H·W·C)\n",
    "    ctx  = RepeatVector(output_horizon, name=\"context\")(flat)  # (B, T_out, H·W·C)\n",
    "\n",
    "    # ── Decoder GRU (temporal) ───────────────────────────────\n",
    "    dec = GRU(2 * n_filters, return_sequences=True, name=\"dec_gru\")(ctx)\n",
    "\n",
    "    # ── Self‑Attention (temporal) ────────────────────────────\n",
    "    attn = MultiHeadAttention(num_heads=n_heads, key_dim=n_filters, dropout=0.1, name=\"mha\")(dec, dec)\n",
    "    attn = Add(name=\"mha_add\")([dec, attn])\n",
    "    attn = LayerNormalization(name=\"mha_norm\")(attn)\n",
    "\n",
    "    # ── Proyección + reshape a grid ──────────────────────────\n",
    "    proj = TimeDistributed(Dense(spatial_height * spatial_width, activation='linear'),name=\"dense_proj\")(attn)\n",
    "    out = Reshape((output_horizon, spatial_height, spatial_width, 1),name=\"reshape_out\")(proj)\n",
    "\n",
    "    model = Model(inputs, out, name=\"ConvLSTM_ED_Attn\")\n",
    "    model.compile(optimizer=Adam(lr), loss='mse')\n",
    "    return model\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────────────── Métricas ────────────────────────╮\n",
    "\n",
    "def evaluate(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, mape, r2\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────────── Quick‑plot ────────────────────────╮\n",
    "\n",
    "def quick_plot(ax, data, cmap, title, date_label, vmin=None, vmax=None):\n",
    "    mesh = ax.pcolormesh(ds.longitude, ds.latitude, data, cmap=cmap, shading='nearest', vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    ax.add_geometries(dept_gdf.geometry,  ccrs.PlateCarree(), edgecolor='black', facecolor='none', linewidth=1)\n",
    "    ax.add_geometries(mpio_gdf.geometry,  ccrs.PlateCarree(), edgecolor='gray',  facecolor='none', linewidth=0.1)\n",
    "    gl = ax.gridlines(draw_labels=True); gl.top_labels = False; gl.right_labels = False\n",
    "    ax.set_title(f\"{title}\\n{date_label}\", pad=12)\n",
    "    return mesh\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────────── Experiments & Folds ─────────────────╮\n",
    "ENABLED_MODELS      = ['GRU']          # ⬅️ puedes cambiarlo a ['LSTM',…]\n",
    "RESULTS: list[dict[str, Any]] = []\n",
    "\n",
    "# ▶️ Fold configuration with activation/deactivation control\n",
    "FOLDS = {\n",
    "    'F1': {'year': 2018, 'active': True},\n",
    "    'F2': {'year': 2017, 'active': False},\n",
    "    'F3': {'year': 2016, 'active': False},\n",
    "    'F4': {'year': 2015, 'active': False},\n",
    "    'F5': {'year': 2014, 'active': False},\n",
    "    'F6': {'year': 2010, 'active': False},\n",
    "    'F7': {'year': 2000, 'active': False},\n",
    "}\n",
    "\n",
    "# Stats BASE FEATURES (12) - ConvGRU-ED foundation (WITHOUT cluster_elevation)\n",
    "BASE_FEATURES = [\n",
    "    # Temporal features\n",
    "    'year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos',\n",
    "    # Precipitation statistics  \n",
    "    'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std',\n",
    "    # Topographic features con rejilla espacial completa\n",
    "    'elevation', 'slope', 'aspect'\n",
    "]\n",
    "\n",
    "# Se usa directamente los nombres de las características one-hot encoding\n",
    "ELEVATION_CLUSTER_FEATURES = [\n",
    "    'elev_high',      # Elevación alta (one-hot)\n",
    "    'elev_med',       # Elevación media (one-hot)\n",
    "    'elev_low'        # Elevación baja (one-hot)\n",
    "]\n",
    "\n",
    "# Stats KCE FEATURES (15) - ConvGRU-ED-KCE (Base + K-means Cluster Elevation one-hot)\n",
    "KCE_FEATURES = BASE_FEATURES + ELEVATION_CLUSTER_FEATURES\n",
    "\n",
    "# Verificar que todas las características mantengan la estructura espacial completa\n",
    "REQUIRE_FULL_GRID_FOR_ALL_FEATURES = True  # Asegurar consistencia espacial en todo el grid\n",
    "\n",
    "# Stats PAFC FEATURES (18) - ConvGRU-ED-KCE-PAFC (KCE + Position-Aware Feature Calibration)\n",
    "PAFC_FEATURES = KCE_FEATURES + [\n",
    "    'total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag12'  # Correct naming\n",
    "]\n",
    "\n",
    "# Stats FUSION FEATURES (34) - AE-FUSION-ConvGRU-ED-KCE-PAFC (PAFC + 16 IMFs)\n",
    "FUSION_FEATURES = PAFC_FEATURES + [\n",
    "    # CEEMDAN IMFs (8) - correct uppercase naming\n",
    "    'CEEMDAN_imf_1', 'CEEMDAN_imf_2', 'CEEMDAN_imf_3', 'CEEMDAN_imf_4', \n",
    "    'CEEMDAN_imf_5', 'CEEMDAN_imf_6', 'CEEMDAN_imf_7', 'CEEMDAN_imf_8',\n",
    "    # TVFEMD IMFs (8) - correct uppercase naming \n",
    "    'TVFEMD_imf_1', 'TVFEMD_imf_2', 'TVFEMD_imf_3', 'TVFEMD_imf_4',\n",
    "    'TVFEMD_imf_5', 'TVFEMD_imf_6', 'TVFEMD_imf_7', 'TVFEMD_imf_8'\n",
    "]\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    # 🏗️ HIERARCHICAL CONVGRU ARCHITECTURE\n",
    "    # =====================================\n",
    "    \n",
    "    'ConvGRU-ED': {\n",
    "        'active': True,\n",
    "        'description': '🔹 BASE: ConvGRU Encoder-Decoder (NO cluster_elevation)',\n",
    "        'model': 'conv_gru_ed',\n",
    "        'features': 'Base features (12)',\n",
    "        'feature_list': BASE_FEATURES,\n",
    "        'architecture': 'ConvGRU2D + Encoder-Decoder',\n",
    "        'use_lags': False,\n",
    "        'use_cluster_elevation': False,\n",
    "        'level': 1\n",
    "    },\n",
    "    \n",
    "    'ConvGRU-ED-KCE': {\n",
    "        'active': True,\n",
    "        'description': '🔸 LEVEL 2: ConvGRU-ED + K-means Cluster Elevation',\n",
    "        'model': 'conv_gru_ed_kce',\n",
    "        'features': 'Base + KCE features (15)',\n",
    "        'feature_list': KCE_FEATURES,\n",
    "        'architecture': 'ConvGRU2D + Encoder-Decoder + K-means Cluster Elevation',\n",
    "        'use_lags': False,\n",
    "        'use_cluster_elevation': True,\n",
    "        'level': 2\n",
    "    },\n",
    "    \n",
    "    'ConvGRU-ED-KCE-PAFC': {\n",
    "        'active': True,\n",
    "        'description': '🔸 LEVEL 3: ConvGRU-ED-KCE + Parcial Autocorretion Function (PAFC)',\n",
    "        'model': 'conv_gru_ed_kce_pafc',\n",
    "        'features': 'KCE + PAFC features (18)',\n",
    "        'feature_list': PAFC_FEATURES,\n",
    "        'architecture': 'ConvGRU2D + Encoder-Decoder + KCE + Lag Features {1,2,12}',\n",
    "        'use_lags': True,\n",
    "        'use_cluster_elevation': True,\n",
    "        'level': 3\n",
    "    },\n",
    "    \n",
    "    'AE-FUSION-ConvGRU-ED-KCE-PAFC-MHA': {\n",
    "        'active': False,\n",
    "        'description': '🔶 LEVEL 4: AE-FUSION + ConvGRU-ED-KCE-PAFC + Multi-Head Attention',\n",
    "        'model': 'ae_fusion_conv_gru_ed_kce_pafc_mha',\n",
    "        'features': 'PAFC + 16 IMFs + MHA (34 total)',\n",
    "        'feature_list': FUSION_FEATURES,\n",
    "        'architecture': 'Conv3D-AE + ConvGRU2D-ED-KCE-PAFC + Multi-Head Attention (4×64d)',\n",
    "        'use_lags': True,\n",
    "        'use_cluster_elevation': True,\n",
    "        'level': 4\n",
    "    },\n",
    "    \n",
    "    'AE-FUSION-ConvGRU-ED-KCE-PAFC-MHA-TopoMask': {\n",
    "        'active': False,\n",
    "        'description': '🔷 LEVEL 5: Full Pipeline + Topographic Mask-Attention',\n",
    "        'model': 'ae_fusion_conv_gru_ed_kce_pafc_mha_topomask',\n",
    "        'features': 'All previous + Topographic Mask Attention (34 total)',\n",
    "        'feature_list': FUSION_FEATURES,\n",
    "        'architecture': 'Full Pipeline: Conv3D-AE + ConvGRU2D-ED-KCE-PAFC + MHA + TopoMask',\n",
    "        'use_lags': True,\n",
    "        'use_cluster_elevation': True,\n",
    "        'level': 5\n",
    "    }\n",
    "}\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────────── Bucle principal ────────────────────╮\n",
    "\n",
    "RESULTS: List[Dict[str, Any]] = []\n",
    "\n",
    "# ╭────────────────────── Experiments & Folds ─────────────────╮\n",
    "# (… definiciones de EXPERIMENTS y FOLDS sin cambios …)\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────── Ventanas deslizadas (FIX) ─────────────╮\n",
    "\n",
    "def make_windows(mask: np.ndarray, *, allow_past_context: bool) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Genera pares (X,y).\n",
    "\n",
    "    * **Entrenamiento** → `allow_past_context=False`: exige que toda la\n",
    "      ventana (input + target) esté dentro del `mask`.\n",
    "    * **Validación** → `allow_past_context=True`: solo los `HORIZON` pasos\n",
    "      objetivo (`y`) deben estar dentro del `mask`; la ventana de entrada\n",
    "      puede comenzar antes.\n",
    "    \"\"\"\n",
    "    seq_X, seq_y = [], []\n",
    "    limit = len(mask) - INPUT_WINDOW - HORIZON + 1\n",
    "    for start in range(limit):\n",
    "        end_w = start + INPUT_WINDOW\n",
    "        end_y = end_w + HORIZON\n",
    "        if allow_past_context:\n",
    "            # solo comprobamos los targets\n",
    "            if not mask[end_w:end_y].all():\n",
    "                continue\n",
    "        else:\n",
    "            # todo debe pertenecer al mask\n",
    "            if not mask[start:end_y].all():\n",
    "                continue\n",
    "        seq_X.append(Xarr[start:end_w])\n",
    "        seq_y.append(yarr[end_w:end_y])\n",
    "    return np.array(seq_X), np.array(seq_y)\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭────────────────── Bucle principal de entrenamiento ────────╮\n",
    "RESULTS: List[Dict[str, Any]] = []\n",
    "\n",
    "def run_all_experiments():\n",
    "    times = pd.to_datetime(ds.time.values)\n",
    "    total = sum(e['active'] for e in EXPERIMENTS.values()) * sum(f['active'] for f in FOLDS.values())\n",
    "    cnt   = 0\n",
    "\n",
    "    for exp_name, exp_cfg in EXPERIMENTS.items():\n",
    "        if not exp_cfg['active']:\n",
    "            continue\n",
    "        vars_ = exp_cfg['feature_list']\n",
    "\n",
    "        # ─ Pre‑load features (independiente del fold) ───────────────\n",
    "        global Xarr, yarr  # usado dentro de make_windows\n",
    "        Xarr = ds[vars_].to_array().transpose('time','latitude','longitude','variable').values.astype(np.float32)\n",
    "        yarr = ds[TARGET_VAR].values.astype(np.float32)\n",
    "        feats = Xarr.shape[-1]\n",
    "\n",
    "        if 'cluster_elevation' in vars_:\n",
    "            idx = vars_.index('cluster_elevation')\n",
    "            Xarr[..., idx] = LabelEncoder().fit_transform(Xarr[..., idx].ravel()).reshape(Xarr[..., idx].shape)\n",
    "\n",
    "        for fold_name, fold_cfg in FOLDS.items():\n",
    "            if not fold_cfg['active']:\n",
    "                continue\n",
    "            cnt += 1\n",
    "            year_val = fold_cfg['year']\n",
    "            print(f\"\\n▶️  [{cnt}/{total}] {exp_name} – {fold_name} (val={year_val})\")\n",
    "\n",
    "            mask_val = times.year == year_val\n",
    "            mask_tr  = ~mask_val\n",
    "            if mask_val.sum() < HORIZON:\n",
    "                print(\"⚠️ Año sin pasos suficientes para los targets → skip\"); continue\n",
    "\n",
    "            X_tr, y_tr = make_windows(mask_tr,  allow_past_context=False)\n",
    "            X_va, y_va = make_windows(mask_val, allow_past_context=True)\n",
    "            print(f\"Ventanas train: {len(X_tr)} · val: {len(X_va)}\")\n",
    "            if len(X_tr)==0 or len(X_va)==0:\n",
    "                print(\"⚠️ Sin ventanas válidas → skip\"); continue\n",
    "\n",
    "            # ─ Scaling (fit solo en train) ─────────────────────────\n",
    "            sx = StandardScaler().fit(X_tr.reshape(-1, feats))\n",
    "            sy = StandardScaler().fit(y_tr.reshape(-1, 1))\n",
    "            X_tr_sc = sx.transform(X_tr.reshape(-1, feats)).reshape(X_tr.shape)\n",
    "            X_va_sc = sx.transform(X_va.reshape(-1, feats)).reshape(X_va.shape)\n",
    "            y_tr_sc = sy.transform(y_tr.reshape(-1, 1)).reshape(y_tr.shape)[..., None]\n",
    "            y_va_sc = sy.transform(y_va.reshape(-1, 1)).reshape(y_va.shape)[..., None]\n",
    "\n",
    "            # ─ Build & train model ─────────────────────────────────\n",
    "            tag        = f\"{exp_name.replace('+','_')}_{fold_name}\"\n",
    "            model_path = BASE_MODEL_DIR / f\"{tag}.keras\"\n",
    "            if model_path.exists():\n",
    "                print(f\"⏩ {tag} ya existe → skip\"); continue\n",
    "\n",
    "            model = build_model(INPUT_WINDOW, HORIZON, lat, lon, feats)\n",
    "            es     = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "            hist   = model.fit(X_tr_sc, y_tr_sc, validation_data=(X_va_sc, y_va_sc), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
    "\n",
    "            # ─ Evaluación ─────────────────────────────────────────\n",
    "            y_hat_sc = model.predict(X_va_sc, verbose=0)\n",
    "            y_hat    = sy.inverse_transform(y_hat_sc.reshape(-1,1)).reshape(y_hat_sc.shape)\n",
    "            y_true   = sy.inverse_transform(y_va_sc.reshape(-1,1)).reshape(y_va_sc.shape)\n",
    "\n",
    "            rmse, mae, mape, r2 = evaluate(y_true.ravel(), y_hat.ravel())\n",
    "            RESULTS.append(dict(experiment=exp_name, fold=fold_name, RMSE=rmse, MAE=mae, MAPE=mape, R2=r2, epochs=len(hist.history['loss'])))\n",
    "\n",
    "            # ─ Guardado artefactos ────────────────────────────────\n",
    "            model.save(model_path)\n",
    "            plt.figure(); plt.plot(hist.history['loss'], label='train'); plt.plot(hist.history['val_loss'], label='val'); plt.legend(); plt.title(tag); plt.savefig(BASE_MODEL_DIR/f\"{tag}.png\"); plt.close()\n",
    "\n",
    "            generate_gif(y_true[0], y_hat[0], tag)\n",
    "            print(f\"✅ Guardado {model_path.name}\")\n",
    "\n",
    "    # ─ Métricas globales ──────────────────────────────────────\n",
    "    df = pd.DataFrame(RESULTS)\n",
    "    out_csv = BASE_MODEL_DIR / \"metrics_experiments_folds.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\n📑 Tabla de métricas en {out_csv}\")\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# ╭──────────────────── Generador de GIF ─────────────────────╮\n",
    "\n",
    "def generate_gif(y_true_sample, y_pred_sample, tag):\n",
    "    pcm_min, pcm_max = 0, np.max(y_pred_sample)\n",
    "    frames = []\n",
    "    for h in range(HORIZON):\n",
    "        pmap = y_pred_sample[h, ..., 0]\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,5), subplot_kw={'projection':ccrs.PlateCarree()})\n",
    "        mesh = ax.pcolormesh(ds.longitude, ds.latitude, pmap, cmap='Blues', shading='nearest', vmin=pcm_min, vmax=pcm_max, transform=ccrs.PlateCarree())\n",
    "        ax.coastlines(); ax.gridlines(draw_labels=True)\n",
    "        ax.set_title(f\"{tag} – H{h+1}\")\n",
    "        fig.colorbar(mesh, ax=ax, fraction=0.046, pad=0.04)\n",
    "        tmp = GIF_DIR/f\"tmp_{tag}_h{h}.png\"\n",
    "        fig.savefig(tmp, bbox_inches='tight'); plt.close(fig)\n",
    "        frames.append(imageio.imread(tmp)); tmp.unlink(missing_ok=True)\n",
    "    gif_path = GIF_DIR/f\"{tag}.gif\"\n",
    "    imageio.mimsave(gif_path, frames, fps=0.5)\n",
    "    print(f\"💾 GIF {gif_path.name} listo\")\n",
    "# ╰────────────────────────────────────────────────────────────╯\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "run_all_experiments()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
