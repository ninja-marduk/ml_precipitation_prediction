{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸŒ§ï¸ Modelo HÃ­brido ConvLSTM-GRU para PredicciÃ³n de PrecipitaciÃ³n\n",
        "\n",
        "## Notebook Refactorizado - Sin DuplicaciÃ³n de CÃ³digo\n",
        "\n",
        "Este notebook implementa modelos hÃ­bridos ConvLSTM-GRU con:\n",
        "- âœ… CÃ³digo unificado sin duplicaciÃ³n\n",
        "- âœ… VisualizaciÃ³n mejorada (archivos + salida del notebook)\n",
        "- âœ… Funciones reutilizables\n",
        "- âœ… ConfiguraciÃ³n centralizada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ IMPORTS Y CONFIGURACIÃ“N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "from __future__ import annotations\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import imageio.v2 as imageio\n",
        "from IPython.display import display, Image as IPImage, HTML\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, ConvLSTM2D, GRU, Flatten, RepeatVector, Reshape,\n",
        "    TimeDistributed, Dense, MultiHeadAttention, Add,\n",
        "    LayerNormalization, Embedding, Concatenate, Lambda\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# ConfiguraciÃ³n de matplotlib para mejor visualizaciÃ³n\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['savefig.dpi'] = 150\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
        "    %pip install -q xarray netCDF4 matplotlib seaborn scikit-learn cartopy geopandas imageio\n",
        "else:\n",
        "    BASE_PATH = Path.cwd()\n",
        "    for p in [BASE_PATH, *BASE_PATH.parents]:\n",
        "        if (p / '.git').exists():\n",
        "            BASE_PATH = p\n",
        "            break\n",
        "\n",
        "import cartopy.crs as ccrs\n",
        "print(f'ğŸ“ BASE_PATH = {BASE_PATH}')\n",
        "\n",
        "# Estructura de directorios\n",
        "DATA_DIR = BASE_PATH / 'data' / 'output'\n",
        "MODEL_DIR = BASE_PATH / 'models' / 'output' / 'HybridLSTMModels'\n",
        "MODEL_INPUT_DIR = BASE_PATH / 'data' / 'input' / 'shapes'\n",
        "IMAGE_DIR = MODEL_DIR / 'images'\n",
        "GIF_DIR = MODEL_DIR / 'gifs'\n",
        "\n",
        "# Crear directorios si no existen\n",
        "for dir_path in [MODEL_DIR, IMAGE_DIR, GIF_DIR]:\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Archivos de datos\n",
        "FULL_NC_CLEAN = DATA_DIR / 'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation_clean.nc'\n",
        "\n",
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HIPERPARÃMETROS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "class Config:\n",
        "    \"\"\"ConfiguraciÃ³n centralizada del modelo\"\"\"\n",
        "    INPUT_WINDOW = 60\n",
        "    HORIZON = 3\n",
        "    TARGET_VAR = 'total_precipitation'\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 16\n",
        "    PATIENCE = 40\n",
        "    LR = 1e-3\n",
        "    \n",
        "    # Features\n",
        "    BASE_FEATURES = [\n",
        "        'year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos',\n",
        "        'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std',\n",
        "        'elevation', 'slope', 'aspect'\n",
        "    ]\n",
        "    ELEV_CLUSTER = ['elev_high', 'elev_med', 'elev_low']\n",
        "    KCE_FEATURES = BASE_FEATURES + ELEV_CLUSTER\n",
        "    PAFC_FEATURES = KCE_FEATURES + ['total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag12']\n",
        "    LAG_VARS = ['total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag12']\n",
        "\n",
        "print(\"âœ… ConfiguraciÃ³n cargada\")\n",
        "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CARGA DE DATOS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "print(\"ğŸ“Š Cargando dataset...\")\n",
        "\n",
        "# Verificar si existe el archivo limpio, si no, crearlo\n",
        "if not FULL_NC_CLEAN.exists():\n",
        "    print(\"âš ï¸ Archivo limpio no encontrado. Procesando dataset original...\")\n",
        "    FULL_NC = DATA_DIR / 'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation.nc'\n",
        "    ds_raw = xr.open_dataset(FULL_NC)\n",
        "    \n",
        "    # AnÃ¡lisis de NaNs\n",
        "    print(\"\\nğŸ“Š Resumen de NaNs en variables lag:\")\n",
        "    print(\"â”€\" * 55)\n",
        "    for var in Config.LAG_VARS:\n",
        "        arr = ds_raw[var].values\n",
        "        total = arr.size\n",
        "        n_nans = int(np.isnan(arr).sum())\n",
        "        print(f\"{var:<28}: {n_nans:>8,} / {total:,} ({n_nans/total:6.2%})\")\n",
        "    \n",
        "    # Limpiar datos (remover 1981 que tiene muchos NaNs)\n",
        "    ds_clean = ds_raw.sel(time=~(ds_raw['time.year'] == 1981))\n",
        "    print(f\"\\nğŸ”„ Timestamps: {len(ds_raw.time)} â†’ {len(ds_clean.time)} (removido 1981)\")\n",
        "    \n",
        "    # Guardar dataset limpio\n",
        "    ds_clean.to_netcdf(FULL_NC_CLEAN, mode='w')\n",
        "    print(f\"ğŸ’¾ Dataset limpio guardado en {FULL_NC_CLEAN}\")\n",
        "    ds = ds_clean\n",
        "else:\n",
        "    ds = xr.open_dataset(FULL_NC_CLEAN)\n",
        "    print(f\"âœ… Dataset cargado desde {FULL_NC_CLEAN}\")\n",
        "\n",
        "# Cargar shapefile\n",
        "dept_gdf = gpd.read_file(MODEL_INPUT_DIR / 'MGN_Departamento.shp')\n",
        "\n",
        "# Dimensiones\n",
        "lat, lon = len(ds.latitude), len(ds.longitude)\n",
        "print(f\"\\nğŸ“ Dimensiones: {lat} x {lon} = {lat * lon} celdas\")\n",
        "print(f\"ğŸ“… PerÃ­odo: {ds.time.values[0]} a {ds.time.values[-1]}\")\n",
        "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FUNCIONES UTILITARIAS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "\n",
        "def evaluate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
        "    \"\"\"Calcula mÃ©tricas de evaluaciÃ³n\"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}\n",
        "\n",
        "\n",
        "def quick_plot(ax, data, cmap, title, date_label, vmin=None, vmax=None, show_departments=True):\n",
        "    \"\"\"FunciÃ³n unificada para plotear mapas\"\"\"\n",
        "    mesh = ax.pcolormesh(ds.longitude, ds.latitude, data, \n",
        "                         cmap=cmap, shading='nearest', \n",
        "                         vmin=vmin, vmax=vmax, \n",
        "                         transform=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    if show_departments and dept_gdf is not None:\n",
        "        ax.add_geometries(dept_gdf.geometry, ccrs.PlateCarree(), \n",
        "                         edgecolor='black', facecolor='none', linewidth=1)\n",
        "    gl = ax.gridlines(draw_labels=True)\n",
        "    gl.top_labels = False\n",
        "    gl.right_labels = False\n",
        "    ax.set_title(f\"{title}\\n{date_label}\", pad=12)\n",
        "    return mesh\n",
        "\n",
        "\n",
        "def generate_and_display_gif(y_true_sample, y_pred_sample, tag, show_in_notebook=True):\n",
        "    \"\"\"Genera GIF y lo muestra en el notebook\"\"\"\n",
        "    pcm_min, pcm_max = 0, np.max(y_pred_sample)\n",
        "    frames = []\n",
        "    \n",
        "    for h in range(Config.HORIZON):\n",
        "        pmap = y_pred_sample[h, ..., 0]\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(8, 6), \n",
        "                              subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "        \n",
        "        mesh = quick_plot(ax, pmap, 'Blues', f\"{tag}\", f\"Horizonte {h+1}\", \n",
        "                         vmin=pcm_min, vmax=pcm_max)\n",
        "        fig.colorbar(mesh, ax=ax, fraction=0.046, pad=0.04, label='PrecipitaciÃ³n (mm)')\n",
        "        \n",
        "        # Guardar frame temporal\n",
        "        tmp = GIF_DIR / f\"tmp_{tag}_h{h}.png\"\n",
        "        fig.savefig(tmp, bbox_inches='tight', dpi=100)\n",
        "        plt.close(fig)\n",
        "        \n",
        "        frames.append(imageio.imread(tmp))\n",
        "        tmp.unlink(missing_ok=True)\n",
        "    \n",
        "    # Guardar GIF\n",
        "    gif_path = GIF_DIR / f\"{tag}.gif\"\n",
        "    imageio.mimsave(gif_path, frames, fps=0.5)\n",
        "    print(f\"ğŸ’¾ GIF guardado: {gif_path.name}\")\n",
        "    \n",
        "    # Mostrar en notebook\n",
        "    if show_in_notebook:\n",
        "        display(HTML(f'<h4>ğŸ¬ {tag}</h4>'))\n",
        "        display(IPImage(filename=str(gif_path)))\n",
        "    \n",
        "    return gif_path\n",
        "\n",
        "\n",
        "def plot_training_history(history, tag, show_in_notebook=True):\n",
        "    \"\"\"Plotea y guarda el historial de entrenamiento\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    ax.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "    ax.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss (MSE)')\n",
        "    ax.set_title(f'Training History - {tag}')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Guardar\n",
        "    img_path = IMAGE_DIR / f\"{tag}_history.png\"\n",
        "    fig.savefig(img_path, bbox_inches='tight', dpi=150)\n",
        "    \n",
        "    # Mostrar en notebook\n",
        "    if show_in_notebook:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "    \n",
        "    return img_path\n",
        "\n",
        "\n",
        "def make_windows(mask: np.ndarray, Xarr: np.ndarray, yarr: np.ndarray, \n",
        "                allow_past_context: bool) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Genera ventanas deslizantes descartando las que contienen NaNs\"\"\"\n",
        "    seq_X, seq_y = [], []\n",
        "    lim = len(mask) - Config.INPUT_WINDOW - Config.HORIZON + 1\n",
        "    \n",
        "    for start in range(lim):\n",
        "        end_w = start + Config.INPUT_WINDOW\n",
        "        end_y = end_w + Config.HORIZON\n",
        "        \n",
        "        if allow_past_context:\n",
        "            if not mask[end_w:end_y].all():\n",
        "                continue\n",
        "        else:\n",
        "            if not mask[start:end_y].all():\n",
        "                continue\n",
        "        \n",
        "        Xw = Xarr[start:end_w]\n",
        "        yw = yarr[end_w:end_y]\n",
        "        \n",
        "        if np.isnan(Xw).any() or np.isnan(yw).any():\n",
        "            continue\n",
        "        \n",
        "        seq_X.append(Xw)\n",
        "        seq_y.append(yw)\n",
        "    \n",
        "    return np.array(seq_X), np.array(seq_y)\n",
        "\n",
        "\n",
        "def impute_nans(a: np.ndarray, per_feature_mean: Optional[np.ndarray] = None, \n",
        "                is_target: bool = False) -> np.ndarray:\n",
        "    \"\"\"Imputa NaNs restantes (seguridad extra)\"\"\"\n",
        "    if not np.isnan(a).any():\n",
        "        return a\n",
        "    \n",
        "    if is_target:\n",
        "        a[np.isnan(a)] = 0.0\n",
        "        return a\n",
        "    \n",
        "    if per_feature_mean is None:\n",
        "        raise ValueError('per_feature_mean required for imputing X')\n",
        "    \n",
        "    flat = a.reshape(-1, a.shape[-1])\n",
        "    nan_idx = np.isnan(flat)\n",
        "    for f in range(a.shape[-1]):\n",
        "        flat[nan_idx[:, f], f] = per_feature_mean[f]\n",
        "    \n",
        "    return flat.reshape(a.shape)\n",
        "\n",
        "print(\"âœ… Funciones utilitarias definidas\")\n",
        "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DEFINICIÃ“N DEL MODELO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def tile_step_emb(batch_ref, step_emb_tab):\n",
        "    \"\"\"Replica la tabla de embedding para el batch\"\"\"\n",
        "    if isinstance(batch_ref, (tf.TensorShape, tf.TensorSpec)):\n",
        "        return tf.TensorShape([batch_ref[0], step_emb_tab.shape[0], step_emb_tab.shape[1]])\n",
        "    \n",
        "    b = tf.shape(batch_ref)[0]\n",
        "    emb = tf.expand_dims(step_emb_tab, 0)\n",
        "    return tf.tile(emb, [b, 1, 1])\n",
        "\n",
        "\n",
        "def build_convlstm_ed(\n",
        "    *,\n",
        "    input_window: int,\n",
        "    output_horizon: int,\n",
        "    spatial_height: int,\n",
        "    spatial_width: int,\n",
        "    n_features: int,\n",
        "    n_filters: int = 64,\n",
        "    n_heads: int = 4,\n",
        "    use_attention: bool = True,\n",
        "    use_positional_emb: bool = True,\n",
        "    lr: float = 1e-3\n",
        ") -> Model:\n",
        "    \"\"\"\n",
        "    Encoder-Decoder ConvLSTM + GRU con positional embedding mejorado\n",
        "    \"\"\"\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Encoder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    enc_inputs = Input(\n",
        "        shape=(input_window, spatial_height, spatial_width, n_features),\n",
        "        name=\"enc_input\"\n",
        "    )\n",
        "    \n",
        "    x = ConvLSTM2D(n_filters, (3, 3), padding='same',\n",
        "                   return_sequences=True, name=\"enc_lstm_1\")(enc_inputs)\n",
        "    x = ConvLSTM2D(n_filters // 2, (3, 3), padding='same',\n",
        "                   return_sequences=False, name=\"enc_lstm_2\")(x)\n",
        "    \n",
        "    # â”€â”€ Flatten y repetir contexto â”€â”€\n",
        "    flat = Flatten(name=\"flatten_spatial\")(x)\n",
        "    ctx = RepeatVector(output_horizon, name=\"context\")(flat)\n",
        "    \n",
        "    # â”€â”€ Positional embedding mejorado â”€â”€\n",
        "    if use_positional_emb:\n",
        "        step_ids_input = Input(shape=(output_horizon,), dtype=tf.int32, name=\"step_ids\")\n",
        "        step_emb_layer = Embedding(output_horizon, n_filters, name=\"step_embedding\")\n",
        "        step_emb = step_emb_layer(step_ids_input)\n",
        "        dec_in = Concatenate(name=\"dec_concat\")([ctx, step_emb])\n",
        "        model_inputs = [enc_inputs, step_ids_input]\n",
        "    else:\n",
        "        dec_in = ctx\n",
        "        model_inputs = enc_inputs\n",
        "    \n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Decoder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    dec = GRU(2 * n_filters, return_sequences=True, name=\"dec_gru\")(dec_in)\n",
        "    \n",
        "    # â”€â”€â”€â”€â”€â”€â”€ Attention (opcional) â”€â”€â”€â”€â”€â”€â”€\n",
        "    if use_attention:\n",
        "        attn = MultiHeadAttention(num_heads=n_heads, key_dim=n_filters,\n",
        "                                  dropout=0.1, name=\"mha\")(dec, dec)\n",
        "        dec = Add(name=\"mha_residual\")([dec, attn])\n",
        "        dec = LayerNormalization(name=\"mha_norm\")(dec)\n",
        "    \n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ProyecciÃ³n a grilla â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    proj = TimeDistributed(\n",
        "        Dense(spatial_height * spatial_width, activation='linear'),\n",
        "        name=\"dense_proj\"\n",
        "    )(dec)\n",
        "    \n",
        "    out = Reshape(\n",
        "        (output_horizon, spatial_height, spatial_width, 1),\n",
        "        name=\"reshape_out\"\n",
        "    )(proj)\n",
        "    \n",
        "    # Nombre del modelo\n",
        "    name = (\"ConvLSTM_ED_Attn_PE\" if use_attention else \"ConvLSTM_ED_PE\") \\\n",
        "           if use_positional_emb else \\\n",
        "           (\"ConvLSTM_ED_Attn\" if use_attention else \"ConvLSTM_ED\")\n",
        "    \n",
        "    model = Model(model_inputs, out, name=name)\n",
        "    model.compile(optimizer=Adam(lr), loss='mse')\n",
        "    return model\n",
        "\n",
        "\n",
        "# Factories para diferentes configuraciones\n",
        "def factory_no_attn(**kw):\n",
        "    return build_convlstm_ed(use_attention=False, **kw)\n",
        "\n",
        "def factory_attn(**kw):\n",
        "    return build_convlstm_ed(use_attention=True, **kw)\n",
        "\n",
        "print(\"âœ… Arquitectura del modelo definida\")\n",
        "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIGURACIÃ“N DE EXPERIMENTOS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "\n",
        "FOLDS = {\n",
        "    'F1': {'year': 2018, 'active': True}\n",
        "}\n",
        "\n",
        "EXPERIMENTS = {\n",
        "    'ConvLSTM-ED': {\n",
        "        'active': True,\n",
        "        'feature_list': Config.BASE_FEATURES,\n",
        "        'builder': factory_attn,\n",
        "        'n_filters': 64,\n",
        "        'n_heads': 4\n",
        "    },\n",
        "    'ConvLSTM-ED-KCE': {\n",
        "        'active': True,\n",
        "        'feature_list': Config.KCE_FEATURES,\n",
        "        'builder': factory_attn,\n",
        "        'n_filters': 64,\n",
        "        'n_heads': 4,\n",
        "    },\n",
        "    'ConvLSTM-ED-KCE-PAFC': {\n",
        "        'active': True,\n",
        "        'feature_list': Config.PAFC_FEATURES,\n",
        "        'builder': factory_attn,\n",
        "        'n_filters': 96,\n",
        "        'n_heads': 6,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(\"ğŸ“‹ Experimentos configurados:\")\n",
        "for exp_name, exp_cfg in EXPERIMENTS.items():\n",
        "    if exp_cfg['active']:\n",
        "        print(f\"  â€¢ {exp_name}: {len(exp_cfg['feature_list'])} features\")\n",
        "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ENTRENAMIENTO Y EVALUACIÃ“N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "\n",
        "def run_experiments(show_visualizations=True):\n",
        "    \"\"\"Ejecuta todos los experimentos configurados\"\"\"\n",
        "    times = pd.to_datetime(ds.time.values)\n",
        "    results = []\n",
        "    \n",
        "    # Contador de experimentos\n",
        "    total_exp = sum(e['active'] for e in EXPERIMENTS.values()) * sum(f['active'] for f in FOLDS.values())\n",
        "    exp_count = 0\n",
        "    \n",
        "    for exp_name, exp_cfg in EXPERIMENTS.items():\n",
        "        if not exp_cfg['active']:\n",
        "            continue\n",
        "        \n",
        "        # ConfiguraciÃ³n del experimento\n",
        "        feature_list = exp_cfg['feature_list']\n",
        "        builder = exp_cfg['builder']\n",
        "        n_filters = exp_cfg.get('n_filters', 64)\n",
        "        n_heads = exp_cfg.get('n_heads', 4)\n",
        "        \n",
        "        # Cargar features\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸ”¬ Experimento: {exp_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        Xarr = ds[feature_list].to_array().transpose('time', 'latitude', 'longitude', 'variable').values.astype(np.float32)\n",
        "        yarr = ds[Config.TARGET_VAR].values.astype(np.float32)\n",
        "        n_features = Xarr.shape[-1]\n",
        "        \n",
        "        for fold_name, fold_cfg in FOLDS.items():\n",
        "            if not fold_cfg['active']:\n",
        "                continue\n",
        "            \n",
        "            exp_count += 1\n",
        "            year_val = fold_cfg['year']\n",
        "            \n",
        "            print(f\"\\nâ–¶ï¸ [{exp_count}/{total_exp}] {exp_name} - {fold_name} (val={year_val})\")\n",
        "            \n",
        "            # Crear mÃ¡scaras temporales\n",
        "            mask_val = times.year == year_val\n",
        "            mask_tr = ~mask_val\n",
        "            \n",
        "            if mask_val.sum() < Config.HORIZON:\n",
        "                print(\"âš ï¸ AÃ±o sin suficientes datos â†’ skip\")\n",
        "                continue\n",
        "            \n",
        "            # Generar ventanas\n",
        "            X_tr, y_tr = make_windows(mask_tr, Xarr, yarr, allow_past_context=False)\n",
        "            X_va, y_va = make_windows(mask_val, Xarr, yarr, allow_past_context=True)\n",
        "            \n",
        "            print(f\"ğŸ“Š Ventanas - Train: {len(X_tr)}, Val: {len(X_va)}\")\n",
        "            \n",
        "            if len(X_tr) == 0 or len(X_va) == 0:\n",
        "                print(\"âš ï¸ Sin ventanas vÃ¡lidas â†’ skip\")\n",
        "                continue\n",
        "            \n",
        "            # ImputaciÃ³n de NaNs\n",
        "            feat_mean = np.nanmean(X_tr.reshape(-1, n_features), axis=0)\n",
        "            X_tr = impute_nans(X_tr, feat_mean)\n",
        "            X_va = impute_nans(X_va, feat_mean)\n",
        "            y_tr = impute_nans(y_tr, is_target=True)\n",
        "            y_va = impute_nans(y_va, is_target=True)\n",
        "            \n",
        "            # Escalado\n",
        "            sx = StandardScaler().fit(X_tr.reshape(-1, n_features))\n",
        "            sy = StandardScaler().fit(y_tr.reshape(-1, 1))\n",
        "            \n",
        "            X_tr_sc = sx.transform(X_tr.reshape(-1, n_features)).reshape(X_tr.shape)\n",
        "            X_va_sc = sx.transform(X_va.reshape(-1, n_features)).reshape(X_va.shape)\n",
        "            y_tr_sc = sy.transform(y_tr.reshape(-1, 1)).reshape(y_tr.shape)[..., None]\n",
        "            y_va_sc = sy.transform(y_va.reshape(-1, 1)).reshape(y_va.shape)[..., None]\n",
        "            \n",
        "            # Construir modelo\n",
        "            tag = f\"{exp_name.replace('+', '_')}_{fold_name}\"\n",
        "            model_path = MODEL_DIR / f\"{tag}.keras\"\n",
        "            \n",
        "            if model_path.exists():\n",
        "                print(f\"â© Modelo {tag} ya existe â†’ skip\")\n",
        "                continue\n",
        "            \n",
        "            model = builder(\n",
        "                input_window=Config.INPUT_WINDOW,\n",
        "                output_horizon=Config.HORIZON,\n",
        "                spatial_height=lat,\n",
        "                spatial_width=lon,\n",
        "                n_features=n_features,\n",
        "                n_filters=n_filters,\n",
        "                n_heads=n_heads,\n",
        "                lr=Config.LR\n",
        "            )\n",
        "            \n",
        "            # Preparar inputs segÃºn el modelo\n",
        "            uses_pe = len(model.inputs) > 1\n",
        "            \n",
        "            if uses_pe:\n",
        "                step_ids_train = np.tile(np.arange(Config.HORIZON), (len(X_tr_sc), 1))\n",
        "                step_ids_val = np.tile(np.arange(Config.HORIZON), (len(X_va_sc), 1))\n",
        "                X_train_input = [X_tr_sc, step_ids_train]\n",
        "                X_val_input = [X_va_sc, step_ids_val]\n",
        "            else:\n",
        "                X_train_input = X_tr_sc\n",
        "                X_val_input = X_va_sc\n",
        "            \n",
        "            # Entrenar\n",
        "            print(\"ğŸƒ Entrenando modelo...\")\n",
        "            es = EarlyStopping(monitor='val_loss', patience=Config.PATIENCE, restore_best_weights=True)\n",
        "            \n",
        "            history = model.fit(\n",
        "                X_train_input, y_tr_sc,\n",
        "                validation_data=(X_val_input, y_va_sc),\n",
        "                epochs=Config.EPOCHS,\n",
        "                batch_size=Config.BATCH_SIZE,\n",
        "                callbacks=[es],\n",
        "                verbose=1\n",
        "            )\n",
        "            \n",
        "            # Guardar modelo\n",
        "            model.save(model_path)\n",
        "            print(f\"ğŸ’¾ Modelo guardado: {model_path.name}\")\n",
        "            \n",
        "            # Visualizar historial\n",
        "            plot_training_history(history, tag, show_in_notebook=show_visualizations)\n",
        "            \n",
        "            # PredicciÃ³n y evaluaciÃ³n\n",
        "            if uses_pe:\n",
        "                y_hat_sc = model.predict([X_va_sc, step_ids_val], verbose=0)\n",
        "            else:\n",
        "                y_hat_sc = model.predict(X_va_sc, verbose=0)\n",
        "            \n",
        "            y_hat = sy.inverse_transform(y_hat_sc.reshape(-1, 1)).reshape(y_hat_sc.shape)\n",
        "            y_true = sy.inverse_transform(y_va_sc.reshape(-1, 1)).reshape(y_va_sc.shape)\n",
        "            \n",
        "            # MÃ©tricas\n",
        "            metrics = evaluate_metrics(y_true.ravel(), y_hat.ravel())\n",
        "            metrics.update({\n",
        "                'experiment': exp_name,\n",
        "                'fold': fold_name,\n",
        "                'epochs': len(history.history['loss'])\n",
        "            })\n",
        "            results.append(metrics)\n",
        "            \n",
        "            print(f\"\\nğŸ“ˆ MÃ©tricas: RMSE={metrics['RMSE']:.3f}, MAE={metrics['MAE']:.3f}, \"\n",
        "                  f\"MAPE={metrics['MAPE']:.1f}%, RÂ²={metrics['R2']:.3f}\")\n",
        "            \n",
        "            # Verificar variaciÃ³n entre horizontes\n",
        "            print(\"\\nğŸ” VerificaciÃ³n de predicciones por horizonte:\")\n",
        "            predictions_vary = False\n",
        "            \n",
        "            for h in range(Config.HORIZON):\n",
        "                pred_h = y_hat[0, h, ..., 0]\n",
        "                stats = {\n",
        "                    'min': pred_h.min(),\n",
        "                    'max': pred_h.max(),\n",
        "                    'mean': pred_h.mean(),\n",
        "                    'std': pred_h.std()\n",
        "                }\n",
        "                print(f\"  H{h+1}: min={stats['min']:.3f}, max={stats['max']:.3f}, \"\n",
        "                      f\"mean={stats['mean']:.3f}, std={stats['std']:.3f}\")\n",
        "                \n",
        "                if h > 0:\n",
        "                    diff = np.abs(y_hat[0, h] - y_hat[0, 0]).mean()\n",
        "                    if diff > 0.001:\n",
        "                        predictions_vary = True\n",
        "            \n",
        "            if not predictions_vary and Config.HORIZON > 1:\n",
        "                print(\"âš ï¸ ADVERTENCIA: Las predicciones parecen idÃ©nticas entre horizontes\")\n",
        "            else:\n",
        "                print(\"âœ… Las predicciones varÃ­an correctamente entre horizontes\")\n",
        "            \n",
        "            # Generar GIF\n",
        "            last_idx = min(len(y_hat) - 1, 10)\n",
        "            generate_and_display_gif(y_true[last_idx], y_hat[last_idx], tag, \n",
        "                                   show_in_notebook=show_visualizations)\n",
        "    \n",
        "    # Guardar resultados\n",
        "    if results:\n",
        "        df_results = pd.DataFrame(results)\n",
        "        csv_path = MODEL_DIR / \"metrics_experiments.csv\"\n",
        "        df_results.to_csv(csv_path, index=False)\n",
        "        print(f\"\\nğŸ“Š MÃ©tricas guardadas en: {csv_path}\")\n",
        "        \n",
        "        # Mostrar resumen\n",
        "        print(\"\\nğŸ“‹ Resumen de resultados:\")\n",
        "        display(df_results[['experiment', 'fold', 'RMSE', 'MAE', 'MAPE', 'R2']].round(3))\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Ejecutar experimentos\n",
        "print(\"ğŸš€ Iniciando experimentos...\\n\")\n",
        "results = run_experiments(show_visualizations=True)\n",
        "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ EVALUACIÃ“N DE MODELOS GUARDADOS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
        "\n",
        "def evaluate_saved_models(show_visualizations=True):\n",
        "    \"\"\"EvalÃºa todos los modelos guardados\"\"\"\n",
        "    print(\"\\nğŸ” Evaluando modelos guardados...\\n\")\n",
        "    \n",
        "    all_metrics = []\n",
        "    times = pd.to_datetime(ds.time.values)\n",
        "    \n",
        "    # Custom objects para cargar modelos\n",
        "    custom_objects = {'tile_step_emb': tile_step_emb}\n",
        "    \n",
        "    for model_path in sorted(MODEL_DIR.glob(\"*.keras\")):\n",
        "        tag = model_path.stem\n",
        "        parts = tag.split(\"_\")\n",
        "        fold = parts[-1]\n",
        "        exp_name = \"_\".join(parts[:-1]).replace(\"_\", \"-\")\n",
        "        \n",
        "        if exp_name not in EXPERIMENTS:\n",
        "            print(f\"âš ï¸ Experimento no encontrado para {tag}\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nğŸ“Š Evaluando: {tag}\")\n",
        "        \n",
        "        # Cargar features\n",
        "        feature_list = EXPERIMENTS[exp_name]['feature_list']\n",
        "        Xarr = ds[feature_list].to_array().transpose('time', 'latitude', 'longitude', 'variable').values.astype(np.float32)\n",
        "        yarr = ds[Config.TARGET_VAR].values.astype(np.float32)\n",
        "        T, _, _, F = Xarr.shape\n",
        "        \n",
        "        # Ventana final para evaluaciÃ³n\n",
        "        start = T - Config.INPUT_WINDOW - Config.HORIZON\n",
        "        end_w = start + Config.INPUT_WINDOW\n",
        "        end_y = end_w + Config.HORIZON\n",
        "        \n",
        "        X_eval = Xarr[start:end_w]\n",
        "        y_eval = yarr[end_w:end_y]\n",
        "        \n",
        "        # Escalado\n",
        "        sx = StandardScaler().fit(Xarr.reshape(-1, F))\n",
        "        sy = StandardScaler().fit(yarr.reshape(-1, 1))\n",
        "        \n",
        "        Xe_sc = sx.transform(X_eval.reshape(-1, F)).reshape(1, Config.INPUT_WINDOW, lat, lon, F)\n",
        "        \n",
        "        # Cargar modelo\n",
        "        model = tf.keras.models.load_model(model_path, compile=False, custom_objects=custom_objects)\n",
        "        \n",
        "        # PredicciÃ³n\n",
        "        uses_pe = len(model.inputs) > 1\n",
        "        if uses_pe:\n",
        "            step_ids_eval = np.tile(np.arange(Config.HORIZON), (1, 1))\n",
        "            yhat_sc = model.predict([Xe_sc, step_ids_eval], verbose=0)\n",
        "        else:\n",
        "            yhat_sc = model.predict(Xe_sc, verbose=0)\n",
        "        \n",
        "        yhat = sy.inverse_transform(yhat_sc.reshape(-1, 1)).reshape(Config.HORIZON, lat, lon)\n",
        "        \n",
        "        # MÃ©tricas por horizonte\n",
        "        for h in range(Config.HORIZON):\n",
        "            yt = y_eval[h].ravel()\n",
        "            yp = yhat[h].ravel()\n",
        "            \n",
        "            # Filtrar NaN/Inf\n",
        "            mask = np.isfinite(yt) & np.isfinite(yp)\n",
        "            if mask.sum() == 0:\n",
        "                continue\n",
        "            \n",
        "            yt, yp = yt[mask], yp[mask]\n",
        "            \n",
        "            metrics = evaluate_metrics(yt, yp)\n",
        "            metrics.update({\n",
        "                'model': tag,\n",
        "                'experiment': exp_name,\n",
        "                'fold': fold,\n",
        "                'horizon': h + 1\n",
        "            })\n",
        "            all_metrics.append(metrics)\n",
        "        \n",
        "        # VisualizaciÃ³n comparativa\n",
        "        if show_visualizations:\n",
        "            fig, axes = plt.subplots(Config.HORIZON, 3, figsize=(15, 5 * Config.HORIZON),\n",
        "                                   subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "            \n",
        "            if Config.HORIZON == 1:\n",
        "                axes = axes.reshape(1, -1)\n",
        "            \n",
        "            dates = pd.date_range(times[end_w], periods=Config.HORIZON, freq='MS')\n",
        "            vmin, vmax = 0, max(yhat.max(), y_eval.max())\n",
        "            \n",
        "            for h in range(Config.HORIZON):\n",
        "                # Real\n",
        "                quick_plot(axes[h, 0], y_eval[h], 'Blues', f\"Real H{h+1}\",\n",
        "                          dates[h].strftime('%Y-%m'), vmin, vmax)\n",
        "                \n",
        "                # PredicciÃ³n\n",
        "                quick_plot(axes[h, 1], yhat[h], 'Blues', f\"Pred H{h+1}\",\n",
        "                          dates[h].strftime('%Y-%m'), vmin, vmax)\n",
        "                \n",
        "                # Error MAPE\n",
        "                err = np.clip(np.abs((y_eval[h] - yhat[h]) / (y_eval[h] + 1e-5)) * 100, 0, 100)\n",
        "                quick_plot(axes[h, 2], err, 'Reds', f\"MAPE% H{h+1}\",\n",
        "                          dates[h].strftime('%Y-%m'), 0, 100)\n",
        "            \n",
        "            fig.suptitle(f\"{tag} - EvaluaciÃ³n Final\", fontsize=16)\n",
        "            fig.tight_layout()\n",
        "            \n",
        "            # Guardar y mostrar\n",
        "            eval_img_path = MODEL_DIR / f\"eval_{tag}.png\"\n",
        "            fig.savefig(eval_img_path, dpi=150, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            \n",
        "            # Generar GIF de predicciones\n",
        "            generate_and_display_gif(y_eval, yhat[:, :, :, np.newaxis], f\"eval_{tag}\",\n",
        "                                   show_in_notebook=True)\n",
        "    \n",
        "    # Guardar mÃ©tricas\n",
        "    if all_metrics:\n",
        "        df_metrics = pd.DataFrame(all_metrics)\n",
        "        csv_path = MODEL_DIR / 'metrics_evaluation.csv'\n",
        "        df_metrics.to_csv(csv_path, index=False)\n",
        "        print(f\"\\nğŸ“Š MÃ©tricas de evaluaciÃ³n guardadas en: {csv_path}\")\n",
        "        \n",
        "        # Mostrar resumen por modelo\n",
        "        print(\"\\nğŸ“‹ Resumen de evaluaciÃ³n:\")\n",
        "        summary = df_metrics.groupby('model')[['RMSE', 'MAE', 'MAPE', 'R2']].mean().round(3)\n",
        "        display(summary)\n",
        "    \n",
        "    return df_metrics\n",
        "\n",
        "# Ejecutar evaluaciÃ³n\n",
        "df_evaluation = evaluate_saved_models(show_visualizations=True)\n",
        "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Resumen\n",
        "\n",
        "Este notebook refactorizado ha:\n",
        "\n",
        "1. **Eliminado cÃ³digo duplicado**: Funciones unificadas para plotting, evaluaciÃ³n y procesamiento\n",
        "2. **Mejorado la visualizaciÃ³n**: Las imÃ¡genes y GIFs se guardan Y se muestran en el notebook\n",
        "3. **Centralizado la configuraciÃ³n**: Clase Config con todos los hiperparÃ¡metros\n",
        "4. **AÃ±adido verificaciones**: DetecciÃ³n de predicciones idÃ©nticas entre horizontes\n",
        "5. **Mejorado la documentaciÃ³n**: Comentarios claros y estructura organizada\n",
        "\n",
        "### ğŸ¯ PrÃ³ximos pasos:\n",
        "- Experimentar con diferentes arquitecturas\n",
        "- Ajustar hiperparÃ¡metros\n",
        "- AÃ±adir mÃ¡s mÃ©tricas de evaluaciÃ³n\n",
        "- Implementar visualizaciones adicionales\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
