# üöÄ Mejoras Propuestas para Modelos Espaciales de Precipitaci√≥n

## üìä An√°lisis de Resultados Actuales

### Problemas Identificados:

1. **R¬≤ Negativos**: Varios modelos muestran R¬≤ < 0, especialmente en H=2
   - ConvLSTM en KCE/PAFC: R¬≤ = -0.042 y -0.161
   - ConvRNN en KCE: R¬≤ = -0.340
   - ConvGRU en PAFC: R¬≤ = -0.052

2. **Degradaci√≥n en H=3**: RMSE > 100 en muchos casos
   - ConvLSTM: RMSE hasta 111.3
   - ConvGRU: RMSE hasta 106.9
   - ConvRNN: RMSE hasta 87.3

3. **Inestabilidad**: Batch size = 4 es muy peque√±o

### Mejores Resultados Actuales:
- **H=1**: ConvRNN BASIC (RMSE=43.49, R¬≤=0.767)
- **H=2**: ConvGRU BASIC (RMSE=32.40, R¬≤=0.401)
- **H=3**: ConvRNN KCE (RMSE=71.47, R¬≤=0.611)

## üîß Mejoras Implementadas

### 1. Optimizaci√≥n de Hiperpar√°metros

| Par√°metro | Valor Original | Valor Mejorado | Justificaci√≥n |
|-----------|----------------|----------------|---------------|
| Batch Size | 4 | **16** | Mayor estabilidad en gradientes |
| Learning Rate | 1e-3 | **5e-4** | Convergencia m√°s suave |
| Epochs | 50 | **100** | M√°s tiempo con early stopping |
| Patience | 6 | **10** | Evitar detenci√≥n prematura |
| Dropout | 0 | **0.2** | Regularizaci√≥n |
| L2 Reg | 0 | **1e-5** | Prevenir overfitting |

### 2. Arquitecturas Mejoradas

#### ConvLSTM con Atenci√≥n (ConvLSTM_Att)
```python
- 3 capas ConvLSTM (64‚Üí32‚Üí16 filtros)
- CBAM (Channel + Spatial Attention)
- BatchNorm + Dropout en cada capa
- Cabeza multi-escala (1√ó1, 3√ó3, 5√ó5)
```

#### ConvGRU Residual (ConvGRU_Res)
```python
- Skip connections desde input
- BatchNorm mejorado
- 2 bloques ConvGRU (64‚Üí32 filtros)
- Conexi√≥n residual final
```

#### Transformer H√≠brido (Hybrid_Trans)
```python
- Encoder CNN temporal
- Multi-head attention (4 heads)
- LSTM para agregaci√≥n temporal
- Decoder espacial
```

### 3. T√©cnicas Avanzadas

#### Learning Rate Scheduling
- **Warmup**: 5 √©pocas iniciales
- **Cosine Decay**: Reducci√≥n suave despu√©s del warmup
- **ReduceLROnPlateau**: Reducci√≥n adicional si se estanca

#### Data Augmentation
- Ruido gaussiano (œÉ=0.005)
- Preserva coherencia espacial y temporal

#### Regularizaci√≥n
- Dropout espacial (0.2)
- L2 en todos los pesos
- Batch Normalization

## üìà Mejoras Esperadas

### Por Horizonte:
- **H=1**: RMSE < 40 (mejora ~8%)
- **H=2**: RMSE < 30, R¬≤ > 0.5 (mejora significativa)
- **H=3**: RMSE < 65, R¬≤ > 0.65 (mejora ~10%)

### Por Modelo:
1. **ConvLSTM_Att**: Mejor captura de patrones espaciales relevantes
2. **ConvGRU_Res**: Mayor estabilidad y menos degradaci√≥n temporal
3. **Hybrid_Trans**: Mejor modelado de dependencias largas

## üöÄ Pr√≥ximos Pasos

### Corto Plazo:
1. Entrenar modelos con configuraci√≥n mejorada
2. Validar mejoras en m√©tricas
3. An√°lisis de errores por regi√≥n

### Medio Plazo:
1. **Ensemble Methods**: Combinar mejores modelos
2. **Multi-Task Learning**: Predecir m√∫ltiples variables
3. **Physics-Informed Loss**: Incorporar restricciones f√≠sicas

### Largo Plazo:
1. **Modelos 3D**: ConvLSTM3D para capturar altura
2. **Graph Neural Networks**: Para relaciones espaciales irregulares
3. **Uncertainty Quantification**: Intervalos de confianza

## üíª Uso del Script

```bash
# Entrenar modelos avanzados
python models/train_advanced_models.py

# Con GPU espec√≠fica
CUDA_VISIBLE_DEVICES=0 python models/train_advanced_models.py
```

## üìä Monitoreo

Los resultados se guardan en:
- `models/output/Advanced_Spatial/advanced_results.csv`
- Historiales de entrenamiento por experimento
- Modelos guardados en formato .keras

## üîç Comparaci√≥n con Baseline

El script genera autom√°ticamente comparaciones con los modelos originales, mostrando:
- % de mejora en RMSE
- Evoluci√≥n de R¬≤ por horizonte
- Tabla resumen de mejores modelos 