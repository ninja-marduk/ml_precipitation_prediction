import json
import re

def code_review():
    """Code review completo del flujo de datos"""
    
    print("ğŸ” CODE REVIEW: VALIDACIÃ“N DEL FLUJO DE DATOS")
    print("=" * 80)
    
    # Cargar notebook
    with open('models/hybrid_models_GRU-w12.ipynb', 'r') as f:
        notebook = json.load(f)
    
    content = ''.join([''.join(cell['source']) for cell in notebook['cells']])
    
    print(f"ğŸ“‹ AnÃ¡lisis del notebook: {len(notebook['cells'])} celdas")
    
    # 1. PROBLEMA CRÃTICO: FUNCIONES DUPLICADAS
    print("\nğŸš¨ 1. PROBLEMAS CRÃTICOS ENCONTRADOS:")
    print("-" * 50)
    
    duplicates = ['def build_dataloaders', 'EXPERIMENTS = {']
    for func in duplicates:
        count = content.count(func)
        if count > 1:
            print(f"   âŒ {func}: {count} definiciones DUPLICADAS")
            print(f"      ğŸ”§ ACCIÃ“N REQUERIDA: Mantener solo la Ãºltima definiciÃ³n")
    
    # 2. ANÃLISIS DEL FLUJO DE DATOS
    print("\nğŸ” 2. ANÃLISIS DEL FLUJO DE DATOS:")
    print("-" * 50)
    
    # Buscar el patrÃ³n de llamadas
    flow_patterns = [
        ("run_complete_training_pipeline", "all_results = train_all_active_experiments\\(dataset\\)"),
        ("train_all_active_experiments", "result = train_experiment_complete\\(exp_name, fold_name, dataset"),
        ("train_experiment_complete", "dataloader_config = build_dataloaders\\(exp_name, fold_name, dataset"),
        ("build_dataloaders", "features = EXPERIMENTS\\[.*\\]\\['feature_list'\\]")
    ]
    
    for func_name, pattern in flow_patterns:
        if re.search(pattern, content):
            print(f"   âœ… {func_name}: Pasa datos correctamente")
        else:
            print(f"   âŒ {func_name}: PROBLEMA en paso de datos")
            print(f"      PatrÃ³n esperado: {pattern}")
    
    # 3. VALIDACIÃ“N DE CONFIGURACIÃ“N DE EXPERIMENTOS
    print("\nğŸ” 3. CONFIGURACIÃ“N DE EXPERIMENTOS:")
    print("-" * 50)
    
    # Buscar configuraciones de experimentos
    exp_matches = re.findall(r"'(ConvGRU-ED|ConvGRU-ED-KCE|ConvGRU-ED-KCE-PAFC)'", content)
    if exp_matches:
        unique_experiments = list(set(exp_matches))
        print(f"   âœ… Experimentos configurados: {unique_experiments}")
        
        # Verificar feature_list para cada experimento
        for exp in unique_experiments:
            feature_pattern = rf"'{exp}':[^}}]*'feature_list':\s*\[([^\]]*)\]"
            features_match = re.search(feature_pattern, content, re.DOTALL)
            if features_match:
                features_str = features_match.group(1)
                feature_count = len(re.findall(r"'[^']*'", features_str))
                print(f"      â€¢ {exp}: {feature_count} caracterÃ­sticas definidas")
            else:
                print(f"      âŒ {exp}: NO tiene feature_list definida")
    else:
        print("   âŒ NO se encontraron experimentos configurados")
    
    # 4. VALIDACIÃ“N DE build_dataloaders
    print("\nğŸ” 4. VALIDACIÃ“N DE build_dataloaders:")
    print("-" * 50)
    
    # Buscar la funciÃ³n build_dataloaders (usar la Ãºltima definiciÃ³n)
    build_functions = re.findall(r"def build_dataloaders\([^)]*\):(.*?)(?=def [^_]|\Z)", content, re.DOTALL)
    
    if build_functions:
        latest_build = build_functions[-1]  # Usar Ãºltima definiciÃ³n
        
        # Verificar pasos crÃ­ticos en build_dataloaders
        critical_checks = [
            ("features = EXPERIMENTS\\[", "Extrae features del experimento"),
            ("for feature in features:", "Itera sobre features"),
            ("if feature in dataset:", "Verifica feature existe en dataset"),
            ("feature_data\\[feature\\] =", "Almacena datos de feature"),
            ("return.*dataset", "Retorna datasets procesados")
        ]
        
        for pattern, description in critical_checks:
            if re.search(pattern, latest_build):
                print(f"   âœ… {description}")
            else:
                print(f"   âŒ {description} - FALTA!")
    else:
        print("   âŒ build_dataloaders NO encontrada")
    
    # 5. PROBLEMA POTENCIAL CON PARÃMETROS
    print("\nğŸ” 5. VALIDACIÃ“N DE PARÃMETROS:")
    print("-" * 50)
    
    # Verificar consistencia en nombres de parÃ¡metros
    param_issues = []
    
    # En run_complete_training_pipeline
    if "def run_complete_training_pipeline(dataset=None)" in content:
        if "dataset = ds_full" in content:
            print("   âœ… run_complete_training_pipeline: Maneja dataset por defecto")
        else:
            param_issues.append("run_complete_training_pipeline no tiene fallback para dataset")
    
    # En train_experiment_complete
    if "train_experiment_complete(exp_name, fold_name, dataset" in content:
        print("   âœ… train_experiment_complete: Recibe parÃ¡metros correctos")
    else:
        param_issues.append("train_experiment_complete no recibe parÃ¡metros esperados")
    
    # En build_dataloaders
    if "build_dataloaders(exp_name, fold_name, dataset" in content:
        print("   âœ… build_dataloaders: Recibe parÃ¡metros correctos")
    else:
        param_issues.append("build_dataloaders no recibe parÃ¡metros esperados")
    
    if param_issues:
        for issue in param_issues:
            print(f"   âŒ {issue}")
    
    # 6. RECOMENDACIONES CRÃTICAS
    print("\nğŸ”§ 6. RECOMENDACIONES CRÃTICAS:")
    print("-" * 50)
    
    recommendations = []
    
    # Funciones duplicadas
    if content.count('def build_dataloaders') > 1:
        recommendations.append("ELIMINAR build_dataloaders duplicada - usar solo la Ãºltima definiciÃ³n")
    
    if content.count('EXPERIMENTS = {') > 1:
        recommendations.append("ELIMINAR EXPERIMENTS duplicada - usar solo la Ãºltima definiciÃ³n")
    
    # Validaciones faltantes
    if "if not dataset" not in content:
        recommendations.append("AÃ‘ADIR validaciÃ³n de dataset no vacÃ­o")
    
    if "assert" not in content:
        recommendations.append("AÃ‘ADIR validaciones assert para parÃ¡metros crÃ­ticos")
    
    # Logging
    if "info_print.*feature.*extracted" not in content:
        recommendations.append("AÃ‘ADIR logging detallado de extracciÃ³n de features")
    
    # Mostrar recomendaciones
    if recommendations:
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")
    else:
        print("   âœ… No se encontraron problemas adicionales")
    
    # 7. CÃ“DIGO DE PRUEBA SUGERIDO
    print("\nğŸ§ª 7. CÃ“DIGO DE PRUEBA SUGERIDO:")
    print("-" * 50)
    
    test_code = '''
# Prueba rÃ¡pida del flujo de datos
def test_data_flow():
    print("ğŸ§ª Probando flujo de datos...")
    
    # 1. Verificar que ds_full existe
    assert 'ds_full' in globals(), "Dataset ds_full no existe"
    
    # 2. Verificar experimentos activos
    active_exps = [name for name, config in EXPERIMENTS.items() if config.get('active', False)]
    print(f"   Experimentos activos: {active_exps}")
    
    # 3. Probar build_dataloaders con primer experimento
    if active_exps:
        exp_name = active_exps[0]
        fold_name = 'F1'
        
        print(f"   Probando: {exp_name} - {fold_name}")
        
        # Verificar configuraciÃ³n
        exp_config = EXPERIMENTS[exp_name]
        features = exp_config['feature_list']
        print(f"   Features requeridas: {len(features)}")
        
        # Verificar features en dataset
        missing_features = [f for f in features if f not in ds_full.data_vars]
        if missing_features:
            print(f"   âŒ Features faltantes en dataset: {missing_features}")
        else:
            print(f"   âœ… Todas las features estÃ¡n en el dataset")
        
        try:
            # Probar build_dataloaders
            result = build_dataloaders(exp_name, fold_name, ds_full, 32)
            if result:
                print(f"   âœ… build_dataloaders ejecutado exitosamente")
                print(f"   ğŸ“Š Muestras train: {result.get('train_samples', 'N/A')}")
                print(f"   ğŸ“Š Muestras val: {result.get('val_samples', 'N/A')}")
            else:
                print(f"   âŒ build_dataloaders retornÃ³ None")
        except Exception as e:
            print(f"   âŒ Error en build_dataloaders: {e}")
    
    print("ğŸ§ª Prueba completada")

# Ejecutar prueba
# test_data_flow()
'''
    
    print(test_code)
    
    print("\n" + "=" * 80)
    print("ğŸ¯ RESUMEN DEL CODE REVIEW")
    print("=" * 80)
    print("âœ… Flujo principal: run_complete_training_pipeline â†’ train_all â†’ train_experiment â†’ build_dataloaders")
    print("âš ï¸ PROBLEMAS ENCONTRADOS:")
    print("   1. Funciones duplicadas (build_dataloaders, EXPERIMENTS)")
    print("   2. Posibles conflictos de definiciones")
    print("   3. Falta validaciÃ³n robusta de datos")
    print("\nğŸ”§ ACCIÃ“N INMEDIATA REQUERIDA:")
    print("   1. Eliminar duplicaciones")
    print("   2. Ejecutar cÃ³digo de prueba sugerido")
    print("   3. Validar que cada modelo recibe sus features correctas")

if __name__ == "__main__":
    code_review() 