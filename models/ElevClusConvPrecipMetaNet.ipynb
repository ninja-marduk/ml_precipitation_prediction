{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827c19f7",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/feature%2Fhybrid-models/models/hybrid_models_enconders_layering_w3_ST-HybridWaveStack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43abece5",
   "metadata": {},
   "source": [
    "# Meta-Modelo Convolucional: ElevClusConvPrecipMetaNet\n",
    "\n",
    "Este modelo implementa una arquitectura convolucional avanzada para la predicción espaciotemporal de precipitación con horizonte de 12 meses.\n",
    "\n",
    "## Arquitectura\n",
    "\n",
    "1. **Entradas**:\n",
    "   - Mapas de predicción de los modelos base (ConvBiGRU-AE y ConvLSTM-AE) para cada horizonte (12 meses)\n",
    "   - Información de elevación y clusters para condicionamiento (FiLM)\n",
    "\n",
    "2. **Reducción Temprana de Canales**:\n",
    "   - Reduce los 24 canales (2 modelos × 12 horizontes) a 16 para optimizar memoria\n",
    "   - Aplica Conv2D(1×1) para mezclar información sin perder resolución espacial\n",
    "\n",
    "3. **Bloques Residuales Multiescala**:\n",
    "   - Bloques depthwise-separables con distintas dilataciones (1,2,4)\n",
    "   - Captura patrones a diferentes escalas espaciales sin incrementar parámetros\n",
    "\n",
    "4. **Atención Espacial por Cluster**:\n",
    "   - FiLM (Feature-wise Linear Modulation): γ_cluster ⊗ F + β_cluster\n",
    "   - Adapta el comportamiento según el régimen orográfico\n",
    "\n",
    "5. **U-Net Compacto**:\n",
    "   - Arquitectura de encoder-decoder con skip connections\n",
    "   - Solo 2 niveles de downsampling para preservar detalle\n",
    "\n",
    "6. **Agrupamiento de Horizontes**:\n",
    "   - Conv3D para procesar conjuntamente la dimensión temporal de horizontes\n",
    "   - Permite aprender relaciones entre meses consecutivos\n",
    "\n",
    "7. **Salida Multi-Horizonte**:\n",
    "   - Genera los 12 mapas refinados de predicción\n",
    "\n",
    "8. **Estrategias Memory-Friendly**:\n",
    "   - Mixed precision (float16)\n",
    "   - Gradient checkpointing\n",
    "   - Acumulación de gradientes\n",
    "   - Entrenamiento por etapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción Espaciotemporal de Precipitación Mensual - Notebook Completo\n",
    "\n",
    "# 0) Configuración del entorno, rutas y dependencias\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import joblib  # Para persistir scalers\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def log_and_print(msg):\n",
    "    logger.info(msg)\n",
    "    print(msg)\n",
    "\n",
    "# Detectar entorno (Colab o local)\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "log_and_print(f\"Ejecutando en Colab: {IN_COLAB}\")\n",
    "\n",
    "# Definir rutas base\n",
    "desired_repo = 'ml_precipitation_prediction'\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_PATH = Path('/content/drive/MyDrive') / desired_repo\n",
    "    if not Path(desired_repo).exists():\n",
    "        log_and_print(\"Clonando repositorio...\")\n",
    "        get_ipython().system('git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git')\n",
    "    os.chdir(desired_repo)\n",
    "    get_ipython().system('pip install -q xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open cartopy geopandas joblib')\n",
    "else:\n",
    "    # Instalación más simple sin PyEMD\n",
    "    %pip install -q xarray netCDF4 scikit-image\n",
    "    current = Path.cwd()\n",
    "    for p in [current] + list(current.parents):\n",
    "        if (p / '.git').is_dir() or (p / 'requirements.txt').is_file() or (p / 'README.md').is_file():\n",
    "            BASE_PATH = p\n",
    "            break\n",
    "    else:\n",
    "        BASE_PATH = current\n",
    "    log_and_print(f\"Ejecutando en local. Base path: {BASE_PATH}\")\n",
    "\n",
    "# Rutas de datos y modelos\n",
    "DATA_OUTPUT   = BASE_PATH / 'data' / 'output'\n",
    "MODELS_OUTPUT = BASE_PATH / 'models' / 'output'\n",
    "PREDS_DIR     = MODELS_OUTPUT / 'base_model_predictions'\n",
    "SHP_PATH      = BASE_PATH / 'data' / 'input' / 'shapes' / 'MGN_Departamento.shp'\n",
    "\n",
    "# Crear directorios\n",
    "MODELS_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "PREDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parámetros generales\n",
    "INPUT_WINDOW   = 60\n",
    "OUTPUT_HORIZON = 12  # 12 meses\n",
    "BATCH_SIZE     = 16\n",
    "MAX_EPOCHS     = 300\n",
    "PATIENCE       = 50\n",
    "LR             = 1e-3\n",
    "\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log_and_print(f\"Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "\n",
    "# 1) Imports adicionales y utilidades\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature  # Añadido para características cartográficas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler # Mixed precision training\n",
    "from torch.utils.checkpoint import checkpoint # Gradient checkpointing\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  # Añadido para learning rate adaptativo\n",
    "from IPython.display import clear_output  # Para actualizar gráficos durante entrenamiento\n",
    "import pywt\n",
    "from scipy.signal import hilbert\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "# 2) Carga y preprocesamiento de datos - Versión simplificada\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    log_and_print(\"Cargando datos...\")\n",
    "    \n",
    "    # Cargar datos completos\n",
    "    ds_full = xr.open_dataset(DATA_OUTPUT / 'complete_dataset_with_features_with_clusters_elevation_with_windows.nc')\n",
    "    log_and_print(f\"Dataset completo cargado, dims: {ds_full.dims}\")\n",
    "    \n",
    "    # Cargar componentes directamente de archivos específicos\n",
    "    ds_ceemdan = xr.open_dataset(MODELS_OUTPUT / 'features_CEEMDAN.nc')\n",
    "    log_and_print(f\"Dataset CEEMDAN cargado, dims: {ds_ceemdan.dims}\")\n",
    "    log_and_print(f\"Variables disponibles en CEEMDAN: {list(ds_ceemdan.data_vars.keys())}\")\n",
    "    \n",
    "    ds_tvfemd = xr.open_dataset(MODELS_OUTPUT / 'features_TVFEMD.nc')\n",
    "    log_and_print(f\"Dataset TVF-EMD cargado, dims: {ds_tvfemd.dims}\")\n",
    "    log_and_print(f\"Variables disponibles en TVF-EMD: {list(ds_tvfemd.data_vars.keys())}\")\n",
    "    \n",
    "    # Cargar shapefile para visualizaciones\n",
    "    gdf = gpd.read_file(SHP_PATH)\n",
    "    if gdf.crs is None:\n",
    "        gdf = gdf.set_crs(epsg=4326)\n",
    "    elif gdf.crs.to_epsg() != 4326:\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "    log_and_print(\"Shapefile cargado y CRS validado.\")\n",
    "\n",
    "    # Extraer información temporal\n",
    "    times = ds_full.time.values.astype('datetime64[M]')\n",
    "    REF = np.datetime64('2024-02','M')\n",
    "    idx_ref = int(np.where(times==REF)[0][0])\n",
    "    log_and_print(f\"Referencia (REF) = {REF}, index={idx_ref}\")\n",
    "    \n",
    "    return ds_full, ds_ceemdan, ds_tvfemd, gdf, times, REF, idx_ref\n",
    "\n",
    "# Ejecutar carga/preproc con los archivos específicos\n",
    "ds_full, ds_ceemdan, ds_tvfemd, gdf, times, REF, idx_ref = load_and_preprocess_data()\n",
    "\n",
    "# Mantenemos sólo las funciones de preprocesamiento que aún se necesitan\n",
    "def calculate_afc(signal, lags=[1, 3, 6]):\n",
    "    \"\"\"Calcula la Función de Autocorrelación para los lags dados.\"\"\"\n",
    "    afc = [np.correlate(signal[lag:], signal[:-lag], mode='valid') for lag in lags]\n",
    "    return afc\n",
    "\n",
    "# Funciones de preprocesamiento adicionales\n",
    "def wavelet_denoise(data, wavelet='db4', level=3):\n",
    "    \"\"\"Aplica denoising wavelet a los datos.\"\"\"\n",
    "    try:\n",
    "        # API moderna de scikit-image (0.19+)\n",
    "        return denoise_wavelet(\n",
    "            data, \n",
    "            wavelet=wavelet, \n",
    "            mode='soft',\n",
    "            method='BayesShrink',\n",
    "            channel_axis=None\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en wavelet denoising: {str(e)}. Intentando método alternativo.\")\n",
    "        # Si falla, intentar solo con parámetros básicos\n",
    "        return denoise_wavelet(data, wavelet=wavelet)\n",
    "\n",
    "# 3) Definición de Datasets PyTorch\n",
    "class PrecipitationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para datos de precipitación que maneja la reducción\n",
    "    de dimensionalidad y garantiza la compatibilidad dimensional.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, target, seq_length):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).float()\n",
    "        self.seq_length = seq_length\n",
    "        self.target_shape = target.shape[1:]  # Guardar la forma objetivo (height, width)\n",
    "        \n",
    "        print(f\"Dataset inicializado - Forma de datos: {self.data.shape}\")\n",
    "        print(f\"Dataset inicializado - Forma de targets: {self.target.shape}\")\n",
    "        print(f\"Forma objetivo almacenada: {self.target_shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener secuencia de datos\n",
    "        inputs = self.data[idx:idx+self.seq_length]\n",
    "        labels = self.target[idx:idx+self.seq_length]\n",
    "        \n",
    "        # Para debugging, imprimir formas solo para el primer elemento\n",
    "        if idx == 0:\n",
    "            print(f\"Ejemplo de entrada - forma original: {inputs.shape}\")\n",
    "            \n",
    "        # Simplificar dimensiones si es posible\n",
    "        if len(inputs.shape) > 3 and inputs.shape[1] == 1:  # Si hay una sola ventana/característica\n",
    "            inputs = inputs.squeeze(1)  # Eliminar dimensión redundante \n",
    "            \n",
    "        # Para debugging\n",
    "        if idx == 0:\n",
    "            print(f\"Ejemplo de entrada - forma final: {inputs.shape}\")\n",
    "            print(f\"Ejemplo de etiqueta: {labels.shape}\")\n",
    "            \n",
    "        return inputs, labels\n",
    "\n",
    "# 4) Modelos Híbridos: ConvBiGRU-AE y ConvLSTM-AE\n",
    "class ConvBiGRU_AE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, num_layers, output_channels, seq_length, target_shape=(61, 65), kernel_size=3, padding=1):\n",
    "        super(ConvBiGRU_AE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.target_shape = target_shape  # Guardar la forma objetivo\n",
    "        \n",
    "        # Encoder - Convoluciones 2D para cada paso de tiempo\n",
    "        # En lugar de esperar múltiples canales, procesaremos cada paso de tiempo independientemente\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm2 = nn.InstanceNorm2d(hidden_dim)\n",
    "        \n",
    "        # GRU para procesar la secuencia comprimida\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.dnorm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_dim, output_channels * seq_length, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        # Usar la forma objetivo proporcionada o la predeterminada\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "        \n",
    "        # x tiene forma [batch_size, seq_length, height, width]\n",
    "        batch_size, seq_len, H, W = x.size()\n",
    "        \n",
    "        # Procesar cada paso de tiempo individualmente\n",
    "        processed_features = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Obtener el paso de tiempo actual y añadir dimensión de canal\n",
    "            x_t = x[:, t].unsqueeze(1)  # [batch_size, 1, height, width]\n",
    "            \n",
    "            # Aplicar convoluciones\n",
    "            x_t = F.relu(self.norm1(self.conv1(x_t)))\n",
    "            x_t = F.relu(self.norm2(self.conv2(x_t)))\n",
    "            \n",
    "            # Extraer características globales\n",
    "            # Promedio espacial para reducir a [batch_size, hidden_dim]\n",
    "            x_t_features = x_t.mean(dim=(2, 3))\n",
    "            \n",
    "            # Almacenar características para este paso de tiempo\n",
    "            processed_features.append(x_t_features)\n",
    "        \n",
    "        # Concatenar características para todos los pasos de tiempo\n",
    "        sequence_features = torch.stack(processed_features, dim=1)  # [batch_size, seq_length, hidden_dim]\n",
    "        \n",
    "        # Aplicar GRU a la secuencia\n",
    "        output, _ = self.gru(sequence_features)  # [batch_size, seq_length, hidden_dim*2]\n",
    "        \n",
    "        # Tomar el último estado y preparar para deconv\n",
    "        output = output[:, -1, :].view(batch_size, self.hidden_dim*2, 1, 1)\n",
    "        output = F.interpolate(output, size=(H, W), mode='nearest')\n",
    "        \n",
    "        # Decoder\n",
    "        output = F.relu(self.dnorm1(self.deconv1(output)))\n",
    "        output = self.deconv2(output)  # [batch_size, seq_length*output_channels, H, W]\n",
    "        \n",
    "        # Reorganizar para obtener [batch_size, seq_length, output_channels, H, W]\n",
    "        output = output.view(batch_size, self.seq_length, self.output_channels, H, W)\n",
    "        \n",
    "        # Redimensionar a la forma objetivo usando interpolación bilineal\n",
    "        # Primero reorganizamos para [batch_size*seq_length, output_channels, H, W]\n",
    "        output_reshaped = output.view(batch_size * self.seq_length, self.output_channels, H, W)\n",
    "        output_resized = F.interpolate(output_reshaped, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Reorganizar de nuevo a [batch_size, seq_length, output_channels, target_H, target_W]\n",
    "        output = output_resized.view(batch_size, self.seq_length, self.output_channels, target_shape[0], target_shape[1])\n",
    "        \n",
    "        return output\n",
    "\n",
    "class ConvBiLSTM_AE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, num_layers, output_channels, seq_length, target_shape=(61, 65), kernel_size=3, padding=1):\n",
    "        super(ConvBiLSTM_AE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.target_shape = target_shape  # Guardar la forma objetivo\n",
    "        \n",
    "        # Encoder para procesar cada paso de tiempo individualmente\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm2 = nn.InstanceNorm2d(hidden_dim)\n",
    "        \n",
    "        # LSTM para procesar la secuencia\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.dnorm1 = nn.InstanceNorm2d(hidden_dim)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_dim, output_channels * seq_length, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        # Usar la forma objetivo proporcionada o la predeterminada\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "            \n",
    "        # x tiene forma [batch_size, seq_length, height, width]\n",
    "        batch_size, seq_len, H, W = x.size()\n",
    "        \n",
    "        # Procesar cada paso de tiempo individualmente\n",
    "        processed_features = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Obtener el paso de tiempo actual y añadir dimensión de canal\n",
    "            x_t = x[:, t].unsqueeze(1)  # [batch_size, 1, height, width]\n",
    "            \n",
    "            # Aplicar convoluciones\n",
    "            x_t = F.relu(self.norm1(self.conv1(x_t)))\n",
    "            x_t = F.relu(self.norm2(self.conv2(x_t)))\n",
    "            \n",
    "            # Extraer características globales\n",
    "            # Promedio espacial para reducir a [batch_size, hidden_dim]\n",
    "            x_t_features = x_t.mean(dim=(2, 3))\n",
    "            \n",
    "            # Almacenar características para este paso de tiempo\n",
    "            processed_features.append(x_t_features)\n",
    "        \n",
    "        # Concatenar características para todos los pasos de tiempo\n",
    "        sequence_features = torch.stack(processed_features, dim=1)  # [batch_size, seq_length, hidden_dim]\n",
    "        \n",
    "        # Aplicar LSTM a la secuencia\n",
    "        output, _ = self.lstm(sequence_features)  # [batch_size, seq_length, hidden_dim*2]\n",
    "        \n",
    "        # Tomar el último estado y preparar para deconv\n",
    "        output = output[:, -1, :].view(batch_size, self.hidden_dim*2, 1, 1)\n",
    "        output = F.interpolate(output, size=(H, W), mode='nearest')\n",
    "        \n",
    "        # Decoder\n",
    "        output = F.relu(self.dnorm1(self.deconv1(output)))\n",
    "        output = self.deconv2(output)  # [batch_size, seq_length*output_channels, H, W]\n",
    "        \n",
    "        # Reorganizar para obtener [batch_size, seq_length, output_channels, H, W]\n",
    "        output = output.view(batch_size, self.seq_length, self.output_channels, H, W)\n",
    "        \n",
    "        # Redimensionar a la forma objetivo usando interpolación bilineal\n",
    "        output_reshaped = output.view(batch_size * self.seq_length, self.output_channels, H, W)\n",
    "        output_resized = F.interpolate(output_reshaped, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        output = output_resized.view(batch_size, self.seq_length, self.output_channels, target_shape[0], target_shape[1])\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 4.5) Modelos ConvGRU y ConvLSTM simples para comparación\n",
    "class SimpleConvGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo simple ConvGRU para comparar con los modelos híbridos.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_dim, output_channels, seq_length=12, target_shape=(61, 65)):\n",
    "        super(SimpleConvGRU, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.seq_length = seq_length\n",
    "        self.target_shape = target_shape\n",
    "        \n",
    "        # Capas convolucionales para procesar entrada\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_dim // 2, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_dim // 2)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim // 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        \n",
    "        # Capa GRU\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_dim * target_shape[0] * target_shape[1], \n",
    "            hidden_size=hidden_dim * 4, \n",
    "            num_layers=2, \n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Capas para generar salida\n",
    "        self.upconv1 = nn.Conv2d(hidden_dim * 4, hidden_dim * 2, kernel_size=3, padding=1)\n",
    "        self.upbn1 = nn.BatchNorm2d(hidden_dim * 2)\n",
    "        self.upconv2 = nn.Conv2d(hidden_dim * 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.upbn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        \n",
    "        # Capa final para generar múltiples horizontes de predicción\n",
    "        self.out_conv = nn.Conv2d(hidden_dim, output_channels * seq_length, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor de entrada que puede tener varias formas:\n",
    "               - [batch_size, seq_len, input_window, channels, height, width]\n",
    "               - [batch_size, seq_len, channels, height, width]\n",
    "               - [batch_size, channels, height, width]\n",
    "            target_shape: Forma objetivo para la salida\n",
    "        \"\"\"\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "        \n",
    "        # NUEVO: Manejar el caso de 6 dimensiones [batch, seq, window, channel, H, W]\n",
    "        if len(x.shape) == 6:  \n",
    "            batch_size, seq_len, window, channels, H, W = x.shape\n",
    "            \n",
    "            # Reorganizar a [batch, seq, channels*window, H, W] combinando window y channels\n",
    "            x = x.permute(0, 1, 3, 2, 4, 5).contiguous()  # [batch, seq, channel, window, H, W]\n",
    "            x = x.view(batch_size, seq_len, channels*window, H, W)  # [batch, seq, channel*window, H, W]\n",
    "            \n",
    "            # Procesar cada paso de tiempo independientemente\n",
    "            processed_features = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                # Extraer slice temporal: [batch, channels*window, H, W]\n",
    "                xt = x[:, t]\n",
    "                \n",
    "                # Aplicar convoluciones\n",
    "                xt = F.relu(self.bn1(self.conv1(xt)))\n",
    "                xt = F.relu(self.bn2(self.conv2(xt)))\n",
    "                \n",
    "                # Aplanar para GRU: [batch, hidden_dim*H*W]\n",
    "                xt = xt.view(batch_size, -1)\n",
    "                processed_features.append(xt)\n",
    "            \n",
    "            # Stack para secuencia: [batch, seq_len, features]\n",
    "            x_sequence = torch.stack(processed_features, dim=1)\n",
    "            \n",
    "            # Aplicar GRU\n",
    "            gru_out, _ = self.gru(x_sequence)\n",
    "            \n",
    "            # Tomar último estado\n",
    "            last_out = gru_out[:, -1]  # [batch, hidden_dim*4]\n",
    "            \n",
    "        # Verificar y manejar diferentes formas de entrada\n",
    "        elif len(x.shape) == 5:  # [batch, seq_len, channels, height, width]\n",
    "            batch_size = x.size(0)\n",
    "            seq_len = x.size(1)\n",
    "            \n",
    "            # Procesar cada paso de tiempo independientemente\n",
    "            processed_features = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                # Extraer slice temporal: [batch, channels, H, W]\n",
    "                xt = x[:, t]\n",
    "                \n",
    "                # Aplicar convoluciones\n",
    "                xt = F.relu(self.bn1(self.conv1(xt)))\n",
    "                xt = F.relu(self.bn2(self.conv2(xt)))\n",
    "                \n",
    "                # Aplanar para GRU: [batch, hidden_dim*H*W]\n",
    "                xt = xt.view(batch_size, -1)\n",
    "                processed_features.append(xt)\n",
    "            \n",
    "            # Stack para secuencia: [batch, seq_len, features]\n",
    "            x_sequence = torch.stack(processed_features, dim=1)\n",
    "            \n",
    "            # Aplicar GRU\n",
    "            gru_out, _ = self.gru(x_sequence)\n",
    "            \n",
    "            # Tomar último estado\n",
    "            last_out = gru_out[:, -1]  # [batch, hidden_dim*4]\n",
    "            \n",
    "        elif len(x.shape) == 4:  # [batch, channels, height, width] (sin dimensión de secuencia)\n",
    "            batch_size = x.size(0)\n",
    "            \n",
    "            # Aplicar convoluciones directamente\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = F.relu(self.bn2(self.conv2(x)))\n",
    "            \n",
    "            # Aplanar\n",
    "            x_flat = x.view(batch_size, -1)\n",
    "            \n",
    "            # Añadir dimensión de secuencia ficticia\n",
    "            x_sequence = x_flat.unsqueeze(1)  # [batch, 1, features]\n",
    "            \n",
    "            # Aplicar GRU\n",
    "            gru_out, _ = self.gru(x_sequence)\n",
    "            \n",
    "            # Tomar salida\n",
    "            last_out = gru_out[:, -1]  # [batch, hidden_dim*4]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Forma de entrada no soportada: {x.shape}\")\n",
    "        \n",
    "        # Reformar para procesamiento convolucional\n",
    "        last_out = last_out.view(batch_size, self.hidden_dim * 4, 1, 1)\n",
    "        last_out = F.interpolate(last_out, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Capas finales\n",
    "        out = F.relu(self.upbn1(self.upconv1(last_out)))\n",
    "        out = F.relu(self.upbn2(self.upconv2(out)))\n",
    "        out = self.out_conv(out)\n",
    "        \n",
    "        # Reorganizar para obtener [batch, seq_len, channels, H, W]\n",
    "        out = out.view(batch_size, self.seq_length, self.output_channels, *target_shape)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "class SimpleConvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo simple ConvLSTM para comparar con los modelos híbridos.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_dim, output_channels, seq_length=12, target_shape=(61, 65)):\n",
    "        super(SimpleConvLSTM, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_channels = output_channels\n",
    "        self.seq_length = seq_length\n",
    "        self.target_shape = target_shape\n",
    "        \n",
    "        # Capas convolucionales para procesar entrada\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_dim // 2, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_dim // 2)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim // 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        \n",
    "        # Capa LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim * target_shape[0] * target_shape[1], \n",
    "            hidden_size=hidden_dim * 4, \n",
    "            num_layers=2, \n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Capas para generar salida\n",
    "        self.upconv1 = nn.Conv2d(hidden_dim * 4, hidden_dim * 2, kernel_size=3, padding=1)\n",
    "        self.upbn1 = nn.BatchNorm2d(hidden_dim * 2)\n",
    "        self.upconv2 = nn.Conv2d(hidden_dim * 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.upbn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        \n",
    "        # Capa final para generar múltiples horizontes de predicción\n",
    "        self.out_conv = nn.Conv2d(hidden_dim, output_channels * seq_length, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, target_shape=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor de entrada que puede tener varias formas:\n",
    "               - [batch_size, seq_len, input_window, channels, height, width]\n",
    "               - [batch_size, seq_len, channels, height, width]\n",
    "               - [batch_size, channels, height, width]\n",
    "            target_shape: Forma objetivo para la salida\n",
    "        \"\"\"\n",
    "        if target_shape is None:\n",
    "            target_shape = self.target_shape\n",
    "            \n",
    "        # NUEVO: Manejar el caso de 6 dimensiones [batch, seq, window, channel, H, W]\n",
    "        if len(x.shape) == 6:  \n",
    "            batch_size, seq_len, window, channels, H, W = x.shape\n",
    "            \n",
    "            # Reorganizar a [batch, seq, channels*window, H, W] combinando window y channels\n",
    "            x = x.permute(0, 1, 3, 2, 4, 5).contiguous()  # [batch, seq, channel, window, H, W]\n",
    "            x = x.view(batch_size, seq_len, channels*window, H, W)  # [batch, seq, channel*window, H, W]\n",
    "            \n",
    "            # Procesar cada paso de tiempo independientemente\n",
    "            processed_features = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                # Extraer slice temporal: [batch, channels*window, H, W]\n",
    "                xt = x[:, t]\n",
    "                \n",
    "                # Aplicar convoluciones\n",
    "                xt = F.relu(self.bn1(self.conv1(xt)))\n",
    "                xt = F.relu(self.bn2(self.conv2(xt)))\n",
    "                \n",
    "                # Aplanar para LSTM: [batch, hidden_dim*H*W]\n",
    "                xt = xt.view(batch_size, -1)\n",
    "                processed_features.append(xt)\n",
    "            \n",
    "            # Stack para secuencia: [batch, seq_len, features]\n",
    "            x_sequence = torch.stack(processed_features, dim=1)\n",
    "            \n",
    "            # Aplicar LSTM\n",
    "            lstm_out, _ = self.lstm(x_sequence)\n",
    "            \n",
    "            # Tomar último estado\n",
    "            last_out = lstm_out[:, -1]  # [batch, hidden_dim*4]\n",
    "            \n",
    "        # Verificar y manejar diferentes formas de entrada\n",
    "        elif len(x.shape) == 5:  # [batch, seq_len, channels, height, width]\n",
    "            batch_size = x.size(0)\n",
    "            seq_len = x.size(1)\n",
    "            \n",
    "            # Procesar cada paso de tiempo independientemente\n",
    "            processed_features = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                # Extraer slice temporal: [batch, channels, H, W]\n",
    "                xt = x[:, t]\n",
    "                \n",
    "                # Aplicar convoluciones\n",
    "                xt = F.relu(self.bn1(self.conv1(xt)))\n",
    "                xt = F.relu(self.bn2(self.conv2(xt)))\n",
    "                \n",
    "                # Aplanar para LSTM: [batch, hidden_dim*H*W]\n",
    "                xt = xt.view(batch_size, -1)\n",
    "                processed_features.append(xt)\n",
    "            \n",
    "            # Stack para secuencia: [batch, seq_len, features]\n",
    "            x_sequence = torch.stack(processed_features, dim=1)\n",
    "            \n",
    "            # Aplicar LSTM\n",
    "            lstm_out, _ = self.lstm(x_sequence)\n",
    "            \n",
    "            # Tomar último estado\n",
    "            last_out = lstm_out[:, -1]  # [batch, hidden_dim*4]\n",
    "            \n",
    "        elif len(x.shape) == 4:  # [batch, channels, height, width] (sin dimensión de secuencia)\n",
    "            batch_size = x.size(0)\n",
    "            \n",
    "            # Aplicar convoluciones directamente\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = F.relu(self.bn2(self.conv2(x)))\n",
    "            \n",
    "            # Aplanar\n",
    "            x_flat = x.view(batch_size, -1)\n",
    "            \n",
    "            # Añadir dimensión de secuencia ficticia\n",
    "            x_sequence = x_flat.unsqueeze(1)  # [batch, 1, features]\n",
    "            \n",
    "            # Aplicar LSTM\n",
    "            lstm_out, _ = self.lstm(x_sequence)\n",
    "            \n",
    "            # Tomar salida\n",
    "            last_out = lstm_out[:, -1]  # [batch, hidden_dim*4]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Forma de entrada no soportada: {x.shape}\")\n",
    "        \n",
    "        # Reformar para procesamiento convolucional\n",
    "        last_out = last_out.view(batch_size, self.hidden_dim * 4, 1, 1)\n",
    "        last_out = F.interpolate(last_out, size=target_shape, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Capas finales\n",
    "        out = F.relu(self.upbn1(self.upconv1(last_out)))\n",
    "        out = F.relu(self.upbn2(self.upconv2(out)))\n",
    "        out = self.out_conv(out)\n",
    "        \n",
    "        # Reorganizar para obtener [batch, seq_len, channels, H, W]\n",
    "        out = out.view(batch_size, self.seq_length, self.output_channels, *target_shape)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Función para entrenar y evaluar todos los modelos disponibles\n",
    "def train_and_compare_models(X_train, y_train, X_val, y_val, force_retrain=False):\n",
    "    \"\"\"\n",
    "    Entrena y compara modelos simples y híbridos usando las mismas entradas.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Datos de entrenamiento\n",
    "        y_train: Etiquetas de entrenamiento\n",
    "        X_val: Datos de validación\n",
    "        y_val: Etiquetas de validación\n",
    "        force_retrain: Si reentrenar aunque existan modelos guardados\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con modelos entrenados y sus métricas\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ENTRENAMIENTO Y COMPARACIÓN DE MODELOS SIMPLES Y HÍBRIDOS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Directorios para guardar modelos\n",
    "    models_dir = MODELS_OUTPUT / 'comparison_models'\n",
    "    models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Parámetros comunes\n",
    "    input_channels = X_train.shape[1] if len(X_train.shape) > 3 else 1\n",
    "    hidden_dim = 128\n",
    "    output_channels = 1\n",
    "    seq_length = OUTPUT_HORIZON\n",
    "    \n",
    "    # Obtener shape de target si está disponible\n",
    "    if len(y_train.shape) >= 3:\n",
    "        target_shape = y_train.shape[-2:]\n",
    "    else:\n",
    "        target_shape = (61, 65)  # valores por defecto\n",
    "    \n",
    "    print(f\"Configuración común: input_channels={input_channels}, hidden_dim={hidden_dim}, output_channels={output_channels}\")\n",
    "    print(f\"Secuencia: {seq_length}, target_shape: {target_shape}\")\n",
    "    \n",
    "    # Definir los modelos a entrenar con sus rutas de guardado\n",
    "    models = {\n",
    "        'SimpleConvGRU': {\n",
    "            'class': SimpleConvGRU,\n",
    "            'path': models_dir / 'simple_convgru.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'SimpleConvLSTM': {\n",
    "            'class': SimpleConvLSTM,\n",
    "            'path': models_dir / 'simple_convlstm.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'ConvBiGRU-AE': {\n",
    "            'class': ConvBiGRU_AE,\n",
    "            'path': models_dir / 'convbigru_ae.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'num_layers': 3,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        },\n",
    "        'ConvBiLSTM-AE': {\n",
    "            'class': ConvBiLSTM_AE,\n",
    "            'path': models_dir / 'convbilstm_ae.pth',\n",
    "            'params': {\n",
    "                'input_channels': input_channels,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'num_layers': 3,\n",
    "                'output_channels': output_channels,\n",
    "                'seq_length': seq_length,\n",
    "                'target_shape': target_shape\n",
    "            },\n",
    "            'metrics': {},\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Crear datasets y dataloaders\n",
    "    train_dataset = PrecipitationDataset(X_train, y_train, seq_length)\n",
    "    val_dataset = PrecipitationDataset(X_val, y_val, seq_length)\n",
    "    \n",
    "    batch_size = 16\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Iterar sobre cada modelo\n",
    "    for model_name, config in models.items():\n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(f\"PROCESANDO MODELO: {model_name}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        # Verificar si existe modelo guardado\n",
    "        if config['path'].exists() and not force_retrain:\n",
    "            print(f\"Modelo encontrado en {config['path']}, cargando...\")\n",
    "            try:\n",
    "                # Cargar modelo existente\n",
    "                model = config['class'](**config['params']).to(DEVICE)\n",
    "                checkpoint = torch.load(config['path'], map_location=DEVICE)\n",
    "                \n",
    "                # Verificar contenido del checkpoint\n",
    "                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "                    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                    config['train_losses'] = checkpoint.get('train_losses', [])\n",
    "                    config['val_losses'] = checkpoint.get('val_losses', [])\n",
    "                else:\n",
    "                    # Formato antiguo (solo state_dict)\n",
    "                    model.load_state_dict(checkpoint)\n",
    "                \n",
    "                print(f\"✅ Modelo {model_name} cargado correctamente\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error al cargar modelo: {str(e)}\")\n",
    "                print(\"Entrenando el modelo desde cero...\")\n",
    "                \n",
    "                # Instanciar modelo\n",
    "                model = config['class'](**config['params']).to(DEVICE)\n",
    "                \n",
    "                # Configurar entrenamiento\n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "                scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "                \n",
    "                # Entrenar modelo\n",
    "                model, train_losses, val_losses = train_hybrid_model(\n",
    "                    name=model_name,\n",
    "                    model=model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    epochs=100,\n",
    "                    patience=20,\n",
    "                    optimizer=optimizer,\n",
    "                    criterion=criterion,\n",
    "                    scheduler=scheduler\n",
    "                )\n",
    "                \n",
    "                # Guardar historial de pérdidas\n",
    "                config['train_losses'] = train_losses\n",
    "                config['val_losses'] = val_losses\n",
    "                \n",
    "                # Guardar modelo\n",
    "                save_data = {\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses\n",
    "                }\n",
    "                torch.save(save_data, config['path'])\n",
    "        else:\n",
    "            # Entrenar modelo\n",
    "            print(f\"Entrenando {model_name} desde cero...\")\n",
    "            \n",
    "            # Instanciar modelo\n",
    "            model = config['class'](**config['params']).to(DEVICE)\n",
    "            \n",
    "            # Configurar entrenamiento\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "            \n",
    "            # Entrenar modelo\n",
    "            model, train_losses, val_losses = train_hybrid_model(\n",
    "                name=model_name,\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                epochs=100,\n",
    "                patience=20,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                scheduler=scheduler\n",
    "            )\n",
    "            \n",
    "            # Guardar historial de pérdidas\n",
    "            config['train_losses'] = train_losses\n",
    "            config['val_losses'] = val_losses\n",
    "            \n",
    "            # Guardar modelo\n",
    "            save_data = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses\n",
    "            }\n",
    "            torch.save(save_data, config['path'])\n",
    "        \n",
    "        # Evaluar modelo con métricas adicionales\n",
    "        print(f\"Evaluando {model_name} con métricas adicionales...\")\n",
    "        model.eval()\n",
    "        \n",
    "        all_targets = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Asegurar dimensión de canal si es necesario\n",
    "                if len(outputs.shape) == 5 and outputs.shape[2] == 1:\n",
    "                    outputs = outputs.squeeze(2)\n",
    "                \n",
    "                # Transformar a numpy para métricas\n",
    "                preds = outputs.cpu().numpy()\n",
    "                targets_np = targets.numpy()\n",
    "                \n",
    "                # Almacenar para métricas globales\n",
    "                all_targets.append(targets_np)\n",
    "                all_preds.append(preds)\n",
    "        \n",
    "        # Concatenar todas las predicciones y targets\n",
    "        all_targets = np.concatenate(all_targets, axis=0)\n",
    "        all_preds = np.concatenate(all_preds, axis=0)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        # Aplanar para métricas generales\n",
    "        flat_targets = all_targets.flatten()\n",
    "        flat_preds = all_preds.flatten()\n",
    "        \n",
    "        # Eliminar valores NaN si existen\n",
    "        mask = ~np.isnan(flat_targets) & ~np.isnan(flat_preds)\n",
    "        flat_targets = flat_targets[mask]\n",
    "        flat_preds = flat_preds[mask]\n",
    "        \n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(flat_targets, flat_preds)\n",
    "        rmse = np.sqrt(mean_squared_error(flat_targets, flat_preds))\n",
    "        r2 = r2_score(flat_targets, flat_preds)\n",
    "        corr = np.corrcoef(flat_targets, flat_preds)[0, 1]\n",
    "        \n",
    "        # Calcular MAPE evitando divisiones por cero\n",
    "        mask_nonzero = flat_targets != 0\n",
    "        mape = np.mean(np.abs((flat_targets[mask_nonzero] - flat_preds[mask_nonzero]) / flat_targets[mask_nonzero])) * 100\n",
    "        \n",
    "        # Almacenar métricas\n",
    "        config['metrics'] = {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape,\n",
    "            'r': corr,\n",
    "            'R²': r2\n",
    "        }\n",
    "        \n",
    "        # Almacenar modelo en el diccionario\n",
    "        config['model'] = model\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print(f\"\\nMétricas para {model_name}:\")\n",
    "        print(f\"  MAE: {mae:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  r (correlación): {corr:.4f}\")\n",
    "        print(f\"  R²: {r2:.4f}\")\n",
    "    \n",
    "    # Devolver diccionario con todos los modelos y resultados\n",
    "    return models\n",
    "\n",
    "# Función para generar visualizaciones comparativas\n",
    "def visualize_model_comparisons(models_dict):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones comparativas para todos los modelos\n",
    "    \n",
    "    Args:\n",
    "        models_dict: Diccionario con modelos y sus métricas\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERANDO VISUALIZACIONES COMPARATIVAS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Crear directorio para visualizaciones\n",
    "    vis_dir = MODELS_OUTPUT / 'visualization' / 'comparisons'\n",
    "    vis_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # 1. Tabla comparativa de métricas\n",
    "    model_names = list(models_dict.keys())\n",
    "    metrics = ['MAE', 'RMSE', 'MAPE (%)', 'r', 'R²']\n",
    "    \n",
    "    # Crear DataFrame para tabla\n",
    "    metrics_data = {metric: [] for metric in metrics}\n",
    "    metrics_data['Modelo'] = model_names\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        for metric in metrics:\n",
    "            value = models_dict[model_name]['metrics'].get(metric, np.nan)\n",
    "            metrics_data[metric].append(value)\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    # Mostrar tabla\n",
    "    print(\"\\n📊 TABLA COMPARATIVA DE MÉTRICAS\")\n",
    "    print(metrics_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "    \n",
    "    # Guardar como CSV\n",
    "    metrics_csv_path = vis_dir / 'metrics_comparison.csv'\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False, float_format='%.4f')\n",
    "    print(f\"\\nTabla guardada en {metrics_csv_path}\")\n",
    "    \n",
    "    # 2. Gráfico de barras comparativo de métricas\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Iterar sobre las métricas\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        values = [models_dict[model]['metrics'].get(metric, np.nan) for model in model_names]\n",
    "        \n",
    "        # Crear gráfico de barras\n",
    "        bars = plt.bar(model_names, values)\n",
    "        \n",
    "        # Añadir etiquetas de valor sobre cada barra\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{value:.4f}',\n",
    "                    ha='center', va='bottom', rotation=0, fontsize=9)\n",
    "        \n",
    "        plt.title(f'Comparación de {metric}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(alpha=0.3, axis='y')\n",
    "        \n",
    "        # Para métricas donde menor es mejor, destacar el mejor modelo\n",
    "        if metric in ['MAE', 'RMSE', 'MAPE (%)']:\n",
    "            best_idx = np.nanargmin(values)\n",
    "            bars[best_idx].set_color('green')\n",
    "        else:  # Para métricas donde mayor es mejor\n",
    "            best_idx = np.nanargmax(values)\n",
    "            bars[best_idx].set_color('green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    metrics_plot_path = vis_dir / 'metrics_comparison.png'\n",
    "    plt.savefig(metrics_plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico de métricas guardado en {metrics_plot_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Curvas de aprendizaje comparativas\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Pérdidas de entrenamiento\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for model_name in model_names:\n",
    "        train_losses = models_dict[model_name].get('train_losses', [])\n",
    "        if train_losses:\n",
    "            plt.plot(train_losses, label=model_name)\n",
    "    \n",
    "    plt.title('Pérdidas de Entrenamiento')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Pérdidas de validación\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for model_name in model_names:\n",
    "        val_losses = models_dict[model_name].get('val_losses', [])\n",
    "        if val_losses:\n",
    "            plt.plot(val_losses, label=model_name)\n",
    "    \n",
    "    plt.title('Pérdidas de Validación')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    learning_curves_path = vis_dir / 'learning_curves_comparison.png'\n",
    "    plt.savefig(learning_curves_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Curvas de aprendizaje guardadas en {learning_curves_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Mapa de predicciones vs reales y errores para un mes específico\n",
    "    # Generar predicciones\n",
    "    try:\n",
    "        # Cargar datos de validación\n",
    "        val_batch = next(iter(val_loader))\n",
    "        inputs, targets = val_batch\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        \n",
    "        # Seleccionar un mes para visualización (por ejemplo, el tercero)\n",
    "        month_idx = min(2, OUTPUT_HORIZON - 1)  # mes 3 (índice 2) o el último si el horizonte es menor\n",
    "        \n",
    "        plt.figure(figsize=(20, 4 * len(model_names)))\n",
    "        \n",
    "        # Para cada modelo\n",
    "        for i, (model_name, config) in enumerate(models_dict.items()):\n",
    "            model = config['model']\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Ajustar dimensiones\n",
    "                if len(outputs.shape) == 5 and outputs.shape[2] == 1:\n",
    "                    outputs = outputs.squeeze(2)\n",
    "                \n",
    "                # Seleccionar primer batch y mes específico\n",
    "                pred = outputs[0, month_idx].cpu().numpy()\n",
    "                \n",
    "                # Extraer target correspondiente\n",
    "                if len(targets.shape) == 4 and targets.shape[1] > month_idx:\n",
    "                    target = targets[0, month_idx].numpy()\n",
    "                elif len(targets.shape) == 3:\n",
    "                    target = targets[0].numpy()\n",
    "                else:\n",
    "                    target = targets[0, 0].numpy()\n",
    "                    \n",
    "                # Extraer coordenadas para visualización\n",
    "                latitudes = ds_full.latitude.values\n",
    "                longitudes = ds_full.longitude.values\n",
    "                lon_mesh, lat_mesh = np.meshgrid(longitudes, latitudes)\n",
    "                \n",
    "                # Calcular error y métricas\n",
    "                error = pred - target\n",
    "                month_mae = np.mean(np.abs(error))\n",
    "                month_rmse = np.sqrt(np.mean(error**2))\n",
    "                mask_nonzero = target != 0\n",
    "                month_mape = np.mean(np.abs(error[mask_nonzero] / target[mask_nonzero])) * 100 if np.any(mask_nonzero) else np.nan\n",
    "                \n",
    "                # Visualizar\n",
    "                plt.subplot(len(model_names), 3, i*3 + 1)\n",
    "                plt.pcolormesh(lon_mesh, lat_mesh, target)\n",
    "                plt.colorbar(label='Precipitación (mm)')\n",
    "                plt.title(f'Real - Mes {month_idx+1}')\n",
    "                \n",
    "                plt.subplot(len(model_names), 3, i*3 + 2)\n",
    "                plt.pcolormesh(lon_mesh, lat_mesh, pred)\n",
    "                plt.colorbar(label='Precipitación (mm)')\n",
    "                plt.title(f'{model_name} - Predicción')\n",
    "                \n",
    "                plt.subplot(len(model_names), 3, i*3 + 3)\n",
    "                plt.pcolormesh(lon_mesh, lat_mesh, error, cmap='RdBu_r')\n",
    "                plt.colorbar(label='Error (mm)')\n",
    "                plt.title(f'Error - MAE:{month_mae:.2f}, MAPE:{month_mape:.2f}%')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        predictions_path = vis_dir / 'predictions_comparison.png'\n",
    "        plt.savefig(predictions_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Comparación de predicciones guardada en {predictions_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar visualización de predicciones: {str(e)}\")\n",
    "    \n",
    "    return vis_dir\n",
    "\n",
    "# Añadir a la parte principal de ejecución\n",
    "# Preparar datos para entrenamiento y evaluación\n",
    "def prepare_train_val_data(ds_full, input_window=INPUT_WINDOW, output_horizon=OUTPUT_HORIZON):\n",
    "    \"\"\"\n",
    "    Prepara los datos de entrenamiento y validación desde el dataset completo.\n",
    "    \n",
    "    Args:\n",
    "        ds_full: Dataset completo con variables\n",
    "        input_window: Tamaño de la ventana de entrada\n",
    "        output_horizon: Horizonte de predicción\n",
    "    \n",
    "    Returns:\n",
    "        X_train, y_train, X_val, y_val: Arrays de entrenamiento y validación\n",
    "    \"\"\"\n",
    "    print(\"Preparando datos para entrenamiento y validación...\")\n",
    "    \n",
    "    # Extraer precipitación como variable objetivo\n",
    "    # Check if 'precipitacion' exists in the dataset\n",
    "    if 'precipitacion' in ds_full.data_vars:\n",
    "        precip = ds_full.precipitacion.values\n",
    "        print(\"Using 'precipitacion' as target variable\")\n",
    "    # If not, check for 'total_precipitation'\n",
    "    elif 'total_precipitation' in ds_full.data_vars:\n",
    "        precip = ds_full.total_precipitation.values\n",
    "        print(\"Using 'total_precipitation' as target variable\")\n",
    "    else:\n",
    "        # If neither exists, raise an error\n",
    "        raise ValueError(\"Could not find precipitation variable in dataset. Available variables: \" + \n",
    "                        str(list(ds_full.data_vars.keys())))\n",
    "    \n",
    "    # Ensure precip has 3 dimensions (time, lat, lon)\n",
    "    if len(precip.shape) != 3:\n",
    "        raise ValueError(f\"Expected precipitation data to have 3 dimensions (time, lat, lon), got {precip.shape}\")\n",
    "    \n",
    "    n_times, height, width = precip.shape\n",
    "    print(f\"Precipitation data shape: {precip.shape}\")\n",
    "    \n",
    "    # Extraer features, por ejemplo cluster y elevación\n",
    "    features = []\n",
    "    \n",
    "    # Verificar si las features estáticas existen y expandirlas para todas las timesteps\n",
    "    if 'cluster' in ds_full.data_vars:\n",
    "        cluster_data = ds_full.cluster.values\n",
    "        # Si cluster es 2D (lat, lon), expandir a 3D (time, lat, lon)\n",
    "        if len(cluster_data.shape) == 2:\n",
    "            cluster_data = np.repeat(cluster_data[np.newaxis, :, :], n_times, axis=0)\n",
    "        features.append(cluster_data)\n",
    "        print(\"Añadida variable 'cluster', shape:\", cluster_data.shape)\n",
    "    \n",
    "    if 'elevation' in ds_full.data_vars:\n",
    "        elev_data = ds_full.elevation.values\n",
    "        # Si elevation es 2D (lat, lon), expandir a 3D (time, lat, lon)\n",
    "        if len(elev_data.shape) == 2:\n",
    "            elev_data = np.repeat(elev_data[np.newaxis, :, :], n_times, axis=0)\n",
    "        features.append(elev_data)\n",
    "        print(\"Añadida variable 'elevation', shape:\", elev_data.shape)\n",
    "    \n",
    "    # Si no hay features específicas, usar precipitación histórica como feature\n",
    "    if not features:\n",
    "        print(\"No se encontraron features específicas, usando precipitación histórica\")\n",
    "        # Usar precipitación como característica, añadiendo una dimensión de canal\n",
    "        features_array = precip.reshape(n_times, 1, height, width)\n",
    "        print(f\"Shape de features: {features_array.shape}\")\n",
    "    else:\n",
    "        # Concatenar features en un solo array a lo largo de una nueva dimensión (canal)\n",
    "        features_array = np.stack(features, axis=1)\n",
    "        print(f\"Shape de features combinadas: {features_array.shape}\")\n",
    "    \n",
    "    # Crear ventanas deslizantes de manera segura\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(n_times - input_window - output_horizon + 1):\n",
    "        # Input: ventana de datos\n",
    "        X.append(features_array[i:i+input_window].copy())\n",
    "        # Output: horizonte de predicción \n",
    "        y.append(precip[i+input_window:i+input_window+output_horizon].copy())\n",
    "    \n",
    "    # Verificar formas antes de convertir\n",
    "    if not X or not y:\n",
    "        raise ValueError(\"No se pudieron crear ventanas válidas. Verifique los datos de entrada.\")\n",
    "        \n",
    "    # Usar np.stack en lugar de np.array para garantizar arrays homogéneos\n",
    "    X = np.stack(X)\n",
    "    y = np.stack(y)\n",
    "    \n",
    "    print(f\"Datos preparados - X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    \n",
    "    # División train/val (80/20)\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    print(f\"Train shapes - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "    print(f\"Val shapes - X: {X_val.shape}, y: {y_val.shape}\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# Función para entrenar modelos híbridos\n",
    "def train_hybrid_model(name, model, train_loader, val_loader, epochs=100, patience=20, \n",
    "                      optimizer=None, criterion=None, scheduler=None):\n",
    "    \"\"\"\n",
    "    Entrena un modelo híbrido con optimizaciones avanzadas y realiza evaluación\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"ENTRENAMIENTO DE {name}\")\n",
    "    print(f\"{'='*30}\")\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Importar tqdm si no está disponible\n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "    except ImportError:\n",
    "        # Definir una versión simple si no está instalado\n",
    "        def tqdm(iterable, **kwargs):\n",
    "            print(kwargs.get('desc', ''))\n",
    "            return iterable\n",
    "    \n",
    "    # Optimizador y función de pérdida si no fueron proporcionados\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        print(\"Usando optimizador Adam por defecto con lr=1e-3\")\n",
    "    \n",
    "    if criterion is None:\n",
    "        criterion = nn.MSELoss()\n",
    "        print(\"Usando criterio MSELoss por defecto\")\n",
    "    \n",
    "    if scheduler is None:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=10, verbose=True\n",
    "        )\n",
    "        print(\"Usando scheduler ReduceLROnPlateau por defecto\")\n",
    "    \n",
    "    # Tracking de métricas\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Obtener información de las dimensiones de los datos\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    sample_inputs, sample_targets = sample_batch\n",
    "    input_seq_len = sample_inputs.shape[1] if len(sample_inputs.shape) >= 2 else 1\n",
    "    target_seq_len = sample_targets.shape[1] if len(sample_targets.shape) >= 2 else 1\n",
    "    print(f\"INPUT SEQ LEN: {input_seq_len}, TARGET SEQ LEN: {target_seq_len}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        batch_losses = []\n",
    "        \n",
    "        for batch_data in tqdm(train_loader, desc=f\"Época {epoch+1}/{epochs} [Train]\", leave=False):\n",
    "            inputs, targets = batch_data\n",
    "            \n",
    "            # Debugging para el primer batch del epoch inicial\n",
    "            if epoch == 0 and len(batch_losses) == 0:\n",
    "                print(f\"Train batch shapes - inputs: {inputs.shape}, targets: {targets.shape}\")\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if epoch == 0 and len(batch_losses) == 0:\n",
    "                print(f\"Train outputs shape: {outputs.shape}\")\n",
    "            \n",
    "            # Ajustar dimensiones si es necesario\n",
    "            if len(outputs.shape) == 5 and outputs.shape[2] == 1:  # [batch, seq, 1, H, W]\n",
    "                outputs = outputs.squeeze(2)  # [batch, seq, H, W]\n",
    "            \n",
    "            # NUEVO: Manejar caso especial de targets con 5 dimensiones (doble seq) [batch, seq, seq, H, W]\n",
    "            if len(targets.shape) == 5 and len(outputs.shape) == 4 and outputs.shape[1] == targets.shape[1]:\n",
    "                # Seleccionar solo uno de los seq_len (por ejemplo, primera dimensión temporal para cada secuencia)\n",
    "                targets = targets[:, :, 0, :, :]  # Convertir [batch, seq, seq, H, W] a [batch, seq, H, W]\n",
    "                print(f\"Convertido targets de forma {targets.shape} eliminando dimensión redundante\")\n",
    "\n",
    "            # NUEVO: Manejar caso donde targets tiene forma [batch, seq, seq_target, H, W]\n",
    "            elif len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                # Seleccionar diagonal o promediar sobre la 3ra dimensión\n",
    "                targets_reshaped = []\n",
    "                for i in range(min(targets.shape[1], outputs.shape[1])):\n",
    "                    # Para cada paso temporal, quedarse con el primer elemento o con la diagonal\n",
    "                    if i < targets.shape[2]:\n",
    "                        targets_reshaped.append(targets[:, i, i])\n",
    "                    else:\n",
    "                        targets_reshaped.append(targets[:, i, -1])\n",
    "                \n",
    "                # Apilar para formar [batch, seq, H, W]\n",
    "                targets = torch.stack(targets_reshaped, dim=1)\n",
    "                print(f\"Convertido targets mediante selección diagonal: {targets.shape}\")\n",
    "            \n",
    "            # NUEVO: Ajuste de secuencia cuando output_seq_len != target_seq_len\n",
    "            if len(outputs.shape) == 4 and len(targets.shape) == 4:\n",
    "                output_seq_len = outputs.shape[1]\n",
    "                target_seq_len = targets.shape[1]\n",
    "                \n",
    "                if output_seq_len > target_seq_len:\n",
    "                    # Si el modelo produce una secuencia más larga, usar solo los primeros target_seq_len elementos\n",
    "                    outputs = outputs[:, :target_seq_len]\n",
    "                    print(f\"Recortando outputs de {output_seq_len} a {target_seq_len}\")\n",
    "                elif output_seq_len < target_seq_len:\n",
    "                    # Si el modelo produce una secuencia más corta, repetir el último elemento\n",
    "                    padding = targets[:, output_seq_len:target_seq_len].shape[1]\n",
    "                    last_output = outputs[:, -1:].repeat(1, padding, 1, 1)\n",
    "                    outputs = torch.cat([outputs, last_output], dim=1)\n",
    "                    print(f\"Expandiendo outputs de {output_seq_len} a {target_seq_len}\")\n",
    "            \n",
    "            # Manejar diferentes formatos de target\n",
    "            if len(targets.shape) == 3 and len(outputs.shape) == 4:  # targets: [batch, H, W], outputs: [batch, seq, H, W]\n",
    "                targets = targets.unsqueeze(1).repeat(1, outputs.shape[1], 1, 1)\n",
    "                \n",
    "            elif len(targets.shape) == 4 and len(outputs.shape) == 4 and targets.shape[1] == 1:\n",
    "                # Si targets tiene solo 1 paso temporal pero outputs tiene múltiples\n",
    "                targets = targets.repeat(1, outputs.shape[1], 1, 1)\n",
    "            \n",
    "            # Asegurar dimensiones compatibles antes de calcular la pérdida\n",
    "            if outputs.shape != targets.shape:\n",
    "                print(f\"⚠️ Advertencia: Las formas siguen siendo incompatibles después de ajustes:\")\n",
    "                print(f\"   outputs.shape: {outputs.shape}, targets.shape: {targets.shape}\")\n",
    "                \n",
    "                # NUEVO: Mejor manejo de dimensiones inconsistentes\n",
    "                # Caso específico: [batch, seq, H, W] vs [batch, seq, seq, H, W]\n",
    "                if len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                    # Colapsar los dos dims de secuencia en targets\n",
    "                    B, S1, S2, H, W = targets.shape\n",
    "                    targets = targets.view(B, S1*S2, H, W)\n",
    "                    # Luego tomar solo los primeros S1 elementos\n",
    "                    targets = targets[:, :outputs.shape[1]]\n",
    "                    print(f\"   Redimensionado targets a: {targets.shape}\")\n",
    "                \n",
    "                # Caso genérico: ajustar el mínimo de dimensiones compatibles\n",
    "                if outputs.shape != targets.shape:\n",
    "                    try:\n",
    "                        # Intento de broadcast\n",
    "                        min_shape = [min(o, t) for o, t in zip(outputs.shape, targets.shape) \n",
    "                                   if o is not None and t is not None]\n",
    "                        slices_out = tuple(slice(0, m) for m in min_shape)\n",
    "                        slices_tgt = tuple(slice(0, m) for m in min_shape)\n",
    "                        \n",
    "                        outputs = outputs[slices_out]\n",
    "                        targets = targets[slices_tgt]\n",
    "                        print(f\"   Redimensionado a shape común: {outputs.shape}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error en redimensionado: {str(e)}\")\n",
    "                        # Último recurso: aplanar todo y recortar\n",
    "                        flat_out = outputs.flatten()[:10000]  # Límite para evitar OOM\n",
    "                        flat_tgt = targets.flatten()[:10000]\n",
    "                        outputs = flat_out.unsqueeze(0)\n",
    "                        targets = flat_tgt.unsqueeze(0)\n",
    "                        print(f\"   ⚡ Aplanado a: {outputs.shape}\")\n",
    "            \n",
    "            # Debugging final shapes\n",
    "            if epoch == 0 and len(batch_losses) == 0:\n",
    "                print(f\"Adjusted shapes - outputs: {outputs.shape}, targets: {targets.shape}\")\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_losses.append(loss.item())\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        train_loss = sum(batch_losses) / len(batch_losses)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_batch_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(val_loader, desc=f\"Época {epoch+1}/{epochs} [Val]\", leave=False):\n",
    "                inputs, targets = batch_data\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Aplicar los mismos ajustes que en el entrenamiento\n",
    "                if len(outputs.shape) == 5 and outputs.shape[2] == 1:\n",
    "                    outputs = outputs.squeeze(2)\n",
    "                    \n",
    "                # Manejar caso especial de targets con 5 dimensiones\n",
    "                if len(targets.shape) == 5 and len(outputs.shape) == 4 and outputs.shape[1] == targets.shape[1]:\n",
    "                    targets = targets[:, :, 0, :, :]\n",
    "\n",
    "                # Manejar dimensión de secuencia extra en targets\n",
    "                elif len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                    targets_reshaped = []\n",
    "                    for i in range(min(targets.shape[1], outputs.shape[1])):\n",
    "                        if i < targets.shape[2]:\n",
    "                            targets_reshaped.append(targets[:, i, i])\n",
    "                        else:\n",
    "                            targets_reshaped.append(targets[:, i, -1])\n",
    "                    targets = torch.stack(targets_reshaped, dim=1)\n",
    "                \n",
    "                # Ajuste de longitud de secuencia\n",
    "                if len(outputs.shape) == 4 and len(targets.shape) == 4:\n",
    "                    output_seq_len = outputs.shape[1]\n",
    "                    target_seq_len = targets.shape[1]\n",
    "                    \n",
    "                    if output_seq_len > target_seq_len:\n",
    "                        outputs = outputs[:, :target_seq_len]\n",
    "                    elif output_seq_len < target_seq_len:\n",
    "                        padding = targets[:, output_seq_len:target_seq_len].shape[1]\n",
    "                        last_output = outputs[:, -1:].repeat(1, padding, 1, 1)\n",
    "                        outputs = torch.cat([outputs, last_output], dim=1)\n",
    "                \n",
    "                if len(targets.shape) == 3 and len(outputs.shape) == 4:\n",
    "                    targets = targets.unsqueeze(1).repeat(1, outputs.shape[1], 1, 1)\n",
    "                    \n",
    "                elif len(targets.shape) == 4 and len(outputs.shape) == 4 and targets.shape[1] == 1:\n",
    "                    targets = targets.repeat(1, outputs.shape[1], 1, 1)\n",
    "                \n",
    "                # Compatibilidad final de formas\n",
    "                if outputs.shape != targets.shape:\n",
    "                    # Caso específico: [batch, seq, H, W] vs [batch, seq, seq, H, W]\n",
    "                    if len(targets.shape) == 5 and len(outputs.shape) == 4:\n",
    "                        B, S1, S2, H, W = targets.shape\n",
    "                        targets = targets.view(B, S1*S2, H, W)[:, :outputs.shape[1]]\n",
    "                    \n",
    "                    # Caso genérico\n",
    "                    if outputs.shape != targets.shape:\n",
    "                        try:\n",
    "                            min_shape = [min(o, t) for o, t in zip(outputs.shape, targets.shape) \n",
    "                                       if o is not None and t is not None]\n",
    "                            slices_out = tuple(slice(0, m) for m in min_shape)\n",
    "                            slices_tgt = tuple(slice(0, m) for m in min_shape)\n",
    "                            \n",
    "                            outputs = outputs[slices_out]\n",
    "                            targets = targets[slices_tgt]\n",
    "                        except:\n",
    "                            # Último recurso\n",
    "                            flat_out = outputs.flatten()[:10000]\n",
    "                            flat_tgt = targets.flatten()[:10000]\n",
    "                            outputs = flat_out.unsqueeze(0)\n",
    "                            targets = flat_tgt.unsqueeze(0)\n",
    "                \n",
    "                loss = criterion(outputs, targets)\n",
    "                val_batch_losses.append(loss.item())\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        val_loss = sum(val_batch_losses) / len(val_batch_losses)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Update learning rate if scheduler is provided\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f\"{name} - Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model state\n",
    "            best_model_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "                break\n",
    "    \n",
    "    # Restore best model state\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    print(f\"Training completed for {name}. Best validation loss: {best_val_loss:.6f}\")\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "# Preparar datos para entrenamiento\n",
    "X_train, y_train, X_val, y_val = prepare_train_val_data(ds_full)\n",
    "\n",
    "# Entrenar modelos SimpleConvGRU y SimpleConvLSTM y comparar\n",
    "print(\"\\nEntrenando modelos simples y comparando con híbridos...\")\n",
    "\n",
    "# Entrenar y comparar modelos con los datos preparados\n",
    "comparison_models = train_and_compare_models(X_train, y_train, X_val, y_val)\n",
    "visualize_model_comparisons(comparison_models)\n",
    "\n",
    "# Mostrar mensaje de éxito\n",
    "print(\"\\n✅ Comparación completa. Todos los resultados guardados en \" + str(MODELS_OUTPUT / 'visualization' / 'comparisons'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
