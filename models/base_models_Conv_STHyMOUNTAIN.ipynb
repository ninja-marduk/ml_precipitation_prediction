{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4e7925",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/main/models/base_models_STHyMOUNTAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3744f4",
   "metadata": {
    "id": "af3744f4"
   },
   "source": [
    "# ğŸ“˜ Entrenamiento de Modelos Baseline para PredicciÃ³n Espaciotemporal de PrecipitaciÃ³n Mensual STHyMOUNTAIN\n",
    "\n",
    "Este notebook implementa modelos baseline para la predicciÃ³n de precipitaciones usando datos espaciotemporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994be36",
   "metadata": {},
   "source": [
    "## ğŸ” ImplementaciÃ³n de Modelos Avanzados y TÃ©cnicas de ValidaciÃ³n\n",
    "\n",
    "AdemÃ¡s de los modelos tabulares baseline, implementaremos:\n",
    "\n",
    "1. **Modelos de Deep Learning** para capturar patrones espaciales y temporales:\n",
    "   - Redes CNN para patrones espaciales\n",
    "   - Redes ConvLSTM para patrones temporales\n",
    "   - Redes ConvGRU para patrones temporales\n",
    "\n",
    "El objetivo es proporcionar una evaluaciÃ³n completa de diferentes enfoques de modelado para la predicciÃ³n de precipitaciÃ³n en regiones montaÃ±osas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06416284",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06416284",
    "outputId": "a8e4c864-34e9-41b2-d5c3-e6ccaaf3699e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_PATH = /Users/riperez/Conda/anaconda3/envs/precipitation_prediction/github.com/ml_precipitation_prediction\n",
      "Dataset â†’ time=518, lat=61, lon=65\n",
      "\n",
      "=== Experimento BASICÂ (12Â features) ===\n",
      "â†’Â ConvLSTM\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueÃ³ al ejecutar cÃ³digo en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el cÃ³digo de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquÃ­</a> para obtener mÃ¡s informaciÃ³n. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener mÃ¡s detalles."
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from pathlib import Path\n",
    "import sys, os, gc, warnings, shutil\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Input, Conv2D, ConvLSTM2D, BatchNormalization,\n",
    "                                     MaxPooling2D, Dropout, Flatten, Dense, Reshape)\n",
    "from tensorflow.keras.layers import (Input, ConvLSTM2D, SimpleRNN, Conv2D, BatchNormalization,\n",
    "                                     Flatten, Dense, Add, LayerNormalization, TimeDistributed)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error,\n",
    "                             mean_absolute_percentage_error, r2_score)\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Agrega la raÃ­z del proyecto al sys.path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "from lib.ConvGRU2D import ConvGRU2D\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â 0.Â Entorno â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !git clone -q https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
    "    %cd ml_precipitation_prediction\n",
    "    !pip install -q -r requirements.txt xarray netCDF4 seaborn scikit-learn geopandas imageio\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    for p in [BASE_PATH, *BASE_PATH.parents]:\n",
    "        if (p/'.git').exists():\n",
    "            BASE_PATH = p; break\n",
    "\n",
    "print('BASE_PATH =', BASE_PATH)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid'); sns.set_context('notebook')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import imageio.v2 as imageio\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PATHS & CONST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_FILE = BASE_PATH/'data'/'output'/(\n",
    "    'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation_clean.nc')\n",
    "OUT_ROOT  = BASE_PATH/'models'/'output'/'Spatial_CONVRNN'\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SHAPE_DIR = BASE_PATH/'data'/'input'/'shapes'\n",
    "DEPT_GDF = gpd.read_file(SHAPE_DIR/'MGN_Departamento.shp')\n",
    "\n",
    "INPUT_WINDOW = 60; HORIZON = 3; EPOCHS = 50; BATCH = 4; LR = 1e-3\n",
    "PATIENCE = 6\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FEATURE SETS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BASE_FEATS = ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
    "              'max_daily_precipitation','min_daily_precipitation','daily_precipitation_std',\n",
    "              'elevation','slope','aspect']\n",
    "ELEV_CLUSTER = ['elev_high','elev_med','elev_low']\n",
    "KCE_FEATS = BASE_FEATS + ELEV_CLUSTER\n",
    "PAFC_FEATS= KCE_FEATS + ['total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag12']\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    'BASIC': BASE_FEATS,\n",
    "    'KCE'  : KCE_FEATS,\n",
    "    'PAFC' : PAFC_FEATS\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATASET â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ds = xr.open_dataset(DATA_FILE)\n",
    "lat, lon = len(ds.latitude), len(ds.longitude)\n",
    "print(f\"Dataset â†’ time={len(ds.time)}, lat={lat}, lon={lon}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def windowed_arrays(X:np.ndarray, y:np.ndarray):\n",
    "    \"\"\"Crea ventanas deslizantes 5â€‘D para X y 4â€‘D para y.\"\"\"\n",
    "    seq_X, seq_y = [], []\n",
    "    T = len(X)\n",
    "    for start in range(T-INPUT_WINDOW-HORIZON+1):\n",
    "        end_w = start+INPUT_WINDOW; end_y=end_w+HORIZON\n",
    "        Xw = X[start:end_w]; yw = y[end_w:end_y]\n",
    "        if np.isnan(Xw).any() or np.isnan(yw).any():\n",
    "            continue\n",
    "        seq_X.append(Xw); seq_y.append(yw)\n",
    "    return np.array(seq_X,dtype=np.float32), np.array(seq_y,dtype=np.float32)\n",
    "\n",
    "\n",
    "def quick_plot(ax,data,cmap,title,vmin=None,vmax=None):\n",
    "    mesh = ax.pcolormesh(ds.longitude,ds.latitude,data,cmap=cmap,shading='nearest',\n",
    "                         vmin=vmin,vmax=vmax,transform=ccrs.PlateCarree())\n",
    "    ax.coastlines(); ax.add_geometries(DEPT_GDF.geometry,ccrs.PlateCarree(),edgecolor='black',facecolor='none',linewidth=1)\n",
    "    ax.gridlines(draw_labels=True,top_labels=False,right_labels=False)\n",
    "    ax.set_title(title,fontsize=9); return mesh\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MODEL FACTORIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def build_conv_lstm(n_feats:int):\n",
    "    inp = Input(shape=(INPUT_WINDOW,lat,lon,n_feats),name='in')\n",
    "    x   = ConvLSTM2D(64,(3,3),padding='same',return_sequences=True)(inp)\n",
    "    x   = ConvLSTM2D(32,(3,3),padding='same')(x)\n",
    "    x   = Flatten()(x)\n",
    "    x   = Dense(HORIZON*lat*lon,activation='linear')(x)\n",
    "    out = Reshape((HORIZON,lat,lon,1))(x)\n",
    "    m   = Model(inp,out,name='ConvLSTM'); m.compile('adam','mse'); return m\n",
    "\n",
    "\n",
    "def build_conv_gru(n_feats:int):\n",
    "    inp = Input(shape=(INPUT_WINDOW,lat,lon,n_feats))\n",
    "    x = ConvGRU2D(64,(3,3),padding='same',return_sequences=True)(inp)\n",
    "    x = ConvGRU2D(32,(3,3),padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(HORIZON*lat*lon)(x)\n",
    "    out=Reshape((HORIZON,lat,lon,1))(x)\n",
    "    m=Model(inp,out,name='ConvGRU'); m.compile('adam','mse'); return m\n",
    "\n",
    "\n",
    "def build_conv_rnn(n_feats:int):\n",
    "    inp = Input(shape=(INPUT_WINDOW,lat,lon,n_feats))\n",
    "    x = SimpleRNN(128,activation='tanh')(Flatten()(inp))\n",
    "    x = Dense(HORIZON*lat*lon)(x)\n",
    "    out=Reshape((HORIZON,lat,lon,1))(x)\n",
    "    m=Model(inp,out,name='ConvRNN'); m.compile('adam','mse'); return m\n",
    "\n",
    "MODELS = {\n",
    "    'ConvLSTM': build_conv_lstm,\n",
    "    'ConvGRU' : build_conv_gru,\n",
    "    'ConvRNN' : build_conv_rnn\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRAIN + EVAL LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "results=[]\n",
    "for exp, feat_list in EXPERIMENTS.items():\n",
    "    print(f\"\\n=== Experimento {exp}Â ({len(feat_list)}Â features) ===\")\n",
    "    Xarr = ds[feat_list].to_array().transpose('time','latitude','longitude','variable').values.astype(np.float32)\n",
    "    yarr = ds['total_precipitation'].values.astype(np.float32)[...,None]  # (T,H,W,1)\n",
    "\n",
    "    X, y = windowed_arrays(Xarr, yarr)\n",
    "    split=int(0.8*len(X))\n",
    "\n",
    "    sx = StandardScaler().fit(X[:split].reshape(-1,len(feat_list)))\n",
    "    sy = StandardScaler().fit(y[:split].reshape(-1,1))\n",
    "\n",
    "    X_sc = sx.transform(X.reshape(-1,len(feat_list))).reshape(X.shape)\n",
    "    y_sc = sy.transform(y.reshape(-1,1)).reshape(y.shape)\n",
    "\n",
    "    X_tr, X_va = X_sc[:split], X_sc[split:]\n",
    "    y_tr, y_va = y_sc[:split], y_sc[split:]\n",
    "\n",
    "    OUT_EXP = OUT_ROOT/exp; OUT_EXP.mkdir(exist_ok=True)\n",
    "\n",
    "    for mdl_name,builder in MODELS.items():\n",
    "        print(f\"â†’Â {mdl_name}\")\n",
    "        model_path = OUT_EXP/f\"{mdl_name.lower()}_best.keras\"\n",
    "        if model_path.exists():\n",
    "            print(\"â©Â ya entrenado, cargando â€¦\"); model=tf.keras.models.load_model(model_path,compile=False)\n",
    "        else:\n",
    "            model = builder(n_feats=len(feat_list))\n",
    "            cb = [EarlyStopping('val_loss',patience=PATIENCE,restore_best_weights=True),\n",
    "                  ModelCheckpoint(model_path,save_best_only=True)]\n",
    "            model.fit(X_tr,y_tr,validation_data=(X_va,y_va),epochs=EPOCHS,batch_size=BATCH,callbacks=cb,verbose=0)\n",
    "        # --- PredicciÃ³n Ãºltimo batch validaciÃ³n ---\n",
    "        y_hat_sc = model.predict(X_va[-1:],verbose=0)\n",
    "        y_hat    = sy.inverse_transform(y_hat_sc.reshape(-1,1)).reshape(HORIZON,lat,lon)\n",
    "        y_true   = sy.inverse_transform(y_va[-1:].reshape(-1,1)).reshape(HORIZON,lat,lon)\n",
    "\n",
    "        # --- Mapas & GIF ---\n",
    "        vmin=0; vmax=max(y_true.max(),y_hat.max())\n",
    "        frames=[]; dates=pd.date_range(ds.time.values[-HORIZON],periods=HORIZON,freq='MS')\n",
    "        for h in range(HORIZON):\n",
    "            err = np.clip(np.abs((y_true[h]-y_hat[h])/(y_true[h]+1e-5))*100,0,100)\n",
    "            fig,axs=plt.subplots(1,3,figsize=(12,4),subplot_kw={'projection':ccrs.PlateCarree()})\n",
    "            quick_plot(axs[0],y_true[h],'Blues',f\"RealÂ h={h+1}\",vmin,vmax)\n",
    "            quick_plot(axs[1],y_hat[h],'Blues',f\"PredÂ {mdl_name}Â h={h+1}\",vmin,vmax)\n",
    "            quick_plot(axs[2],err,'Reds',f\"MAPE%Â h={h+1}\",0,100)\n",
    "            fig.suptitle(f\"{mdl_name} â€“Â {exp} â€“Â {dates[h].strftime('%Y-%m')}\")\n",
    "            png = OUT_EXP/f\"{mdl_name}_{h+1}.png\"; plt.savefig(png,bbox_inches='tight'); plt.close(fig)\n",
    "            frames.append(imageio.imread(png))\n",
    "        imageio.mimsave(OUT_EXP/f\"{mdl_name}.gif\",frames,fps=0.5)\n",
    "\n",
    "        # --- MÃ©tricas ---\n",
    "        for h in range(HORIZON):\n",
    "            results.append({\n",
    "                'Experiment':exp,'Model':mdl_name,'H':h+1,\n",
    "                'RMSE':np.sqrt(mean_squared_error(y_true[h].ravel(),y_hat[h].ravel())),\n",
    "                'MAE': mean_absolute_error(y_true[h].ravel(),y_hat[h].ravel()),\n",
    "                'R2':  r2_score(y_true[h].ravel(),y_hat[h].ravel())\n",
    "            })\n",
    "        tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSV FINAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "res_df=pd.DataFrame(results)\n",
    "res_df.to_csv(OUT_ROOT/'metrics_spatial.csv',index=False)\n",
    "print(\"\\nğŸ“‘Â Metrics saved â†’\", OUT_ROOT/'metrics_spatial.csv')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
