{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/feature%2Fbase-models/models/base_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "635dc005",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "635dc005",
        "outputId": "6f1a5d90-1724-49d1-ab64-6afc474c3533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'ml_precipitation_prediction' already exists and is not an empty directory.\n",
            "/content/ml_precipitation_prediction/ml_precipitation_prediction\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2025.3.1)\n",
            "Requirement already satisfied: rioxarray in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.19.0)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.4.3)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2024.12.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (4.67.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.5.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.18.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4->-r requirements.txt (line 5)) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4->-r requirements.txt (line 5)) (2025.4.26)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray->-r requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (1.1.1)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 9)) (2.1.0)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (2025.3.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (8.7.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->-r requirements.txt (line 13)) (2.21.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (0.37.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->-r requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 15)) (0.45.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask->-r requirements.txt (line 10)) (3.21.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (0.15.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask->-r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 15)) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 15)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 15)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 15)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (0.1.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.3.1)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: ace_tools_open in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (24.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.4.26)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: itables in /usr/local/lib/python3.11/dist-packages (from ace_tools_open) (2.3.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (from ace_tools_open) (7.34.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython->ace_tools_open) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython->ace_tools_open) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->ace_tools_open) (0.2.13)\n",
            "Entorno configurado. Usando ruta base: /content/drive/MyDrive/ml_precipitation_prediction\n"
          ]
        }
      ],
      "source": [
        "# Configuraci√≥n del entorno (compatible con Colab y local)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "# Regenerar el c√≥digo con las condiciones espec√≠ficas\n",
        "notebook_globals = {\n",
        "    \"USE_CROSS_VALIDATION\": False,\n",
        "    \"ENABLED_MODELS\": ['CNN', 'GRU'],\n",
        "    \"ENABLED_EXPERIMENTS\": ['time+cycles', 'all_features'],\n",
        "    \"ENABLED_HORIZONS\": [3],\n",
        "}\n",
        "\n",
        "# Detectar si estamos en Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Si estamos en Colab, clonar el repositorio\n",
        "    !git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
        "    %cd ml_precipitation_prediction\n",
        "    # Instalar dependencias necesarias\n",
        "    !pip install -r requirements.txt\n",
        "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open\n",
        "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
        "else:\n",
        "    # Si estamos en local, usar la ruta actual\n",
        "    if '/models' in os.getcwd():\n",
        "        BASE_PATH = Path('..')\n",
        "    else:\n",
        "        BASE_PATH = Path('.')\n",
        "\n",
        "print(f\"Entorno configurado. Usando ruta base: {BASE_PATH}\")\n",
        "\n",
        "# Si BASE_PATH viene como string, lo convertimos\n",
        "BASE_PATH = Path(BASE_PATH)\n",
        "\n",
        "# Ahora puedes concatenar correctamente\n",
        "data_output_dir = BASE_PATH / 'data' / 'output'\n",
        "model_output_dir = BASE_PATH / 'models' / 'output'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8ccc04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8ccc04",
        "outputId": "84ff3d1d-5eb5-4247-fcfe-bafbe391e893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Detectando dispositivo disponible...\n",
            "‚úÖ GPU detectada: /physical_device:GPU:0\n",
            "‚ÑπÔ∏è Entrenamiento acelerado con GPU activado.\n",
            "üìÇ Configurando directorios y cargando dataset...\n",
            "‚úîÔ∏è Modelos en: /content/drive/MyDrive/ml_precipitation_prediction/models/output/ST_HybridWaveStack\n",
            "‚úîÔ∏è Curvas en: /content/drive/MyDrive/ml_precipitation_prediction/models/output/ST_HybridWaveStack/learning_curves\n",
            "‚úîÔ∏è Dataset cargado desde: /content/drive/MyDrive/ml_precipitation_prediction/data/output/complete_dataset_with_features_with_clusters_elevation_with_windows.nc\n",
            "‚úÖ Variables requeridas presentes.\n",
            "\n",
            "üöÄ Experimento: time+cycles\n",
            "üìâ Secuencias orig.: 2101351, v√°lidas: 2101351, eliminadas: 0 (0.00%)\n",
            "üîß Modelo: CNN\n",
            "‚è© Ya existe fold 1, skip.\n",
            "‚è© Ya existe fold 2, skip.\n",
            "‚è© Ya existe fold 3, skip.\n",
            "üîß Modelo: GRU\n",
            "‚è© Ya existe fold 1, skip.\n",
            "‚è© Ya existe fold 2, skip.\n",
            "‚è© Ya existe fold 3, skip.\n",
            "\n",
            "üöÄ Experimento: all_features\n",
            "üìâ Secuencias orig.: 2101351, v√°lidas: 1958611, eliminadas: 142740 (6.79%)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# ==== Variables de control ====\n",
        "USE_CROSS_VALIDATION = True\n",
        "ENABLED_MODELS = ['CNN', 'GRU']\n",
        "ENABLED_EXPERIMENTS = ['time+cycles', 'all_features']\n",
        "ENABLED_HORIZONS = [3]\n",
        "input_window = 96  # 8 a√±os (mensual)\n",
        "\n",
        "# ==== Configuraci√≥n de entorno ====\n",
        "print(\"üîç Detectando dispositivo disponible...\")\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "USE_GPU = bool(gpu_devices)\n",
        "if USE_GPU:\n",
        "    print(\"‚úÖ GPU detectada:\", gpu_devices[0].name)\n",
        "    print(\"‚ÑπÔ∏è Entrenamiento acelerado con GPU activado.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se detect√≥ GPU. Usando CPU.\")\n",
        "\n",
        "# ==== Funciones auxiliares ====\n",
        "def build_model(model_type, input_shape, output_neurons):\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, GRU, Bidirectional, Reshape\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape, dtype='float32'))\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(64))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(64))\n",
        "    elif model_type == 'BLSTM':\n",
        "        model.add(Bidirectional(LSTM(64)))\n",
        "    elif model_type == 'CNN':\n",
        "        model.add(Reshape((*input_shape, 1)))\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "    model.add(Dense(output_neurons))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return rmse, mae, mape, r2\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size=16):\n",
        "        self.x, self.y = x_set.astype(np.float32), y_set.astype(np.float32)\n",
        "        self.batch_size = batch_size\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "def to_dataset(x, y):\n",
        "    x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
        "    y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
        "    return tf.data.Dataset.from_tensor_slices((x, y)).batch(16).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ==== Directorios y Dataset ====\n",
        "print(\"üìÇ Configurando directorios y cargando dataset...\")\n",
        "try:\n",
        "    model_output_dir_STH = model_output_dir / 'ST_HybridWaveStack'\n",
        "    curves_dir = model_output_dir_STH / \"learning_curves\"\n",
        "    if not model_output_dir_STH.exists():\n",
        "        model_output_dir_STH.mkdir(parents=True)\n",
        "    if not curves_dir.exists():\n",
        "        curves_dir.mkdir(parents=True)\n",
        "    print(f\"‚úîÔ∏è Modelos en: {model_output_dir_STH}\")\n",
        "    print(f\"‚úîÔ∏è Curvas en: {curves_dir}\")\n",
        "\n",
        "    file_path = data_output_dir / \"complete_dataset_with_features_with_clusters_elevation_with_windows.nc\"\n",
        "    ds = xr.open_dataset(file_path)\n",
        "    print(f\"‚úîÔ∏è Dataset cargado desde: {file_path}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"‚ùå Error cargando dataset o creando carpetas: {e}\")\n",
        "\n",
        "# ==== Configuraci√≥n de experimentos ====\n",
        "experiment_settings = {\n",
        "    \"time+cycles\": ['year','month','month_sin','month_cos','doy_sin','doy_cos'],\n",
        "    \"time+cycles+lag\": ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
        "        'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "        'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36'],\n",
        "    \"time+cycles+lag+elev\": ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
        "        'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "        'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36',\n",
        "        'elevation','slope','aspect'],\n",
        "    \"all_features\": ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
        "        'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "        'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36',\n",
        "        'elevation','slope','aspect','cluster_elevation']\n",
        "}\n",
        "\n",
        "# Validaci√≥n de variables\n",
        "ds_vars = set(ds.data_vars)\n",
        "for name, vars_list in experiment_settings.items():\n",
        "    missing = [v for v in vars_list if v not in ds_vars]\n",
        "    if missing:\n",
        "        raise ValueError(f\"‚ùå Faltan vars para '{name}': {missing}\")\n",
        "print(\"‚úÖ Variables requeridas presentes.\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# ==== Entrenamiento modular ====\n",
        "for exp_name, variables in experiment_settings.items():\n",
        "    if exp_name not in ENABLED_EXPERIMENTS:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nüöÄ Experimento: {exp_name}\")\n",
        "    try:\n",
        "        # Preparar datos\n",
        "        cluster_idx = variables.index('cluster_elevation') if 'cluster_elevation' in variables else None\n",
        "        subset = ds[variables].to_array().transpose('time','latitude','longitude','variable').values\n",
        "        if cluster_idx is not None:\n",
        "            cd = subset[...,cluster_idx]\n",
        "            subset[...,cluster_idx] = LabelEncoder().fit_transform(cd.ravel()).reshape(cd.shape)\n",
        "        subset = subset.astype(np.float32)\n",
        "        target = ds['total_precipitation'].values\n",
        "        samples,lat,lon,feats = subset.shape\n",
        "        X = subset.reshape(samples, lat*lon, feats)\n",
        "        y = target.reshape(samples, lat*lon)\n",
        "        mask = ~np.isnan(y)\n",
        "        X, y = X[mask], y[mask]\n",
        "\n",
        "        # Generar secuencias\n",
        "        X_seq, Y_targets = [], {h:[] for h in ENABLED_HORIZONS}\n",
        "        for i in range(len(X) - input_window - max(ENABLED_HORIZONS)):\n",
        "            X_seq.append(X[i:i+input_window])\n",
        "            for h in ENABLED_HORIZONS:\n",
        "                Y_targets[h].append(y[i+input_window+h-1])\n",
        "        X_seq = np.array(X_seq)\n",
        "        Y_targets = {h: np.array(Y_targets[h]) for h in ENABLED_HORIZONS}\n",
        "\n",
        "        # --- FILTRAR Secuencias con NaNs y reportar ---\n",
        "        def filtrar_secuencias(Xs, ys):\n",
        "            total = len(Xs)\n",
        "            valid = (~np.isnan(Xs).any(axis=(1,2))) & (~np.isnan(ys))\n",
        "            kept = valid.sum()\n",
        "            lost = total - kept\n",
        "            pct = 100 * lost/total\n",
        "            print(f\"üìâ Secuencias orig.: {total}, v√°lidas: {kept}, eliminadas: {lost} ({pct:.2f}%)\")\n",
        "            return Xs[valid], ys[valid]\n",
        "\n",
        "        for h in ENABLED_HORIZONS:\n",
        "            X_seq, Y_targets[h] = filtrar_secuencias(X_seq, Y_targets[h])\n",
        "\n",
        "        if len(X_seq)==0:\n",
        "            print(f\"‚ö†Ô∏è No quedan secuencias v√°lidas para '{exp_name}'. Saltando.\")\n",
        "            continue\n",
        "\n",
        "        input_shape = (X_seq.shape[1], X_seq.shape[2])\n",
        "\n",
        "        # Cross-validation\n",
        "        for model_name in ENABLED_MODELS:\n",
        "            print(f\"üîß Modelo: {model_name}\")\n",
        "            kf = KFold(n_splits=3, shuffle=False)\n",
        "            for h in ENABLED_HORIZONS:\n",
        "                fold=1\n",
        "                for tr_idx,va_idx in kf.split(X_seq):\n",
        "                    X_tr, X_va = X_seq[tr_idx], X_seq[va_idx]\n",
        "                    y_tr, y_va = Y_targets[h][tr_idx], Y_targets[h][va_idx]\n",
        "                    # Escalar\n",
        "                    scalerX=StandardScaler()\n",
        "                    shpX = X_tr.shape\n",
        "                    X_tr = scalerX.fit_transform(X_tr.reshape(-1,shpX[-1])).reshape(shpX)\n",
        "                    shpX2 = X_va.shape\n",
        "                    X_va = scalerX.transform(X_va.reshape(-1,shpX[-1])).reshape(shpX2)\n",
        "                    scalery=StandardScaler()\n",
        "                    y_tr = scalery.fit_transform(y_tr.reshape(-1,1)).reshape(y_tr.shape)\n",
        "                    y_va = scalery.transform(y_va.reshape(-1,1)).reshape(y_va.shape)\n",
        "\n",
        "                    # Data generators\n",
        "                    train_gen = DataGenerator(X_tr, y_tr, batch_size=16)\n",
        "                    val_gen   = DataGenerator(X_va, y_va, batch_size=16)\n",
        "\n",
        "                    model_path = model_output_dir_STH / f\"{exp_name.replace('+','_')}_{model_name}_H{h}_F{fold}.h5\"\n",
        "                    if model_path.exists():\n",
        "                        print(f\"‚è© Ya existe fold {fold}, skip.\")\n",
        "                        fold+=1\n",
        "                        continue\n",
        "\n",
        "                    model = build_model(model_name, input_shape, 1)\n",
        "                    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "                    history = model.fit(train_gen,\n",
        "                                        validation_data=val_gen,\n",
        "                                        epochs=20,\n",
        "                                        verbose=1,\n",
        "                                        callbacks=[es])\n",
        "\n",
        "                    # Evaluaci√≥n\n",
        "                    y_pred = model.predict(X_va).flatten()\n",
        "                    y_true = y_va.flatten()\n",
        "                    rmse, mae, mape, r2 = evaluate(y_true,y_pred)\n",
        "                    results.append({\n",
        "                        'experiment': exp_name,'model': model_name,\n",
        "                        'horizon':h,'fold':fold,\n",
        "                        'RMSE':rmse,'MAE':mae,'MAPE':mape,'R2':r2,\n",
        "                        'epochs':len(history.history['loss'])\n",
        "                    })\n",
        "\n",
        "                    # Curva\n",
        "                    plt.figure()\n",
        "                    plt.plot(history.history['loss'], label='Train')\n",
        "                    plt.plot(history.history['val_loss'], label='Val')\n",
        "                    plt.title(f'{exp_name}-{model_name}-H{h}-F{fold}')\n",
        "                    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "                    plt.savefig(curves_dir / f\"{exp_name.replace('+','_')}_{model_name}_H{h}_F{fold}.png\")\n",
        "                    plt.close()\n",
        "\n",
        "                    model.save(model_path)\n",
        "                    print(f\"üíæ Guardado fold {fold}\")\n",
        "                    fold+=1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error en '{exp_name}': {e}\")\n",
        "\n",
        "# ==== Guardar resultados ====\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"resultados_modelos_cv_8anios_mvp.csv\", index=False)\n",
        "print(results_df.head())\n",
        "\n",
        "import ace_tools_open as tools\n",
        "tools.display_dataframe_to_user(name=\"Resultados CV MVP\", dataframe=results_df)\n",
        "print(\"‚úÖ Proceso finalizado con √©xito.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizar modelos y m√©tricas\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from pathlib import Path\n",
        "import xarray as xr\n",
        "\n",
        "# ==== Directorios y Dataset ====\n",
        "print(\"üìÇ Configurando directorios y cargando dataset...\")\n",
        "try:\n",
        "    model_output_dir_STH = Path(\"/content/drive/MyDrive/ml_precipitation_prediction/models/output/ST_HybridWaveStack\")\n",
        "    data_output_dir = Path(\"/content/drive/MyDrive/ml_precipitation_prediction/data/output\")\n",
        "    model_files = sorted([f for f in model_output_dir_STH.glob(\"*.h5\")])\n",
        "    print(f\"‚úîÔ∏è Modelos encontrados: {len(model_files)}\")\n",
        "    print(f\"üß† Ejemplos: {[m.name for m in model_files[:3]]}\")\n",
        "\n",
        "    ds_path = data_output_dir / \"complete_dataset_with_features_with_clusters_elevation_with_windows.nc\"\n",
        "    ds = xr.open_dataset(ds_path)\n",
        "    print(f\"‚úîÔ∏è Dataset cargado desde: {ds_path}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"‚ùå Error cargando modelos o dataset: {e}\")\n",
        "\n",
        "input_window = 96\n",
        "horizon = 3\n",
        "features = 18\n",
        "\n",
        "variables = [\n",
        "    'year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos',\n",
        "    'total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag3',\n",
        "    'total_precipitation_lag4', 'total_precipitation_lag12', 'total_precipitation_lag24', 'total_precipitation_lag36',\n",
        "    'elevation', 'slope', 'aspect', 'cluster_elevation'\n",
        "]\n",
        "target_var = 'total_precipitation'\n",
        "\n",
        "subset = ds[variables].to_array().transpose('time', 'latitude', 'longitude', 'variable').values\n",
        "target = ds[target_var].values\n",
        "\n",
        "cluster_idx = variables.index('cluster_elevation') if 'cluster_elevation' in variables else None\n",
        "if cluster_idx is not None:\n",
        "    encoded = LabelEncoder().fit_transform(subset[..., cluster_idx].ravel()).reshape(subset[..., cluster_idx].shape)\n",
        "    subset[..., cluster_idx] = encoded\n",
        "\n",
        "subset = subset.astype(np.float32)\n",
        "samples, lat, lon, feats = subset.shape\n",
        "X_all = subset.reshape(samples, lat * lon, feats)\n",
        "y_all = target.reshape(samples, lat * lon)\n",
        "\n",
        "mask = ~np.isnan(y_all)\n",
        "X_all = X_all[mask]\n",
        "y_all = y_all[mask]\n",
        "\n",
        "X_seq, y_seq = [], []\n",
        "for i in range(len(X_all) - input_window - horizon):\n",
        "    X_seq.append(X_all[i:i + input_window])\n",
        "    y_seq.append(y_all[i + input_window + horizon - 1])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "split_idx = int(len(X_seq) * 0.7)\n",
        "X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]\n",
        "y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "X_train_scaled = scaler_X.fit_transform(X_train_flat).reshape(X_train.shape)\n",
        "X_test_scaled = scaler_X.transform(X_test_flat).reshape(X_test.shape)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return rmse, mae, mape, r2\n",
        "\n",
        "results = []\n",
        "for model_path in model_files:\n",
        "    print(f\"üîç Evaluando modelo: {model_path.name}\")\n",
        "    try:\n",
        "        model = tf.keras.models.load_model(model_path, compile=False)\n",
        "        y_pred_scaled = model.predict(X_test_scaled, verbose=0).flatten()\n",
        "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "        y_true = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
        "        rmse, mae, mape, r2 = evaluate(y_true, y_pred)\n",
        "        results.append({\n",
        "            'model': model_path.name,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'MAPE': mape,\n",
        "            'R2': r2\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error evaluando {model_path.name}: {e}\")\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "import ace_tools_open as tools\n",
        "tools.display_dataframe_to_user(name=\"Resultados Test Final\", dataframe=df_results)\n",
        "print(\"üìä M√©tricas de evaluaci√≥n calculadas y mostradas.\")\n"
      ],
      "metadata": {
        "id": "PszSo0yXlmyd"
      },
      "id": "PszSo0yXlmyd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}