{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V5 GNN-ConvLSTM Stacking - Unit Tests\n",
    "\n",
    "Functional tests for V5 components. CPU-only for portability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1 | Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Force CPU mode\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from typing import Tuple, Optional\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "\n",
    "device = 'cpu'\n",
    "print(f\"PyTorch: {torch.__version__} | Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config created: n_nodes=3965\n"
     ]
    }
   ],
   "source": [
    "class V5Config:\n",
    "    \"\"\"V5 configuration for testing.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.n_lat = 61\n",
    "        self.n_lon = 65\n",
    "        self.n_nodes = self.n_lat * self.n_lon\n",
    "        self.gnn_hidden_dim = 64\n",
    "        self.gnn_num_layers = 2\n",
    "        self.gnn_dropout = 0.1\n",
    "        self.gnn_type = 'GAT'\n",
    "        self.convlstm_hidden_dim = 64\n",
    "        self.convlstm_num_layers = 2\n",
    "        self.fusion_hidden_dim = 128\n",
    "        self.fusion_heads = 4\n",
    "        self.fusion_dropout = 0.1\n",
    "        self.meta_hidden_dim = 64\n",
    "        self.meta_dropout = 0.1\n",
    "        self.horizon = 1\n",
    "        self.learning_rate = 0.001\n",
    "        self.weight_decay = 1e-5\n",
    "        self.batch_size = 4\n",
    "        self.epochs = 100\n",
    "        self.early_stopping_patience = 10\n",
    "\n",
    "    @property\n",
    "    def graph_input_dim(self):\n",
    "        raise AttributeError(\n",
    "            \"V5Config.graph_input_dim removed. Use n_features param: \"\n",
    "            \"GNNBranch(config, n_features=16, n_nodes=...)\"\n",
    "        )\n",
    "\n",
    "config = V5Config()\n",
    "print(f\"Config created: n_nodes={config.n_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test grid: 5x5 = 25 nodes, 80 edges\n"
     ]
    }
   ],
   "source": [
    "def create_grid_graph(n_lat, n_lon, device='cpu'):\n",
    "    \"\"\"Create 4-connected grid graph.\"\"\"\n",
    "    edges = []\n",
    "    for i in range(n_lat):\n",
    "        for j in range(n_lon):\n",
    "            idx = i * n_lon + j\n",
    "            if j < n_lon - 1:\n",
    "                edges.append([idx, idx + 1])\n",
    "                edges.append([idx + 1, idx])\n",
    "            if i < n_lat - 1:\n",
    "                edges.append([idx, idx + n_lon])\n",
    "                edges.append([idx + n_lon, idx])\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous().to(device)\n",
    "    return edge_index\n",
    "\n",
    "# Use small grid for tests\n",
    "test_lat, test_lon = 5, 5\n",
    "test_nodes = test_lat * test_lon\n",
    "edge_index = create_grid_graph(test_lat, test_lon, device)\n",
    "print(f\"Test grid: {test_lat}x{test_lon} = {test_nodes} nodes, {edge_index.shape[1]} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNNBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNBranch defined\n"
     ]
    }
   ],
   "source": [
    "class GNNBranch(nn.Module):\n",
    "    \"\"\"Graph Neural Network branch.\"\"\"\n",
    "\n",
    "    def __init__(self, config, n_features: int, n_nodes: int,\n",
    "                 gnn_type: str = None, validate: bool = True):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.n_features = n_features\n",
    "        self.n_nodes = n_nodes\n",
    "        self.gnn_type = gnn_type or config.gnn_type\n",
    "        self.validate = validate\n",
    "        self.hidden_dim = config.gnn_hidden_dim\n",
    "        self.num_layers = config.gnn_num_layers\n",
    "        self.dropout = config.gnn_dropout\n",
    "\n",
    "        # Build layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        in_dim = n_features\n",
    "        for i in range(self.num_layers):\n",
    "            out_dim = self.hidden_dim\n",
    "            if self.gnn_type == 'GCN':\n",
    "                self.convs.append(GCNConv(in_dim, out_dim))\n",
    "            elif self.gnn_type == 'GAT':\n",
    "                self.convs.append(GATConv(in_dim, out_dim, heads=4, concat=False))\n",
    "            elif self.gnn_type == 'SAGE':\n",
    "                self.convs.append(SAGEConv(in_dim, out_dim))\n",
    "            in_dim = out_dim\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(self.dropout)\n",
    "        self.output_dim = self.hidden_dim\n",
    "\n",
    "    def _validate_tensor(self, tensor, name):\n",
    "        if self.validate:\n",
    "            if torch.isnan(tensor).any():\n",
    "                raise ValueError(f\"{name} contains NaN\")\n",
    "            if torch.isinf(tensor).any():\n",
    "                raise ValueError(f\"{name} contains Inf\")\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        self._validate_tensor(x, \"GNNBranch input\")\n",
    "\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if self.gnn_type == 'GCN' and edge_weight is not None:\n",
    "                x = conv(x, edge_index, edge_weight)\n",
    "            else:\n",
    "                x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = torch.relu(x)\n",
    "                x = self.dropout_layer(x)\n",
    "\n",
    "        self._validate_tensor(x, \"GNNBranch output\")\n",
    "        return x\n",
    "\n",
    "print(\"GNNBranch defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridGraphFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridGraphFusion defined\n"
     ]
    }
   ],
   "source": [
    "class GridGraphFusion(nn.Module):\n",
    "    \"\"\"Cross-attention fusion between grid and graph representations.\"\"\"\n",
    "\n",
    "    def __init__(self, grid_dim: int, graph_dim: int, config):\n",
    "        super().__init__()\n",
    "        self.grid_dim = grid_dim\n",
    "        self.graph_dim = graph_dim\n",
    "        self.hidden_dim = config.fusion_hidden_dim\n",
    "        self.n_heads = config.fusion_heads\n",
    "        self.dropout = config.fusion_dropout\n",
    "\n",
    "        self.grid_proj = nn.Linear(grid_dim, self.hidden_dim)\n",
    "        self.graph_proj = nn.Linear(graph_dim, self.hidden_dim)\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            self.hidden_dim, self.n_heads, dropout=self.dropout, batch_first=True\n",
    "        )\n",
    "        self.output_proj = nn.Linear(self.hidden_dim * 2, self.hidden_dim)\n",
    "        self.layer_norm = nn.LayerNorm(self.hidden_dim)\n",
    "        self.output_dim = self.hidden_dim\n",
    "\n",
    "    def forward(self, grid_features, graph_features):\n",
    "        grid_proj = self.grid_proj(grid_features)\n",
    "        graph_proj = self.graph_proj(graph_features)\n",
    "\n",
    "        fused, _ = self.cross_attention(grid_proj, graph_proj, graph_proj)\n",
    "        combined = torch.cat([grid_proj, fused], dim=-1)\n",
    "        output = self.output_proj(combined)\n",
    "        output = self.layer_norm(output)\n",
    "        return output\n",
    "\n",
    "print(\"GridGraphFusion defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaLearner defined\n"
     ]
    }
   ],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "    \"\"\"Meta-learner for combining branch predictions.\"\"\"\n",
    "\n",
    "    def __init__(self, fusion_dim: int, config):\n",
    "        super().__init__()\n",
    "        self.fusion_dim = fusion_dim\n",
    "        self.hidden_dim = config.meta_hidden_dim\n",
    "        self.dropout = config.meta_dropout\n",
    "\n",
    "        self.fc1 = nn.Linear(fusion_dim, self.hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.hidden_dim // 2)\n",
    "        self.fc_weights = nn.Linear(self.hidden_dim // 2, 2)\n",
    "        self.fc_pred = nn.Linear(self.hidden_dim // 2, 1)\n",
    "        self.dropout_layer = nn.Dropout(self.dropout)\n",
    "\n",
    "    def forward(self, fusion_features):\n",
    "        x = torch.relu(self.fc1(fusion_features))\n",
    "        x = self.dropout_layer(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "\n",
    "        weights = torch.softmax(self.fc_weights(x), dim=-1)\n",
    "        prediction = self.fc_pred(x)\n",
    "        return prediction, weights\n",
    "\n",
    "print(\"MetaLearner defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Suite 1: GNNBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST SUITE 1: GNNBranch\n",
      "============================================================\n",
      "[PASS] 1.1 Basic forward pass\n",
      "[PASS] 1.2 Batch processing\n",
      "[PASS] 1.3 GNN type: GCN\n",
      "[PASS] 1.3 GNN type: GAT\n",
      "[PASS] 1.3 GNN type: SAGE\n",
      "[PASS] 1.4 NaN detection\n",
      "\n",
      "Suite 1 Results: 6 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST SUITE 1: GNNBranch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "passed, failed = 0, 0\n",
    "\n",
    "# Test 1.1: Basic forward pass\n",
    "try:\n",
    "    gnn = GNNBranch(config, n_features=16, n_nodes=test_nodes, gnn_type='GAT').to(device)\n",
    "    x = torch.randn(test_nodes, 16, device=device)\n",
    "    out = gnn(x, edge_index)\n",
    "    assert out.shape == (test_nodes, config.gnn_hidden_dim)\n",
    "    print(\"[PASS] 1.1 Basic forward pass\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 1.1 Basic forward pass: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 1.2: Batch processing\n",
    "try:\n",
    "    x_batch = torch.randn(2, test_nodes, 16, device=device)\n",
    "    out_batch = torch.stack([gnn(x_batch[i], edge_index) for i in range(2)])\n",
    "    assert out_batch.shape == (2, test_nodes, config.gnn_hidden_dim)\n",
    "    print(\"[PASS] 1.2 Batch processing\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 1.2 Batch processing: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 1.3: GNN types\n",
    "for gnn_type in ['GCN', 'GAT', 'SAGE']:\n",
    "    try:\n",
    "        gnn_test = GNNBranch(config, n_features=16, n_nodes=test_nodes, gnn_type=gnn_type).to(device)\n",
    "        out = gnn_test(x, edge_index)\n",
    "        assert out.shape == (test_nodes, config.gnn_hidden_dim)\n",
    "        print(f\"[PASS] 1.3 GNN type: {gnn_type}\")\n",
    "        passed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] 1.3 GNN type {gnn_type}: {e}\")\n",
    "        failed += 1\n",
    "\n",
    "# Test 1.4: NaN detection\n",
    "try:\n",
    "    x_nan = torch.randn(test_nodes, 16, device=device)\n",
    "    x_nan[0, 0] = float('nan')\n",
    "    try:\n",
    "        gnn(x_nan, edge_index)\n",
    "        print(\"[FAIL] 1.4 NaN detection - should have raised error\")\n",
    "        failed += 1\n",
    "    except ValueError as e:\n",
    "        if \"NaN\" in str(e):\n",
    "            print(\"[PASS] 1.4 NaN detection\")\n",
    "            passed += 1\n",
    "        else:\n",
    "            raise e\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 1.4 NaN detection: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "print(f\"\\nSuite 1 Results: {passed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Suite 2: GridGraphFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST SUITE 2: GridGraphFusion\n",
      "============================================================\n",
      "[PASS] 2.1 Basic fusion\n",
      "[PASS] 2.2 Different input dimensions\n",
      "[PASS] 2.3 Single sample\n",
      "\n",
      "Suite 2 Results: 3 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST SUITE 2: GridGraphFusion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "passed, failed = 0, 0\n",
    "\n",
    "# Test 2.1: Basic fusion\n",
    "try:\n",
    "    fusion = GridGraphFusion(64, 64, config).to(device)\n",
    "    grid_feat = torch.randn(4, test_nodes, 64, device=device)\n",
    "    graph_feat = torch.randn(4, test_nodes, 64, device=device)\n",
    "    out = fusion(grid_feat, graph_feat)\n",
    "    assert out.shape == (4, test_nodes, config.fusion_hidden_dim)\n",
    "    print(\"[PASS] 2.1 Basic fusion\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 2.1 Basic fusion: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 2.2: Different input dimensions\n",
    "try:\n",
    "    fusion2 = GridGraphFusion(32, 128, config).to(device)\n",
    "    grid_feat = torch.randn(4, test_nodes, 32, device=device)\n",
    "    graph_feat = torch.randn(4, test_nodes, 128, device=device)\n",
    "    out = fusion2(grid_feat, graph_feat)\n",
    "    assert out.shape == (4, test_nodes, config.fusion_hidden_dim)\n",
    "    print(\"[PASS] 2.2 Different input dimensions\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 2.2 Different input dimensions: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 2.3: Single sample\n",
    "try:\n",
    "    grid_feat = torch.randn(1, test_nodes, 64, device=device)\n",
    "    graph_feat = torch.randn(1, test_nodes, 64, device=device)\n",
    "    out = fusion(grid_feat, graph_feat)\n",
    "    assert out.shape == (1, test_nodes, config.fusion_hidden_dim)\n",
    "    print(\"[PASS] 2.3 Single sample\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 2.3 Single sample: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "print(f\"\\nSuite 2 Results: {passed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Suite 3: MetaLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST SUITE 3: MetaLearner\n",
      "============================================================\n",
      "[PASS] 3.1 Basic forward\n",
      "[PASS] 3.2 Weights sum to 1\n",
      "[PASS] 3.3 Weights in [0, 1]\n",
      "\n",
      "Suite 3 Results: 3 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST SUITE 3: MetaLearner\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "passed, failed = 0, 0\n",
    "\n",
    "# Test 3.1: Basic forward\n",
    "try:\n",
    "    meta = MetaLearner(128, config).to(device)\n",
    "    fusion_feat = torch.randn(4, test_nodes, 128, device=device)\n",
    "    pred, weights = meta(fusion_feat)\n",
    "    assert pred.shape == (4, test_nodes, 1)\n",
    "    assert weights.shape == (4, test_nodes, 2)\n",
    "    print(\"[PASS] 3.1 Basic forward\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 3.1 Basic forward: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 3.2: Weights sum to 1\n",
    "try:\n",
    "    weight_sums = weights.sum(dim=-1)\n",
    "    assert torch.allclose(weight_sums, torch.ones_like(weight_sums), atol=1e-5)\n",
    "    print(\"[PASS] 3.2 Weights sum to 1\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 3.2 Weights sum to 1: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 3.3: Weights in [0, 1]\n",
    "try:\n",
    "    assert (weights >= 0).all() and (weights <= 1).all()\n",
    "    print(\"[PASS] 3.3 Weights in [0, 1]\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 3.3 Weights in [0, 1]: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "print(f\"\\nSuite 3 Results: {passed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Suite 4: V5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST SUITE 4: V5Config\n",
      "============================================================\n",
      "[PASS] 4.1 Required attributes present\n",
      "[PASS] 4.2 graph_input_dim raises helpful error\n",
      "[PASS] 4.3 n_nodes = n_lat * n_lon\n",
      "\n",
      "Suite 4 Results: 3 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST SUITE 4: V5Config\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "passed, failed = 0, 0\n",
    "\n",
    "# Test 4.1: Required attributes\n",
    "required = ['n_lat', 'n_lon', 'n_nodes', 'gnn_hidden_dim', 'gnn_num_layers',\n",
    "            'gnn_dropout', 'convlstm_hidden_dim', 'fusion_hidden_dim', 'meta_hidden_dim']\n",
    "try:\n",
    "    for attr in required:\n",
    "        assert hasattr(config, attr), f\"Missing {attr}\"\n",
    "    print(\"[PASS] 4.1 Required attributes present\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 4.1 Required attributes: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 4.2: Removed attribute error\n",
    "try:\n",
    "    _ = config.graph_input_dim\n",
    "    print(\"[FAIL] 4.2 graph_input_dim - should raise AttributeError\")\n",
    "    failed += 1\n",
    "except AttributeError as e:\n",
    "    if \"removed\" in str(e).lower() or \"n_features\" in str(e).lower():\n",
    "        print(\"[PASS] 4.2 graph_input_dim raises helpful error\")\n",
    "        passed += 1\n",
    "    else:\n",
    "        print(f\"[FAIL] 4.2 graph_input_dim - wrong error message: {e}\")\n",
    "        failed += 1\n",
    "\n",
    "# Test 4.3: n_nodes calculation\n",
    "try:\n",
    "    assert config.n_nodes == config.n_lat * config.n_lon\n",
    "    print(\"[PASS] 4.3 n_nodes = n_lat * n_lon\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 4.3 n_nodes calculation: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "print(f\"\\nSuite 4 Results: {passed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Suite 5: Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST SUITE 5: Integration\n",
      "============================================================\n",
      "[PASS] 5.1 Full pipeline forward\n",
      "[PASS] 5.2 Gradient flow (no NaN)\n",
      "\n",
      "Suite 5 Results: 2 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST SUITE 5: Integration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "passed, failed = 0, 0\n",
    "\n",
    "# Test 5.1: Full pipeline\n",
    "try:\n",
    "    batch_size = 2\n",
    "    n_features = 16\n",
    "\n",
    "    # Create modules\n",
    "    gnn = GNNBranch(config, n_features=n_features, n_nodes=test_nodes, gnn_type='GAT').to(device)\n",
    "    fusion = GridGraphFusion(gnn.output_dim, gnn.output_dim, config).to(device)\n",
    "    meta = MetaLearner(fusion.output_dim, config).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    x = torch.randn(batch_size, test_nodes, n_features, device=device)\n",
    "    gnn_out = torch.stack([gnn(x[i], edge_index) for i in range(batch_size)])\n",
    "    grid_feat = torch.randn(batch_size, test_nodes, gnn.output_dim, device=device)\n",
    "    fused = fusion(grid_feat, gnn_out)\n",
    "    pred, weights = meta(fused)\n",
    "\n",
    "    assert pred.shape == (batch_size, test_nodes, 1)\n",
    "    assert weights.shape == (batch_size, test_nodes, 2)\n",
    "    print(\"[PASS] 5.1 Full pipeline forward\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 5.1 Full pipeline: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 5.2: Gradient flow\n",
    "try:\n",
    "    pred.sum().backward()\n",
    "    # Check gradients exist\n",
    "    for name, param in gnn.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            assert not torch.isnan(param.grad).any(), f\"NaN in {name} grad\"\n",
    "    print(\"[PASS] 5.2 Gradient flow (no NaN)\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 5.2 Gradient flow: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "print(f\"\\nSuite 5 Results: {passed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Suite 6: Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST SUITE 6: Edge Cases\n",
      "============================================================\n",
      "[PASS] 6.1 Single node graph\n",
      "[PASS] 6.2 Single feature dimension\n",
      "[PASS] 6.3 Large feature dimension\n",
      "[PASS] 6.4 Zero input\n",
      "\n",
      "Suite 6 Results: 4 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST SUITE 6: Edge Cases\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "passed, failed = 0, 0\n",
    "\n",
    "# Test 6.1: Single node graph\n",
    "try:\n",
    "    single_edge = torch.tensor([[0], [0]], device=device)\n",
    "    gnn_single = GNNBranch(config, n_features=16, n_nodes=1, gnn_type='GCN').to(device)\n",
    "    x_single = torch.randn(1, 16, device=device)\n",
    "    out = gnn_single(x_single, single_edge)\n",
    "    assert out.shape == (1, config.gnn_hidden_dim)\n",
    "    print(\"[PASS] 6.1 Single node graph\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 6.1 Single node: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 6.2: Very small features\n",
    "try:\n",
    "    gnn_small = GNNBranch(config, n_features=1, n_nodes=test_nodes, gnn_type='GCN').to(device)\n",
    "    x_small = torch.randn(test_nodes, 1, device=device)\n",
    "    out = gnn_small(x_small, edge_index)\n",
    "    assert out.shape == (test_nodes, config.gnn_hidden_dim)\n",
    "    print(\"[PASS] 6.2 Single feature dimension\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 6.2 Single feature: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 6.3: Large feature dimension\n",
    "try:\n",
    "    gnn_large = GNNBranch(config, n_features=512, n_nodes=test_nodes, gnn_type='GCN').to(device)\n",
    "    x_large = torch.randn(test_nodes, 512, device=device)\n",
    "    out = gnn_large(x_large, edge_index)\n",
    "    assert out.shape == (test_nodes, config.gnn_hidden_dim)\n",
    "    print(\"[PASS] 6.3 Large feature dimension\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 6.3 Large feature: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "# Test 6.4: Zero input\n",
    "try:\n",
    "    x_zero = torch.zeros(test_nodes, 16, device=device)\n",
    "    gnn_test = GNNBranch(config, n_features=16, n_nodes=test_nodes, gnn_type='GCN', validate=False).to(device)\n",
    "    out = gnn_test(x_zero, edge_index)\n",
    "    assert not torch.isnan(out).any()\n",
    "    print(\"[PASS] 6.4 Zero input\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 6.4 Zero input: {e}\")\n",
    "    failed += 1\n",
    "\n",
    "print(f\"\\nSuite 6 Results: {passed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Suite 7: Static Notebook Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST SUITE 7: Static Notebook Validation\n",
      "============================================================\n",
      "[PASS] 7.1 Main notebook is valid JSON\n",
      "[PASS] 7.2 No config.graph_input_dim references\n",
      "[PASS] 7.3 GNNBranch uses n_features parameter\n",
      "\n",
      "Suite 7 Results: 3 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST SUITE 7: Static Notebook Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "passed, failed = 0, 0\n",
    "\n",
    "MAIN_NOTEBOOK = 'base_models_gnn_convlstm_stacking_v5.ipynb'\n",
    "\n",
    "# Test 7.1: Valid JSON\n",
    "try:\n",
    "    with open(MAIN_NOTEBOOK, encoding='utf-8') as f:\n",
    "        main_nb = json.load(f)\n",
    "    print(\"[PASS] 7.1 Main notebook is valid JSON\")\n",
    "    passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] 7.1 JSON parsing: {e}\")\n",
    "    failed += 1\n",
    "    main_nb = None\n",
    "\n",
    "if main_nb:\n",
    "    # Test 7.2: No config.graph_input_dim\n",
    "    try:\n",
    "        bad_pattern = re.compile(r'config\\.graph_input_dim')\n",
    "        found = []\n",
    "        for i, cell in enumerate(main_nb['cells']):\n",
    "            src = ''.join(cell.get('source', []))\n",
    "            if bad_pattern.search(src):\n",
    "                found.append(i)\n",
    "        if found:\n",
    "            print(f\"[FAIL] 7.2 Found config.graph_input_dim in cells: {found}\")\n",
    "            failed += 1\n",
    "        else:\n",
    "            print(\"[PASS] 7.2 No config.graph_input_dim references\")\n",
    "            passed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] 7.2: {e}\")\n",
    "        failed += 1\n",
    "\n",
    "    # Test 7.3: GNNBranch has n_features param\n",
    "    try:\n",
    "        gnn_pattern = re.compile(r'GNNBranch\\s*\\([^)]*n_features')\n",
    "        found_correct = False\n",
    "        for cell in main_nb['cells']:\n",
    "            src = ''.join(cell.get('source', []))\n",
    "            if gnn_pattern.search(src):\n",
    "                found_correct = True\n",
    "                break\n",
    "        if found_correct:\n",
    "            print(\"[PASS] 7.3 GNNBranch uses n_features parameter\")\n",
    "            passed += 1\n",
    "        else:\n",
    "            print(\"[FAIL] 7.3 GNNBranch missing n_features parameter\")\n",
    "            failed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] 7.3: {e}\")\n",
    "        failed += 1\n",
    "\n",
    "print(f\"\\nSuite 7 Results: {passed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "V5 TEST SUMMARY\n",
      "============================================================\n",
      "\n",
      "Test Suites:\n",
      "1. GNNBranch      - Forward pass, batch, types, NaN\n",
      "2. GridGraphFusion - Basic fusion, dims, single sample\n",
      "3. MetaLearner    - Forward, weights sum, bounds\n",
      "4. V5Config       - Required attrs, removed attr\n",
      "5. Integration    - Full pipeline, gradients\n",
      "6. Edge Cases     - Single node, feature dims, zero\n",
      "7. Static         - JSON valid, no bad patterns\n",
      "\n",
      "All tests use CPU mode for portability.\n",
      "Run in Colab or local Jupyter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"V5 TEST SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "Test Suites:\n",
    "1. GNNBranch      - Forward pass, batch, types, NaN\n",
    "2. GridGraphFusion - Basic fusion, dims, single sample\n",
    "3. MetaLearner    - Forward, weights sum, bounds\n",
    "4. V5Config       - Required attrs, removed attr\n",
    "5. Integration    - Full pipeline, gradients\n",
    "6. Edge Cases     - Single node, feature dims, zero\n",
    "7. Static         - JSON valid, no bad patterns\n",
    "\n",
    "All tests use CPU mode for portability.\n",
    "Run in Colab or local Jupyter.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
