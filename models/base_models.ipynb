{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635dc005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n del entorno (compatible con Colab y local)\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Detectar si estamos en Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Si estamos en Colab, clonar el repositorio\n",
    "    !git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
    "    %cd ml_precipitation_prediction\n",
    "    # Instalar dependencias necesarias\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn\n",
    "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
    "else:\n",
    "    # Si estamos en local, usar la ruta actual\n",
    "    if '/models' in os.getcwd():\n",
    "        BASE_PATH = Path('..')\n",
    "    else:\n",
    "        BASE_PATH = Path('.')\n",
    "\n",
    "print(f\"Entorno configurado. Usando ruta base: {BASE_PATH}\")\n",
    "\n",
    "# Si BASE_PATH viene como string, lo convertimos\n",
    "BASE_PATH = Path(BASE_PATH)\n",
    "\n",
    "# Ahora puedes concatenar correctamente\n",
    "data_output_dir = BASE_PATH / 'data' / 'output'\n",
    "model_output_dir = BASE_PATH / 'models' / 'output'\n",
    "model_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directorio para salida de modelos creado: {model_output_dir}\")\n",
    "\n",
    "# Implementaci√≥n de resiliencia para interacci√≥n con Google Drive y restauraci√≥n de datos\n",
    "def backup_dataframe(df, backup_path):\n",
    "    \"\"\"Guarda un DataFrame como respaldo en formato Parquet.\"\"\"\n",
    "    try:\n",
    "        df.to_parquet(backup_path, index=False)\n",
    "        print(f\"Respaldo del DataFrame guardado en: {backup_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar respaldo del DataFrame: {e}\")\n",
    "\n",
    "def restore_dataframe(backup_path):\n",
    "    \"\"\"Restaura un DataFrame desde un archivo de respaldo en formato Parquet.\"\"\"\n",
    "    try:\n",
    "        if backup_path.exists():\n",
    "            df_restored = pd.read_parquet(backup_path)\n",
    "            print(f\"DataFrame restaurado desde: {backup_path}\")\n",
    "            return df_restored\n",
    "        else:\n",
    "            print(f\"No se encontr√≥ el archivo de respaldo en: {backup_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al restaurar el DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ruta para respaldo temporal del DataFrame\n",
    "temp_dir = BASE_PATH / 'data' / 'output' / 'temp'\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "temp_file_path = temp_dir / 'dataframe_backup.parquet'\n",
    "\n",
    "# Respaldo inicial del DataFrame principal\n",
    "if 'df' in locals() and df is not None:\n",
    "    backup_dataframe(df, temp_file_path)\n",
    "\n",
    "# Modificar interacci√≥n con Google Drive para reintentos\n",
    "max_retries = 3\n",
    "retry_delay = 5  # segundos\n",
    "\n",
    "def mount_google_drive():\n",
    "    \"\"\"Intenta montar Google Drive con reintentos.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"Google Drive montado exitosamente.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error al montar Google Drive (intento {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "    print(\"No se pudo montar Google Drive despu√©s de varios intentos.\")\n",
    "    return False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not mount_google_drive():\n",
    "        print(\"Usando datos en memoria o restaurando desde respaldo local.\")\n",
    "        df = restore_dataframe(temp_file_path)\n",
    "\n",
    "# Restaurar modelos guardados en caso de fallo\n",
    "model_files = {\n",
    "    'RandomForest': model_output_dir / 'RandomForest.pkl',\n",
    "    'XGBoost': model_output_dir / 'XGBoost.pkl',\n",
    "    'LightGBM': model_output_dir / 'LightGBM.pkl'\n",
    "}\n",
    "\n",
    "def load_saved_model(model_name, model_path):\n",
    "    \"\"\"Carga un modelo guardado desde disco.\"\"\"\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "            print(f\"Modelo {model_name} cargado desde: {model_path}\")\n",
    "            return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Inicializar `modelos_base` como un diccionario vac√≠o\n",
    "modelos_base = {}\n",
    "\n",
    "# Intentar cargar modelos guardados\n",
    "for model_name, model_path in model_files.items():\n",
    "    if model_name not in modelos_base:\n",
    "        modelos_base[model_name] = load_saved_model(model_name, model_path)\n",
    "\n",
    "# Implementaci√≥n de resiliencia para modelos CNN y ConvLSTM\n",
    "\n",
    "# Respaldo y restauraci√≥n de modelos CNN y ConvLSTM\n",
    "cnn_model_path = model_output_dir / 'cnn_model.h5'\n",
    "convlstm_model_path = model_output_dir / 'convlstm_model.h5'\n",
    "\n",
    "def backup_model(model, model_path):\n",
    "    \"\"\"Guarda un modelo de Keras como respaldo.\"\"\"\n",
    "    try:\n",
    "        model.save(model_path)\n",
    "        print(f\"Modelo respaldado en: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar respaldo del modelo: {e}\")\n",
    "\n",
    "def restore_model(model_path):\n",
    "    \"\"\"Restaura un modelo de Keras desde un archivo de respaldo.\"\"\"\n",
    "    try:\n",
    "        if model_path.exists():\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"Modelo restaurado desde: {model_path}\")\n",
    "            return model\n",
    "        else:\n",
    "            print(f\"No se encontr√≥ el archivo de respaldo en: {model_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al restaurar el modelo: {e}\")\n",
    "        return None\n",
    "\n",
    "# Respaldo inicial de modelos si existen\n",
    "if 'cnn_model' in locals() and cnn_model is not None:\n",
    "    backup_model(cnn_model, cnn_model_path)\n",
    "if 'convlstm_model' in locals() and convlstm_model is not None:\n",
    "    backup_model(convlstm_model, convlstm_model_path)\n",
    "\n",
    "# Restaurar modelos en caso de fallo\n",
    "if 'cnn_model' not in locals() or cnn_model is None:\n",
    "    cnn_model = restore_model(cnn_model_path)\n",
    "if 'convlstm_model' not in locals() or convlstm_model is None:\n",
    "    convlstm_model = restore_model(convlstm_model_path)\n",
    "\n",
    "# Modificar interacci√≥n con Google Drive para reintentos\n",
    "max_retries = 3\n",
    "retry_delay = 5  # segundos\n",
    "\n",
    "def mount_google_drive():\n",
    "    \"\"\"Intenta montar Google Drive con reintentos.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"Google Drive montado exitosamente.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error al montar Google Drive (intento {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "    print(\"No se pudo montar Google Drive despu√©s de varios intentos.\")\n",
    "    return False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not mount_google_drive():\n",
    "        print(\"Usando datos en memoria o restaurando desde respaldo local para modelos CNN y ConvLSTM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cdb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importaciones necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import optuna\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importaciones para barras de progreso y mejora de visualizaci√≥n\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import time\n",
    "\n",
    "# Configurar visualizaci√≥n m√°s atractiva\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ccc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ST-HybridWaveStack - Evaluaci√≥n comparativa de configuraciones\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, GRU, Bidirectional, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Funciones auxiliares\n",
    "def create_sequences(X, y, window=12):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - window):\n",
    "        X_seq.append(X[i:i+window])\n",
    "        y_seq.append(y[i+window])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "def build_model(model_type, input_shape, output_neurons):\n",
    "    model = Sequential()\n",
    "    if model_type == 'LSTM':\n",
    "        model.add(LSTM(64, input_shape=input_shape))\n",
    "    elif model_type == 'GRU':\n",
    "        model.add(GRU(64, input_shape=input_shape))\n",
    "    elif model_type == 'BLSTM':\n",
    "        model.add(Bidirectional(LSTM(64), input_shape=input_shape))\n",
    "    elif model_type == 'CNN':\n",
    "        model.add(Reshape((*input_shape, 1), input_shape=input_shape))\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "    model.add(Dense(output_neurons))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, mape, r2\n",
    "\n",
    "# Ruta del archivo\n",
    "try:\n",
    "    file_path = data_output_dir / \"complete_dataset_with_features_with_clusters_elevation.nc\"\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    print(f\"‚úîÔ∏è Dataset cargado desde: {file_path}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"‚ùå Error cargando dataset: {e}\")\n",
    "\n",
    "# Configuraciones del experimento\n",
    "experiment_settings = {\n",
    "    \"precip+time\": ['month_sin', 'month_cos'],\n",
    "    \"precip+time+elev\": ['month_sin', 'month_cos', 'elevation', 'slope', 'aspect'],\n",
    "    \"all_features\": ['month_sin', 'month_cos', 'elevation', 'slope', 'aspect', 'cluster_elevation']\n",
    "}\n",
    "\n",
    "results = {\n",
    "    'experiment': [],\n",
    "    'model': [],\n",
    "    'RMSE': [],\n",
    "    'MAE': [],\n",
    "    'MAPE': [],\n",
    "    'R2': []\n",
    "}\n",
    "\n",
    "for exp_name, variables in experiment_settings.items():\n",
    "    print(f\"\\nüöÄ Ejecutando experimento: {exp_name}\")\n",
    "\n",
    "    try:\n",
    "        cluster_elevation_index = variables.index('cluster_elevation') if 'cluster_elevation' in variables else None\n",
    "        subset_array = ds[variables].to_array().transpose('time', 'latitude', 'longitude', 'variable')\n",
    "        subset_np = subset_array.values\n",
    "\n",
    "        if cluster_elevation_index is not None:\n",
    "            cluster_data = subset_np[..., cluster_elevation_index]\n",
    "            encoded = LabelEncoder().fit_transform(cluster_data.ravel()).reshape(cluster_data.shape)\n",
    "            subset_np[..., cluster_elevation_index] = encoded\n",
    "\n",
    "        subset_np = subset_np.astype(np.float32)\n",
    "        target = ds['total_precipitation'].values\n",
    "\n",
    "        samples, lat, lon, feats = subset_np.shape\n",
    "        X = subset_np.reshape(samples, lat * lon, feats)\n",
    "        y = target.reshape(samples, lat * lon)\n",
    "\n",
    "        mask = ~np.isnan(y)\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "\n",
    "        X_seq, y_seq = create_sequences(X, y, window=12)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "        X_train_feed = X_train.reshape((X_train.shape[0], X_train.shape[1], -1))\n",
    "        X_test_feed = X_test.reshape((X_test.shape[0], X_test.shape[1], -1))\n",
    "        input_shape = (X_train_feed.shape[1], X_train_feed.shape[2])\n",
    "\n",
    "        for model_name in ['LSTM', 'GRU', 'BLSTM', 'CNN']:\n",
    "            print(f\"\\tüèóÔ∏è Entrenando modelo {model_name}...\")\n",
    "            model = build_model(model_name, input_shape, 1)\n",
    "            es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            model.fit(X_train_feed, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0, callbacks=[es])\n",
    "\n",
    "            y_pred = model.predict(X_test_feed).flatten()\n",
    "            y_true = y_test.flatten()\n",
    "\n",
    "            rmse, mae, mape, r2 = evaluate(y_true, y_pred)\n",
    "            results['experiment'].append(exp_name)\n",
    "            results['model'].append(model_name)\n",
    "            results['RMSE'].append(rmse)\n",
    "            results['MAE'].append(mae)\n",
    "            results['MAPE'].append(mape)\n",
    "            results['R2'].append(r2)\n",
    "            print(f\"\\t‚úÖ {model_name} -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, MAPE: {mape:.2f}%, R¬≤: {r2:.3f}\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"‚ùå Error en experimento '{exp_name}': {err}\")\n",
    "\n",
    "# Mostrar resultados finales\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='RMSE')\n",
    "results_df.to_csv('resultados_comparativos_modelos.csv', index=False)\n",
    "print(\"\\nüìä Resultados finales ordenados por RMSE:\")\n",
    "print(results_df)\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
