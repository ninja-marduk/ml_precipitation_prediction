{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4e7925",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/main/models/base_models_STHyMOUNTAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3744f4",
   "metadata": {
    "id": "af3744f4"
   },
   "source": [
    "# 📘 Entrenamiento de Modelos Baseline para Predicción Espaciotemporal de Precipitación Mensual STHyMOUNTAIN\n",
    "\n",
    "Este notebook implementa modelos baseline para la predicción de precipitaciones usando datos espaciotemporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994be36",
   "metadata": {},
   "source": [
    "## 🔍 Implementación de Modelos Avanzados y Técnicas de Validación\n",
    "\n",
    "Además de los modelos tabulares baseline, implementaremos:\n",
    "\n",
    "1. **Modelos de Deep Learning** para capturar patrones espaciales y temporales:\n",
    "   - Redes CNN para patrones espaciales\n",
    "   - Redes ConvLSTM para patrones temporales\n",
    "   - Redes ConvGRU para patrones temporales\n",
    "\n",
    "El objetivo es proporcionar una evaluación completa de diferentes enfoques de modelado para la predicción de precipitación en regiones montañosas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06416284",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06416284",
    "outputId": "a8e4c864-34e9-41b2-d5c3-e6ccaaf3699e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_PATH = /Users/riperez/Conda/anaconda3/envs/precipitation_prediction/github.com/ml_precipitation_prediction\n",
      "Dataset → time=518, lat=61, lon=65\n",
      "\n",
      "=== Experimento BASIC (12 features) ===\n",
      "→ ConvLSTM\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "# ───────────────────────────────────── imports ─────────────────────────────────────\n",
    "from pathlib import Path\n",
    "import sys, os, gc, warnings, shutil\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Input, Conv2D, ConvLSTM2D, BatchNormalization,\n",
    "                                     MaxPooling2D, Dropout, Flatten, Dense, Reshape)\n",
    "from tensorflow.keras.layers import (Input, ConvLSTM2D, SimpleRNN, Conv2D, BatchNormalization,\n",
    "                                     Flatten, Dense, Add, LayerNormalization, TimeDistributed)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error,\n",
    "                             mean_absolute_percentage_error, r2_score)\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Agrega la raíz del proyecto al sys.path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "from lib.ConvGRU2D import ConvGRU2D\n",
    "\n",
    "\n",
    "# ───────────────────────── 0. Entorno ─────────────────────────\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !git clone -q https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
    "    %cd ml_precipitation_prediction\n",
    "    !pip install -q -r requirements.txt xarray netCDF4 seaborn scikit-learn geopandas imageio\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    for p in [BASE_PATH, *BASE_PATH.parents]:\n",
    "        if (p/'.git').exists():\n",
    "            BASE_PATH = p; break\n",
    "\n",
    "print('BASE_PATH =', BASE_PATH)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid'); sns.set_context('notebook')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import imageio.v2 as imageio\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# ───────────────────────── PATHS & CONST ─────────────────────────\n",
    "DATA_FILE = BASE_PATH/'data'/'output'/(\n",
    "    'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation_clean.nc')\n",
    "OUT_ROOT  = BASE_PATH/'models'/'output'/'Spatial_CONVRNN'\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SHAPE_DIR = BASE_PATH/'data'/'input'/'shapes'\n",
    "DEPT_GDF = gpd.read_file(SHAPE_DIR/'MGN_Departamento.shp')\n",
    "\n",
    "INPUT_WINDOW = 60; HORIZON = 3; EPOCHS = 50; BATCH = 4; LR = 1e-3\n",
    "PATIENCE = 6\n",
    "\n",
    "# ───────────────────────── FEATURE SETS ─────────────────────────\n",
    "BASE_FEATS = ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
    "              'max_daily_precipitation','min_daily_precipitation','daily_precipitation_std',\n",
    "              'elevation','slope','aspect']\n",
    "ELEV_CLUSTER = ['elev_high','elev_med','elev_low']\n",
    "KCE_FEATS = BASE_FEATS + ELEV_CLUSTER\n",
    "PAFC_FEATS= KCE_FEATS + ['total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag12']\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    'BASIC': BASE_FEATS,\n",
    "    'KCE'  : KCE_FEATS,\n",
    "    'PAFC' : PAFC_FEATS\n",
    "}\n",
    "\n",
    "# ───────────────────────── DATASET ─────────────────────────\n",
    "ds = xr.open_dataset(DATA_FILE)\n",
    "lat, lon = len(ds.latitude), len(ds.longitude)\n",
    "print(f\"Dataset → time={len(ds.time)}, lat={lat}, lon={lon}\")\n",
    "\n",
    "# ───────────────────────── HELPERS ─────────────────────────\n",
    "\n",
    "def windowed_arrays(X:np.ndarray, y:np.ndarray):\n",
    "    \"\"\"Crea ventanas deslizantes 5‑D para X y 4‑D para y.\"\"\"\n",
    "    seq_X, seq_y = [], []\n",
    "    T = len(X)\n",
    "    for start in range(T-INPUT_WINDOW-HORIZON+1):\n",
    "        end_w = start+INPUT_WINDOW; end_y=end_w+HORIZON\n",
    "        Xw = X[start:end_w]; yw = y[end_w:end_y]\n",
    "        if np.isnan(Xw).any() or np.isnan(yw).any():\n",
    "            continue\n",
    "        seq_X.append(Xw); seq_y.append(yw)\n",
    "    return np.array(seq_X,dtype=np.float32), np.array(seq_y,dtype=np.float32)\n",
    "\n",
    "\n",
    "def quick_plot(ax,data,cmap,title,vmin=None,vmax=None):\n",
    "    mesh = ax.pcolormesh(ds.longitude,ds.latitude,data,cmap=cmap,shading='nearest',\n",
    "                         vmin=vmin,vmax=vmax,transform=ccrs.PlateCarree())\n",
    "    ax.coastlines(); ax.add_geometries(DEPT_GDF.geometry,ccrs.PlateCarree(),edgecolor='black',facecolor='none',linewidth=1)\n",
    "    ax.gridlines(draw_labels=True,top_labels=False,right_labels=False)\n",
    "    ax.set_title(title,fontsize=9); return mesh\n",
    "\n",
    "# ───────────────────────── MODEL FACTORIES ─────────────────────────\n",
    "\n",
    "def build_conv_lstm(n_feats:int):\n",
    "    inp = Input(shape=(INPUT_WINDOW,lat,lon,n_feats),name='in')\n",
    "    x   = ConvLSTM2D(64,(3,3),padding='same',return_sequences=True)(inp)\n",
    "    x   = ConvLSTM2D(32,(3,3),padding='same')(x)\n",
    "    x   = Flatten()(x)\n",
    "    x   = Dense(HORIZON*lat*lon,activation='linear')(x)\n",
    "    out = Reshape((HORIZON,lat,lon,1))(x)\n",
    "    m   = Model(inp,out,name='ConvLSTM'); m.compile('adam','mse'); return m\n",
    "\n",
    "\n",
    "def build_conv_gru(n_feats:int):\n",
    "    inp = Input(shape=(INPUT_WINDOW,lat,lon,n_feats))\n",
    "    x = ConvGRU2D(64,(3,3),padding='same',return_sequences=True)(inp)\n",
    "    x = ConvGRU2D(32,(3,3),padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(HORIZON*lat*lon)(x)\n",
    "    out=Reshape((HORIZON,lat,lon,1))(x)\n",
    "    m=Model(inp,out,name='ConvGRU'); m.compile('adam','mse'); return m\n",
    "\n",
    "\n",
    "def build_conv_rnn(n_feats:int):\n",
    "    inp = Input(shape=(INPUT_WINDOW,lat,lon,n_feats))\n",
    "    x = SimpleRNN(128,activation='tanh')(Flatten()(inp))\n",
    "    x = Dense(HORIZON*lat*lon)(x)\n",
    "    out=Reshape((HORIZON,lat,lon,1))(x)\n",
    "    m=Model(inp,out,name='ConvRNN'); m.compile('adam','mse'); return m\n",
    "\n",
    "MODELS = {\n",
    "    'ConvLSTM': build_conv_lstm,\n",
    "    'ConvGRU' : build_conv_gru,\n",
    "    'ConvRNN' : build_conv_rnn\n",
    "}\n",
    "\n",
    "# ───────────────────────── TRAIN + EVAL LOOP ─────────────────────────\n",
    "results=[]\n",
    "for exp, feat_list in EXPERIMENTS.items():\n",
    "    print(f\"\\n=== Experimento {exp} ({len(feat_list)} features) ===\")\n",
    "    Xarr = ds[feat_list].to_array().transpose('time','latitude','longitude','variable').values.astype(np.float32)\n",
    "    yarr = ds['total_precipitation'].values.astype(np.float32)[...,None]  # (T,H,W,1)\n",
    "\n",
    "    X, y = windowed_arrays(Xarr, yarr)\n",
    "    split=int(0.8*len(X))\n",
    "\n",
    "    sx = StandardScaler().fit(X[:split].reshape(-1,len(feat_list)))\n",
    "    sy = StandardScaler().fit(y[:split].reshape(-1,1))\n",
    "\n",
    "    X_sc = sx.transform(X.reshape(-1,len(feat_list))).reshape(X.shape)\n",
    "    y_sc = sy.transform(y.reshape(-1,1)).reshape(y.shape)\n",
    "\n",
    "    X_tr, X_va = X_sc[:split], X_sc[split:]\n",
    "    y_tr, y_va = y_sc[:split], y_sc[split:]\n",
    "\n",
    "    OUT_EXP = OUT_ROOT/exp; OUT_EXP.mkdir(exist_ok=True)\n",
    "\n",
    "    for mdl_name,builder in MODELS.items():\n",
    "        print(f\"→ {mdl_name}\")\n",
    "        model_path = OUT_EXP/f\"{mdl_name.lower()}_best.keras\"\n",
    "        if model_path.exists():\n",
    "            print(\"⏩ ya entrenado, cargando …\"); model=tf.keras.models.load_model(model_path,compile=False)\n",
    "        else:\n",
    "            model = builder(n_feats=len(feat_list))\n",
    "            cb = [EarlyStopping('val_loss',patience=PATIENCE,restore_best_weights=True),\n",
    "                  ModelCheckpoint(model_path,save_best_only=True)]\n",
    "            model.fit(X_tr,y_tr,validation_data=(X_va,y_va),epochs=EPOCHS,batch_size=BATCH,callbacks=cb,verbose=0)\n",
    "        # --- Predicción último batch validación ---\n",
    "        y_hat_sc = model.predict(X_va[-1:],verbose=0)\n",
    "        y_hat    = sy.inverse_transform(y_hat_sc.reshape(-1,1)).reshape(HORIZON,lat,lon)\n",
    "        y_true   = sy.inverse_transform(y_va[-1:].reshape(-1,1)).reshape(HORIZON,lat,lon)\n",
    "\n",
    "        # --- Mapas & GIF ---\n",
    "        vmin=0; vmax=max(y_true.max(),y_hat.max())\n",
    "        frames=[]; dates=pd.date_range(ds.time.values[-HORIZON],periods=HORIZON,freq='MS')\n",
    "        for h in range(HORIZON):\n",
    "            err = np.clip(np.abs((y_true[h]-y_hat[h])/(y_true[h]+1e-5))*100,0,100)\n",
    "            fig,axs=plt.subplots(1,3,figsize=(12,4),subplot_kw={'projection':ccrs.PlateCarree()})\n",
    "            quick_plot(axs[0],y_true[h],'Blues',f\"Real h={h+1}\",vmin,vmax)\n",
    "            quick_plot(axs[1],y_hat[h],'Blues',f\"Pred {mdl_name} h={h+1}\",vmin,vmax)\n",
    "            quick_plot(axs[2],err,'Reds',f\"MAPE% h={h+1}\",0,100)\n",
    "            fig.suptitle(f\"{mdl_name} – {exp} – {dates[h].strftime('%Y-%m')}\")\n",
    "            png = OUT_EXP/f\"{mdl_name}_{h+1}.png\"; plt.savefig(png,bbox_inches='tight'); plt.close(fig)\n",
    "            frames.append(imageio.imread(png))\n",
    "        imageio.mimsave(OUT_EXP/f\"{mdl_name}.gif\",frames,fps=0.5)\n",
    "\n",
    "        # --- Métricas ---\n",
    "        for h in range(HORIZON):\n",
    "            results.append({\n",
    "                'Experiment':exp,'Model':mdl_name,'H':h+1,\n",
    "                'RMSE':np.sqrt(mean_squared_error(y_true[h].ravel(),y_hat[h].ravel())),\n",
    "                'MAE': mean_absolute_error(y_true[h].ravel(),y_hat[h].ravel()),\n",
    "                'R2':  r2_score(y_true[h].ravel(),y_hat[h].ravel())\n",
    "            })\n",
    "        tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "# ───────────────────────── CSV FINAL ─────────────────────────\n",
    "res_df=pd.DataFrame(results)\n",
    "res_df.to_csv(OUT_ROOT/'metrics_spatial.csv',index=False)\n",
    "print(\"\\n📑 Metrics saved →\", OUT_ROOT/'metrics_spatial.csv')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
