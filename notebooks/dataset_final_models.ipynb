{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645b7cd3",
   "metadata": {},
   "source": [
    "# Generación de dataset completo con variables artificiales\n",
    "\n",
    "Este notebook genera un dataset completo para modelos de predicción de precipitación que incluye:\n",
    "- Variables de precipitación (CHIRPS)\n",
    "- Variables topográficas (DEM)\n",
    "- Transformaciones temporales (seno/coseno de meses y día del año)\n",
    "\n",
    "Se utilizan técnicas de gestión de memoria para evitar problemas con el kernel.\n",
    "\n",
    "Este notebook es compatible tanto con entornos locales como con Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e6e7a",
   "metadata": {},
   "source": [
    "## Configuración del Entorno\n",
    "\n",
    "Primero detectamos si estamos ejecutando en Google Colab o en un entorno local para configurar adecuadamente las rutas y dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar si estamos en Google Colab o en entorno local\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Función para instalar paquetes\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Verificar si estamos en Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# Configuración según el entorno\n",
    "if IN_COLAB:\n",
    "    print(\"Ejecutando en Google Colab. Configurando entorno...\")\n",
    "    \n",
    "    # Instalar dependencias necesarias para Colab\n",
    "    required_packages = ['richdem', 'matplotlib', 'xarray', 'dask', 'netCDF4', 'psutil']\n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\"✓ {package} ya está instalado\")\n",
    "        except ImportError:\n",
    "            print(f\"Instalando {package}...\")\n",
    "            install_package(package)\n",
    "    \n",
    "    # Montar Google Drive para acceder/guardar datos\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Definir rutas base para Colab\n",
    "    # Puedes ajustar esta ruta según tu estructura en Google Drive\n",
    "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
    "    \n",
    "    # Crear carpetas necesarias si no existen\n",
    "    for folder in ['data/output', 'models']:\n",
    "        os.makedirs(os.path.join(BASE_PATH, folder), exist_ok=True)\n",
    "    \n",
    "    print(f\"Base path configurado a: {BASE_PATH}\")\n",
    "    print(\"Entorno de Colab configurado correctamente.\")\n",
    "else:\n",
    "    print(\"Ejecutando en entorno local.\")\n",
    "    # En entorno local, usamos rutas relativas\n",
    "    BASE_PATH = '..'\n",
    "    \n",
    "    # Verificar si las dependencias están instaladas\n",
    "    try:\n",
    "        import richdem\n",
    "        import xarray\n",
    "        import matplotlib\n",
    "        import psutil\n",
    "        print(\"Todas las dependencias necesarias están instaladas.\")\n",
    "    except ImportError as e:\n",
    "        print(f\"Advertencia: {e}\")\n",
    "        print(\"Algunas dependencias podrían faltar. Instálalas con pip o conda.\")\n",
    "\n",
    "print(f\"Configuración completada. BASE_PATH = {BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2ddb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import richdem as rd\n",
    "import gc\n",
    "import psutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Configurar xarray para trabajar con dask para procesamiento paralelo\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Suprimir advertencias\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "750c7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para verificar el uso de memoria\n",
    "def check_memory_usage():\n",
    "    \"\"\"Muestra el uso actual de memoria y sugiere posibles acciones.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_info = process.memory_info()\n",
    "    \n",
    "    # Convertir a MB para mejor legibilidad\n",
    "    memory_usage_mb = memory_info.rss / 1024 / 1024\n",
    "    virtual_memory = psutil.virtual_memory()\n",
    "    available_mb = virtual_memory.available / 1024 / 1024\n",
    "    total_mb = virtual_memory.total / 1024 / 1024\n",
    "    used_percentage = virtual_memory.percent\n",
    "    \n",
    "    print(f\"\\n--- Uso de Memoria ---\")\n",
    "    print(f\"Memoria usada por este proceso: {memory_usage_mb:.1f} MB\")\n",
    "    print(f\"Memoria total disponible: {available_mb:.1f} MB de {total_mb:.1f} MB ({used_percentage:.1f}%)\")\n",
    "    \n",
    "    # Sugerir acciones basadas en el uso de memoria\n",
    "    if used_percentage > 85:\n",
    "        print(\"ADVERTENCIA: Uso de memoria crítico! Se recomienda:\")\n",
    "        print(\"  - Liberar variables innecesarias (use 'del variable')\")\n",
    "        print(\"  - Ejecutar gc.collect() para liberar memoria\")\n",
    "        print(\"  - Reducir el tamaño de los chunks\")\n",
    "        print(\"  - Guardar resultados intermedios y reiniciar el kernel\")\n",
    "    elif used_percentage > 70:\n",
    "        print(\"ATENCIÓN: Uso de memoria elevado. Considere liberar variables no utilizadas.\")\n",
    "    else:\n",
    "        print(\"Uso de memoria normal.\")\n",
    "        \n",
    "    return memory_usage_mb, available_mb, used_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd9c5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase auxiliar para monitorear el progreso\n",
    "class DatasetGenerator:\n",
    "    \"\"\"Clase auxiliar para generar y monitorear el dataset completo.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def monitor_computation(func):\n",
    "        \"\"\"Decorador para monitorear el progreso de computaciones.\"\"\"\n",
    "        def wrapper(*args, **kwargs):\n",
    "            print(f\"Iniciando: {func.__name__}\")\n",
    "            check_memory_usage()\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            with ProgressBar():\n",
    "                result = func(*args, **kwargs)\n",
    "                \n",
    "            end_time = datetime.now()\n",
    "            duration = end_time - start_time\n",
    "            print(f\"Completado: {func.__name__} en {duration}\")\n",
    "            check_memory_usage()\n",
    "            return result\n",
    "        return wrapper\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_sample(dataset, var_name, time_index=0):\n",
    "        \"\"\"Visualiza una muestra del dataset.\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        if 'time' in dataset[var_name].dims:\n",
    "            # Variable con dimensión temporal\n",
    "            data = dataset[var_name].isel(time=time_index)\n",
    "            title = f\"{var_name} - {pd.Timestamp(dataset.time.values[time_index]).strftime('%Y-%m-%d')}\"\n",
    "        else:\n",
    "            # Variable sin dimensión temporal\n",
    "            data = dataset[var_name]\n",
    "            title = f\"{var_name}\"\n",
    "        \n",
    "        # Crear mapa de calor\n",
    "        im = plt.imshow(data, cmap='viridis')\n",
    "        plt.colorbar(im, label=var_name)\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Longitud')\n",
    "        plt.ylabel('Latitud')\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "        \n",
    "        # Mostrar estadísticas básicas\n",
    "        stats = {\n",
    "            'min': float(data.min().values),\n",
    "            'max': float(data.max().values),\n",
    "            'mean': float(data.mean().values),\n",
    "            'std': float(data.std().values)\n",
    "        }\n",
    "        print(f\"Estadísticas para {var_name}:\")\n",
    "        for k, v in stats.items():\n",
    "            print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5cace2",
   "metadata": {},
   "source": [
    "## 1. Cargar datos de precipitación y elevación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el tamaño de chunk para optimizar el rendimiento\n",
    "# Ajusta estos valores según la RAM disponible\n",
    "CHUNK_SIZE = {'time': 20, 'lat': 100, 'lon': 100}  # Ajustar según sea necesario\n",
    "\n",
    "# Definir rutas usando BASE_PATH para compatibilidad entre entorno local y Colab\n",
    "chirps_path = os.path.join(BASE_PATH, 'data/output/boyaca_region_daily.nc')\n",
    "dem_path = os.path.join(BASE_PATH, 'data/output/dem_boyaca_90.nc')\n",
    "\n",
    "# Definir ruta de salida usando BASE_PATH\n",
    "output_directory = os.path.join(BASE_PATH, 'data/output')\n",
    "output_path = os.path.join(output_directory, 'complete_dataset_with_features.nc')\n",
    "\n",
    "# Verificar que el directorio existe, si no, crearlo\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "    print(f\"Directorio creado: {output_directory}\")\n",
    "else:\n",
    "    print(f\"Directorio de salida existe: {output_directory}\")\n",
    "\n",
    "# Verificar si los archivos existen\n",
    "for file_path in [chirps_path, dem_path]:\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Archivo encontrado: {file_path}\")\n",
    "    else:\n",
    "        print(f\"ADVERTENCIA: Archivo no encontrado: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a937324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando generación del dataset completo...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 49.7 MB\n",
      "Memoria total disponible: 5188.2 MB de 16384.0 MB (68.3%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "1. Cargando datos con chunks...\n",
      "CHIRPS cargado: FrozenMappingWarningOnValuesAccess({'time': 16130, 'latitude': 62, 'longitude': 66})\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 83.5 MB\n",
      "Memoria total disponible: 5195.4 MB de 16384.0 MB (68.3%)\n",
      "Uso de memoria normal.\n",
      "DEM cargado: FrozenMappingWarningOnValuesAccess({'latitude': 4800, 'longitude': 7200})\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 84.6 MB\n",
      "Memoria total disponible: 5193.6 MB de 16384.0 MB (68.3%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "2. Identificando variable de precipitación en CHIRPS...\n",
      "Variable encontrada: precip\n",
      "Usando precip como variable de precipitación\n",
      "\n",
      "3. Alineando coordenadas DEM con CHIRPS...\n",
      "Interpolando DEM a la resolución de CHIRPS...\n",
      "Interpolación completada.\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 316.3 MB\n",
      "Memoria total disponible: 5139.3 MB de 16384.0 MB (68.6%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "4. Generando variables temporales (seno/coseno)...\n",
      "Extrayendo fechas del dataset...\n",
      "Calculando seno/coseno de meses...\n",
      "Calculando seno/coseno del día del año...\n",
      "\n",
      "5. Extrayendo variables de elevación del DEM...\n",
      "\n",
      "6. Calculando características topográficas usando RichDEM...\n",
      "Preparando cálculo de pendiente y aspecto...\n",
      "Interpolación completada.\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 316.3 MB\n",
      "Memoria total disponible: 5139.3 MB de 16384.0 MB (68.6%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "4. Generando variables temporales (seno/coseno)...\n",
      "Extrayendo fechas del dataset...\n",
      "Calculando seno/coseno de meses...\n",
      "Calculando seno/coseno del día del año...\n",
      "\n",
      "5. Extrayendo variables de elevación del DEM...\n",
      "\n",
      "6. Calculando características topográficas usando RichDEM...\n",
      "Preparando cálculo de pendiente y aspecto...\n",
      "Calculando pendiente...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 553.3 MB\n",
      "Memoria total disponible: 5463.2 MB de 16384.0 MB (66.7%)\n",
      "Uso de memoria normal.\n",
      "Calculando aspecto...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 553.3 MB\n",
      "Memoria total disponible: 5464.8 MB de 16384.0 MB (66.6%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "7. Calculando estadísticas mensuales de precipitación...\n",
      "\n",
      "8. Creando dataset final con todas las variables...\n",
      "Agregando precipitación original...\n",
      "Calculando pendiente...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 553.3 MB\n",
      "Memoria total disponible: 5463.2 MB de 16384.0 MB (66.7%)\n",
      "Uso de memoria normal.\n",
      "Calculando aspecto...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 553.3 MB\n",
      "Memoria total disponible: 5464.8 MB de 16384.0 MB (66.6%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "7. Calculando estadísticas mensuales de precipitación...\n",
      "\n",
      "8. Creando dataset final con todas las variables...\n",
      "Agregando precipitación original...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A Slope calculation (degrees)\u001b[39m\n",
      "C Horn, B.K.P., 1981. Hill shading and the reflectance map. Proceedings of the IEEE 69, 14–47. doi:10.1109/PROC.1981.11918\u001b[39m\n",
      "\n",
      "\u001b[2Kt Wall-time = 0.000540834\u001b[39m==================== ] (98% - 0.0s - 1 threads)\n",
      "\n",
      "A Aspect attribute calculation\u001b[39m\n",
      "C Horn, B.K.P., 1981. Hill shading and the reflectance map. Proceedings of the IEEE 69, 14–47. doi:10.1109/PROC.1981.11918\u001b[39m\n",
      "\n",
      "\u001b[2Kt Wall-time = 0.00050425\u001b[39m===================== ] (98% - 0.0s - 1 threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 1043.3 MB\n",
      "Memoria total disponible: 4967.0 MB de 16384.0 MB (69.7%)\n",
      "Uso de memoria normal.\n",
      "Calculando total de precipitación mensual...\n",
      "Procesando 530 meses únicos...\n",
      "Procesando mes 1/530: 1981-01\n",
      "Procesando mes 11/530: 1981-11\n",
      "Procesando mes 21/530: 1982-09\n",
      "Procesando mes 31/530: 1983-07\n",
      "Procesando mes 41/530: 1984-05\n",
      "Procesando mes 51/530: 1985-03\n",
      "Procesando mes 61/530: 1986-01\n",
      "Procesando mes 71/530: 1986-11\n",
      "Procesando mes 81/530: 1987-09\n",
      "Procesando mes 91/530: 1988-07\n",
      "Procesando mes 101/530: 1989-05\n",
      "Procesando mes 111/530: 1990-03\n",
      "Procesando mes 121/530: 1991-01\n",
      "Procesando mes 131/530: 1991-11\n",
      "Procesando mes 141/530: 1992-09\n",
      "Procesando mes 151/530: 1993-07\n",
      "Procesando mes 161/530: 1994-05\n",
      "Procesando mes 171/530: 1995-03\n",
      "Procesando mes 181/530: 1996-01\n",
      "Procesando mes 191/530: 1996-11\n",
      "Procesando mes 201/530: 1997-09\n",
      "Procesando mes 211/530: 1998-07\n",
      "Procesando mes 221/530: 1999-05\n",
      "Procesando mes 231/530: 2000-03\n",
      "Procesando mes 241/530: 2001-01\n",
      "Procesando mes 251/530: 2001-11\n",
      "Procesando mes 261/530: 2002-09\n",
      "Procesando mes 271/530: 2003-07\n",
      "Procesando mes 281/530: 2004-05\n",
      "Procesando mes 291/530: 2005-03\n",
      "Procesando mes 301/530: 2006-01\n",
      "Procesando mes 311/530: 2006-11\n",
      "Procesando mes 321/530: 2007-09\n",
      "Procesando mes 331/530: 2008-07\n",
      "Procesando mes 341/530: 2009-05\n",
      "Procesando mes 351/530: 2010-03\n",
      "Procesando mes 361/530: 2011-01\n",
      "Procesando mes 371/530: 2011-11\n",
      "Procesando mes 381/530: 2012-09\n",
      "Procesando mes 391/530: 2013-07\n",
      "Procesando mes 401/530: 2014-05\n",
      "Procesando mes 411/530: 2015-03\n",
      "Procesando mes 421/530: 2016-01\n",
      "Procesando mes 431/530: 2016-11\n",
      "Procesando mes 441/530: 2017-09\n",
      "Procesando mes 451/530: 2018-07\n",
      "Procesando mes 461/530: 2019-05\n",
      "Procesando mes 471/530: 2020-03\n",
      "Procesando mes 481/530: 2021-01\n",
      "Procesando mes 491/530: 2021-11\n",
      "Procesando mes 501/530: 2022-09\n",
      "Procesando mes 511/530: 2023-07\n",
      "Procesando mes 521/530: 2024-05\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 792.0 MB\n",
      "Memoria total disponible: 5190.4 MB de 16384.0 MB (68.3%)\n",
      "Uso de memoria normal.\n",
      "Agregando variables mensuales al dataset...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 792.1 MB\n",
      "Memoria total disponible: 5189.6 MB de 16384.0 MB (68.3%)\n",
      "Uso de memoria normal.\n",
      "Agregando variables cíclicas de tiempo...\n",
      "Creando arrays 3D para variables cíclicas...\n",
      "Procesados 50/530 pasos de tiempo para variables cíclicas\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 792.0 MB\n",
      "Memoria total disponible: 5190.4 MB de 16384.0 MB (68.3%)\n",
      "Uso de memoria normal.\n",
      "Agregando variables mensuales al dataset...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 792.1 MB\n",
      "Memoria total disponible: 5189.6 MB de 16384.0 MB (68.3%)\n",
      "Uso de memoria normal.\n",
      "Agregando variables cíclicas de tiempo...\n",
      "Creando arrays 3D para variables cíclicas...\n",
      "Procesados 50/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 100/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 150/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 100/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 150/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 200/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 250/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 200/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 250/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 300/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 350/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 300/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 350/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 400/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 450/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 400/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 450/530 pasos de tiempo para variables cíclicas\n",
      "Procesados 500/530 pasos de tiempo para variables cíclicas\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 808.6 MB\n",
      "Memoria total disponible: 5172.1 MB de 16384.0 MB (68.4%)\n",
      "Uso de memoria normal.\n",
      "Agregando variables topográficas...\n",
      "Procesados 500/530 pasos de tiempo para variables cíclicas\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 808.6 MB\n",
      "Memoria total disponible: 5172.1 MB de 16384.0 MB (68.4%)\n",
      "Uso de memoria normal.\n",
      "Agregando variables topográficas...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 890.4 MB\n",
      "Memoria total disponible: 4928.4 MB de 16384.0 MB (69.9%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "9. Combinando datasets...\n",
      "\n",
      "10. Configurando chunks para almacenamiento eficiente...\n",
      "\n",
      "11. Guardando dataset final en /Users/riperez/Conda/anaconda3/doc/precipitation/output/complete_dataset_with_features.nc...\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 890.4 MB\n",
      "Memoria total disponible: 4928.4 MB de 16384.0 MB (69.9%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "9. Combinando datasets...\n",
      "\n",
      "10. Configurando chunks para almacenamiento eficiente...\n",
      "\n",
      "11. Guardando dataset final en /Users/riperez/Conda/anaconda3/doc/precipitation/output/complete_dataset_with_features.nc...\n",
      "\n",
      "Dataset generado y guardado exitosamente en /Users/riperez/Conda/anaconda3/doc/precipitation/output/complete_dataset_with_features.nc\n",
      "Dimensiones finales del dataset:\n",
      "- Variables: ['total_precipitation', 'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos', 'elevation', 'slope', 'aspect']\n",
      "- Dimensiones: {'time': 530, 'latitude': 62, 'longitude': 66}\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 850.4 MB\n",
      "Memoria total disponible: 5013.4 MB de 16384.0 MB (69.4%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 850.4 MB\n",
      "Memoria total disponible: 5011.5 MB de 16384.0 MB (69.4%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "Generación del dataset completada con éxito.\n",
      "Para visualizar los resultados, cargue el dataset desde el archivo guardado.\n",
      "\n",
      "Dataset generado y guardado exitosamente en /Users/riperez/Conda/anaconda3/doc/precipitation/output/complete_dataset_with_features.nc\n",
      "Dimensiones finales del dataset:\n",
      "- Variables: ['total_precipitation', 'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos', 'elevation', 'slope', 'aspect']\n",
      "- Dimensiones: {'time': 530, 'latitude': 62, 'longitude': 66}\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 850.4 MB\n",
      "Memoria total disponible: 5013.4 MB de 16384.0 MB (69.4%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "--- Uso de Memoria ---\n",
      "Memoria usada por este proceso: 850.4 MB\n",
      "Memoria total disponible: 5011.5 MB de 16384.0 MB (69.4%)\n",
      "Uso de memoria normal.\n",
      "\n",
      "Generación del dataset completada con éxito.\n",
      "Para visualizar los resultados, cargue el dataset desde el archivo guardado.\n"
     ]
    }
   ],
   "source": [
    "def generate_complete_dataset(chirps_path, dem_path, output_path, chunk_size=20):\n",
    "    \"\"\"\n",
    "    Genera un dataset completo con variables artificiales de elevación, precipitación,\n",
    "    y transformaciones temporales (seno/coseno de meses y año).\n",
    "    Utiliza chunks y técnicas de gestión de memoria para prevenir fallos en el kernel.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    chirps_path : str\n",
    "        Ruta al dataset CHIRPS\n",
    "    dem_path : str\n",
    "        Ruta al dataset DEM\n",
    "    output_path : str\n",
    "        Ruta donde se guardará el dataset final\n",
    "    chunk_size : int\n",
    "        Tamaño de los chunks para procesamiento\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Iniciando generación del dataset completo...\")\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # 1. Cargar datos con chunks para optimizar memoria\n",
    "        print(\"\\n1. Cargando datos con chunks...\")\n",
    "        chirps_chunks = {'latitude': chunk_size, 'longitude': chunk_size, 'time': -1}\n",
    "        dem_chunks = {'latitude': chunk_size, 'longitude': chunk_size}\n",
    "        \n",
    "        chirps_ds = xr.open_dataset(chirps_path, chunks=chirps_chunks)\n",
    "        print(f\"CHIRPS cargado: {chirps_ds.dims}\")\n",
    "        check_memory_usage()\n",
    "        \n",
    "        dem_ds = xr.open_dataset(dem_path, chunks=dem_chunks)\n",
    "        print(f\"DEM cargado: {dem_ds.dims}\")\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # 2. Identificar la variable de precipitación en CHIRPS\n",
    "        print(\"\\n2. Identificando variable de precipitación en CHIRPS...\")\n",
    "        precip_var = None\n",
    "        for var_name in chirps_ds.data_vars:\n",
    "            print(f\"Variable encontrada: {var_name}\")\n",
    "            precip_var = var_name\n",
    "            break\n",
    "            \n",
    "        if not precip_var:\n",
    "            raise ValueError(\"No se encontró ninguna variable de datos en CHIRPS\")\n",
    "            \n",
    "        print(f\"Usando {precip_var} como variable de precipitación\")\n",
    "        \n",
    "        # 3. Alinear coordenadas - interpolando DEM a la resolución de CHIRPS\n",
    "        print(\"\\n3. Alineando coordenadas DEM con CHIRPS...\")\n",
    "        if dem_ds.sizes['longitude'] != chirps_ds.sizes['longitude'] or dem_ds.sizes['latitude'] != chirps_ds.sizes['latitude']:\n",
    "            print(\"Interpolando DEM a la resolución de CHIRPS...\")\n",
    "            dem_ds = dem_ds.interp(\n",
    "                longitude=chirps_ds.longitude,\n",
    "                latitude=chirps_ds.latitude,\n",
    "                method='nearest'\n",
    "            )\n",
    "            print(\"Interpolación completada.\")\n",
    "        \n",
    "        check_memory_usage()\n",
    "        \n",
    "        # 4. Crear variables derivadas del tiempo (mes/año)\n",
    "        print(\"\\n4. Generando variables temporales (seno/coseno)...\")\n",
    "        \n",
    "        # Extraer tiempo como dataframe para facilitar manipulación\n",
    "        print(\"Extrayendo fechas del dataset...\")\n",
    "        times = pd.to_datetime(chirps_ds.time.values)\n",
    "        months = times.month\n",
    "        years = times.year\n",
    "        days_in_year = 365.25\n",
    "        \n",
    "        # Crear variables cíclicas para mes (periodo = 12)\n",
    "        print(\"Calculando seno/coseno de meses...\")\n",
    "        month_sin = np.sin(2 * np.pi * months / 12)\n",
    "        month_cos = np.cos(2 * np.pi * months / 12)\n",
    "        \n",
    "        # Crear variables cíclicas para día del año (periodo = 365.25)\n",
    "        print(\"Calculando seno/coseno del día del año...\")\n",
    "        day_of_year = times.dayofyear\n",
    "        doy_sin = np.sin(2 * np.pi * day_of_year / days_in_year)\n",
    "        doy_cos = np.cos(2 * np.pi * day_of_year / days_in_year)\n",
    "        \n",
    "        # 5. Extraer la variable de elevación del DEM\n",
    "        print(\"\\n5. Extrayendo variables de elevación del DEM...\")\n",
    "        elevation = dem_ds.to_array().isel(variable=0)\n",
    "        \n",
    "        # 6. Calcular variables topográficas usando RichDEM con manejo de memoria\n",
    "        print(\"\\n6. Calculando características topográficas usando RichDEM...\")\n",
    "        \n",
    "        # Procesar por bloques para evitar problemas de memoria\n",
    "        print(\"Preparando cálculo de pendiente y aspecto...\")\n",
    "        dem_data = elevation.values\n",
    "        \n",
    "        # Verificar si hay valores NaN y reemplazarlos con un valor NoData para richdem\n",
    "        nan_mask = np.isnan(dem_data)\n",
    "        if nan_mask.any():\n",
    "            print(f\"Encontrados {nan_mask.sum()} valores NaN en DEM, reemplazando con NoData\")\n",
    "            dem_data_clean = np.copy(dem_data)\n",
    "            dem_data_clean[nan_mask] = -9999  # Valor NoData para richdem\n",
    "        else:\n",
    "            dem_data_clean = dem_data\n",
    "        \n",
    "        # Calcular pendiente (slope)\n",
    "        print(\"Calculando pendiente...\")\n",
    "        dem_rd = rd.rdarray(dem_data_clean, no_data=-9999)\n",
    "        dem_rd.geotransform = [0, 1, 0, 0, 0, -1]  # Transformación geoespacial simple\n",
    "        slope = rd.TerrainAttribute(dem_rd, attrib='slope_degrees')\n",
    "        # Restaurar NaNs\n",
    "        slope = slope.astype(np.float32)\n",
    "        if nan_mask.any():\n",
    "            slope[nan_mask] = np.nan\n",
    "        \n",
    "        # Liberar memoria\n",
    "        del dem_rd\n",
    "        gc.collect()\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # Calcular aspecto (aspect)\n",
    "        print(\"Calculando aspecto...\")\n",
    "        dem_rd = rd.rdarray(dem_data_clean, no_data=-9999)\n",
    "        dem_rd.geotransform = [0, 1, 0, 0, 0, -1]\n",
    "        aspect = rd.TerrainAttribute(dem_rd, attrib='aspect')\n",
    "        # Restaurar NaNs\n",
    "        aspect = aspect.astype(np.float32)\n",
    "        if nan_mask.any():\n",
    "            aspect[nan_mask] = np.nan\n",
    "        \n",
    "        # Liberar memoria\n",
    "        del dem_rd, dem_data_clean, nan_mask\n",
    "        gc.collect()\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # 7. Calcular variables mensuales de precipitación\n",
    "        print(\"\\n7. Calculando estadísticas mensuales de precipitación...\")\n",
    "        \n",
    "        # Crear dataset con todas las variables derivadas\n",
    "        print(\"\\n8. Creando dataset final con todas las variables...\")\n",
    "        \n",
    "        # Iniciar con un dataset vacío\n",
    "        ds_final = xr.Dataset(\n",
    "            coords={\n",
    "                'time': chirps_ds.time,\n",
    "                'latitude': chirps_ds.latitude,\n",
    "                'longitude': chirps_ds.longitude\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Agregar precipitación original\n",
    "        print(\"Agregando precipitación original...\")\n",
    "        ds_final['precipitation'] = chirps_ds[precip_var]\n",
    "        \n",
    "        # Liberar memoria de chirps_ds si ya no se necesita\n",
    "        chirps_data = chirps_ds[precip_var].values\n",
    "        chirps_ds.close()\n",
    "        del chirps_ds\n",
    "        gc.collect()\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # Calcular estadísticas mensuales de precipitación\n",
    "        print(\"Calculando total de precipitación mensual...\")\n",
    "        # Agrupar por año y mes\n",
    "        dates_pd = pd.DataFrame({'time': times, 'month': months, 'year': years})\n",
    "        unique_year_months = dates_pd.drop_duplicates(['year', 'month'])[['year', 'month']].values\n",
    "        \n",
    "        # Inicializar arrays para las estadísticas mensuales\n",
    "        lat_dim = len(ds_final.latitude)\n",
    "        lon_dim = len(ds_final.longitude)\n",
    "        time_dim = len(unique_year_months)  # Número de meses únicos\n",
    "        \n",
    "        monthly_total = np.zeros((time_dim, lat_dim, lon_dim), dtype=np.float32)\n",
    "        monthly_max = np.zeros((time_dim, lat_dim, lon_dim), dtype=np.float32)\n",
    "        monthly_min = np.zeros((time_dim, lat_dim, lon_dim), dtype=np.float32)\n",
    "        monthly_std = np.zeros((time_dim, lat_dim, lon_dim), dtype=np.float32)\n",
    "        \n",
    "        # Crear array para las fechas mensuales\n",
    "        monthly_dates = []\n",
    "        \n",
    "        # Procesar mes por mes para evitar problemas de memoria\n",
    "        print(f\"Procesando {len(unique_year_months)} meses únicos...\")\n",
    "        for i, (year, month) in enumerate(unique_year_months):\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Procesando mes {i+1}/{len(unique_year_months)}: {year}-{month:02d}\")\n",
    "            \n",
    "            # Filtrar fechas para este mes\n",
    "            month_indices = np.where((years == year) & (months == month))[0]\n",
    "            month_data = chirps_data[month_indices]\n",
    "            \n",
    "            # Calcular estadísticas\n",
    "            monthly_total[i] = np.sum(month_data, axis=0)\n",
    "            monthly_max[i] = np.max(month_data, axis=0)\n",
    "            monthly_min[i] = np.min(month_data, axis=0)\n",
    "            monthly_std[i] = np.std(month_data, axis=0)\n",
    "            \n",
    "            # Añadir fecha (primer día del mes)\n",
    "            monthly_dates.append(np.datetime64(f\"{year}-{month:02d}-01\"))\n",
    "        \n",
    "        # Crear coordenada de tiempo mensual\n",
    "        monthly_time = np.array(monthly_dates)\n",
    "        \n",
    "        # Liberar memoria\n",
    "        del chirps_data\n",
    "        gc.collect()\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # Añadir variables mensuales al dataset\n",
    "        print(\"Agregando variables mensuales al dataset...\")\n",
    "        ds_monthly = xr.Dataset(\n",
    "            data_vars={\n",
    "                'total_precipitation': xr.DataArray(\n",
    "                    monthly_total,\n",
    "                    dims=['time', 'latitude', 'longitude'],\n",
    "                    coords={'time': monthly_time, 'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "                ),\n",
    "                'max_daily_precipitation': xr.DataArray(\n",
    "                    monthly_max,\n",
    "                    dims=['time', 'latitude', 'longitude'],\n",
    "                    coords={'time': monthly_time, 'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "                ),\n",
    "                'min_daily_precipitation': xr.DataArray(\n",
    "                    monthly_min,\n",
    "                    dims=['time', 'latitude', 'longitude'],\n",
    "                    coords={'time': monthly_time, 'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "                ),\n",
    "                'daily_precipitation_std': xr.DataArray(\n",
    "                    monthly_std,\n",
    "                    dims=['time', 'latitude', 'longitude'],\n",
    "                    coords={'time': monthly_time, 'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Liberar memoria de arrays intermedios\n",
    "        del monthly_total, monthly_max, monthly_min, monthly_std\n",
    "        gc.collect()\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # Añadir variables cíclicas de tiempo\n",
    "        print(\"Agregando variables cíclicas de tiempo...\")\n",
    "        \n",
    "        # Extraer mes y año para las fechas mensuales\n",
    "        monthly_dates_pd = pd.DatetimeIndex(monthly_time)\n",
    "        monthly_month = monthly_dates_pd.month\n",
    "        monthly_doy = monthly_dates_pd.dayofyear\n",
    "        \n",
    "        # Calcular seno y coseno para meses\n",
    "        month_sin_monthly = np.sin(2 * np.pi * monthly_month / 12)\n",
    "        month_cos_monthly = np.cos(2 * np.pi * monthly_month / 12)\n",
    "        \n",
    "        # Calcular seno y coseno para día del año\n",
    "        doy_sin_monthly = np.sin(2 * np.pi * monthly_doy / days_in_year)\n",
    "        doy_cos_monthly = np.cos(2 * np.pi * monthly_doy / days_in_year)\n",
    "        \n",
    "        # Crear arrays 3D usando numpy directamente en lugar de broadcast_to\n",
    "        print(\"Creando arrays 3D para variables cíclicas...\")\n",
    "        time_size = len(monthly_time)\n",
    "        \n",
    "        # Inicializar arrays vacíos\n",
    "        month_sin_3d = np.zeros((time_size, lat_dim, lon_dim), dtype=np.float32)\n",
    "        month_cos_3d = np.zeros((time_size, lat_dim, lon_dim), dtype=np.float32)\n",
    "        doy_sin_3d = np.zeros((time_size, lat_dim, lon_dim), dtype=np.float32)\n",
    "        doy_cos_3d = np.zeros((time_size, lat_dim, lon_dim), dtype=np.float32)\n",
    "        \n",
    "        # Llenar los arrays manualmente para evitar problemas de memoria\n",
    "        for t in range(time_size):\n",
    "            # Asignar el mismo valor a toda la slice de tiempo\n",
    "            month_sin_3d[t, :, :] = month_sin_monthly[t]\n",
    "            month_cos_3d[t, :, :] = month_cos_monthly[t]\n",
    "            doy_sin_3d[t, :, :] = doy_sin_monthly[t]\n",
    "            doy_cos_3d[t, :, :] = doy_cos_monthly[t]\n",
    "            \n",
    "            # Liberar memoria cada cierto número de iteraciones\n",
    "            if t > 0 and t % 50 == 0:\n",
    "                gc.collect()\n",
    "                print(f\"Procesados {t}/{time_size} pasos de tiempo para variables cíclicas\")\n",
    "        \n",
    "        # Crear DataArrays con los arrays 3D ya inicializados\n",
    "        ds_monthly['month_sin'] = xr.DataArray(\n",
    "            month_sin_3d,\n",
    "            dims=['time', 'latitude', 'longitude'],\n",
    "            coords={'time': monthly_time, 'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "        )\n",
    "        \n",
    "        ds_monthly['month_cos'] = xr.DataArray(\n",
    "            month_cos_3d,\n",
    "            dims=['time', 'latitude', 'longitude'],\n",
    "            coords={'time': monthly_time, 'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "        )\n",
    "        \n",
    "        ds_monthly['doy_sin'] = xr.DataArray(\n",
    "            doy_sin_3d,\n",
    "            dims=['time', 'latitude', 'longitude'],\n",
    "            coords={'time': monthly_time, 'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "        )\n",
    "        \n",
    "        ds_monthly['doy_cos'] = xr.DataArray(\n",
    "            doy_cos_3d,\n",
    "            dims=['time', 'latitude', 'longitude'],\n",
    "            coords={'time': monthly_time, 'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "        )\n",
    "        \n",
    "        # Liberar memoria de los arrays temporales\n",
    "        del month_sin_monthly, month_cos_monthly, doy_sin_monthly, doy_cos_monthly\n",
    "        del month_sin_3d, month_cos_3d, doy_sin_3d, doy_cos_3d\n",
    "        gc.collect()\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # Añadir variables topográficas\n",
    "        print(\"Agregando variables topográficas...\")\n",
    "        ds_topo = xr.Dataset(\n",
    "            data_vars={\n",
    "                'elevation': xr.DataArray(\n",
    "                    elevation.values,\n",
    "                    dims=['latitude', 'longitude'],\n",
    "                    coords={'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "                ),\n",
    "                'slope': xr.DataArray(\n",
    "                    slope,\n",
    "                    dims=['latitude', 'longitude'],\n",
    "                    coords={'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "                ),\n",
    "                'aspect': xr.DataArray(\n",
    "                    aspect,\n",
    "                    dims=['latitude', 'longitude'],\n",
    "                    coords={'latitude': ds_final.latitude, 'longitude': ds_final.longitude}\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Liberar memoria\n",
    "        del elevation, slope, aspect\n",
    "        gc.collect()\n",
    "        check_memory_usage()\n",
    "        \n",
    "        # Combinar datasets (mensual y topo)\n",
    "        print(\"\\n9. Combinando datasets...\")\n",
    "        final_combined = xr.merge([ds_monthly, ds_topo])\n",
    "        \n",
    "        # Añadir metadatos\n",
    "        final_combined.attrs['description'] = 'ST-HyMOUNTAIN-Net ready dataset with CHIRPS monthly precipitation and DEM variables'\n",
    "        final_combined.attrs['source'] = 'CHIRPS v2.0 & DEM Boyacá'\n",
    "        final_combined.attrs['author'] = 'Your Name'\n",
    "        final_combined.attrs['created_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Configurar chunks óptimos para el almacenamiento\n",
    "        print(\"\\n10. Configurando chunks para almacenamiento eficiente...\")\n",
    "        encoding = {var: {'zlib': True, 'complevel': 5} for var in final_combined.data_vars}\n",
    "        \n",
    "        # Guardar el dataset resultante\n",
    "        print(f\"\\n11. Guardando dataset final en {output_path}...\")\n",
    "        final_combined.to_netcdf(\n",
    "            output_path,\n",
    "            encoding=encoding,\n",
    "            compute=True  # Fuerza la computación ahora\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nDataset generado y guardado exitosamente en {output_path}\")\n",
    "        print(\"Dimensiones finales del dataset:\")\n",
    "        print(f\"- Variables: {list(final_combined.data_vars)}\")\n",
    "        print(f\"- Dimensiones: {dict(final_combined.dims)}\")\n",
    "        \n",
    "        # Verificar uso final de memoria\n",
    "        check_memory_usage()\n",
    "        \n",
    "        return final_combined\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generando dataset completo: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    finally:\n",
    "        # Asegurarse de liberar toda la memoria\n",
    "        gc.collect()\n",
    "        check_memory_usage()\n",
    "\n",
    "# Ejecutar la generación del dataset completo\n",
    "# Ya definimos estas rutas arriba usando BASE_PATH\n",
    "# chirps_path, dem_path y output_path ya están definidos\n",
    "\n",
    "# Ejecutar con manejo de excepciones\n",
    "try:\n",
    "    complete_dataset = generate_complete_dataset(\n",
    "        chirps_path=chirps_path,\n",
    "        dem_path=dem_path,\n",
    "        output_path=output_path,\n",
    "        chunk_size=20  # Ajustar según las capacidades del sistema\n",
    "    )\n",
    "    \n",
    "    if complete_dataset is not None:\n",
    "        print(\"\\nGeneración del dataset completada con éxito.\")\n",
    "        print(\"Para visualizar los resultados, cargue el dataset desde el archivo guardado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error ejecutando la generación del dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f778bbe",
   "metadata": {},
   "source": [
    "## Visualización de Resultados\n",
    "\n",
    "A continuación, cargamos el dataset generado y visualizamos algunas de las variables para verificar que todo se ha generado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset generado\n",
    "try:\n",
    "    dataset = xr.open_dataset(output_path)\n",
    "    print(f\"Dataset cargado exitosamente con {len(dataset.data_vars)} variables.\")\n",
    "    print(f\"Variables disponibles: {list(dataset.data_vars)}\")\n",
    "    print(f\"Dimensiones: {dict(dataset.dims)}\")\n",
    "    \n",
    "    # Visualizar algunas variables\n",
    "    print(\"\\nVisualizando variables:\")\n",
    "    \n",
    "    # Visualizar topografía (constante en el tiempo)\n",
    "    DatasetGenerator.plot_sample(dataset, 'elevation')\n",
    "    DatasetGenerator.plot_sample(dataset, 'slope')\n",
    "    \n",
    "    # Visualizar precipitación para el primer mes\n",
    "    DatasetGenerator.plot_sample(dataset, 'total_precipitation', time_index=0)\n",
    "    \n",
    "    # Visualizar una variable temporal cíclica\n",
    "    DatasetGenerator.plot_sample(dataset, 'month_sin', time_index=0)\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar o visualizar el dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060db32",
   "metadata": {},
   "source": [
    "## Compartir el Dataset (Google Colab)\n",
    "\n",
    "Si estás trabajando en Google Colab y deseas compartir o descargar el dataset, puedes usar el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para compartir o descargar el dataset desde Google Colab\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(f\"El dataset generado está disponible en: {output_path}\")\n",
    "        print(\"Para descargar el archivo, ejecuta la siguiente celda:\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al preparar descarga: {e}\")\n",
    "    \n",
    "    # Esta celda descargará el archivo cuando se ejecute\n",
    "    # files.download(output_path)\n",
    "else:\n",
    "    print(\"No estás en Google Colab, el dataset ya está guardado localmente en:\")\n",
    "    print(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
