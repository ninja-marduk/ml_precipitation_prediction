{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "635dc005",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "635dc005",
        "outputId": "6debef30-7776-447d-d06b-a618849d92db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entorno configurado. Usando ruta base: ..\n"
          ]
        }
      ],
      "source": [
        "# Configuraci√≥n del entorno (compatible con Colab y local)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "# Detectar si estamos en Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Si estamos en Colab, clonar el repositorio\n",
        "    !git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
        "    %cd ml_precipitation_prediction\n",
        "    # Instalar dependencias necesarias\n",
        "    !pip install -r requirements.txt\n",
        "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools\n",
        "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
        "else:\n",
        "    # Si estamos en local, usar la ruta actual\n",
        "    if '/models' in os.getcwd():\n",
        "        BASE_PATH = Path('..')\n",
        "    else:\n",
        "        BASE_PATH = Path('.')\n",
        "\n",
        "print(f\"Entorno configurado. Usando ruta base: {BASE_PATH}\")\n",
        "\n",
        "# Si BASE_PATH viene como string, lo convertimos\n",
        "BASE_PATH = Path(BASE_PATH)\n",
        "\n",
        "# Ahora puedes concatenar correctamente\n",
        "data_output_dir = BASE_PATH / 'data' / 'output'\n",
        "model_output_dir = BASE_PATH / 'models' / 'output'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8ccc04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "7f8ccc04",
        "outputId": "9c975eb1-2e4a-4abb-f5b1-49c266ec88f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Detectando dispositivo disponible...\n",
            "‚ö†Ô∏è No se detect√≥ GPU. Usando CPU.\n",
            "‚ÑπÔ∏è En Colab puedes activar GPU en Entorno de ejecuci√≥n > Cambiar tipo de entorno de ejecuci√≥n.\n",
            "üìÇ Configurando directorios y cargando dataset...\n",
            "‚úîÔ∏è Dataset cargado desde: ../data/output/complete_dataset_with_features_with_clusters_elevation_with_windows.nc\n",
            "‚úÖ Todas las variables requeridas est√°n presentes.\n",
            "\n",
            "üöÄ Iniciando experimento: time+cycles\n",
            "üß± Generando secuencias multihorizonte...\n",
            "‚úÇÔ∏è Dividiendo datos en entrenamiento y prueba...\n"
          ]
        }
      ],
      "source": [
        "# Versi√≥n final ajustada con trazabilidad y control de errores\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==== Configuraci√≥n de entorno para GPU o CPU ====\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(\"üîç Detectando dispositivo disponible...\")\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "USE_GPU = bool(gpu_devices)\n",
        "\n",
        "if USE_GPU:\n",
        "    print(\"‚úÖ GPU detectada:\", gpu_devices[0].name)\n",
        "    try:\n",
        "        from tensorflow.keras import mixed_precision\n",
        "        mixed_precision.set_global_policy('mixed_float16')\n",
        "        print(\"‚ö° Pol√≠tica 'mixed_float16' activada.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è No se pudo activar mixed precision: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se detect√≥ GPU. Usando CPU.\")\n",
        "    print(\"‚ÑπÔ∏è En Colab puedes activar GPU en Entorno de ejecuci√≥n > Cambiar tipo de entorno de ejecuci√≥n.\")\n",
        "\n",
        "\n",
        "# Funciones auxiliares\n",
        "def build_model(model_type, input_shape, output_neurons):\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, GRU, Bidirectional, Reshape, Input\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(64))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(64))\n",
        "    elif model_type == 'BLSTM':\n",
        "        model.add(Bidirectional(LSTM(64)))\n",
        "    elif model_type == 'CNN':\n",
        "        model.add(Reshape((*input_shape, 1)))\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "    model.add(Dense(output_neurons))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return rmse, mae, mape, r2\n",
        "\n",
        "# Directorios\n",
        "print(\"üìÇ Configurando directorios y cargando dataset...\")\n",
        "try:\n",
        "    model_output_dir = Path(\"output/ST_HybridWaveStack\")\n",
        "    curves_dir = model_output_dir / \"learning_curves\"\n",
        "    model_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    curves_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    file_path = data_output_dir / \"complete_dataset_with_features_with_clusters_elevation_with_windows.nc\"\n",
        "    ds = xr.open_dataset(file_path)\n",
        "    print(f\"‚úîÔ∏è Dataset cargado desde: {file_path}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"‚ùå Error cargando dataset o creando carpetas: {e}\")\n",
        "\n",
        "experiment_settings = {\n",
        "    \"time+cycles\": ['year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos'],\n",
        "    \"time+cycles+lag\": ['year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos',\n",
        "                        'total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag3',\n",
        "                        'total_precipitation_lag4', 'total_precipitation_lag12', 'total_precipitation_lag24', 'total_precipitation_lag36'],\n",
        "    \"time+cycles+lag+elev\": ['year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos',\n",
        "                             'total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag3',\n",
        "                             'total_precipitation_lag4', 'total_precipitation_lag12', 'total_precipitation_lag24', 'total_precipitation_lag36',\n",
        "                             'elevation', 'slope', 'aspect'],\n",
        "    \"all_features\": ['year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos',\n",
        "                     'total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag3',\n",
        "                     'total_precipitation_lag4', 'total_precipitation_lag12', 'total_precipitation_lag24', 'total_precipitation_lag36',\n",
        "                     'elevation', 'slope', 'aspect', 'cluster_elevation']\n",
        "}\n",
        "\n",
        "ds_vars = set(ds.data_vars)\n",
        "for name, vars_list in experiment_settings.items():\n",
        "    missing = [v for v in vars_list if v not in ds_vars]\n",
        "    if missing:\n",
        "        raise ValueError(f\"‚ùå Faltan variables necesarias para el experimento '{name}': {missing}\")\n",
        "print(\"‚úÖ Todas las variables requeridas est√°n presentes.\")\n",
        "\n",
        "model_types = ['LSTM', 'GRU', 'BLSTM', 'CNN']\n",
        "prediction_horizons = [3, 6, 12]\n",
        "input_window = 120  # 10 a√±os\n",
        "\n",
        "results = []\n",
        "\n",
        "for exp_name, variables in experiment_settings.items():\n",
        "    print(f\"\\nüöÄ Iniciando experimento: {exp_name}\")\n",
        "    try:\n",
        "        cluster_elevation_index = variables.index('cluster_elevation') if 'cluster_elevation' in variables else None\n",
        "        subset_array = ds[variables].to_array().transpose('time', 'latitude', 'longitude', 'variable')\n",
        "        subset_np = subset_array.values\n",
        "\n",
        "        if cluster_elevation_index is not None:\n",
        "            print(\"üîÑ Codificando variable categ√≥rica 'cluster_elevation'...\")\n",
        "            cluster_data = subset_np[..., cluster_elevation_index]\n",
        "            encoded = LabelEncoder().fit_transform(cluster_data.ravel()).reshape(cluster_data.shape)\n",
        "            subset_np[..., cluster_elevation_index] = encoded\n",
        "\n",
        "        subset_np = subset_np.astype(np.float32)\n",
        "        target = ds['total_precipitation'].values\n",
        "\n",
        "        samples, lat, lon, feats = subset_np.shape\n",
        "        X = subset_np.reshape(samples, lat * lon, feats)\n",
        "        y = target.reshape(samples, lat * lon)\n",
        "\n",
        "        mask = ~np.isnan(y)\n",
        "        X = X[mask]\n",
        "        y = y[mask]\n",
        "\n",
        "        print(\"üß± Generando secuencias multihorizonte...\")\n",
        "        X_seq = []\n",
        "        Y_targets = {h: [] for h in prediction_horizons}\n",
        "        for i in range(len(X) - input_window - max(prediction_horizons)):\n",
        "            X_seq.append(X[i:i + input_window])\n",
        "            for h in prediction_horizons:\n",
        "                Y_targets[h].append(y[i + input_window + h - 1])\n",
        "\n",
        "        X_seq = np.array(X_seq)\n",
        "        Y_targets = {h: np.array(Y_targets[h]) for h in prediction_horizons}\n",
        "\n",
        "        print(\"‚úÇÔ∏è Dividiendo datos en entrenamiento y prueba...\")\n",
        "        X_train, X_test = train_test_split(X_seq, test_size=0.2, random_state=42)\n",
        "        Y_train_dict = {h: train_test_split(Y_targets[h], test_size=0.2, random_state=42)[0] for h in prediction_horizons}\n",
        "        Y_test_dict = {h: train_test_split(Y_targets[h], test_size=0.2, random_state=42)[1] for h in prediction_horizons}\n",
        "\n",
        "        X_train_feed = X_train.reshape((X_train.shape[0], X_train.shape[1], -1))\n",
        "        X_test_feed = X_test.reshape((X_test.shape[0], X_test.shape[1], -1))\n",
        "        input_shape = (X_train_feed.shape[1], X_train_feed.shape[2])\n",
        "\n",
        "\n",
        "        def to_dataset(x, y):\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "            ds = ds.batch(16).prefetch(tf.data.AUTOTUNE)\n",
        "            return ds\n",
        "        \n",
        "        train_ds = to_dataset(X_train, Y_train_dict[3])\n",
        "\n",
        "        for model_name in model_types:\n",
        "            from tensorflow.keras.callbacks import EarlyStopping\n",
        "            print(f\"\\nüèóÔ∏è Entrenando modelo: {model_name}...\")\n",
        "            model = build_model(model_name, input_shape, 1)\n",
        "            \n",
        "            es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "            print(device_lib.list_local_devices())\n",
        "            history = model.fit(train_ds, \n",
        "                                epochs=50, \n",
        "                                validation_split=0.2 \n",
        "                                if not USE_GPU \n",
        "                                else None, \n",
        "                                verbose=1, \n",
        "                                callbacks=[es])\n",
        "\n",
        "            optimal_epochs = len(history.history['loss'])\n",
        "\n",
        "            # Curva de aprendizaje\n",
        "            plt.figure()\n",
        "            plt.plot(history.history['loss'], label='Train Loss')\n",
        "            plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "            plt.title(f'Curva aprendizaje - {exp_name} - {model_name}')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.legend()\n",
        "            plt.savefig(curves_dir / f\"{exp_name.replace('+','_')}_{model_name}_curve.png\")\n",
        "            plt.close()\n",
        "\n",
        "            # Evaluaci√≥n\n",
        "            for h in prediction_horizons:\n",
        "                print(f\"üìà Evaluando modelo {model_name} para horizonte {h} meses...\")\n",
        "                y_pred = model.predict(X_test_feed).flatten()\n",
        "                y_true = Y_test_dict[h].flatten()\n",
        "                rmse, mae, mape, r2 = evaluate(y_true, y_pred)\n",
        "                results.append({\n",
        "                    'experiment': exp_name,\n",
        "                    'model': model_name,\n",
        "                    'horizon': h,\n",
        "                    'RMSE': rmse,\n",
        "                    'MAE': mae,\n",
        "                    'MAPE': mape,\n",
        "                    'R2': r2,\n",
        "                    'optimal_epochs': optimal_epochs\n",
        "                })\n",
        "\n",
        "            fname = f\"{exp_name.replace('+','_')}_{model_name}_win{input_window}.h5\"\n",
        "            model.save(model_output_dir / fname)\n",
        "            print(f\"üíæ Modelo guardado: {model_output_dir / fname}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error durante el experimento '{exp_name}': {e}\")\n",
        "\n",
        "# Exportar resultados\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"resultados_modelos_10anios.csv\", index=False)\n",
        "print(\"\\n‚úÖ Proceso finalizado. Resultados guardados en 'resultados_modelos_10anios.csv'\")\n",
        "\n",
        "# Mostrar tabla\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Resultados Modelos - 10 A√±os Entrenamiento\", dataframe=results_df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "precipitation_prediction",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
