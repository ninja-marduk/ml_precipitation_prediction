{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ IMPORTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import sys, os, gc, warnings\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, ConvLSTM2D, SimpleRNN, Flatten, Dense, Reshape,\n",
    "    Lambda, Permute\n",
    ")\n",
    "\n",
    "# â”€â”€ ConvGRU2D: Verificar disponibilidad â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "try:\n",
    "    from tensorflow.keras.layers import ConvGRU2D  # TF â‰¥ 2.8\n",
    "    HAS_CONVGRU = True\n",
    "    print(\"âœ… ConvGRU2D nativo disponible\")\n",
    "except ImportError:\n",
    "    HAS_CONVGRU = False\n",
    "    print(\"âš ï¸ ConvGRU2D no disponible. Se usarÃ¡ ConvLSTM2D como alternativa.\")\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt, seaborn as sns, geopandas as gpd, imageio.v2 as imageio\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid'); sns.set_context('notebook')\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ENTORNO / GPU â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "## â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Rutas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â–¶ï¸ Path configuration\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
    "    # Instalar dependencias necesarias\n",
    "    %pip install -r requirements.txt\n",
    "    %pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open cartopy geopandas\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    for p in [BASE_PATH, *BASE_PATH.parents]:\n",
    "        if (p / '.git').exists():\n",
    "            BASE_PATH = p; break\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# limitar crecimiento de memoriaâ€‘GPU (evita OOM)\n",
    "for g in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PATHS & CONST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_FILE = BASE_PATH/'data'/'output'/(\n",
    "    'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation_clean.nc')\n",
    "OUT_ROOT  = BASE_PATH/'models'/'output'/'Spatial_CONVRNN'\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SHAPE_DIR = BASE_PATH/'data'/'input'/'shapes'\n",
    "DEPT_GDF   = gpd.read_file(SHAPE_DIR/'MGN_Departamento.shp')\n",
    "\n",
    "INPUT_WINDOW = 60\n",
    "HORIZON = 3 \n",
    "EPOCHS = 50\n",
    "BATCH = 4\n",
    "LR = 1e-3\n",
    "PATIENCE = 6\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FEATURE SETS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BASE_FEATS = ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
    "              'max_daily_precipitation','min_daily_precipitation','daily_precipitation_std',\n",
    "              'elevation','slope','aspect']\n",
    "ELEV_CLUSTER = ['elev_high','elev_med','elev_low']\n",
    "KCE_FEATS = BASE_FEATS + ELEV_CLUSTER\n",
    "PAFC_FEATS= KCE_FEATS + ['total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag12']\n",
    "EXPERIMENTS = {'BASIC':BASE_FEATS,'KCE':KCE_FEATS,'PAFC':PAFC_FEATS}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATASET â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ds = xr.open_dataset(DATA_FILE)\n",
    "lat, lon = len(ds.latitude), len(ds.longitude)\n",
    "print(f\"Dataset â†’ time={len(ds.time)}, lat={lat}, lon={lon}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def windowed_arrays(X:np.ndarray, y:np.ndarray):\n",
    "    seq_X, seq_y = [], []\n",
    "    T = len(X)\n",
    "    for start in range(T-INPUT_WINDOW-HORIZON+1):\n",
    "        end_w = start+INPUT_WINDOW; end_y=end_w+HORIZON\n",
    "        Xw, yw = X[start:end_w], y[end_w:end_y]\n",
    "        if np.isnan(Xw).any() or np.isnan(yw).any():\n",
    "            continue\n",
    "        seq_X.append(Xw); seq_y.append(yw)\n",
    "    return np.asarray(seq_X,dtype=np.float32), np.asarray(seq_y,dtype=np.float32)\n",
    "\n",
    "def quick_plot(ax,data,cmap,title,vmin=None,vmax=None):\n",
    "    mesh = ax.pcolormesh(ds.longitude,ds.latitude,data,cmap=cmap,shading='nearest',\n",
    "                         vmin=vmin,vmax=vmax,transform=ccrs.PlateCarree())\n",
    "    ax.coastlines(); ax.add_geometries(DEPT_GDF.geometry,ccrs.PlateCarree(),\n",
    "                                       edgecolor='black',facecolor='none',linewidth=1)\n",
    "    # etiquetas desactivadas para evitar bug en cartopy\n",
    "    ax.gridlines(draw_labels=False, linewidth=.5, linestyle='--', alpha=.4)\n",
    "    ax.set_title(title,fontsize=9)\n",
    "    return mesh\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LIGHTWEIGHT HEAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def _spatial_head(x):\n",
    "    \"\"\"ProyecciÃ³n 1Ã—1 â†’ (B, H,lat,lon,1) con *shape hints* para que\n",
    "    Keras pueda reconstruir la capa `Lambda` al volver a cargar el modelo.\n",
    "    \"\"\"\n",
    "    #   1) Conv 1Ã—1 que genera H mapas (uno por horizonte)\n",
    "    x = Conv2D(\n",
    "        HORIZON,\n",
    "        (1, 1),\n",
    "        padding=\"same\",\n",
    "        activation=\"linear\",\n",
    "        name=\"head_conv1x1\",\n",
    "    )(x)  # ==> (B, lat, lon, H)\n",
    "\n",
    "    #   2) Transponemos a (B, H, lat, lon)\n",
    "    x = Lambda(\n",
    "        lambda t: tf.transpose(t, [0, 3, 1, 2]),\n",
    "        output_shape=(HORIZON, lat, lon),\n",
    "        name=\"head_transpose\",\n",
    "    )(x)\n",
    "\n",
    "    #   3) AÃ±adimos eje canales: (B, H, lat, lon, 1)\n",
    "    x = Lambda(\n",
    "        lambda t: tf.expand_dims(t, -1),\n",
    "        output_shape=(HORIZON, lat, lon, 1),\n",
    "        name=\"head_expand_dim\",\n",
    "    )(x)\n",
    "    return x\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MODEL FACTORIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def build_conv_lstm(n_feats:int):\n",
    "    inp = Input(shape=(INPUT_WINDOW,lat,lon,n_feats))\n",
    "    x   = ConvLSTM2D(32,(3,3),padding='same',return_sequences=True)(inp)\n",
    "    x   = ConvLSTM2D(16,(3,3),padding='same',return_sequences=False)(x)\n",
    "    out = _spatial_head(x)\n",
    "    return Model(inp, out, name='ConvLSTM')\n",
    "\n",
    "def build_conv_gru(n_feats: int):\n",
    "    \"\"\"\n",
    "    Construye modelo ConvGRU si estÃ¡ disponible, \n",
    "    de lo contrario usa ConvLSTM2D como alternativa\n",
    "    \"\"\"\n",
    "    inp = Input(shape=(INPUT_WINDOW, lat, lon, n_feats))\n",
    "    \n",
    "    if HAS_CONVGRU:\n",
    "        # Usar ConvGRU2D nativo\n",
    "        x = ConvGRU2D(32, (3, 3), padding=\"same\", return_sequences=True)(inp)\n",
    "        x = ConvGRU2D(16, (3, 3), padding=\"same\", return_sequences=False)(x)\n",
    "        model_name = \"ConvGRU\"\n",
    "    else:\n",
    "        # Usar ConvLSTM2D como alternativa robusta\n",
    "        print(\"  â†’ Usando ConvLSTM2D como alternativa a ConvGRU2D\")\n",
    "        x = ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True)(inp)\n",
    "        x = ConvLSTM2D(16, (3, 3), padding=\"same\", return_sequences=False)(x)\n",
    "        model_name = \"ConvGRU_alt\"\n",
    "    \n",
    "    out = _spatial_head(x)\n",
    "    return Model(inp, out, name=model_name)\n",
    "\n",
    "def build_conv_rnn(n_feats:int):\n",
    "    inp = Input(shape=(INPUT_WINDOW,lat,lon,n_feats))\n",
    "    x = Flatten()(inp)\n",
    "    x = SimpleRNN(64,activation='tanh')(x)\n",
    "    x = Dense(lat*lon*HORIZON)(x)\n",
    "    out = Reshape((HORIZON,lat,lon,1))(x)\n",
    "    return Model(inp, out, name='ConvRNN')\n",
    "\n",
    "MODELS = {'ConvLSTM': build_conv_lstm, 'ConvRNN': build_conv_rnn}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRAIN + EVAL LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "results=[]\n",
    "for exp, feat_list in EXPERIMENTS.items():\n",
    "    print(f\"\\n=== Experimento {exp} ({len(feat_list)} feats) ===\")\n",
    "    Xarr = ds[feat_list].to_array().transpose('time','latitude','longitude','variable').values.astype(np.float32)\n",
    "    yarr = ds['total_precipitation'].values.astype(np.float32)[...,None]\n",
    "    X, y = windowed_arrays(Xarr, yarr)\n",
    "    split=int(0.8*len(X))\n",
    "\n",
    "    sx = StandardScaler().fit(X[:split].reshape(-1,len(feat_list)))\n",
    "    sy = StandardScaler().fit(y[:split].reshape(-1,1))\n",
    "    X_sc = sx.transform(X.reshape(-1,len(feat_list))).reshape(X.shape)\n",
    "    y_sc = sy.transform(y.reshape(-1,1)).reshape(y.shape)\n",
    "    X_tr, X_va = X_sc[:split], X_sc[split:]\n",
    "    y_tr, y_va = y_sc[:split], y_sc[split:]\n",
    "\n",
    "    OUT_EXP = OUT_ROOT/exp; OUT_EXP.mkdir(exist_ok=True)\n",
    "\n",
    "    for mdl_name,builder in MODELS.items():\n",
    "        print(f\"â†’ {mdl_name}\")\n",
    "        model_path = OUT_EXP/f\"{mdl_name.lower()}_best.keras\"\n",
    "        if model_path.exists():\n",
    "            model_path.unlink()  # Eliminar modelo antiguo\n",
    "        \n",
    "        try:\n",
    "            # Siempre construir y entrenar desde cero\n",
    "            model = builder(n_feats=len(feat_list))\n",
    "            model.compile(tf.keras.optimizers.Adam(LR), 'mse')\n",
    "            cb=[EarlyStopping('val_loss',patience=PATIENCE,restore_best_weights=True),\n",
    "                ModelCheckpoint(model_path,save_best_only=True)]\n",
    "            model.fit(X_tr, y_tr, validation_data=(X_va,y_va),\n",
    "                      epochs=EPOCHS, batch_size=BATCH, callbacks=cb, verbose=0)\n",
    "\n",
    "            # â”€ Pred Ãºltima ventana validaciÃ³n â”€\n",
    "            y_hat_sc = model.predict(X_va[-1:],verbose=0)\n",
    "            y_hat = sy.inverse_transform(y_hat_sc.reshape(-1,1)).reshape(HORIZON,lat,lon)\n",
    "            y_true= sy.inverse_transform(y_va[-1:].reshape(-1,1)).reshape(HORIZON,lat,lon)\n",
    "\n",
    "            # â”€ Mapas & GIF â”€\n",
    "            vmin,vmax=0,max(y_true.max(),y_hat.max()); frames=[]\n",
    "            dates=pd.date_range(ds.time.values[-HORIZON],periods=HORIZON,freq='MS')\n",
    "            for h in range(HORIZON):\n",
    "                err=np.clip(np.abs((y_true[h]-y_hat[h])/(y_true[h]+1e-5))*100,0,100)\n",
    "                fig,axs=plt.subplots(1,3,figsize=(12,4),subplot_kw={'projection':ccrs.PlateCarree()})\n",
    "                quick_plot(axs[0],y_true[h],'Blues',f\"Real h={h+1}\",vmin,vmax)\n",
    "                quick_plot(axs[1],y_hat[h],'Blues',f\"{mdl_name} h={h+1}\",vmin,vmax)\n",
    "                quick_plot(axs[2],err,'Reds',f\"MAPE% h={h+1}\",0,100)\n",
    "                fig.suptitle(f\"{mdl_name} â€“ {exp} â€“ {dates[h].strftime('%Y-%m')}\")\n",
    "                png=OUT_EXP/f\"{mdl_name}_{h+1}.png\"; fig.savefig(png,bbox_inches='tight'); plt.close(fig)\n",
    "                frames.append(imageio.imread(png))\n",
    "            imageio.mimsave(OUT_EXP/f\"{mdl_name}.gif\",frames,fps=0.5)\n",
    "\n",
    "            # â”€ MÃ©tricas â”€\n",
    "            for h in range(HORIZON):\n",
    "                results.append({\n",
    "                    'Experiment':exp,'Model':mdl_name,'H':h+1,\n",
    "                    'RMSE':np.sqrt(mean_squared_error(y_true[h].ravel(),y_hat[h].ravel())),\n",
    "                    'MAE': mean_absolute_error(y_true[h].ravel(),y_hat[h].ravel()),\n",
    "                    'R2' : r2_score(y_true[h].ravel(),y_hat[h].ravel())\n",
    "                })\n",
    "            tf.keras.backend.clear_session(); gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ Error en {mdl_name}: {str(e)}\")\n",
    "            print(f\"  â†’ Saltando {mdl_name} para {exp}\")\n",
    "            continue\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSV FINAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "res_df=pd.DataFrame(results)\n",
    "res_df.to_csv(OUT_ROOT/'metrics_spatial.csv',index=False)\n",
    "print(\"\\nğŸ“‘ Metrics saved â†’\", OUT_ROOT/'metrics_spatial.csv')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
