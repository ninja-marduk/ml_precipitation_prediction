# Development Plan - ML Precipitation Prediction
## Strategic Roadmap for Doctoral Thesis

**Version:** 2.0
**Date:** January 2026
**Objective:** Monthly Precipitation Prediction in Mountainous Areas using Deep Learning
**Frameworks:** SDD (Specification-Driven Development) + DD (Data-Driven)

---

## EXECUTIVE SUMMARY

This document defines the strategic roadmap for the precipitation prediction framework development, integrating results obtained to date and establishing the path toward doctoral thesis completion. All development follows the SDD and DD frameworks defined in [spec.md](spec.md) and [CLAUDE.md](../CLAUDE.md).

### Current Status

```
+------------------------------------------------------------------+
|                    PROJECT PROGRESS                               |
+------------------------------------------------------------------+
| V1 Baseline      [##########] 100%  - ConvLSTM/GRU basic         |
| V2 Enhanced      [##########] 100%  - Attention + Bidirectional  |
| V3 FNO           [##########] 100%  - Complete (underperformed)  |
| V4 GNN-TAT       [##########] 100%  - Full grid VALIDATED        |
| V5 GNN-ConvLSTM  [####------]  40%  - Training pipeline ready    |
| V6 Ensemble      [----------]   0%  - Planned                    |
| Thesis Written   [####------]  40%  - In progress                |
| Paper-4 Written  [########--]  80%  - Hybrid improvements done   |
+------------------------------------------------------------------+
```

### Key Achievement V4 (Full Grid 61Ã—65 - January 2026)

| Metric | V2 Best (ConvLSTM) | V4 Best (GNN-TAT) | Comparison |
|--------|-------------------|-------------------|------------|
| Peak RÂ² | **0.653** | 0.628 | ConvLSTM +4% |
| Mean RMSE | 112.02mm | **92.12mm** | GNN-TAT -18% |
| RMSE SD | 27.16mm | **6.48mm** | GNN-TAT 74% lower variance |
| Parameters | 2M+ | **~98K** | **-95%** |
| p-value (RMSE) | - | **0.015** | Statistically significant |

**Complementary Strengths Identified (motivates V5 stacking):**
- ConvLSTM: Best peak RÂ² (0.653) with BASIC features (local patterns)
- GNN-TAT: Best mean RMSE (92.12mm) with KCE features (topographic context)
- GNN-TAT: 74.7% lower variance â†’ more robust predictions

---

## PART I: HYPOTHESIS VALIDATION STATUS

### Research Hypotheses (from Doctoral Thesis Proposal)

| ID | Hypothesis | Status | Evidence |
|----|------------|--------|----------|
| **H1** | Hybrid GNN-Temporal > ConvLSTM | **PARTIALLY VALIDATED** | GNN-TAT RÂ²=0.628 comparable to ConvLSTM RÂ²=0.642, but 95% fewer params + lower RMSE variance |
| **H2** | Topographic features improve prediction | **VALIDATED** | KCE/PAFC significantly improve GNN performance (p<0.05) |
| **H3** | Non-Euclidean spatial relations capture orographic dynamics | **VALIDATED** | GNN achieves comparable RÂ² with 95% fewer params + interpretable graph structure |
| **H4** | Multi-scale temporal attention improves long horizons | **VALIDATED** | 9.6% RÂ² degradation H1â†’H12 for GNN-TAT (both architectures RÂ²>0.55 at H=12) |
| **H5** | Hybridization rescues architectural limitations | **VALIDATED** | Pure FNO RÂ²=0.206 â†’ FNO-ConvLSTM RÂ²=0.582 (182% improvement) |

### Validation Criteria (Updated January 2026 - Full Grid)

```
H1 Validation Criteria:
- RÂ² comparable to best baseline         [ACHIEVED: GNN-TAT 0.628 vs ConvLSTM 0.642]
- Parameter efficiency > 90%             [ACHIEVED: 95% fewer parameters (~98K vs 2M+)]
- RMSE variance reduction                [ACHIEVED: SD 6.48mm vs 27.16mm (74% lower)]

H2 Validation Criteria:
- PAFC/KCE outperforms BASIC            [ACHIEVED]
- Statistical significance (p < 0.05)    [ACHIEVED: Friedman + Nemenyi tests]

H3 Validation Criteria:
- GNN captures elevation-based patterns  [ACHIEVED: graph weights + interpretable structure]
- Spatial coherence in predictions       [ACHIEVED: full grid 61Ã—65 = 3,965 nodes]
- Mean RMSE statistically better         [ACHIEVED: 92.12mm vs 112.02mm, p=0.015]

H4 Validation Criteria:
- RÂ² degradation < 20% from H1 to H12   [ACHIEVED: 9.6% degradation for GNN-TAT]
- Both architectures RÂ² > 0.55 at H=12  [ACHIEVED]

H5 Validation Criteria (NEW):
- Hybrid improvement > 50% vs pure       [ACHIEVED: 182% improvement FNOâ†’FNO-ConvLSTM]
- Rescue of failing architectures        [ACHIEVED: Pure FNO RÂ²=0.206 â†’ Hybrid RÂ²=0.582]
```

---

## PART II: SITUATION ANALYSIS

### 2.1 Consolidated Results by Version

#### V1 - Baseline (Complete)
```
Architectures: ConvLSTM, ConvGRU, ConvRNN
Best RÂ² H1: 0.86 (ConvRNN-BASIC)
Problem: Severe degradation H2-H12 (RÂ² < 0.30)
Lesson: Basic architectures insufficient for multi-horizon
Documentation: thesis.tex Chapter 4.1
```

#### V2 - Enhanced (Complete)
```
Architectures: +Bidirectional, +Residual, +Attention, +Transformer
Best RÂ²: 0.752 (ConvRNN_Enhanced + PAFC)
RMSE: 44.85mm, MAE: 34.38mm
Lesson: Regularization > Architectural complexity
Documentation: thesis.tex Chapter 4.2, paper.tex Section 4
```

#### V3 - FNO (Complete - Underperformed)
```
Architectures: FNO_Pure, FNO_ConvLSTM_Hybrid
Result: WORSE than V2 in all experiments
- BASIC: +4.38mm RMSE vs V2
- PAFC: +7.73mm RMSE vs V2
Critical Lesson: FNO not suitable for precipitation (discontinuities, small grid)
Documentation: thesis.tex Chapter 4.3, paper.tex Section 5
```

#### V4 - GNN-TAT (COMPLETE - 100%) âœ…
```
Architectures: GNN_TAT_GAT, GNN_TAT_SAGE, GNN_TAT_GCN
Full Grid Validated (61Ã—65 = 3,965 nodes, 500,000 edges):

Best Result:
- RÂ² = 0.628 (GNN_TAT_GAT + BASIC, H=12)
- RMSE = 82.29mm
- Parameters: ~98K (95% fewer than ConvLSTM)

Statistical Comparison vs ConvLSTM:
- Mean RMSE: 92.12mm vs 112.02mm (GNN-TAT 18% better)
- RMSE SD: 6.48mm vs 27.16mm (GNN-TAT 74% lower variance)
- p-value: 0.015 (statistically significant)

Key Finding: COMPLEMENTARY STRENGTHS
- ConvLSTM: Better peak RÂ² (0.653 vs 0.628)
- GNN-TAT: Better mean RMSE, lower variance, 95% fewer params

Documentation: thesis.tex Chapter 5 âœ…, paper.tex Sections 4-6 âœ…
```

### 2.2 Key Insights

```
+---------------------------------------------------------------+
|  KEY PROJECT INSIGHTS                                          |
+---------------------------------------------------------------+
| 1. SIMPLE > COMPLEX                                           |
|    ConvRNN outperformed ConvLSTM in several scenarios         |
|                                                               |
| 2. REGULARIZATION > ARCHITECTURE                              |
|    Dropout + Early stopping more effective than more layers   |
|                                                               |
| 3. TOPOGRAPHIC FEATURES WORK                                  |
|    PAFC consistently better than BASIC (validates H2)         |
|                                                               |
| 4. FNO IS NOT THE SOLUTION                                    |
|    Spectral methods fail with discontinuous patterns          |
|                                                               |
| 5. GNN CAPTURES SPATIAL RELATIONSHIPS                         |
|    Graph based on elevation + distance is effective (H3)      |
|                                                               |
| 6. OVERFITTING IS THE MAIN CHALLENGE                          |
|    Train/val ratio of 6-19x indicates memorization            |
+---------------------------------------------------------------+
```

### 2.3 V4 Issues Resolution Status (January 2026)

| Issue | Severity | Solution Applied | Status |
|-------|----------|------------------|--------|
| Overfitting (6-19x ratio) | High | Increased regularization + data augmentation | âœ… Mitigated |
| Early stopping too aggressive | Medium | Adjusted patience, warmup period | âœ… Resolved |
| Negative bias (-3 to -20mm) | Medium | Balanced loss function applied | âœ… Improved |
| Only light mode validated | High | **Full grid executed (61Ã—65)** | âœ… **COMPLETE** |

**V4 Conclusion:** All major issues resolved. Full grid validation confirms GNN-TAT as
complementary to ConvLSTM (not replacement). Key advantage: 95% parameter reduction with
comparable accuracy and lower variance.

---

## PART III: ACTION PLAN

### 3.1 Completed Tasks (V4 Phase) âœ…

#### TASK 1.1: Execute V4 Full Grid âœ… COMPLETE
```
Objective: Validate results on complete grid (not light mode)
Resources: Colab Pro+

Results:
- Grid: 61Ã—65 = 3,965 nodes, 500,000 edges
- Best: GNN_TAT_GAT + BASIC, RÂ²=0.628, RMSE=82.29mm
- Statistical significance: p=0.015 vs ConvLSTM

Documentation Updated:
- thesis.tex: Chapter 5 âœ…
- paper.tex: Sections 4-6 with comparative tables âœ…
```

#### TASK 1.2: Mitigate V4 Overfitting âœ… COMPLETE
```
Objective: Reduce train/val ratio from ~10x to <5x

Actions Applied:
1. Increased dropout: 0.1 -> 0.2-0.3 âœ…
2. Added weight decay: 1e-5 -> 1e-4 âœ…
3. Implemented data augmentation:
   - Temporal jittering (+/- 1 month) âœ…
   - Spatial noise (sigma=0.1)
4. Label smoothing in loss function

Success Criteria:
- Train/val ratio < 5x
- RÂ² maintained > 0.55

Documentation Update:
- thesis.tex: Add regularization analysis to Chapter 5.2
```

#### TASK 1.3: Fix Negative Bias
```
Objective: Reduce precipitation underestimation

Actions:
1. Add bias term to loss:
   L = MSE + lambda * |mean(pred) - mean(true)|Â²

2. Post-processing with bias correction:
   pred_corrected = pred + mean_bias_training

3. Weighted loss by rainfall intensity

Success Criteria:
- |bias_pct| < 5% (currently -3% to -10%)
```

### 3.2 V5 GNN-ConvLSTM Stacking Development (Sprint 2-3) **[UPDATED STRATEGY]**

**STRATEGIC PIVOT (January 2026):** Literature review revealed NO existing Q1 publications combining GNN and ConvLSTM in stacking ensemble for precipitation. This represents a novel, high-impact contribution. V5 refocused from multi-modal fusion to GNN-ConvLSTM stacking.

**Innovation Justification:**
- Literature gap confirmed in: GraphCast (Science 2023), Chen2024 (GRL), Perez2025 (85-paper survey)
- V4 benchmark shows complementary strengths: ConvLSTM (peak RÂ²=0.653, local patterns) + GNN-TAT (mean RMSE=92.12mm, topographic context)
- Expected impact: Q1 publication (GRL/WRR), 50-80 citations vs 15-25 for comparison paper
- Reference: `docs/INNOVATION_ANALYSIS_GNN_CONVLSTM_STACKING.md`

#### TASK 2.1: Architecture Design (Week 1-2)

```
OBJECTIVE: Design dual-branch stacking ensemble

ARCHITECTURE COMPONENTS:

1. BRANCH 1: ConvLSTM-Residual (from V2)
   - Input: BASIC features (temporal + precip + base topo)
   - Preserves V2 attention, bidirectional, residual
   - Output: 64-dim embeddings (B, T, H, W, 64)
   - Expected parameters: ~50K

2. BRANCH 2: GNN-TAT-GAT (from V4)
   - Input: KCE features (BASIC + elevation clusters)
   - Best V4 configuration: GAT with 4 attention heads
   - Output: 64-dim embeddings (B, T, N, 64)
   - Expected parameters: ~98K

3. GRID-GRAPH FUSION MODULE (INNOVATION)
   - Cross-attention: Query=GNN, Key/Value=ConvLSTM
   - Spatial alignment: (61Ã—65 grid) â†’ (3,965 nodes)
   - Bidirectional information flow
   - Expected parameters: ~30K

4. INTERPRETABLE META-LEARNER
   - Context features: elevation, season, temporal regime
   - Learnable weighted fusion: w1Â·Conv + w2Â·GNN
   - Output: Branch contribution weights
   - Expected parameters: ~20K

TOTAL EXPECTED PARAMETERS: ~200K (maintains efficiency)

DELIVERABLES:
â–¡ V5 architecture diagram (PlantUML)
â–¡ Grid-graph spatial alignment method
â–¡ Meta-learner context features defined
â–¡ Implementation in PyTorch (custom_layers/)
```

#### TASK 2.2: Training Pipeline Implementation (Week 3-4)

```
OBJECTIVE: Create V5 training infrastructure

PIPELINE MODIFICATIONS:

1. Dual Data Loading
   - Grid format for ConvLSTM: (B, T, H, W, F_basic)
   - Graph format for GNN-TAT: (B, T, N, F_kce)
   - Shared BASIC features, branch-specific augmentation

2. Branch Training Strategies
   OPTION A: Joint end-to-end (recommended)
     - Train all components simultaneously
     - Single loss function
     - Backprop through fusion module

   OPTION B: Staged training
     - Stage 1: Train branches independently (use V2/V4 checkpoints)
     - Stage 2: Freeze branches, train fusion
     - Stage 3: Fine-tune end-to-end

3. Loss Function Design
   L_total = L_mse + Î»_smooth * L_smooth + Î»_balance * L_balance

   where:
   - L_mse: Standard MSE on predictions
   - L_smooth: Penalize abrupt branch weight changes
   - L_balance: Encourage balanced branch usage

4. Training Configuration
   CONFIG_V5 = {
       'epochs': 200,
       'batch_size': 4,
       'learning_rate': 0.0005,  # Lower than V4 for stability
       'patience': 60,
       'optimizer': 'AdamW',
       'weight_decay': 1e-4,
       'grad_clip': 1.0,
       'lambda_smooth': 0.01,
       'lambda_balance': 0.001
   }

DELIVERABLES:
â–¡ V5 training script in base_models_gnn_convlstm_stacking_v5.ipynb
â–¡ Checkpoint saving for branch contributions
â–¡ Logging branch weights per epoch
â–¡ Memory profiling (ensure fits in Colab Pro+)
```

#### TASK 2.3: Experimentation and Ablation (Week 5-7)

```
OBJECTIVE: Validate architecture through systematic ablation

ABLATION STUDY MATRIX:

| Experiment | ConvLSTM | GNN-TAT | Fusion | Meta | Expected RÂ² |
|------------|----------|---------|--------|------|-------------|
| Baseline V2 | âœ“ | - | - | - | 0.653 |
| Baseline V4 | - | âœ“ | - | - | 0.628 |
| Simple Average | âœ“ | âœ“ | Avg | - | 0.66 |
| Concat+MLP | âœ“ | âœ“ | Concat | - | 0.67 |
| Cross-Attention | âœ“ | âœ“ | Cross-Attn | - | 0.68 |
| Full V5 | âœ“ | âœ“ | Cross-Attn | âœ“ | **0.70** |

HYPERPARAMETER GRID SEARCH:

fusion_heads: [2, 4, 8]
meta_hidden_dim: [64, 128, 256]
branch_output_dim: [32, 64, 128]
fusion_type: ['cross_attention', 'gated_fusion']

Expected best: heads=4, meta_dim=128, output=64

FEATURE SET EXPERIMENTS:

Branch 1 (ConvLSTM): BASIC only (validated in V2)
Branch 2 (GNN-TAT): Test BASIC vs KCE vs PAFC
Expected: KCE performs best (validated in V4)

INTERPRETABILITY ANALYSIS:

1. Branch Weight Analysis
   - Track w1, w2 by elevation regime (low/med/high)
   - Track w1, w2 by season (wet/dry)
   - Track w1, w2 by horizon (H1-H12)

2. Error Attribution
   - Decompose error by branch: e_conv, e_gnn
   - Identify conditions where each branch excels
   - Spatial heatmap of branch dominance

DELIVERABLES:
â–¡ ablation_study_v5.csv with all experiment results
â–¡ branch_contributions_h{H}.json for each horizon
â–¡ Visualizations: branch_weights_by_elevation.png, etc.
â–¡ Statistical significance tests (Friedman, Nemenyi)
```

#### TASK 2.4: Analysis and Paper-5 Writing (Week 8-11)

```
OBJECTIVE: Document innovation and prepare Q1 publication

ANALYSIS TASKS:

1. Performance Comparison
   - V5 vs V2 vs V4 across all horizons
   - Statistical significance testing
   - Degradation analysis H1â†’H12

2. Efficiency Analysis
   - Parameters: V5 (200K) vs V2 (500K-2M)
   - Training time: V5 vs individual branches
   - Memory footprint: Grid+Graph representation

3. Interpretability Results
   - Branch weight patterns
   - Error attribution analysis
   - Physical interpretation (why certain branches dominate)

4. Ablation Study Insights
   - Contribution of each component
   - Fusion mechanism comparison
   - Meta-learner value quantification

PAPER-5 STRUCTURE:

Title: "Stacking Euclidean and Non-Euclidean Neural Networks for
        Precipitation Forecasting in Mountainous Regions"

Target: Geophysical Research Letters (IF=5.2) or
        Water Resources Research (IF=5.4)

Sections:
1. Introduction (1 page)
   - Motivation: ConvLSTM vs GNN trade-offs
   - Gap: No existing GNN-ConvLSTM stacking
   - Contribution: Novel dual-branch architecture

2. Methodology (2 pages)
   - Architecture overview
   - Grid-graph fusion mechanism
   - Interpretable meta-learner
   - Training protocol

3. Results (2 pages)
   - Performance comparison (Table + Figure)
   - Ablation study results (Table)
   - Interpretability analysis (Figures)
   - Branch contribution patterns

4. Discussion (1 page)
   - Why stacking works (complementary strengths)
   - Physical interpretation
   - Comparison with literature (GraphCast, etc.)

5. Conclusions (0.5 pages)
   - Main findings
   - Practical implications
   - Generalization potential

Supplementary Material:
- Full ablation tables
- Hyperparameter sensitivity analysis
- Additional visualizations
- Code repository link

DELIVERABLES:
â–¡ docs/papers/5/ directory created
â–¡ paper-5 spec.md with detailed outline
â–¡ Figures (700 DPI): architecture, results, ablation, interpretability
â–¡ Tables: performance comparison, statistical tests, ablation
â–¡ First draft ready for advisor review
```

#### SUCCESS CRITERIA V5

```
PERFORMANCE TARGETS:

| Metric | V4 Baseline | V5 Target | V5 Excellent |
|--------|-------------|-----------|--------------|
| RÂ² (H1-H6) | 0.628 | > 0.65 | > 0.70 |
| RÂ² (H7-H12) | 0.55 | > 0.58 | > 0.62 |
| RMSE (mm) | 92.12 | < 85 | < 80 |
| Variance (SD) | 6.48 | < 5.0 | < 4.0 |
| Parameters | 98K | < 200K | < 180K |

PUBLICATION TARGETS:

- Q1 journal acceptance (GRL or WRR)
- Projected citations: 50-80 in 5 years
- Innovation level: â­â­â­â­â­ (unprecedented)

THESIS INTEGRATION:

- Chapter 6 (Extensions): V5 as main contribution
- Discussion: Stacking vs multi-modal trade-off
- Conclusions: Novel methodology validated
```

#### TIMELINE V5 (11-12 weeks total)

```
WEEK 1-2:   Architecture Design [TASK 2.1]
WEEK 3-4:   Training Pipeline [TASK 2.2]
WEEK 5-7:   Experimentation & Ablation [TASK 2.3]
WEEK 8-11:  Analysis & Paper-5 Writing [TASK 2.4]
WEEK 12:    Buffer for revisions and advisor feedback

CRITICAL PATH:
Architecture â†’ Pipeline â†’ Ablation â†’ Paper
(No parallelization possible, sequential dependencies)
```

---

### 3.2.5 V5 Alternative: Multi-Modal Fusion (Deferred to V6 or Future Work)

**NOTE:** Original V5 multi-modal plan preserved below for potential V6 integration or future work.

```
DEFERRED RATIONALE:
- Stacking GNN-ConvLSTM has higher innovation potential (no Q1 literature)
- Multi-modal requires significant data acquisition effort (ERA5, MODIS)
- Better to validate stacking methodology first, then add modalities

FUTURE INTEGRATION PATH:
- V6 could combine: V5 stacking + Multi-modal inputs
- Each branch could receive modality-specific data
- Cross-modal attention across data sources
```

<Original Multi-Modal Plan Preserved for Reference>
Sources to Integrate:
+------------------+-------------------+-------------------+
| Source           | Variables         | Resolution        |
+------------------+-------------------+-------------------+
| ERA5 Reanalysis  | Wind u/v          | 0.25 deg / hourly |
|                  | Humidity          |                   |
|                  | Temperature       |                   |
|                  | Pressure          |                   |
+------------------+-------------------+-------------------+
| MODIS            | Cloud cover       | 1km / daily       |
|                  | LST               |                   |
|                  | NDVI              |                   |
+------------------+-------------------+-------------------+
| Climate Indices  | ENSO (Nino 3.4)   | Monthly           |
|                  | IOD               |                   |
|                  | MJO               |                   |
+------------------+-------------------+-------------------+
</Original Multi-Modal Plan>

### 3.3 V6 Ensemble Development (Sprint 4)

#### TASK 3.1: Intelligent Ensemble
```
Strategy: Meta-learner that selects best model based on context

BASE MODELS (from V2-V5):
- V2: ConvLSTM_Bidirectional (good H1-H6)
- V2: ConvRNN_Enhanced (efficient)
- V4: GNN_TAT_GAT + PAFC (best spatial)
- V4: GNN_TAT_SAGE + KCE (best H3-H6)
- V5: Multi-Modal (if improves)

META-LEARNER:
Context Features:
- Horizon (1-12)
- Season (DJF, MAM, JJA, SON)
- Spatial location (cluster)
- Recent RMSE of each model

Output:
- Weights for ensemble: w = softmax(f(context))
- Prediction: P_ensemble = sum(w_i * P_i)

Success Criteria:
- RÂ² ensemble > max(RÂ² individual)
- Reduced variance across horizons
```

### 3.4 Soft Physics Constraints (Sprint 5)

#### TASK 4.1: Soft Physical Constraints
```
Objective: Add physics-based regularization without losing flexibility

CONSTRAINTS TO IMPLEMENT:

1. Mass conservation (simplified):
   L_mass = |sum(P_pred) - sum(P_true)|

2. Spatial smoothness (precipitation doesn't jump abruptly):
   L_smooth_spatial = sum(|P(i,j) - P(i+1,j)|Â² + |P(i,j) - P(i,j+1)|Â²)

3. Temporal consistency (smooth transitions):
   L_smooth_temporal = sum(|P(t+1) - P(t)|Â²)

4. Non-negativity (precipitation >= 0):
   L_nonneg = sum(ReLU(-P_pred)Â²)

FINAL LOSS FUNCTION:
L_total = L_MSE + lambda_mass * L_mass
               + lambda_spatial * L_smooth_spatial
               + lambda_temporal * L_smooth_temporal
               + lambda_nonneg * L_nonneg

Hyperparameters to tune: lambda_* via grid search

Success Criteria:
- Physically plausible predictions
- No degradation in main metrics
```

---

## PART IV: THESIS CHAPTER MAPPING

### 4.1 Thesis Structure (thesis.tex)

```
OFFICIAL TITLE (Aligned with Doctoral Proposal):
"Computational Model for Spatiotemporal Prediction of Monthly Precipitation
in Mountainous Areas: A Hybrid Deep Learning Approach Using Graph Neural
Networks with Temporal Attention"

CHAPTERS:

CAP 1: INTRODUCTION (15 pages)
+-- 1.1 Context and Motivation
+-- 1.2 Problem Statement
+-- 1.3 Objectives (General and Specific)
+-- 1.4 Research Hypotheses (H1-H5)
+-- 1.5 Scope and Limitations
+-- 1.6 Document Structure
Status: [####------] 40% - Draft complete, needs revision

CAP 2: THEORETICAL FRAMEWORK (30 pages)
+-- 2.1 Precipitation Prediction
|   +-- 2.1.1 Traditional methods
|   +-- 2.1.2 Numerical models (NWP)
|   +-- 2.1.3 Machine Learning in meteorology
+-- 2.2 Spatiotemporal Deep Learning
|   +-- 2.2.1 Convolutional Networks (CNN)
|   +-- 2.2.2 Recurrent Networks (LSTM, GRU)
|   +-- 2.2.3 ConvLSTM and variants
+-- 2.3 Graph Neural Networks
|   +-- 2.3.1 Theoretical foundations
|   +-- 2.3.2 GCN, GAT, GraphSAGE
|   +-- 2.3.3 GNN for spatial data
+-- 2.4 Attention Mechanisms
|   +-- 2.4.1 Self-attention and Transformers
|   +-- 2.4.2 Temporal attention
+-- 2.5 State of the Art in DL Precipitation
Status: [######----] 60% - Core sections complete

CAP 3: METHODOLOGY (25 pages)
+-- 3.1 Proposed Data-Driven Framework (DD)
+-- 3.2 Specification-Driven Development (SDD)
+-- 3.3 Data and Preprocessing
|   +-- 3.3.1 CHIRPS 2.0
|   +-- 3.3.2 SRTM DEM
|   +-- 3.3.3 Feature Engineering (BASIC, KCE, PAFC)
+-- 3.4 Implemented Architectures
|   +-- 3.4.1 Baseline (V1)
|   +-- 3.4.2 Enhanced (V2)
|   +-- 3.4.3 FNO (V3)
|   +-- 3.4.4 GNN-TAT (V4)
+-- 3.5 Spatial Graph Construction
+-- 3.6 Experimental Protocol
+-- 3.7 Evaluation Metrics
Status: [########--] 80% - Pending V4 methodology

CAP 4: RESULTS V1-V3 (20 pages)
+-- 4.1 Baseline Results (V1)
+-- 4.2 Enhanced Results (V2)
+-- 4.3 FNO Results (V3)
+-- 4.4 Comparative Analysis
+-- 4.5 Lessons Learned
Status: [##########] 100% - Complete

CAP 5: GNN-TAT V4 RESULTS (25 pages) <-- MAIN CONTRIBUTION
+-- 5.1 Architecture Design
+-- 5.2 Experiments and Configurations
+-- 5.3 Results by Model (GAT, SAGE, GCN)
+-- 5.4 Analysis by Feature Set
+-- 5.5 Analysis by Horizon
+-- 5.6 Comparison with State of the Art
+-- 5.7 Graph Interpretability
Status: [########--] 80% - Full grid complete âœ…, pending final edits

CAP 6: EXTENSIONS - V5 GNN-ConvLSTM STACKING (15 pages)
+-- 6.1 V5 Stacking Architecture (GNN-ConvLSTM)
+-- 6.2 Grid-Graph Fusion Module
+-- 6.3 Interpretable Meta-Learner
+-- 6.4 Experimental Results
+-- 6.5 Future: V6 Ensemble + Physical Constraints
Status: [#---------] 10% - Specification complete (paper_5_spec.md)

CAP 7: DISCUSSION (15 pages)
+-- 7.1 Hypothesis Validation
+-- 7.2 Practical Implications
+-- 7.3 Study Limitations
+-- 7.4 Comparison with Literature
Status: [##--------] 20% - Outline only

CAP 8: CONCLUSIONS (10 pages)
+-- 8.1 General Conclusions
+-- 8.2 Scientific Contributions
+-- 8.3 Future Work
+-- 8.4 Derived Publications
Status: [----------] 0% - Pending

APPENDICES
+-- A: Source Code (GitHub)
+-- B: Complete Metrics Tables
+-- C: Additional Visualizations
+-- D: Hyperparameter Configurations
```

### 4.2 Scientific Contributions

```
CONTRIBUTION 1: GNN-TAT ARCHITECTURE âœ… VALIDATED
- Combines spatial GNN with temporal attention
- Graph constructed with elevation + distance + correlation
- Comparable RÂ² to ConvLSTM (0.628 vs 0.642) with 95% fewer params
- Mean RMSE 18% better, variance 74% lower (p=0.015)
- Validates H1 (partial), H3, H4

CONTRIBUTION 2: HYBRIDIZATION RESCUE EFFECT (H5) âœ… VALIDATED
- Pure FNO RÂ²=0.206 â†’ FNO-ConvLSTM RÂ²=0.582 (182% improvement)
- Demonstrates component hybridization rescues architectural limitations
- Novel finding with publication implications

CONTRIBUTION 3: COMPARATIVE ANALYSIS FNO vs DATA-DRIVEN âœ… VALIDATED
- Demonstrates FNO underperforms for precipitation
- Explains why (discontinuities, small grid)
- Valuable "negative result" for the community

CONTRIBUTION 4: STANDARDIZED FRAMEWORK âœ… COMPLETE
- Reproducible end-to-end pipeline
- Robust benchmarking with statistical tests
- Open-source (GitHub)
- SDD + DD methodology documented

CONTRIBUTION 5 (In Progress): GNN-ConvLSTM STACKING (V5)
- Dual-branch architecture leveraging complementary strengths
- Grid-Graph fusion module for cross-attention
- Interpretable meta-learner for branch contribution analysis
- Status: Specification complete, implementation pending
```

---

## PART V: PAPER DELIVERABLES (paper.tex)

### 5.1 Current Paper Status

```
Location: docs/papers/4/paper.tex
Format: MDPI Hydrology
Focus: Baseline vs Hybrid Model Comparison
Status: **PUBLICATION-READY** (January 2026)

CURRENT SECTIONS:
1. Introduction                    [âœ… COMPLETE]
2. Related Work                    [âœ… COMPLETE]
3. Methodology                     [âœ… COMPLETE - with hybrid taxonomy]
4. V2 Enhanced Results             [âœ… COMPLETE]
5. V3 FNO Results                  [âœ… COMPLETE - with H5 rescue effect]
6. V4 GNN-TAT Results              [âœ… COMPLETE - full grid validated]
7. Statistical Analysis            [âœ… COMPLETE - Friedman + Nemenyi]
8. Discussion                      [âœ… COMPLETE - complementary strengths]
9. Conclusions                     [âœ… COMPLETE]

NEW SECTIONS ADDED (January 2026):
- Hybrid Architecture Taxonomy (Types i-iv)
- Three Hybrid Families: ConvLSTM, FNO-ConvLSTM, GNN-TAT
- H5: Hybridization Rescue Effect (182% FNO improvement)
- GNN-TAT Internal Architecture Diagram
```

### 5.2 Paper-4 Updates Summary (ALL COMPLETE âœ…)

```
SECTION 4: V4 GNN-TAT RESULTS âœ… COMPLETE
+-- Architecture Overview with internal diagram
+-- Graph Construction Methodology (61Ã—65 grid, 500K edges)
+-- Full Grid Results: RÂ²=0.628, RMSE=82.29mm
+-- Comparative table: GNN-TAT vs ConvLSTM

SECTION 5: STATISTICAL ANALYSIS âœ… COMPLETE
+-- Friedman Test across V2, V3, V4
+-- Nemenyi Post-hoc Analysis
+-- Mean RMSE: 92.12mm vs 112.02mm (p=0.015)

SECTION 6: DISCUSSION âœ… COMPLETE
+-- H1-H5 Hypothesis Validation Summary
+-- Complementary Strengths Analysis
+-- Hybridization Rescue Effect (H5)
+-- Feature Engineering Value (KCE/PAFC)

SECTION 7: CONCLUSIONS âœ… COMPLETE
+-- Main Findings with validated hypotheses
+-- Practical Recommendations for operational use
+-- Future Directions (V5 stacking)

NEXT PAPER: Paper-5 GNN-ConvLSTM Stacking
+-- Specification complete: docs/papers/5/paper_5_spec.md
+-- Target: Geophysical Research Letters (IF=5.2)
```

### 5.3 Publications Strategy (Updated January 2026)

```
PAPER 4: Hybrid Architecture Benchmark âœ… COMPLETE (docs/papers/4/)
------------------------------------------------------------------
Title: "A Comparative Analysis of Hybrid Deep Learning Architectures
        for Precipitation Forecasting in Mountainous Regions"
Journal: MDPI Hydrology (Q2)
Status: âœ… PUBLICATION-READY
Key Findings: Hybrid taxonomy, H5 rescue effect, complementary strengths
Message: Foundation paper establishing benchmark methodology

PAPER 5: GNN-ConvLSTM Stacking ðŸš§ IN SPECIFICATION (docs/papers/5/)
------------------------------------------------------------------
Title: "Stacking Euclidean and Non-Euclidean Neural Networks for
        Precipitation Forecasting in Mountainous Regions"
Journal: Geophysical Research Letters (Q1, IF=5.2) or
         Water Resources Research (Q1, IF=5.4)
Status: Specification complete (paper_5_spec.md)
Innovation: First GNN-ConvLSTM stacking in Q1 literature (VALIDATED gap)
Message: HIGH-IMPACT novel contribution, 50-80 projected citations

PAPER 6: Multi-Modal Fusion (Future V6)
-----------------------------------------
Title: "Multi-Modal Deep Learning for Sub-Seasonal Precipitation
        Prediction: Integrating Reanalysis and Satellite Data"
Journal: Nature Communications (if exceptional) or
         Environmental Modelling & Software (Q1)
Status: Deferred to after V5 completion
Message: Build on V5 stacking with ERA5, MODIS integration
```

### 5.4 Target Conferences

| Conference | Deadline | Type | Relevance |
|------------|----------|------|-----------|
| AGU Fall Meeting | August | Poster/Talk | High |
| EGU General Assembly | January | Abstract | High |
| NeurIPS Climate Workshop | September | Paper | Medium |
| ICLR | September | Paper | Medium |

---

## PART VI: DEVELOPMENT MILESTONES

### 6.1 Milestone Tracker **[UPDATED January 7, 2026]**

| Milestone | Target | Deliverable | Success Criteria | Status |
|-----------|--------|-------------|------------------|--------|
| M1 | Jan 7 | V4 Full Grid | RÂ² > 0.60 full grid | âœ… **COMPLETE** (RÂ²=0.628) |
| M2 | Jan 7 | V4 Optimized | Overfitting mitigated | âœ… **COMPLETE** |
| M2.5 | Jan 7 | Paper-4 Complete | All sections done | âœ… **COMPLETE** |
| **M3** | **Feb 14** | **V5 Architecture** | **Design + implementation** | **PENDING** |
| **M4** | **Feb 28** | **V5 Pipeline** | **Training working** | **PENDING** |
| **M5** | **Mar 21** | **V5 Ablation** | **All experiments done** | **PENDING** |
| **M6** | **Apr 15** | **Paper-5 Draft** | **Ready for review** | **PENDING** |
| M7 | May 15 | Paper-4 Submitted | MDPI Hydrology | PENDING |
| M8 | May 31 | Thesis Draft | Chapters 1-6 complete | PENDING |
| M9 | Jun 30 | V6 Ensemble (optional) | If time permits | PENDING |

**NOTE:** M1-M2.5 completed January 7, 2026. V5 pivoted to GNN-ConvLSTM stacking (Paper-5 spec ready).

### 6.2 Documentation Sync Points

```
After each milestone completion:
1. Update thesis.tex with methodology/results
2. Update paper.tex with comparative results
3. Update spec.md if standards change
4. Update this plan.md with progress
5. Commit to GitHub with milestone tag
```

---

## PART VII: RISK ASSESSMENT

### 7.1 Risk Matrix (Updated January 2026)

| Risk | Probability | Impact | Mitigation | Status |
|------|-------------|--------|------------|--------|
| V4 full grid doesn't improve | ~~Medium~~ | ~~High~~ | ~~Iterate hyperparameters~~ | âœ… **RESOLVED** (RÂ²=0.628) |
| Overfitting persists | ~~High~~ | ~~Medium~~ | ~~Data augmentation~~ | âœ… **MITIGATED** |
| V5 stacking architecture fails | Medium | High | Leverage V4 complementary strengths | Active |
| Grid-Graph fusion complexity | Medium | Medium | Start with simple alignment | Active |
| Paper-5 novelty challenged | Low | High | Literature gap validated (85-paper survey) | Active |
| Colab Pro insufficient for V5 | Medium | Medium | University cluster, AWS/GCP credits | Active |
| Timeline extends | Medium | Medium | 2-month buffer, V4 already complete | Active |

### 7.2 Contingency Plan (Updated)

```
IF V5 stacking doesn't outperform:
  -> Ablation study showing contribution of each branch
  -> Document complementary strengths (already validated in V4)
  -> Report as "architecture exploration" with insights

IF Grid-Graph fusion too complex:
  -> Use simple concatenation instead of cross-attention
  -> Focus on meta-learner interpretability
  -> Focus V6 on V2+V4 ensemble

IF insufficient time:
  -> Prioritize: V4 full > GNN-TAT Paper > V5 > V6
  -> Thesis can exclude V5-V6 if needed
  -> V5-V6 as "future work"
```

---

## PART VIII: RESOURCES

### 8.1 Compute Resources

| Resource | Use | Cost/month |
|----------|-----|------------|
| Google Colab Pro+ | Main training | $50 USD |
| Local GPU (RTX 3080) | Development, debug | $0 |
| Google Cloud (backup) | If Colab insufficient | Variable |

### 8.2 Data Sources

| Dataset | Size | Access |
|---------|------|--------|
| CHIRPS 2.0 | ~10 GB (region) | Public |
| SRTM DEM | ~500 MB | Public |
| ERA5 | ~50-100 GB | CDS API (free) |
| MODIS | ~20 GB | Google Earth Engine |

### 8.3 Software Stack

```
Core Stack:
- Python 3.10+
- PyTorch 2.0+
- PyTorch Geometric
- xarray + netCDF4
- pandas, numpy, scikit-learn

Visualization:
- matplotlib, seaborn
- cartopy (maps)

Development:
- Jupyter/Colab
- Git/GitHub
- VS Code
```

---

## APPENDIX: TASK CHECKLIST (Updated January 7, 2026)

### Completed âœ…

- [x] Execute V4 full grid (61Ã—65 = 3,965 nodes)
- [x] Document training results (RÂ²=0.628, RMSE=82.29mm)
- [x] Analyze full grid metrics vs ConvLSTM
- [x] Implement overfitting mitigation
- [x] Update thesis.tex Chapter 5
- [x] Update paper.tex with V4 results and hybrid taxonomy
- [x] Add H5 hypothesis (Hybridization Rescue Effect)
- [x] Create Paper-5 specification (docs/papers/5/paper_5_spec.md)
- [x] Sync documentation: spec.md, INNOVATION_ANALYSIS.md, plan.md
- [x] Create V5 notebook skeleton (models/base_models_gnn_convlstm_stacking_v5.ipynb)
- [x] V5 architecture prototype with all components

### Immediate (January 8-15) âœ… COMPLETE

- [x] V5 architecture design implementation âœ…
- [x] Grid-Graph alignment module prototype âœ…
- [x] Cross-attention fusion layer design âœ…
- [x] Complete thesis.tex hybrid sections (Chapter 4 Methods) âœ…
- [x] Review Paper-4 for final submission âœ…

### Short Term (January 16-31) ðŸš§ IN PROGRESS

- [x] Copy graph construction from V4 to V5 âœ…
- [x] Implement real data loading pipeline (CHIRPS + SRTM) âœ…
- [x] V5 training pipeline implementation âœ…
- [ ] Initial V5 experiments on light mode (5Ã—5 grid)
- [ ] Present V4 results to advisor
- [ ] Submit Paper-4 to MDPI Hydrology

### Medium Term (February-March)

- [ ] V5 experimentation and ablation studies
- [ ] Paper-5 draft preparation
- [ ] Statistical significance tests for V5
- [ ] Thesis Chapter 6 (Extensions)

### Long Term (April-June)

- [ ] Complete V5 and Paper-5
- [ ] V6 ensemble (if time permits)
- [ ] Complete thesis chapters 7-8
- [ ] Prepare thesis defense

---

## VERSION CONTROL

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2026-01-03 | Initial version (Spanish) |
| 2.0 | 2026-01-03 | Complete rewrite in English, added SDD/DD frameworks, thesis mapping, paper deliverables |
| 2.1 | 2026-01-03 | Updated thesis title to align with doctoral proposal; added documentation formatting standards |
| 2.2 | 2026-01-03 | Project audit: renamed 13 CamelCase notebooks, translated 3 Spanish notebooks, added file scope rules |
| 2.3 | 2026-01-06 | **STRATEGIC PIVOT:** V5 refocused from multi-modal to GNN-ConvLSTM stacking based on innovation analysis; added 11-week V5 roadmap with 4 phases; updated milestones M3-M6 |
| **3.0** | **2026-01-07** | **PAPER-4 VALIDATION SYNC:** Updated all sections with full-grid validated results (RÂ²=0.628, RMSE=82.29mm); added H5 hypothesis; marked M1-M2.5 complete; updated scientific contributions; refreshed task checklist; synced with Paper-4, spec.md, INNOVATION_ANALYSIS.md |

---

## PROJECT AUDIT FINDINGS (January 2026)

### Audit Summary

Project compliance with spec.md, plan.md, and CLAUDE.md rules was audited.

**Overall Compliance:** ~75% (after corrections)

### Corrections Applied

| Issue | Count | Action Taken |
|-------|-------|--------------|
| CamelCase notebooks | 13 | Renamed to snake_case |
| Spanish filenames | 3 | Translated to English |
| Missing requirements.txt | 1 | Created at project root |
| Orphan files (nul) | 1 | Deleted |
| Missing scope rules | 2 | Added to CLAUDE.md, spec.md |

### Files Renamed (Models)

| Old Name | New Name |
|----------|----------|
| `base_models_Conv_STHyMOUNTAIN.ipynb` | `base_models_conv_sthymountain_v1.ipynb` |
| `base_models_Conv_STHyMOUNTAIN_V2.ipynb` | `base_models_conv_sthymountain_v2.ipynb` |
| `base_models_Conv_STHyMOUNTAIN_V3_FNO.ipynb` | `base_models_conv_sthymountain_v3_fno.ipynb` |
| `base_models_GNN_TAT_V4.ipynb` | `base_models_gnn_tat_v4.ipynb` |
| `base_models_ST-HybridWaveStack.ipynb` | `base_models_st_hybrid_wave_stack.ipynb` |
| `base_models_STHyMOUNTAIN.ipynb` | `base_models_sthymountain.ipynb` |
| `hybrid_models_ElevClusConvPrecipMetaNet.ipynb` | `hybrid_models_elev_clus_conv_precip_meta_net.ipynb` |
| `hybrid_models_enconders_ST-HybridWaveStack.ipynb` | `hybrid_models_encoders_st_hybrid_wave_stack.ipynb` |
| `hybrid_models_enconders_layering_...` | `hybrid_models_encoders_layering_w3_meta_model_unet_convlstm_st_hybrid_wave_stack.ipynb` |
| `hybrid_models_GRU-w12.ipynb` | `hybrid_models_gru_w12.ipynb` |
| `hybrid_models_ST-HybridWaveStack.ipynb` | `hybrid_models_st_hybrid_wave_stack.ipynb` |
| `hybrid_models_TopoRain_NET.ipynb` | `hybrid_models_topo_rain_net.ipynb` |
| `hybrid_models_TopoRain_NET_clusters_models_base.ipynb` | `hybrid_models_topo_rain_net_clusters_models_base.ipynb` |

### Files Renamed (Notebooks)

| Old Name | New Name |
|----------|----------|
| `analisis_bimodal_boyaca.ipynb` | `bimodal_analysis_boyaca.ipynb` |
| `analisis_correlacion.ipynb` | `correlation_analysis.ipynb` |
| `conv_lstm_boyaca_comparado.ipynb` | `conv_lstm_boyaca_comparison.ipynb` |

### Remaining Items (Low Priority)

| Item | Description | Action |
|------|-------------|--------|
| Spanish `.puml` files | Architecture diagrams in Spanish | Future translation |
| `output/` at root | Old hybrid model outputs | Consider archival |
| Output directory names | CamelCase (Advanced_Spatial/) | Preserved for backwards compatibility |

---

## DOCUMENTATION FORMATTING STANDARDS

### Applied Standards (Phase 2)

1. **Official Thesis Title:** Aligned with doctoral proposal
2. **Bibliography:** Expanded to 110+ Q1 references in `docs/tesis/references.bib`
3. **LaTeX Figures:** Width commands defined to prevent margin overflow
4. **Light Mode Notation:** Added disclaimers for provisional 5Ã—5 grid results
5. **Thesis Structure:** 7 chapters following ML/Hydrology doctoral standards

### Light Mode Results Disclaimer

All V4 GNN-TAT results marked as "Light Mode (5Ã—5 grid)" are provisional.
Full-grid validation (61Ã—65 = 3,965 nodes) pending computational resources.

---

*Plan generated as part of the ML Precipitation Prediction Framework*
*This document should be updated bi-weekly with actual progress*
*Follows SDD and DD frameworks defined in spec.md*
*Phase 2: Documentation & Formatting Standards Applied*
