{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1f4e7925",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/main/models/base_models_STHyMOUNTAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3744f4",
      "metadata": {
        "id": "af3744f4"
      },
      "source": [
        "# 📘 Entrenamiento de Modelos Baseline para Predicción Espaciotemporal de Precipitación Mensual STHyMOUNTAIN\n",
        "\n",
        "Este notebook implementa modelos baseline para la predicción de precipitaciones usando datos espaciotemporales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "Xjn1C7PKysIw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjn1C7PKysIw",
        "outputId": "dd29e4f7-1612-4094-c1c6-06c9f06ccf11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "06416284",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06416284",
        "outputId": "a8e4c864-34e9-41b2-d5c3-e6ccaaf3699e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ml_precipitation_prediction'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: 'ml_precipitation_prediction'\n",
            "/content\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.1.2)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (24.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.1.31)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.14.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Entorno configurado. Usando ruta base: /content/drive/MyDrive/ml_precipitation_prediction\n",
            "Directorio para salida de modelos creado: /content/drive/MyDrive/ml_precipitation_prediction/models/output\n"
          ]
        }
      ],
      "source": [
        "# Configuración del entorno (compatible con Colab y local)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Detectar si estamos en Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Si estamos en Colab, clonar el repositorio\n",
        "    !git clone https://github.com/username/ml_precipitation_prediction.git\n",
        "    %cd ml_precipitation_prediction\n",
        "    # Instalar dependencias necesarias\n",
        "    !pip install -r requirements.txt\n",
        "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn\n",
        "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
        "else:\n",
        "    # Si estamos en local, usar la ruta actual\n",
        "    if '/models' in os.getcwd():\n",
        "        BASE_PATH = Path('..')\n",
        "    else:\n",
        "        BASE_PATH = Path('.')\n",
        "\n",
        "print(f\"Entorno configurado. Usando ruta base: {BASE_PATH}\")\n",
        "\n",
        "# Si BASE_PATH viene como string, lo convertimos\n",
        "BASE_PATH = Path(BASE_PATH)\n",
        "\n",
        "# Ahora puedes concatenar correctamente\n",
        "model_output_dir = BASE_PATH / 'models' / 'output'\n",
        "model_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Directorio para salida de modelos creado: {model_output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e47fb555",
      "metadata": {
        "id": "e47fb555"
      },
      "outputs": [],
      "source": [
        "# 1. Importaciones necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import optuna\n",
        "import pickle\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "26215d90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "26215d90",
        "outputId": "ccb06926-e151-453f-a306-999f15566bd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buscando archivo en: /content/drive/MyDrive/ml_precipitation_prediction/data/output/complete_dataset_with_features.nc\n",
            "Intentando cargar el archivo: /content/drive/MyDrive/ml_precipitation_prediction/data/output/complete_dataset_with_features.nc\n",
            "Archivo cargado exitosamente con xarray\n",
            "\n",
            "Información del dataset:\n",
            "xarray.Dataset {\n",
            "dimensions:\n",
            "\ttime = 530 ;\n",
            "\tlatitude = 62 ;\n",
            "\tlongitude = 66 ;\n",
            "\n",
            "variables:\n",
            "\tdatetime64[ns] time(time) ;\n",
            "\tfloat32 latitude(latitude) ;\n",
            "\tfloat32 longitude(longitude) ;\n",
            "\tfloat32 total_precipitation(time, latitude, longitude) ;\n",
            "\tfloat32 max_daily_precipitation(time, latitude, longitude) ;\n",
            "\tfloat32 min_daily_precipitation(time, latitude, longitude) ;\n",
            "\tfloat32 daily_precipitation_std(time, latitude, longitude) ;\n",
            "\tfloat32 month_sin(time, latitude, longitude) ;\n",
            "\tfloat32 month_cos(time, latitude, longitude) ;\n",
            "\tfloat32 doy_sin(time, latitude, longitude) ;\n",
            "\tfloat32 doy_cos(time, latitude, longitude) ;\n",
            "\tfloat64 elevation(latitude, longitude) ;\n",
            "\tfloat32 slope(latitude, longitude) ;\n",
            "\tfloat32 aspect(latitude, longitude) ;\n",
            "\n",
            "// global attributes:\n",
            "\t:description = ST-HyMOUNTAIN-Net ready dataset with CHIRPS monthly precipitation and DEM variables ;\n",
            "\t:source = CHIRPS v2.0 & DEM Boyacá ;\n",
            "\t:created_at = 2025-04-27 19:02:24 ;\n",
            "}None\n",
            "\n",
            "Variables disponibles:\n",
            "- total_precipitation: (530, 62, 66)\n",
            "- max_daily_precipitation: (530, 62, 66)\n",
            "- min_daily_precipitation: (530, 62, 66)\n",
            "- daily_precipitation_std: (530, 62, 66)\n",
            "- month_sin: (530, 62, 66)\n",
            "- month_cos: (530, 62, 66)\n",
            "- doy_sin: (530, 62, 66)\n",
            "- doy_cos: (530, 62, 66)\n",
            "- elevation: (62, 66)\n",
            "- slope: (62, 66)\n",
            "- aspect: (62, 66)\n",
            "Dataset cargado con éxito. Dimensiones: (2168760, 14)\n",
            "\n",
            "Primeras filas del DataFrame:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(\\\"No se pudo cargar el dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1981-01-01 00:00:00\",\n        \"max\": \"1981-01-01 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1981-01-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.3249969482421875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -74.92500305175781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_precipitation\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          40.750823974609375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_daily_precipitation\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          21.819194793701172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_daily_precipitation\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_precipitation_std\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.019045352935791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month_sin\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month_cos\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8660253882408142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doy_sin\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.01720157451927662\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doy_cos\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9998520612716675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"elevation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 123.34058798530309,\n        \"min\": 248.7760453427361,\n        \"max\": 519.7501066909579,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          519.7501066909579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          89.86701965332031\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          73.48167419433594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-15081ce3-b18d-4749-b97a-17789f6d32ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>total_precipitation</th>\n",
              "      <th>max_daily_precipitation</th>\n",
              "      <th>min_daily_precipitation</th>\n",
              "      <th>daily_precipitation_std</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "      <th>doy_sin</th>\n",
              "      <th>doy_cos</th>\n",
              "      <th>elevation</th>\n",
              "      <th>slope</th>\n",
              "      <th>aspect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-01-01</td>\n",
              "      <td>4.324997</td>\n",
              "      <td>-74.975006</td>\n",
              "      <td>47.381050</td>\n",
              "      <td>24.706928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.825776</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.017202</td>\n",
              "      <td>0.999852</td>\n",
              "      <td>493.784552</td>\n",
              "      <td>89.539551</td>\n",
              "      <td>102.044502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-01-01</td>\n",
              "      <td>4.324997</td>\n",
              "      <td>-74.925003</td>\n",
              "      <td>40.750824</td>\n",
              "      <td>21.819195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.019045</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.017202</td>\n",
              "      <td>0.999852</td>\n",
              "      <td>519.750107</td>\n",
              "      <td>89.867020</td>\n",
              "      <td>73.481674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-01-01</td>\n",
              "      <td>4.324997</td>\n",
              "      <td>-74.875008</td>\n",
              "      <td>46.338623</td>\n",
              "      <td>26.092327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.740223</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.017202</td>\n",
              "      <td>0.999852</td>\n",
              "      <td>248.776045</td>\n",
              "      <td>89.722221</td>\n",
              "      <td>65.916817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-01-01</td>\n",
              "      <td>4.324997</td>\n",
              "      <td>-74.825005</td>\n",
              "      <td>48.779938</td>\n",
              "      <td>29.421450</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.611738</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.017202</td>\n",
              "      <td>0.999852</td>\n",
              "      <td>351.415728</td>\n",
              "      <td>86.986130</td>\n",
              "      <td>140.916000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-01-01</td>\n",
              "      <td>4.324997</td>\n",
              "      <td>-74.775002</td>\n",
              "      <td>38.932945</td>\n",
              "      <td>18.483061</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.733574</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.017202</td>\n",
              "      <td>0.999852</td>\n",
              "      <td>278.261922</td>\n",
              "      <td>88.273293</td>\n",
              "      <td>18.439939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15081ce3-b18d-4749-b97a-17789f6d32ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15081ce3-b18d-4749-b97a-17789f6d32ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15081ce3-b18d-4749-b97a-17789f6d32ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68be0e13-4bc8-4d50-8f9a-2810d0d15626\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68be0e13-4bc8-4d50-8f9a-2810d0d15626')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68be0e13-4bc8-4d50-8f9a-2810d0d15626 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        time  latitude  longitude  total_precipitation  \\\n",
              "0 1981-01-01  4.324997 -74.975006            47.381050   \n",
              "1 1981-01-01  4.324997 -74.925003            40.750824   \n",
              "2 1981-01-01  4.324997 -74.875008            46.338623   \n",
              "3 1981-01-01  4.324997 -74.825005            48.779938   \n",
              "4 1981-01-01  4.324997 -74.775002            38.932945   \n",
              "\n",
              "   max_daily_precipitation  min_daily_precipitation  daily_precipitation_std  \\\n",
              "0                24.706928                      0.0                 5.825776   \n",
              "1                21.819195                      0.0                 5.019045   \n",
              "2                26.092327                      0.0                 5.740223   \n",
              "3                29.421450                      0.0                 5.611738   \n",
              "4                18.483061                      0.0                 3.733574   \n",
              "\n",
              "   month_sin  month_cos   doy_sin   doy_cos   elevation      slope      aspect  \n",
              "0        0.5   0.866025  0.017202  0.999852  493.784552  89.539551  102.044502  \n",
              "1        0.5   0.866025  0.017202  0.999852  519.750107  89.867020   73.481674  \n",
              "2        0.5   0.866025  0.017202  0.999852  248.776045  89.722221   65.916817  \n",
              "3        0.5   0.866025  0.017202  0.999852  351.415728  86.986130  140.916000  \n",
              "4        0.5   0.866025  0.017202  0.999852  278.261922  88.273293   18.439939  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 2. Cargar el dataset NetCDF\n",
        "def load_dataset(file_path):\n",
        "    \"\"\"Carga un archivo NetCDF y lo convierte a pandas DataFrame\"\"\"\n",
        "    try:\n",
        "        # Cargar el archivo NetCDF con xarray\n",
        "        print(f\"Intentando cargar el archivo: {file_path}\")\n",
        "        ds = xr.open_dataset(file_path)\n",
        "        print(\"Archivo cargado exitosamente con xarray\")\n",
        "\n",
        "        # Mostrar información del dataset cargado\n",
        "        print(\"\\nInformación del dataset:\")\n",
        "        print(ds.info())\n",
        "        print(\"\\nVariables disponibles:\")\n",
        "        for var_name in ds.data_vars:\n",
        "            print(f\"- {var_name}: {ds[var_name].shape}\")\n",
        "\n",
        "        # Convertir a DataFrame\n",
        "        df = ds.to_dataframe().reset_index()\n",
        "        return df, ds\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar el archivo NetCDF: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Ruta al dataset\n",
        "data_file = BASE_PATH / 'data' / 'output' / 'complete_dataset_with_features.nc'\n",
        "print(f\"Buscando archivo en: {data_file}\")\n",
        "\n",
        "# Cargar el dataset\n",
        "df, ds_original = load_dataset(data_file)\n",
        "\n",
        "# Verificar si se cargó correctamente\n",
        "if df is not None:\n",
        "    print(f\"Dataset cargado con éxito. Dimensiones: {df.shape}\")\n",
        "    print(\"\\nPrimeras filas del DataFrame:\")\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(\"No se pudo cargar el dataset. Verificar la ruta y el formato del archivo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2f0aebbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f0aebbc",
        "outputId": "48e82987-ff47-41e8-9f40-57e53cf90cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columna objetivo identificada: total_precipitation\n",
            "Filas antes de eliminar NaN: 2168760\n",
            "Filas después de eliminar NaN: 2168760\n",
            "\n",
            "Features seleccionadas (12):\n",
            "['latitude', 'longitude', 'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos', 'elevation', 'slope', 'aspect']\n",
            "\n",
            "Variable objetivo: total_precipitation\n"
          ]
        }
      ],
      "source": [
        "# 3. Preparación de los datos\n",
        "if df is not None:\n",
        "    # Identificar la columna objetivo (precipitación)\n",
        "    target_column = 'total_precipitation'  # Ajustar si tiene otro nombre en tu dataset\n",
        "\n",
        "    # Ver si existe 'precip_target' o usar 'total_precipitation'\n",
        "    if 'total_precipitation' in df.columns:\n",
        "        target_column = 'total_precipitation'\n",
        "\n",
        "    print(f\"Columna objetivo identificada: {target_column}\")\n",
        "\n",
        "    # Separar variables predictoras y variable objetivo\n",
        "    feature_cols = [col for col in df.columns if col != target_column and not pd.isna(df[col]).all()]\n",
        "\n",
        "    # Eliminar columnas no numéricas para los modelos (como fechas o coordenadas si no se usan como features)\n",
        "    non_feature_cols = ['time', 'spatial_ref']\n",
        "    feature_cols = [col for col in feature_cols if col not in non_feature_cols]\n",
        "\n",
        "    # Eliminar filas con valores NaN\n",
        "    print(f\"Filas antes de eliminar NaN: {df.shape[0]}\")\n",
        "    df_clean = df.dropna(subset=[target_column] + feature_cols)\n",
        "    print(f\"Filas después de eliminar NaN: {df_clean.shape[0]}\")\n",
        "\n",
        "    # Separar features y target\n",
        "    X = df_clean[feature_cols]\n",
        "    y = df_clean[target_column]\n",
        "\n",
        "    print(f\"\\nFeatures seleccionadas ({len(feature_cols)}):\\n{feature_cols}\")\n",
        "    print(f\"\\nVariable objetivo: {target_column}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "da222af5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da222af5",
        "outputId": "579fbd57-a790-42dd-807a-e61fc1daacbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones del conjunto de entrenamiento: (1735008, 12)\n",
            "Dimensiones del conjunto de prueba: (433752, 12)\n",
            "Escalador guardado en models/output/scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "# 4. División del conjunto de datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Dimensiones del conjunto de entrenamiento: {X_train.shape}\")\n",
        "print(f\"Dimensiones del conjunto de prueba: {X_test.shape}\")\n",
        "\n",
        "# 5. Estandarización de variables predictoras\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Guardar el scaler para uso futuro\n",
        "with open(model_output_dir / 'scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(\"Escalador guardado en models/output/scaler.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c5ba053b",
      "metadata": {
        "id": "c5ba053b"
      },
      "outputs": [],
      "source": [
        "# 6. Funciones de evaluación y entrenamiento\n",
        "def evaluar_modelo(y_true, y_pred):\n",
        "    \"\"\"Evalúa el rendimiento de un modelo usando múltiples métricas\"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return rmse, mae, r2\n",
        "\n",
        "def entrenar_y_evaluar_modelo(modelo, nombre, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"Entrena un modelo y evalúa su rendimiento\"\"\"\n",
        "    print(f\"Entrenando modelo: {nombre}\")\n",
        "    modelo.fit(X_train, y_train)\n",
        "    predicciones = modelo.predict(X_test)\n",
        "    rmse, mae, r2 = evaluar_modelo(y_test, predicciones)\n",
        "    print(f\"{nombre} - RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
        "    return modelo, (rmse, mae, r2)\n",
        "\n",
        "def guardar_modelo(modelo, nombre):\n",
        "    \"\"\"Guarda un modelo entrenado en disco\"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{nombre}_{timestamp}.pkl\"\n",
        "    with open(model_output_dir / filename, 'wb') as f:\n",
        "        pickle.dump(modelo, f)\n",
        "    print(f\"Modelo {nombre} guardado como: {filename}\")\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0f6bc1f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f6bc1f3",
        "outputId": "f5afc22e-c128-477e-b5d4-831958b7b7f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando modelo: RandomForest\n",
            "RandomForest - RMSE: 36.4174, MAE: 24.8917, R²: 0.9168\n",
            "Modelo RandomForest guardado como: RandomForest_20250428_012806.pkl\n",
            "Entrenando modelo: XGBoost\n",
            "XGBoost - RMSE: 37.8542, MAE: 26.3499, R²: 0.9101\n",
            "Modelo XGBoost guardado como: XGBoost_20250428_012933.pkl\n",
            "Entrenando modelo: LightGBM\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017197 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1473\n",
            "[LightGBM] [Info] Number of data points in the train set: 1735008, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 186.821910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM - RMSE: 39.0589, MAE: 27.3338, R²: 0.9043\n",
            "Modelo LightGBM guardado como: LightGBM_20250428_012940.pkl\n"
          ]
        }
      ],
      "source": [
        "# 7. Entrenamiento modelos base sin optimización\n",
        "modelos_base = {\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
        "    'LightGBM': LGBMRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "resultados_base = {}\n",
        "modelos_guardados = {}\n",
        "\n",
        "for nombre, modelo in modelos_base.items():\n",
        "    modelo_entrenado, metricas = entrenar_y_evaluar_modelo(\n",
        "        modelo, nombre, X_train_scaled, y_train, X_test_scaled, y_test\n",
        "    )\n",
        "    resultados_base[nombre] = metricas\n",
        "\n",
        "    # Guardar modelo\n",
        "    modelo_file = guardar_modelo(modelo_entrenado, nombre)\n",
        "    modelos_guardados[nombre] = modelo_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d90151",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c1d90151",
        "outputId": "3564d17f-5103-4615-e806-bbaa1457ef7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-28 01:29:40,112] A new study created in memory with name: no-name-f2097522-b917-45e3-a523-4d5b98a66044\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando optimización de hiperparámetros para RandomForest...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-28 01:58:10,879] Trial 0 finished with value: 36.8066452846521 and parameters: {'n_estimators': 343, 'max_depth': 34, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 36.8066452846521.\n",
            "[I 2025-04-28 02:18:38,335] Trial 1 finished with value: 41.63606143990411 and parameters: {'n_estimators': 304, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 36.8066452846521.\n",
            "[W 2025-04-28 02:18:39,457] Trial 2 failed with parameters: {'n_estimators': 371, 'max_depth': 49, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 'auto'} because of the following error: ValueError('\\nAll the 5 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n3 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\\n    estimator._validate_params()\\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\\n    validate_parameter_constraints(\\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\\n    raise InvalidParameterError(\\nsklearn.utils._param_validation.InvalidParameterError: The \\'max_features\\' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {\\'log2\\', \\'sqrt\\'} or None. Got \\'auto\\' instead.\\n\\n--------------------------------------------------------------------------------\\n2 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\\n    estimator._validate_params()\\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\\n    validate_parameter_constraints(\\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\\n    raise InvalidParameterError(\\nsklearn.utils._param_validation.InvalidParameterError: The \\'max_features\\' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {\\'sqrt\\', \\'log2\\'} or None. Got \\'auto\\' instead.\\n').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-25-63084c155e09>\", line 13, in objective_rf\n",
            "    score = cross_val_score(model, X_train_scaled, y_train,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "                 ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 431, in cross_validate\n",
            "    _warn_or_raise_about_fit_failures(results, error_score)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 5 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "[W 2025-04-28 02:18:39,463] Trial 2 failed with value None.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-63084c155e09>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iniciando optimización de hiperparámetros para RandomForest...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mstudy_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mstudy_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nMejores hiperparámetros encontrados:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-63084c155e09>\u001b[0m in \u001b[0;36mobjective_rf\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     11\u001b[0m     }\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     score = cross_val_score(model, X_train_scaled, y_train, \n\u001b[0m\u001b[1;32m     14\u001b[0m                           scoring='neg_root_mean_squared_error', cv=5, n_jobs=-1)\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Devolvemos negativo porque optimizamos minimizando\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# For callable scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n"
          ]
        }
      ],
      "source": [
        "# 8. Optimización de hiperparámetros con Optuna (RandomForest)\n",
        "def objective_rf(trial):\n",
        "    \"\"\"Función objetivo para optimización de RandomForest con Optuna\"\"\"\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),  # Eliminado 'auto' que ya no es válido\n",
        "        'random_state': 42\n",
        "    }\n",
        "    model = RandomForestRegressor(**params)\n",
        "    try:\n",
        "        score = cross_val_score(model, X_train_scaled, y_train,\n",
        "                          scoring='neg_root_mean_squared_error', cv=5, n_jobs=-1,\n",
        "                          error_score='raise')\n",
        "        return -np.mean(score)  # Devolvemos negativo porque optimizamos minimizando\n",
        "    except Exception as e:\n",
        "        print(f\"Error en prueba de hiperparámetros: {e}\")\n",
        "        # Devolvemos un valor alto para que Optuna descarte esta configuración\n",
        "        return float('inf')\n",
        "\n",
        "print(\"Iniciando optimización de hiperparámetros para RandomForest...\")\n",
        "study_rf = optuna.create_study(direction='minimize')\n",
        "study_rf.optimize(objective_rf, n_trials=30, catch=(ValueError,))\n",
        "\n",
        "print(\"\\nMejores hiperparámetros encontrados:\")\n",
        "print(study_rf.best_params)\n",
        "\n",
        "# Entrenar el mejor modelo RandomForest con los parámetros optimizados\n",
        "best_rf_params = study_rf.best_params\n",
        "best_rf = RandomForestRegressor(**best_rf_params, random_state=42)\n",
        "mejor_rf, metricas_rf = entrenar_y_evaluar_modelo(\n",
        "    best_rf, 'RandomForest_Optuna', X_train_scaled, y_train, X_test_scaled, y_test\n",
        ")\n",
        "resultados_base['RandomForest_Optuna'] = metricas_rf\n",
        "\n",
        "# Guardar el mejor modelo\n",
        "mejor_rf_file = guardar_modelo(mejor_rf, 'RandomForest_Optuna')\n",
        "modelos_guardados['RandomForest_Optuna'] = mejor_rf_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8e1a844",
      "metadata": {
        "id": "a8e1a844"
      },
      "outputs": [],
      "source": [
        "# 9. Visualización de resultados\n",
        "resultados_df = pd.DataFrame(resultados_base, index=['RMSE', 'MAE', 'R2']).T\n",
        "\n",
        "# Visualizar resultados en tabla\n",
        "display(resultados_df)\n",
        "\n",
        "# Gráficas de comparación\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=resultados_df.index, y=resultados_df['RMSE'])\n",
        "plt.title('Comparación de RMSE entre modelos')\n",
        "plt.ylabel('RMSE (menor es mejor)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(model_output_dir / 'rmse_comparison.png')\n",
        "plt.show()\n",
        "\n",
        "# Gráfica de R²\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=resultados_df.index, y=resultados_df['R2'])\n",
        "plt.title('Comparación de R² entre modelos')\n",
        "plt.ylabel('R² (mayor es mejor)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(model_output_dir / 'r2_comparison.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b378c2",
      "metadata": {
        "id": "95b378c2"
      },
      "outputs": [],
      "source": [
        "# 10. Exportar resultados finales\n",
        "# Crear un dataset de xarray con resultados\n",
        "def create_results_dataset(resultados_df):\n",
        "    \"\"\"Crea un dataset de xarray con los resultados para exportar como NetCDF\"\"\"\n",
        "    modelo_names = list(resultados_df.index)\n",
        "    metrics = ['RMSE', 'MAE', 'R2']\n",
        "\n",
        "    # Crear arrays para cada métrica\n",
        "    rmse_values = resultados_df['RMSE'].values\n",
        "    mae_values = resultados_df['MAE'].values\n",
        "    r2_values = resultados_df['R2'].values\n",
        "\n",
        "    # Crear dataset\n",
        "    ds = xr.Dataset(\n",
        "        data_vars={\n",
        "            'RMSE': (['model'], rmse_values),\n",
        "            'MAE': (['model'], mae_values),\n",
        "            'R2': (['model'], r2_values)\n",
        "        },\n",
        "        coords={\n",
        "            'model': modelo_names,\n",
        "        },\n",
        "        attrs={\n",
        "            'description': 'Resultados de modelos de predicción de precipitación STHyMOUNTAIN',\n",
        "            'created': datetime.datetime.now().isoformat(),\n",
        "            'features_used': ', '.join(feature_cols)\n",
        "        }\n",
        "    )\n",
        "    return ds\n",
        "\n",
        "# Crear dataset de resultados\n",
        "results_ds = create_results_dataset(resultados_df)\n",
        "\n",
        "# Guardar resultados como NetCDF\n",
        "results_file = model_output_dir / 'model_results.nc'\n",
        "results_ds.to_netcdf(results_file)\n",
        "print(f\"Resultados guardados como NetCDF en: {results_file}\")\n",
        "\n",
        "# También guardar como CSV para fácil visualización\n",
        "csv_file = model_output_dir / 'model_results.csv'\n",
        "resultados_df.to_csv(csv_file)\n",
        "print(f\"Resultados guardados como CSV en: {csv_file}\")\n",
        "\n",
        "# Crear un diccionario con información del modelo para uso futuro\n",
        "model_info = {\n",
        "    'date_trained': datetime.datetime.now().isoformat(),\n",
        "    'feature_columns': feature_cols,\n",
        "    'target_column': target_column,\n",
        "    'models_saved': modelos_guardados,\n",
        "    'results': resultados_df.to_dict(),\n",
        "    'best_model': resultados_df['RMSE'].idxmin(),\n",
        "    'scaler': 'scaler.pkl'\n",
        "}\n",
        "\n",
        "# Guardar información del modelo\n",
        "with open(model_output_dir / 'model_info.pkl', 'wb') as f:\n",
        "    pickle.dump(model_info, f)\n",
        "print(f\"Información del modelo guardada en: {model_output_dir / 'model_info.pkl'}\")\n",
        "\n",
        "print(\"\\n🔥 Entrenamiento completado con éxito! El mejor modelo es:\", resultados_df['RMSE'].idxmin())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
