{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🌧️ Modelo Híbrido ConvLSTM-GRU para Predicción de Precipitación\n",
        "\n",
        "## Notebook Refactorizado - Sin Duplicación de Código\n",
        "\n",
        "Este notebook implementa modelos híbridos ConvLSTM-GRU con:\n",
        "- ✅ Código unificado sin duplicación\n",
        "- ✅ Visualización mejorada (archivos + salida del notebook)\n",
        "- ✅ Funciones reutilizables\n",
        "- ✅ Configuración centralizada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ╭────────────────────── IMPORTS Y CONFIGURACIÓN ──────────────────╮\n",
        "from __future__ import annotations\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import imageio.v2 as imageio\n",
        "from IPython.display import display, Image as IPImage, HTML\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, ConvLSTM2D, GRU, Flatten, RepeatVector, Reshape,\n",
        "    TimeDistributed, Dense, MultiHeadAttention, Add,\n",
        "    LayerNormalization, Embedding, Concatenate, Lambda\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Configuración de matplotlib para mejor visualización\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['savefig.dpi'] = 150\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# ╭─────────────────────────── PATHS ──────────────────────────╮\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_PATH = Path('/content/drive/MyDrive/ml_precipitation_prediction')\n",
        "    %pip install -q xarray netCDF4 matplotlib seaborn scikit-learn cartopy geopandas imageio\n",
        "else:\n",
        "    BASE_PATH = Path.cwd()\n",
        "    for p in [BASE_PATH, *BASE_PATH.parents]:\n",
        "        if (p / '.git').exists():\n",
        "            BASE_PATH = p\n",
        "            break\n",
        "\n",
        "import cartopy.crs as ccrs\n",
        "print(f'📁 BASE_PATH = {BASE_PATH}')\n",
        "\n",
        "# Estructura de directorios\n",
        "DATA_DIR = BASE_PATH / 'data' / 'output'\n",
        "MODEL_DIR = BASE_PATH / 'models' / 'output' / 'HybridLSTMModels'\n",
        "MODEL_INPUT_DIR = BASE_PATH / 'data' / 'input' / 'shapes'\n",
        "IMAGE_DIR = MODEL_DIR / 'images'\n",
        "GIF_DIR = MODEL_DIR / 'gifs'\n",
        "\n",
        "# Crear directorios si no existen\n",
        "for dir_path in [MODEL_DIR, IMAGE_DIR, GIF_DIR]:\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Archivos de datos\n",
        "FULL_NC_CLEAN = DATA_DIR / 'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation_clean.nc'\n",
        "\n",
        "# ╭──────────────────── HIPERPARÁMETROS ────────────────────╮\n",
        "class Config:\n",
        "    \"\"\"Configuración centralizada del modelo\"\"\"\n",
        "    INPUT_WINDOW = 60\n",
        "    HORIZON = 3\n",
        "    TARGET_VAR = 'total_precipitation'\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 16\n",
        "    PATIENCE = 40\n",
        "    LR = 1e-3\n",
        "    \n",
        "    # Features\n",
        "    BASE_FEATURES = [\n",
        "        'year', 'month', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos',\n",
        "        'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std',\n",
        "        'elevation', 'slope', 'aspect'\n",
        "    ]\n",
        "    ELEV_CLUSTER = ['elev_high', 'elev_med', 'elev_low']\n",
        "    KCE_FEATURES = BASE_FEATURES + ELEV_CLUSTER\n",
        "    PAFC_FEATURES = KCE_FEATURES + ['total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag12']\n",
        "    LAG_VARS = ['total_precipitation_lag1', 'total_precipitation_lag2', 'total_precipitation_lag12']\n",
        "\n",
        "print(\"✅ Configuración cargada\")\n",
        "# ╰────────────────────────────────────────────────────────────╯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ╭────────────────────── CARGA DE DATOS ──────────────────╮\n",
        "print(\"📊 Cargando dataset...\")\n",
        "\n",
        "# Verificar si existe el archivo limpio, si no, crearlo\n",
        "if not FULL_NC_CLEAN.exists():\n",
        "    print(\"⚠️ Archivo limpio no encontrado. Procesando dataset original...\")\n",
        "    FULL_NC = DATA_DIR / 'complete_dataset_with_features_with_clusters_elevation_windows_imfs_with_onehot_elevation.nc'\n",
        "    ds_raw = xr.open_dataset(FULL_NC)\n",
        "    \n",
        "    # Análisis de NaNs\n",
        "    print(\"\\n📊 Resumen de NaNs en variables lag:\")\n",
        "    print(\"─\" * 55)\n",
        "    for var in Config.LAG_VARS:\n",
        "        arr = ds_raw[var].values\n",
        "        total = arr.size\n",
        "        n_nans = int(np.isnan(arr).sum())\n",
        "        print(f\"{var:<28}: {n_nans:>8,} / {total:,} ({n_nans/total:6.2%})\")\n",
        "    \n",
        "    # Limpiar datos (remover 1981 que tiene muchos NaNs)\n",
        "    ds_clean = ds_raw.sel(time=~(ds_raw['time.year'] == 1981))\n",
        "    print(f\"\\n🔄 Timestamps: {len(ds_raw.time)} → {len(ds_clean.time)} (removido 1981)\")\n",
        "    \n",
        "    # Guardar dataset limpio\n",
        "    ds_clean.to_netcdf(FULL_NC_CLEAN, mode='w')\n",
        "    print(f\"💾 Dataset limpio guardado en {FULL_NC_CLEAN}\")\n",
        "    ds = ds_clean\n",
        "else:\n",
        "    ds = xr.open_dataset(FULL_NC_CLEAN)\n",
        "    print(f\"✅ Dataset cargado desde {FULL_NC_CLEAN}\")\n",
        "\n",
        "# Cargar shapefile\n",
        "dept_gdf = gpd.read_file(MODEL_INPUT_DIR / 'MGN_Departamento.shp')\n",
        "\n",
        "# Dimensiones\n",
        "lat, lon = len(ds.latitude), len(ds.longitude)\n",
        "print(f\"\\n📐 Dimensiones: {lat} x {lon} = {lat * lon} celdas\")\n",
        "print(f\"📅 Período: {ds.time.values[0]} a {ds.time.values[-1]}\")\n",
        "# ╰────────────────────────────────────────────────────────────╯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ╭────────────────────── FUNCIONES UTILITARIAS ──────────────────╮\n",
        "\n",
        "def evaluate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
        "    \"\"\"Calcula métricas de evaluación\"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}\n",
        "\n",
        "\n",
        "def quick_plot(ax, data, cmap, title, date_label, vmin=None, vmax=None, show_departments=True):\n",
        "    \"\"\"Función unificada para plotear mapas\"\"\"\n",
        "    mesh = ax.pcolormesh(ds.longitude, ds.latitude, data, \n",
        "                         cmap=cmap, shading='nearest', \n",
        "                         vmin=vmin, vmax=vmax, \n",
        "                         transform=ccrs.PlateCarree())\n",
        "    ax.coastlines()\n",
        "    if show_departments and dept_gdf is not None:\n",
        "        ax.add_geometries(dept_gdf.geometry, ccrs.PlateCarree(), \n",
        "                         edgecolor='black', facecolor='none', linewidth=1)\n",
        "    gl = ax.gridlines(draw_labels=True)\n",
        "    gl.top_labels = False\n",
        "    gl.right_labels = False\n",
        "    ax.set_title(f\"{title}\\n{date_label}\", pad=12)\n",
        "    return mesh\n",
        "\n",
        "\n",
        "def generate_and_display_gif(y_true_sample, y_pred_sample, tag, show_in_notebook=True):\n",
        "    \"\"\"Genera GIF y lo muestra en el notebook\"\"\"\n",
        "    pcm_min, pcm_max = 0, np.max(y_pred_sample)\n",
        "    frames = []\n",
        "    \n",
        "    for h in range(Config.HORIZON):\n",
        "        pmap = y_pred_sample[h, ..., 0]\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(8, 6), \n",
        "                              subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "        \n",
        "        mesh = quick_plot(ax, pmap, 'Blues', f\"{tag}\", f\"Horizonte {h+1}\", \n",
        "                         vmin=pcm_min, vmax=pcm_max)\n",
        "        fig.colorbar(mesh, ax=ax, fraction=0.046, pad=0.04, label='Precipitación (mm)')\n",
        "        \n",
        "        # Guardar frame temporal\n",
        "        tmp = GIF_DIR / f\"tmp_{tag}_h{h}.png\"\n",
        "        fig.savefig(tmp, bbox_inches='tight', dpi=100)\n",
        "        plt.close(fig)\n",
        "        \n",
        "        frames.append(imageio.imread(tmp))\n",
        "        tmp.unlink(missing_ok=True)\n",
        "    \n",
        "    # Guardar GIF\n",
        "    gif_path = GIF_DIR / f\"{tag}.gif\"\n",
        "    imageio.mimsave(gif_path, frames, fps=0.5)\n",
        "    print(f\"💾 GIF guardado: {gif_path.name}\")\n",
        "    \n",
        "    # Mostrar en notebook\n",
        "    if show_in_notebook:\n",
        "        display(HTML(f'<h4>🎬 {tag}</h4>'))\n",
        "        display(IPImage(filename=str(gif_path)))\n",
        "    \n",
        "    return gif_path\n",
        "\n",
        "\n",
        "def plot_training_history(history, tag, show_in_notebook=True):\n",
        "    \"\"\"Plotea y guarda el historial de entrenamiento\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    ax.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "    ax.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss (MSE)')\n",
        "    ax.set_title(f'Training History - {tag}')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Guardar\n",
        "    img_path = IMAGE_DIR / f\"{tag}_history.png\"\n",
        "    fig.savefig(img_path, bbox_inches='tight', dpi=150)\n",
        "    \n",
        "    # Mostrar en notebook\n",
        "    if show_in_notebook:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "    \n",
        "    return img_path\n",
        "\n",
        "\n",
        "def make_windows(mask: np.ndarray, Xarr: np.ndarray, yarr: np.ndarray, \n",
        "                allow_past_context: bool) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Genera ventanas deslizantes descartando las que contienen NaNs\"\"\"\n",
        "    seq_X, seq_y = [], []\n",
        "    lim = len(mask) - Config.INPUT_WINDOW - Config.HORIZON + 1\n",
        "    \n",
        "    for start in range(lim):\n",
        "        end_w = start + Config.INPUT_WINDOW\n",
        "        end_y = end_w + Config.HORIZON\n",
        "        \n",
        "        if allow_past_context:\n",
        "            if not mask[end_w:end_y].all():\n",
        "                continue\n",
        "        else:\n",
        "            if not mask[start:end_y].all():\n",
        "                continue\n",
        "        \n",
        "        Xw = Xarr[start:end_w]\n",
        "        yw = yarr[end_w:end_y]\n",
        "        \n",
        "        if np.isnan(Xw).any() or np.isnan(yw).any():\n",
        "            continue\n",
        "        \n",
        "        seq_X.append(Xw)\n",
        "        seq_y.append(yw)\n",
        "    \n",
        "    return np.array(seq_X), np.array(seq_y)\n",
        "\n",
        "\n",
        "def impute_nans(a: np.ndarray, per_feature_mean: Optional[np.ndarray] = None, \n",
        "                is_target: bool = False) -> np.ndarray:\n",
        "    \"\"\"Imputa NaNs restantes (seguridad extra)\"\"\"\n",
        "    if not np.isnan(a).any():\n",
        "        return a\n",
        "    \n",
        "    if is_target:\n",
        "        a[np.isnan(a)] = 0.0\n",
        "        return a\n",
        "    \n",
        "    if per_feature_mean is None:\n",
        "        raise ValueError('per_feature_mean required for imputing X')\n",
        "    \n",
        "    flat = a.reshape(-1, a.shape[-1])\n",
        "    nan_idx = np.isnan(flat)\n",
        "    for f in range(a.shape[-1]):\n",
        "        flat[nan_idx[:, f], f] = per_feature_mean[f]\n",
        "    \n",
        "    return flat.reshape(a.shape)\n",
        "\n",
        "print(\"✅ Funciones utilitarias definidas\")\n",
        "# ╰────────────────────────────────────────────────────────────╯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ╭────────────────────── DEFINICIÓN DEL MODELO ──────────────────╮\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def tile_step_emb(batch_ref, step_emb_tab):\n",
        "    \"\"\"Replica la tabla de embedding para el batch\"\"\"\n",
        "    if isinstance(batch_ref, (tf.TensorShape, tf.TensorSpec)):\n",
        "        return tf.TensorShape([batch_ref[0], step_emb_tab.shape[0], step_emb_tab.shape[1]])\n",
        "    \n",
        "    b = tf.shape(batch_ref)[0]\n",
        "    emb = tf.expand_dims(step_emb_tab, 0)\n",
        "    return tf.tile(emb, [b, 1, 1])\n",
        "\n",
        "\n",
        "def build_convlstm_ed(\n",
        "    *,\n",
        "    input_window: int,\n",
        "    output_horizon: int,\n",
        "    spatial_height: int,\n",
        "    spatial_width: int,\n",
        "    n_features: int,\n",
        "    n_filters: int = 64,\n",
        "    n_heads: int = 4,\n",
        "    use_attention: bool = True,\n",
        "    use_positional_emb: bool = True,\n",
        "    lr: float = 1e-3\n",
        ") -> Model:\n",
        "    \"\"\"\n",
        "    Encoder-Decoder ConvLSTM + GRU con positional embedding mejorado\n",
        "    \"\"\"\n",
        "    # ──────────────── Encoder ────────────────\n",
        "    enc_inputs = Input(\n",
        "        shape=(input_window, spatial_height, spatial_width, n_features),\n",
        "        name=\"enc_input\"\n",
        "    )\n",
        "    \n",
        "    x = ConvLSTM2D(n_filters, (3, 3), padding='same',\n",
        "                   return_sequences=True, name=\"enc_lstm_1\")(enc_inputs)\n",
        "    x = ConvLSTM2D(n_filters // 2, (3, 3), padding='same',\n",
        "                   return_sequences=False, name=\"enc_lstm_2\")(x)\n",
        "    \n",
        "    # ── Flatten y repetir contexto ──\n",
        "    flat = Flatten(name=\"flatten_spatial\")(x)\n",
        "    ctx = RepeatVector(output_horizon, name=\"context\")(flat)\n",
        "    \n",
        "    # ── Positional embedding mejorado ──\n",
        "    if use_positional_emb:\n",
        "        step_ids_input = Input(shape=(output_horizon,), dtype=tf.int32, name=\"step_ids\")\n",
        "        step_emb_layer = Embedding(output_horizon, n_filters, name=\"step_embedding\")\n",
        "        step_emb = step_emb_layer(step_ids_input)\n",
        "        dec_in = Concatenate(name=\"dec_concat\")([ctx, step_emb])\n",
        "        model_inputs = [enc_inputs, step_ids_input]\n",
        "    else:\n",
        "        dec_in = ctx\n",
        "        model_inputs = enc_inputs\n",
        "    \n",
        "    # ─────────────── Decoder ───────────────\n",
        "    dec = GRU(2 * n_filters, return_sequences=True, name=\"dec_gru\")(dec_in)\n",
        "    \n",
        "    # ─────── Attention (opcional) ───────\n",
        "    if use_attention:\n",
        "        attn = MultiHeadAttention(num_heads=n_heads, key_dim=n_filters,\n",
        "                                  dropout=0.1, name=\"mha\")(dec, dec)\n",
        "        dec = Add(name=\"mha_residual\")([dec, attn])\n",
        "        dec = LayerNormalization(name=\"mha_norm\")(dec)\n",
        "    \n",
        "    # ───────────── Proyección a grilla ─────────────\n",
        "    proj = TimeDistributed(\n",
        "        Dense(spatial_height * spatial_width, activation='linear'),\n",
        "        name=\"dense_proj\"\n",
        "    )(dec)\n",
        "    \n",
        "    out = Reshape(\n",
        "        (output_horizon, spatial_height, spatial_width, 1),\n",
        "        name=\"reshape_out\"\n",
        "    )(proj)\n",
        "    \n",
        "    # Nombre del modelo\n",
        "    name = (\"ConvLSTM_ED_Attn_PE\" if use_attention else \"ConvLSTM_ED_PE\") \\\n",
        "           if use_positional_emb else \\\n",
        "           (\"ConvLSTM_ED_Attn\" if use_attention else \"ConvLSTM_ED\")\n",
        "    \n",
        "    model = Model(model_inputs, out, name=name)\n",
        "    model.compile(optimizer=Adam(lr), loss='mse')\n",
        "    return model\n",
        "\n",
        "\n",
        "# Factories para diferentes configuraciones\n",
        "def factory_no_attn(**kw):\n",
        "    return build_convlstm_ed(use_attention=False, **kw)\n",
        "\n",
        "def factory_attn(**kw):\n",
        "    return build_convlstm_ed(use_attention=True, **kw)\n",
        "\n",
        "print(\"✅ Arquitectura del modelo definida\")\n",
        "# ╰────────────────────────────────────────────────────────────╯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ╭────────────────────── CONFIGURACIÓN DE EXPERIMENTOS ──────────────────╮\n",
        "\n",
        "FOLDS = {\n",
        "    'F1': {'year': 2018, 'active': True}\n",
        "}\n",
        "\n",
        "EXPERIMENTS = {\n",
        "    'ConvLSTM-ED': {\n",
        "        'active': True,\n",
        "        'feature_list': Config.BASE_FEATURES,\n",
        "        'builder': factory_attn,\n",
        "        'n_filters': 64,\n",
        "        'n_heads': 4\n",
        "    },\n",
        "    'ConvLSTM-ED-KCE': {\n",
        "        'active': True,\n",
        "        'feature_list': Config.KCE_FEATURES,\n",
        "        'builder': factory_attn,\n",
        "        'n_filters': 64,\n",
        "        'n_heads': 4,\n",
        "    },\n",
        "    'ConvLSTM-ED-KCE-PAFC': {\n",
        "        'active': True,\n",
        "        'feature_list': Config.PAFC_FEATURES,\n",
        "        'builder': factory_attn,\n",
        "        'n_filters': 96,\n",
        "        'n_heads': 6,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(\"📋 Experimentos configurados:\")\n",
        "for exp_name, exp_cfg in EXPERIMENTS.items():\n",
        "    if exp_cfg['active']:\n",
        "        print(f\"  • {exp_name}: {len(exp_cfg['feature_list'])} features\")\n",
        "# ╰────────────────────────────────────────────────────────────╯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ╭────────────────────── ENTRENAMIENTO Y EVALUACIÓN ──────────────────╮\n",
        "\n",
        "def run_experiments(show_visualizations=True):\n",
        "    \"\"\"Ejecuta todos los experimentos configurados\"\"\"\n",
        "    times = pd.to_datetime(ds.time.values)\n",
        "    results = []\n",
        "    \n",
        "    # Contador de experimentos\n",
        "    total_exp = sum(e['active'] for e in EXPERIMENTS.values()) * sum(f['active'] for f in FOLDS.values())\n",
        "    exp_count = 0\n",
        "    \n",
        "    for exp_name, exp_cfg in EXPERIMENTS.items():\n",
        "        if not exp_cfg['active']:\n",
        "            continue\n",
        "        \n",
        "        # Configuración del experimento\n",
        "        feature_list = exp_cfg['feature_list']\n",
        "        builder = exp_cfg['builder']\n",
        "        n_filters = exp_cfg.get('n_filters', 64)\n",
        "        n_heads = exp_cfg.get('n_heads', 4)\n",
        "        \n",
        "        # Cargar features\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"🔬 Experimento: {exp_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        Xarr = ds[feature_list].to_array().transpose('time', 'latitude', 'longitude', 'variable').values.astype(np.float32)\n",
        "        yarr = ds[Config.TARGET_VAR].values.astype(np.float32)\n",
        "        n_features = Xarr.shape[-1]\n",
        "        \n",
        "        for fold_name, fold_cfg in FOLDS.items():\n",
        "            if not fold_cfg['active']:\n",
        "                continue\n",
        "            \n",
        "            exp_count += 1\n",
        "            year_val = fold_cfg['year']\n",
        "            \n",
        "            print(f\"\\n▶️ [{exp_count}/{total_exp}] {exp_name} - {fold_name} (val={year_val})\")\n",
        "            \n",
        "            # Crear máscaras temporales\n",
        "            mask_val = times.year == year_val\n",
        "            mask_tr = ~mask_val\n",
        "            \n",
        "            if mask_val.sum() < Config.HORIZON:\n",
        "                print(\"⚠️ Año sin suficientes datos → skip\")\n",
        "                continue\n",
        "            \n",
        "            # Generar ventanas\n",
        "            X_tr, y_tr = make_windows(mask_tr, Xarr, yarr, allow_past_context=False)\n",
        "            X_va, y_va = make_windows(mask_val, Xarr, yarr, allow_past_context=True)\n",
        "            \n",
        "            print(f\"📊 Ventanas - Train: {len(X_tr)}, Val: {len(X_va)}\")\n",
        "            \n",
        "            if len(X_tr) == 0 or len(X_va) == 0:\n",
        "                print(\"⚠️ Sin ventanas válidas → skip\")\n",
        "                continue\n",
        "            \n",
        "            # Imputación de NaNs\n",
        "            feat_mean = np.nanmean(X_tr.reshape(-1, n_features), axis=0)\n",
        "            X_tr = impute_nans(X_tr, feat_mean)\n",
        "            X_va = impute_nans(X_va, feat_mean)\n",
        "            y_tr = impute_nans(y_tr, is_target=True)\n",
        "            y_va = impute_nans(y_va, is_target=True)\n",
        "            \n",
        "            # Escalado\n",
        "            sx = StandardScaler().fit(X_tr.reshape(-1, n_features))\n",
        "            sy = StandardScaler().fit(y_tr.reshape(-1, 1))\n",
        "            \n",
        "            X_tr_sc = sx.transform(X_tr.reshape(-1, n_features)).reshape(X_tr.shape)\n",
        "            X_va_sc = sx.transform(X_va.reshape(-1, n_features)).reshape(X_va.shape)\n",
        "            y_tr_sc = sy.transform(y_tr.reshape(-1, 1)).reshape(y_tr.shape)[..., None]\n",
        "            y_va_sc = sy.transform(y_va.reshape(-1, 1)).reshape(y_va.shape)[..., None]\n",
        "            \n",
        "            # Construir modelo\n",
        "            tag = f\"{exp_name.replace('+', '_')}_{fold_name}\"\n",
        "            model_path = MODEL_DIR / f\"{tag}.keras\"\n",
        "            \n",
        "            if model_path.exists():\n",
        "                print(f\"⏩ Modelo {tag} ya existe → skip\")\n",
        "                continue\n",
        "            \n",
        "            model = builder(\n",
        "                input_window=Config.INPUT_WINDOW,\n",
        "                output_horizon=Config.HORIZON,\n",
        "                spatial_height=lat,\n",
        "                spatial_width=lon,\n",
        "                n_features=n_features,\n",
        "                n_filters=n_filters,\n",
        "                n_heads=n_heads,\n",
        "                lr=Config.LR\n",
        "            )\n",
        "            \n",
        "            # Preparar inputs según el modelo\n",
        "            uses_pe = len(model.inputs) > 1\n",
        "            \n",
        "            if uses_pe:\n",
        "                step_ids_train = np.tile(np.arange(Config.HORIZON), (len(X_tr_sc), 1))\n",
        "                step_ids_val = np.tile(np.arange(Config.HORIZON), (len(X_va_sc), 1))\n",
        "                X_train_input = [X_tr_sc, step_ids_train]\n",
        "                X_val_input = [X_va_sc, step_ids_val]\n",
        "            else:\n",
        "                X_train_input = X_tr_sc\n",
        "                X_val_input = X_va_sc\n",
        "            \n",
        "            # Entrenar\n",
        "            print(\"🏃 Entrenando modelo...\")\n",
        "            es = EarlyStopping(monitor='val_loss', patience=Config.PATIENCE, restore_best_weights=True)\n",
        "            \n",
        "            history = model.fit(\n",
        "                X_train_input, y_tr_sc,\n",
        "                validation_data=(X_val_input, y_va_sc),\n",
        "                epochs=Config.EPOCHS,\n",
        "                batch_size=Config.BATCH_SIZE,\n",
        "                callbacks=[es],\n",
        "                verbose=1\n",
        "            )\n",
        "            \n",
        "            # Guardar modelo\n",
        "            model.save(model_path)\n",
        "            print(f\"💾 Modelo guardado: {model_path.name}\")\n",
        "            \n",
        "            # Visualizar historial\n",
        "            plot_training_history(history, tag, show_in_notebook=show_visualizations)\n",
        "            \n",
        "            # Predicción y evaluación\n",
        "            if uses_pe:\n",
        "                y_hat_sc = model.predict([X_va_sc, step_ids_val], verbose=0)\n",
        "            else:\n",
        "                y_hat_sc = model.predict(X_va_sc, verbose=0)\n",
        "            \n",
        "            y_hat = sy.inverse_transform(y_hat_sc.reshape(-1, 1)).reshape(y_hat_sc.shape)\n",
        "            y_true = sy.inverse_transform(y_va_sc.reshape(-1, 1)).reshape(y_va_sc.shape)\n",
        "            \n",
        "            # Métricas\n",
        "            metrics = evaluate_metrics(y_true.ravel(), y_hat.ravel())\n",
        "            metrics.update({\n",
        "                'experiment': exp_name,\n",
        "                'fold': fold_name,\n",
        "                'epochs': len(history.history['loss'])\n",
        "            })\n",
        "            results.append(metrics)\n",
        "            \n",
        "            print(f\"\\n📈 Métricas: RMSE={metrics['RMSE']:.3f}, MAE={metrics['MAE']:.3f}, \"\n",
        "                  f\"MAPE={metrics['MAPE']:.1f}%, R²={metrics['R2']:.3f}\")\n",
        "            \n",
        "            # Verificar variación entre horizontes\n",
        "            print(\"\\n🔍 Verificación de predicciones por horizonte:\")\n",
        "            predictions_vary = False\n",
        "            \n",
        "            for h in range(Config.HORIZON):\n",
        "                pred_h = y_hat[0, h, ..., 0]\n",
        "                stats = {\n",
        "                    'min': pred_h.min(),\n",
        "                    'max': pred_h.max(),\n",
        "                    'mean': pred_h.mean(),\n",
        "                    'std': pred_h.std()\n",
        "                }\n",
        "                print(f\"  H{h+1}: min={stats['min']:.3f}, max={stats['max']:.3f}, \"\n",
        "                      f\"mean={stats['mean']:.3f}, std={stats['std']:.3f}\")\n",
        "                \n",
        "                if h > 0:\n",
        "                    diff = np.abs(y_hat[0, h] - y_hat[0, 0]).mean()\n",
        "                    if diff > 0.001:\n",
        "                        predictions_vary = True\n",
        "            \n",
        "            if not predictions_vary and Config.HORIZON > 1:\n",
        "                print(\"⚠️ ADVERTENCIA: Las predicciones parecen idénticas entre horizontes\")\n",
        "            else:\n",
        "                print(\"✅ Las predicciones varían correctamente entre horizontes\")\n",
        "            \n",
        "            # Generar GIF\n",
        "            last_idx = min(len(y_hat) - 1, 10)\n",
        "            generate_and_display_gif(y_true[last_idx], y_hat[last_idx], tag, \n",
        "                                   show_in_notebook=show_visualizations)\n",
        "    \n",
        "    # Guardar resultados\n",
        "    if results:\n",
        "        df_results = pd.DataFrame(results)\n",
        "        csv_path = MODEL_DIR / \"metrics_experiments.csv\"\n",
        "        df_results.to_csv(csv_path, index=False)\n",
        "        print(f\"\\n📊 Métricas guardadas en: {csv_path}\")\n",
        "        \n",
        "        # Mostrar resumen\n",
        "        print(\"\\n📋 Resumen de resultados:\")\n",
        "        display(df_results[['experiment', 'fold', 'RMSE', 'MAE', 'MAPE', 'R2']].round(3))\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Ejecutar experimentos\n",
        "print(\"🚀 Iniciando experimentos...\\n\")\n",
        "results = run_experiments(show_visualizations=True)\n",
        "# ╰────────────────────────────────────────────────────────────╯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ╭────────────────────── EVALUACIÓN DE MODELOS GUARDADOS ──────────────────╮\n",
        "\n",
        "def evaluate_saved_models(show_visualizations=True):\n",
        "    \"\"\"Evalúa todos los modelos guardados\"\"\"\n",
        "    print(\"\\n🔍 Evaluando modelos guardados...\\n\")\n",
        "    \n",
        "    all_metrics = []\n",
        "    times = pd.to_datetime(ds.time.values)\n",
        "    \n",
        "    # Custom objects para cargar modelos\n",
        "    custom_objects = {'tile_step_emb': tile_step_emb}\n",
        "    \n",
        "    for model_path in sorted(MODEL_DIR.glob(\"*.keras\")):\n",
        "        tag = model_path.stem\n",
        "        parts = tag.split(\"_\")\n",
        "        fold = parts[-1]\n",
        "        exp_name = \"_\".join(parts[:-1]).replace(\"_\", \"-\")\n",
        "        \n",
        "        if exp_name not in EXPERIMENTS:\n",
        "            print(f\"⚠️ Experimento no encontrado para {tag}\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\n📊 Evaluando: {tag}\")\n",
        "        \n",
        "        # Cargar features\n",
        "        feature_list = EXPERIMENTS[exp_name]['feature_list']\n",
        "        Xarr = ds[feature_list].to_array().transpose('time', 'latitude', 'longitude', 'variable').values.astype(np.float32)\n",
        "        yarr = ds[Config.TARGET_VAR].values.astype(np.float32)\n",
        "        T, _, _, F = Xarr.shape\n",
        "        \n",
        "        # Ventana final para evaluación\n",
        "        start = T - Config.INPUT_WINDOW - Config.HORIZON\n",
        "        end_w = start + Config.INPUT_WINDOW\n",
        "        end_y = end_w + Config.HORIZON\n",
        "        \n",
        "        X_eval = Xarr[start:end_w]\n",
        "        y_eval = yarr[end_w:end_y]\n",
        "        \n",
        "        # Escalado\n",
        "        sx = StandardScaler().fit(Xarr.reshape(-1, F))\n",
        "        sy = StandardScaler().fit(yarr.reshape(-1, 1))\n",
        "        \n",
        "        Xe_sc = sx.transform(X_eval.reshape(-1, F)).reshape(1, Config.INPUT_WINDOW, lat, lon, F)\n",
        "        \n",
        "        # Cargar modelo\n",
        "        model = tf.keras.models.load_model(model_path, compile=False, custom_objects=custom_objects)\n",
        "        \n",
        "        # Predicción\n",
        "        uses_pe = len(model.inputs) > 1\n",
        "        if uses_pe:\n",
        "            step_ids_eval = np.tile(np.arange(Config.HORIZON), (1, 1))\n",
        "            yhat_sc = model.predict([Xe_sc, step_ids_eval], verbose=0)\n",
        "        else:\n",
        "            yhat_sc = model.predict(Xe_sc, verbose=0)\n",
        "        \n",
        "        yhat = sy.inverse_transform(yhat_sc.reshape(-1, 1)).reshape(Config.HORIZON, lat, lon)\n",
        "        \n",
        "        # Métricas por horizonte\n",
        "        for h in range(Config.HORIZON):\n",
        "            yt = y_eval[h].ravel()\n",
        "            yp = yhat[h].ravel()\n",
        "            \n",
        "            # Filtrar NaN/Inf\n",
        "            mask = np.isfinite(yt) & np.isfinite(yp)\n",
        "            if mask.sum() == 0:\n",
        "                continue\n",
        "            \n",
        "            yt, yp = yt[mask], yp[mask]\n",
        "            \n",
        "            metrics = evaluate_metrics(yt, yp)\n",
        "            metrics.update({\n",
        "                'model': tag,\n",
        "                'experiment': exp_name,\n",
        "                'fold': fold,\n",
        "                'horizon': h + 1\n",
        "            })\n",
        "            all_metrics.append(metrics)\n",
        "        \n",
        "        # Visualización comparativa\n",
        "        if show_visualizations:\n",
        "            fig, axes = plt.subplots(Config.HORIZON, 3, figsize=(15, 5 * Config.HORIZON),\n",
        "                                   subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "            \n",
        "            if Config.HORIZON == 1:\n",
        "                axes = axes.reshape(1, -1)\n",
        "            \n",
        "            dates = pd.date_range(times[end_w], periods=Config.HORIZON, freq='MS')\n",
        "            vmin, vmax = 0, max(yhat.max(), y_eval.max())\n",
        "            \n",
        "            for h in range(Config.HORIZON):\n",
        "                # Real\n",
        "                quick_plot(axes[h, 0], y_eval[h], 'Blues', f\"Real H{h+1}\",\n",
        "                          dates[h].strftime('%Y-%m'), vmin, vmax)\n",
        "                \n",
        "                # Predicción\n",
        "                quick_plot(axes[h, 1], yhat[h], 'Blues', f\"Pred H{h+1}\",\n",
        "                          dates[h].strftime('%Y-%m'), vmin, vmax)\n",
        "                \n",
        "                # Error MAPE\n",
        "                err = np.clip(np.abs((y_eval[h] - yhat[h]) / (y_eval[h] + 1e-5)) * 100, 0, 100)\n",
        "                quick_plot(axes[h, 2], err, 'Reds', f\"MAPE% H{h+1}\",\n",
        "                          dates[h].strftime('%Y-%m'), 0, 100)\n",
        "            \n",
        "            fig.suptitle(f\"{tag} - Evaluación Final\", fontsize=16)\n",
        "            fig.tight_layout()\n",
        "            \n",
        "            # Guardar y mostrar\n",
        "            eval_img_path = MODEL_DIR / f\"eval_{tag}.png\"\n",
        "            fig.savefig(eval_img_path, dpi=150, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            \n",
        "            # Generar GIF de predicciones\n",
        "            generate_and_display_gif(y_eval, yhat[:, :, :, np.newaxis], f\"eval_{tag}\",\n",
        "                                   show_in_notebook=True)\n",
        "    \n",
        "    # Guardar métricas\n",
        "    if all_metrics:\n",
        "        df_metrics = pd.DataFrame(all_metrics)\n",
        "        csv_path = MODEL_DIR / 'metrics_evaluation.csv'\n",
        "        df_metrics.to_csv(csv_path, index=False)\n",
        "        print(f\"\\n📊 Métricas de evaluación guardadas en: {csv_path}\")\n",
        "        \n",
        "        # Mostrar resumen por modelo\n",
        "        print(\"\\n📋 Resumen de evaluación:\")\n",
        "        summary = df_metrics.groupby('model')[['RMSE', 'MAE', 'MAPE', 'R2']].mean().round(3)\n",
        "        display(summary)\n",
        "    \n",
        "    return df_metrics\n",
        "\n",
        "# Ejecutar evaluación\n",
        "df_evaluation = evaluate_saved_models(show_visualizations=True)\n",
        "# ╰────────────────────────────────────────────────────────────╯\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Resumen\n",
        "\n",
        "Este notebook refactorizado ha:\n",
        "\n",
        "1. **Eliminado código duplicado**: Funciones unificadas para plotting, evaluación y procesamiento\n",
        "2. **Mejorado la visualización**: Las imágenes y GIFs se guardan Y se muestran en el notebook\n",
        "3. **Centralizado la configuración**: Clase Config con todos los hiperparámetros\n",
        "4. **Añadido verificaciones**: Detección de predicciones idénticas entre horizontes\n",
        "5. **Mejorado la documentación**: Comentarios claros y estructura organizada\n",
        "\n",
        "### 🎯 Próximos pasos:\n",
        "- Experimentar con diferentes arquitecturas\n",
        "- Ajustar hiperparámetros\n",
        "- Añadir más métricas de evaluación\n",
        "- Implementar visualizaciones adicionales\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
