{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/feature%2Fbase-models/models/base_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "635dc005",
      "metadata": {
        "id": "635dc005"
      },
      "outputs": [],
      "source": [
        "# Configuración del entorno (compatible con Colab y local)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "# Detectar si estamos en Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Si estamos en Colab, clonar el repositorio\n",
        "    !git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
        "    %cd ml_precipitation_prediction\n",
        "    # Instalar dependencias necesarias\n",
        "    !pip install -r requirements.txt\n",
        "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn\n",
        "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
        "else:\n",
        "    # Si estamos en local, usar la ruta actual\n",
        "    if '/models' in os.getcwd():\n",
        "        BASE_PATH = Path('..')\n",
        "    else:\n",
        "        BASE_PATH = Path('.')\n",
        "\n",
        "print(f\"Entorno configurado. Usando ruta base: {BASE_PATH}\")\n",
        "\n",
        "# Si BASE_PATH viene como string, lo convertimos\n",
        "BASE_PATH = Path(BASE_PATH)\n",
        "\n",
        "# Ahora puedes concatenar correctamente\n",
        "data_output_dir = BASE_PATH / 'data' / 'output'\n",
        "model_output_dir = BASE_PATH / 'models' / 'output'\n",
        "model_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Directorio para salida de modelos creado: {model_output_dir}\")\n",
        "\n",
        "# Implementación de resiliencia para interacción con Google Drive y restauración de datos\n",
        "def backup_dataframe(df, backup_path):\n",
        "    \"\"\"Guarda un DataFrame como respaldo en formato Parquet.\"\"\"\n",
        "    try:\n",
        "        df.to_parquet(backup_path, index=False)\n",
        "        print(f\"Respaldo del DataFrame guardado en: {backup_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al guardar respaldo del DataFrame: {e}\")\n",
        "\n",
        "def restore_dataframe(backup_path):\n",
        "    \"\"\"Restaura un DataFrame desde un archivo de respaldo en formato Parquet.\"\"\"\n",
        "    try:\n",
        "        if backup_path.exists():\n",
        "            df_restored = pd.read_parquet(backup_path)\n",
        "            print(f\"DataFrame restaurado desde: {backup_path}\")\n",
        "            return df_restored\n",
        "        else:\n",
        "            print(f\"No se encontró el archivo de respaldo en: {backup_path}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error al restaurar el DataFrame: {e}\")\n",
        "        return None\n",
        "\n",
        "# Ruta para respaldo temporal del DataFrame\n",
        "temp_dir = BASE_PATH / 'data' / 'output' / 'temp'\n",
        "temp_dir.mkdir(parents=True, exist_ok=True)\n",
        "temp_file_path = temp_dir / 'dataframe_backup.parquet'\n",
        "\n",
        "# Respaldo inicial del DataFrame principal\n",
        "if 'df' in locals() and df is not None:\n",
        "    backup_dataframe(df, temp_file_path)\n",
        "\n",
        "# Modificar interacción con Google Drive para reintentos\n",
        "max_retries = 3\n",
        "retry_delay = 5  # segundos\n",
        "\n",
        "def mount_google_drive():\n",
        "    \"\"\"Intenta montar Google Drive con reintentos.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"Google Drive montado exitosamente.\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error al montar Google Drive (intento {attempt + 1}/{max_retries}): {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(retry_delay)\n",
        "    print(\"No se pudo montar Google Drive después de varios intentos.\")\n",
        "    return False\n",
        "\n",
        "if IN_COLAB:\n",
        "    if not mount_google_drive():\n",
        "        print(\"Usando datos en memoria o restaurando desde respaldo local.\")\n",
        "        df = restore_dataframe(temp_file_path)\n",
        "\n",
        "# Restaurar modelos guardados en caso de fallo\n",
        "model_files = {\n",
        "    'RandomForest': model_output_dir / 'RandomForest.pkl',\n",
        "    'XGBoost': model_output_dir / 'XGBoost.pkl',\n",
        "    'LightGBM': model_output_dir / 'LightGBM.pkl'\n",
        "}\n",
        "\n",
        "def load_saved_model(model_name, model_path):\n",
        "    \"\"\"Carga un modelo guardado desde disco.\"\"\"\n",
        "    try:\n",
        "        with open(model_path, 'rb') as f:\n",
        "            model = pickle.load(f)\n",
        "            print(f\"Modelo {model_name} cargado desde: {model_path}\")\n",
        "            return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar el modelo {model_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Inicializar `modelos_base` como un diccionario vacío\n",
        "modelos_base = {}\n",
        "\n",
        "# Intentar cargar modelos guardados\n",
        "for model_name, model_path in model_files.items():\n",
        "    if model_name not in modelos_base:\n",
        "        modelos_base[model_name] = load_saved_model(model_name, model_path)\n",
        "\n",
        "# Implementación de resiliencia para modelos CNN y ConvLSTM\n",
        "\n",
        "# Respaldo y restauración de modelos CNN y ConvLSTM\n",
        "cnn_model_path = model_output_dir / 'cnn_model.h5'\n",
        "convlstm_model_path = model_output_dir / 'convlstm_model.h5'\n",
        "\n",
        "def backup_model(model, model_path):\n",
        "    \"\"\"Guarda un modelo de Keras como respaldo.\"\"\"\n",
        "    try:\n",
        "        model.save(model_path)\n",
        "        print(f\"Modelo respaldado en: {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al guardar respaldo del modelo: {e}\")\n",
        "\n",
        "def restore_model(model_path):\n",
        "    \"\"\"Restaura un modelo de Keras desde un archivo de respaldo.\"\"\"\n",
        "    try:\n",
        "        if model_path.exists():\n",
        "            model = tf.keras.models.load_model(model_path)\n",
        "            print(f\"Modelo restaurado desde: {model_path}\")\n",
        "            return model\n",
        "        else:\n",
        "            print(f\"No se encontró el archivo de respaldo en: {model_path}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error al restaurar el modelo: {e}\")\n",
        "        return None\n",
        "\n",
        "# Respaldo inicial de modelos si existen\n",
        "if 'cnn_model' in locals() and cnn_model is not None:\n",
        "    backup_model(cnn_model, cnn_model_path)\n",
        "if 'convlstm_model' in locals() and convlstm_model is not None:\n",
        "    backup_model(convlstm_model, convlstm_model_path)\n",
        "\n",
        "# Restaurar modelos en caso de fallo\n",
        "if 'cnn_model' not in locals() or cnn_model is None:\n",
        "    cnn_model = restore_model(cnn_model_path)\n",
        "if 'convlstm_model' not in locals() or convlstm_model is None:\n",
        "    convlstm_model = restore_model(convlstm_model_path)\n",
        "\n",
        "# Modificar interacción con Google Drive para reintentos\n",
        "max_retries = 3\n",
        "retry_delay = 5  # segundos\n",
        "\n",
        "def mount_google_drive():\n",
        "    \"\"\"Intenta montar Google Drive con reintentos.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"Google Drive montado exitosamente.\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error al montar Google Drive (intento {attempt + 1}/{max_retries}): {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(retry_delay)\n",
        "    print(\"No se pudo montar Google Drive después de varios intentos.\")\n",
        "    return False\n",
        "\n",
        "if IN_COLAB:\n",
        "    if not mount_google_drive():\n",
        "        print(\"Usando datos en memoria o restaurando desde respaldo local para modelos CNN y ConvLSTM.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60cdb3b1",
      "metadata": {
        "id": "60cdb3b1"
      },
      "outputs": [],
      "source": [
        "# 1. Importaciones necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import optuna\n",
        "import pickle\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Importaciones para barras de progreso y mejora de visualización\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import time\n",
        "\n",
        "# Configurar visualización más atractiva\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_context(\"notebook\", font_scale=1.2)\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8ccc04",
      "metadata": {
        "id": "7f8ccc04",
        "outputId": "cad3c1a6-8488-42ea-c20b-1f9451a80691",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔️ Dataset cargado desde: /content/drive/MyDrive/ml_precipitation_prediction/data/output/complete_dataset_with_features_with_clusters_elevation.nc\n",
            "\n",
            "🚀 Ejecutando experimento: precip+time\n",
            "\t🏗️ Entrenando modelo LSTM...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 7ms/step - loss: 15573.6006 - val_loss: 10470.9414\n",
            "Epoch 2/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 7ms/step - loss: 10482.1719 - val_loss: 10482.6914\n",
            "Epoch 3/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 7ms/step - loss: 10444.9043 - val_loss: 10510.0811\n",
            "Epoch 4/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 7ms/step - loss: 10478.2305 - val_loss: 10474.4268\n",
            "Epoch 5/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 8ms/step - loss: 10465.0820 - val_loss: 10471.7578\n",
            "Epoch 6/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 8ms/step - loss: 10487.4619 - val_loss: 10472.5469\n",
            "Epoch 7/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 8ms/step - loss: 10478.0820 - val_loss: 10492.5840\n",
            "Epoch 8/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 8ms/step - loss: 10477.7432 - val_loss: 10476.4365\n",
            "Epoch 9/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 8ms/step - loss: 10454.3994 - val_loss: 10474.0977\n",
            "Epoch 10/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 8ms/step - loss: 10493.9746 - val_loss: 10480.3799\n",
            "Epoch 11/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 8ms/step - loss: 10471.1611 - val_loss: 10497.4775\n",
            "\u001b[1m13134/13134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step\n",
            "\t✅ LSTM -> RMSE: 102.246, MAE: 79.840, MAPE: 1537619.75%, R²: 0.332\n",
            "\t🏗️ Entrenando modelo GRU...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 8ms/step - loss: 15481.3652 - val_loss: 10474.9951\n",
            "Epoch 2/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 8ms/step - loss: 10484.7236 - val_loss: 10473.6943\n",
            "Epoch 3/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 8ms/step - loss: 10486.7979 - val_loss: 10470.1777\n",
            "Epoch 4/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 8ms/step - loss: 10467.8867 - val_loss: 10466.8398\n",
            "Epoch 5/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 8ms/step - loss: 10471.9482 - val_loss: 10467.0967\n",
            "Epoch 6/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 8ms/step - loss: 10453.0225 - val_loss: 10466.8906\n",
            "Epoch 7/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 8ms/step - loss: 10468.4893 - val_loss: 10466.3555\n",
            "Epoch 8/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 8ms/step - loss: 10491.4902 - val_loss: 10462.7080\n",
            "Epoch 9/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 8ms/step - loss: 10457.5908 - val_loss: 10457.3730\n",
            "Epoch 10/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 8ms/step - loss: 10455.7285 - val_loss: 10463.6875\n",
            "Epoch 11/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 8ms/step - loss: 10465.8418 - val_loss: 10455.8486\n",
            "Epoch 12/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 8ms/step - loss: 10461.0186 - val_loss: 10448.7793\n",
            "Epoch 13/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 8ms/step - loss: 10458.7842 - val_loss: 10465.5977\n",
            "Epoch 14/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 8ms/step - loss: 10472.7188 - val_loss: 10448.7490\n",
            "Epoch 15/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 8ms/step - loss: 10480.9590 - val_loss: 10452.5840\n",
            "Epoch 16/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 9ms/step - loss: 10439.3643 - val_loss: 10440.6143\n",
            "Epoch 17/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 8ms/step - loss: 10463.0947 - val_loss: 10438.9277\n",
            "Epoch 18/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 8ms/step - loss: 10444.8838 - val_loss: 10442.7334\n",
            "Epoch 19/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 8ms/step - loss: 10465.8506 - val_loss: 10443.0508\n",
            "Epoch 20/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 8ms/step - loss: 10435.8096 - val_loss: 10442.9590\n",
            "Epoch 21/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 8ms/step - loss: 10432.8457 - val_loss: 10449.2285\n",
            "Epoch 22/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 8ms/step - loss: 10457.2900 - val_loss: 10439.7959\n",
            "Epoch 23/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 9ms/step - loss: 10429.2764 - val_loss: 10439.3760\n",
            "Epoch 24/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 8ms/step - loss: 10445.1025 - val_loss: 10444.6572\n",
            "Epoch 25/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 8ms/step - loss: 10451.6777 - val_loss: 10449.4795\n",
            "Epoch 26/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 8ms/step - loss: 10445.1494 - val_loss: 10437.0723\n",
            "Epoch 27/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 8ms/step - loss: 10404.6670 - val_loss: 10439.4795\n",
            "Epoch 28/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 8ms/step - loss: 10430.2041 - val_loss: 10443.6729\n",
            "Epoch 29/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 8ms/step - loss: 10444.9902 - val_loss: 10445.6006\n",
            "Epoch 30/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 8ms/step - loss: 10445.6240 - val_loss: 10441.7109\n",
            "Epoch 31/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 8ms/step - loss: 10436.5273 - val_loss: 10442.1113\n",
            "Epoch 32/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 8ms/step - loss: 10462.3418 - val_loss: 10438.0605\n",
            "Epoch 33/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 8ms/step - loss: 10441.8037 - val_loss: 10438.8584\n",
            "Epoch 34/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 9ms/step - loss: 10450.1504 - val_loss: 10444.0869\n",
            "Epoch 35/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 8ms/step - loss: 10427.1396 - val_loss: 10439.1416\n",
            "Epoch 36/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 8ms/step - loss: 10478.7021 - val_loss: 10440.9707\n",
            "\u001b[1m13134/13134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step\n",
            "\t✅ GRU -> RMSE: 102.077, MAE: 79.766, MAPE: 1568469.12%, R²: 0.334\n",
            "\t🏗️ Entrenando modelo BLSTM...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 8ms/step - loss: 13293.0840 - val_loss: 10482.6797\n",
            "Epoch 2/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 8ms/step - loss: 10472.0654 - val_loss: 10466.9697\n",
            "Epoch 3/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 8ms/step - loss: 10444.4287 - val_loss: 10468.5791\n",
            "Epoch 4/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 8ms/step - loss: 10469.4473 - val_loss: 10468.4736\n",
            "Epoch 5/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 8ms/step - loss: 10456.3633 - val_loss: 10466.6924\n",
            "Epoch 6/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 8ms/step - loss: 10440.4873 - val_loss: 10466.2842\n",
            "Epoch 7/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 8ms/step - loss: 10498.3652 - val_loss: 10463.0576\n",
            "Epoch 8/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 8ms/step - loss: 10447.0508 - val_loss: 10467.2012\n",
            "Epoch 9/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 8ms/step - loss: 10454.5322 - val_loss: 10484.5674\n",
            "Epoch 10/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 8ms/step - loss: 10469.9365 - val_loss: 10466.1846\n",
            "Epoch 11/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 8ms/step - loss: 10455.5674 - val_loss: 10478.8672\n",
            "Epoch 12/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 8ms/step - loss: 10446.5410 - val_loss: 10468.3711\n",
            "Epoch 13/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 8ms/step - loss: 10453.7627 - val_loss: 10453.4844\n",
            "Epoch 14/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 8ms/step - loss: 10460.6367 - val_loss: 10454.7236\n",
            "Epoch 15/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 8ms/step - loss: 10467.9512 - val_loss: 10444.0801\n",
            "Epoch 16/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 8ms/step - loss: 10452.8525 - val_loss: 10445.9902\n",
            "Epoch 17/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 8ms/step - loss: 10461.4443 - val_loss: 10440.8252\n",
            "Epoch 18/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 8ms/step - loss: 10440.3486 - val_loss: 10451.0908\n",
            "Epoch 19/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 8ms/step - loss: 10454.3418 - val_loss: 10442.6973\n",
            "Epoch 20/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 8ms/step - loss: 10432.8057 - val_loss: 10440.2080\n",
            "Epoch 21/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 8ms/step - loss: 10445.9922 - val_loss: 10439.6777\n",
            "Epoch 22/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 8ms/step - loss: 10419.9863 - val_loss: 10439.3340\n",
            "Epoch 23/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 8ms/step - loss: 10434.3174 - val_loss: 10439.4785\n",
            "Epoch 24/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 8ms/step - loss: 10441.9102 - val_loss: 10437.4189\n",
            "Epoch 25/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 8ms/step - loss: 10464.2793 - val_loss: 10450.1865\n",
            "Epoch 26/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 8ms/step - loss: 10463.9902 - val_loss: 10437.2900\n",
            "Epoch 27/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 8ms/step - loss: 10415.6240 - val_loss: 10443.0518\n",
            "Epoch 28/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 8ms/step - loss: 10460.1904 - val_loss: 10441.7891\n",
            "Epoch 29/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 8ms/step - loss: 10454.7969 - val_loss: 10442.7646\n",
            "Epoch 30/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 8ms/step - loss: 10454.4873 - val_loss: 10470.0977\n",
            "Epoch 31/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 9ms/step - loss: 10429.2363 - val_loss: 10439.5156\n",
            "Epoch 32/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 8ms/step - loss: 10472.1123 - val_loss: 10435.7646\n",
            "Epoch 33/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 8ms/step - loss: 10422.8350 - val_loss: 10437.9033\n",
            "Epoch 34/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 8ms/step - loss: 10442.9316 - val_loss: 10437.2822\n",
            "Epoch 35/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 8ms/step - loss: 10456.1992 - val_loss: 10440.9014\n",
            "Epoch 36/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 8ms/step - loss: 10452.3047 - val_loss: 10442.1045\n",
            "Epoch 37/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 8ms/step - loss: 10467.7363 - val_loss: 10441.0215\n",
            "Epoch 38/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 8ms/step - loss: 10435.6777 - val_loss: 10434.6260\n",
            "Epoch 39/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 8ms/step - loss: 10455.0576 - val_loss: 10438.3682\n",
            "Epoch 40/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 8ms/step - loss: 10450.0117 - val_loss: 10436.5312\n",
            "Epoch 41/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 8ms/step - loss: 10458.2832 - val_loss: 10435.7256\n",
            "Epoch 42/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 8ms/step - loss: 10450.3115 - val_loss: 10436.1475\n",
            "Epoch 43/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 8ms/step - loss: 10434.8799 - val_loss: 10436.2627\n",
            "Epoch 44/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 8ms/step - loss: 10420.6758 - val_loss: 10435.4521\n",
            "Epoch 45/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 8ms/step - loss: 10412.0674 - val_loss: 10450.9521\n",
            "Epoch 46/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 8ms/step - loss: 10459.7607 - val_loss: 10435.5117\n",
            "Epoch 47/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 8ms/step - loss: 10442.4258 - val_loss: 10436.7715\n",
            "Epoch 48/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 8ms/step - loss: 10446.5459 - val_loss: 10435.6289\n",
            "\u001b[1m13134/13134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step\n",
            "\t✅ BLSTM -> RMSE: 102.068, MAE: 79.754, MAPE: 1556555.00%, R²: 0.334\n",
            "\t🏗️ Entrenando modelo CNN...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 3ms/step - loss: 11912.6494 - val_loss: 10555.7471\n",
            "Epoch 2/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - loss: 10556.7314 - val_loss: 10495.3965\n",
            "Epoch 3/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - loss: 10489.4551 - val_loss: 10481.2920\n",
            "Epoch 4/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3ms/step - loss: 10480.6504 - val_loss: 10474.6514\n",
            "Epoch 5/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3ms/step - loss: 10499.0068 - val_loss: 10473.0049\n",
            "Epoch 6/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 3ms/step - loss: 10491.9453 - val_loss: 10485.2070\n",
            "Epoch 7/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 3ms/step - loss: 10465.7480 - val_loss: 10470.0898\n",
            "Epoch 8/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - loss: 10462.7900 - val_loss: 10475.0400\n",
            "Epoch 9/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - loss: 10495.2529 - val_loss: 10489.5811\n",
            "Epoch 10/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3ms/step - loss: 10473.9424 - val_loss: 10470.6475\n",
            "Epoch 11/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10450.8418 - val_loss: 10473.7520\n",
            "Epoch 12/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 3ms/step - loss: 10473.1611 - val_loss: 10474.1357\n",
            "Epoch 13/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10502.3525 - val_loss: 10482.2314\n",
            "Epoch 14/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10477.6289 - val_loss: 10473.7979\n",
            "Epoch 15/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - loss: 10483.8594 - val_loss: 10469.1777\n",
            "Epoch 16/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3ms/step - loss: 10451.1885 - val_loss: 10502.6182\n",
            "Epoch 17/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - loss: 10498.9893 - val_loss: 10467.7314\n",
            "Epoch 18/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 3ms/step - loss: 10469.9355 - val_loss: 10465.8184\n",
            "Epoch 19/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10485.2305 - val_loss: 10465.0430\n",
            "Epoch 20/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - loss: 10463.2490 - val_loss: 10465.0518\n",
            "Epoch 21/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - loss: 10482.0488 - val_loss: 10465.7246\n",
            "Epoch 22/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10467.0771 - val_loss: 10474.0342\n",
            "Epoch 23/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10469.5801 - val_loss: 10462.4727\n",
            "Epoch 24/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10476.6973 - val_loss: 10461.9688\n",
            "Epoch 25/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 4ms/step - loss: 10462.7803 - val_loss: 10467.1348\n",
            "Epoch 26/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 3ms/step - loss: 10454.1641 - val_loss: 10496.1406\n",
            "Epoch 27/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3ms/step - loss: 10452.7275 - val_loss: 10460.9023\n",
            "Epoch 28/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3ms/step - loss: 10473.1309 - val_loss: 10463.1855\n",
            "Epoch 29/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3ms/step - loss: 10474.1270 - val_loss: 10479.3633\n",
            "Epoch 30/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 3ms/step - loss: 10484.8232 - val_loss: 10460.8291\n",
            "Epoch 31/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 3ms/step - loss: 10480.7881 - val_loss: 10458.7900\n",
            "Epoch 32/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 3ms/step - loss: 10473.5488 - val_loss: 10459.1250\n",
            "Epoch 33/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - loss: 10474.6250 - val_loss: 10469.6436\n",
            "Epoch 34/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10449.9961 - val_loss: 10459.0947\n",
            "Epoch 35/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 3ms/step - loss: 10456.5781 - val_loss: 10458.9805\n",
            "Epoch 36/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - loss: 10471.1875 - val_loss: 10462.2578\n",
            "Epoch 37/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3ms/step - loss: 10458.8594 - val_loss: 10459.9824\n",
            "Epoch 38/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 3ms/step - loss: 10468.1777 - val_loss: 10461.3535\n",
            "Epoch 39/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3ms/step - loss: 10479.7568 - val_loss: 10461.0039\n",
            "Epoch 40/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3ms/step - loss: 10449.5117 - val_loss: 10466.3701\n",
            "Epoch 41/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - loss: 10467.9316 - val_loss: 10473.7812\n",
            "\u001b[1m13134/13134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step\n",
            "\t✅ CNN -> RMSE: 102.190, MAE: 79.978, MAPE: 1582344.38%, R²: 0.333\n",
            "\n",
            "🚀 Ejecutando experimento: precip+time+elev\n",
            "\t🏗️ Entrenando modelo LSTM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 8ms/step - loss: 19704.6484 - val_loss: 8517.9912\n",
            "Epoch 2/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 8ms/step - loss: 8136.3984 - val_loss: 7286.7954\n",
            "Epoch 3/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 8ms/step - loss: 7425.9297 - val_loss: 7895.3003\n",
            "Epoch 4/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 8ms/step - loss: 7238.7827 - val_loss: 6824.1514\n",
            "Epoch 5/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 8ms/step - loss: 6907.7339 - val_loss: 6682.5112\n",
            "Epoch 6/50\n",
            "\u001b[1m42029/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 8ms/step - loss: 6917.1748 - val_loss: 6669.1782\n",
            "Epoch 7/50\n",
            "\u001b[1m42023/42029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6801.5972"
          ]
        }
      ],
      "source": [
        "# ST-HybridWaveStack - Evaluación comparativa de configuraciones\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, GRU, Bidirectional, Reshape\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Funciones auxiliares\n",
        "def create_sequences(X, y, window=12):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - window):\n",
        "        X_seq.append(X[i:i+window])\n",
        "        y_seq.append(y[i+window])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "def build_model(model_type, input_shape, output_neurons):\n",
        "    model = Sequential()\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(64, input_shape=input_shape))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(64, input_shape=input_shape))\n",
        "    elif model_type == 'BLSTM':\n",
        "        model.add(Bidirectional(LSTM(64), input_shape=input_shape))\n",
        "    elif model_type == 'CNN':\n",
        "        model.add(Reshape((*input_shape, 1), input_shape=input_shape))\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "    model.add(Dense(output_neurons))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return rmse, mae, mape, r2\n",
        "\n",
        "# Ruta del archivo\n",
        "try:\n",
        "    file_path = data_output_dir / \"complete_dataset_with_features_with_clusters_elevation.nc\"\n",
        "    ds = xr.open_dataset(file_path)\n",
        "    print(f\"✔️ Dataset cargado desde: {file_path}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Error cargando dataset: {e}\")\n",
        "\n",
        "# Configuraciones del experimento\n",
        "experiment_settings = {\n",
        "    \"precip+time\": ['month_sin', 'month_cos'],\n",
        "    \"precip+time+elev\": ['month_sin', 'month_cos', 'elevation', 'slope', 'aspect'],\n",
        "    \"all_features\": ['month_sin', 'month_cos', 'elevation', 'slope', 'aspect', 'cluster_elevation']\n",
        "}\n",
        "\n",
        "results = {\n",
        "    'experiment': [],\n",
        "    'model': [],\n",
        "    'RMSE': [],\n",
        "    'MAE': [],\n",
        "    'MAPE': [],\n",
        "    'R2': []\n",
        "}\n",
        "\n",
        "for exp_name, variables in experiment_settings.items():\n",
        "    print(f\"\\n🚀 Ejecutando experimento: {exp_name}\")\n",
        "\n",
        "    try:\n",
        "        cluster_elevation_index = variables.index('cluster_elevation') if 'cluster_elevation' in variables else None\n",
        "        subset_array = ds[variables].to_array().transpose('time', 'latitude', 'longitude', 'variable')\n",
        "        subset_np = subset_array.values\n",
        "\n",
        "        if cluster_elevation_index is not None:\n",
        "            cluster_data = subset_np[..., cluster_elevation_index]\n",
        "            encoded = LabelEncoder().fit_transform(cluster_data.ravel()).reshape(cluster_data.shape)\n",
        "            subset_np[..., cluster_elevation_index] = encoded\n",
        "\n",
        "        subset_np = subset_np.astype(np.float32)\n",
        "        target = ds['total_precipitation'].values\n",
        "\n",
        "        samples, lat, lon, feats = subset_np.shape\n",
        "        X = subset_np.reshape(samples, lat * lon, feats)\n",
        "        y = target.reshape(samples, lat * lon)\n",
        "\n",
        "        mask = ~np.isnan(y)\n",
        "        X = X[mask]\n",
        "        y = y[mask]\n",
        "\n",
        "        X_seq, y_seq = create_sequences(X, y, window=12)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "        X_train_feed = X_train.reshape((X_train.shape[0], X_train.shape[1], -1))\n",
        "        X_test_feed = X_test.reshape((X_test.shape[0], X_test.shape[1], -1))\n",
        "        input_shape = (X_train_feed.shape[1], X_train_feed.shape[2])\n",
        "\n",
        "        for model_name in ['LSTM', 'GRU', 'BLSTM', 'CNN']:\n",
        "            print(f\"\\t🏗️ Entrenando modelo {model_name}...\")\n",
        "            model = build_model(model_name, input_shape, 1)\n",
        "            es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "            model.fit(X_train_feed, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0, callbacks=[es])\n",
        "\n",
        "            y_pred = model.predict(X_test_feed).flatten()\n",
        "            y_true = y_test.flatten()\n",
        "\n",
        "            rmse, mae, mape, r2 = evaluate(y_true, y_pred)\n",
        "            results['experiment'].append(exp_name)\n",
        "            results['model'].append(model_name)\n",
        "            results['RMSE'].append(rmse)\n",
        "            results['MAE'].append(mae)\n",
        "            results['MAPE'].append(mape)\n",
        "            results['R2'].append(r2)\n",
        "            print(f\"\\t✅ {model_name} -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, MAPE: {mape:.2f}%, R²: {r2:.3f}\")\n",
        "\n",
        "    except Exception as err:\n",
        "        print(f\"❌ Error en experimento '{exp_name}': {err}\")\n",
        "\n",
        "# Mostrar resultados finales\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='RMSE')\n",
        "results_df.to_csv('resultados_comparativos_modelos.csv', index=False)\n",
        "print(\"\\n📊 Resultados finales ordenados por RMSE:\")\n",
        "print(results_df)\n",
        "results_df\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "precipitation_prediction",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}