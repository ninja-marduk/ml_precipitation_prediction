{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4e7925",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/main/models/base_models_STHyMOUNTAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3744f4",
   "metadata": {
    "id": "af3744f4"
   },
   "source": [
    "# 📘 Entrenamiento de Modelos Baseline para Predicción Espaciotemporal de Precipitación Mensual STHyMOUNTAIN\n",
    "\n",
    "Este notebook implementa modelos baseline para la predicción de precipitaciones usando datos espaciotemporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994be36",
   "metadata": {},
   "source": [
    "## 🔍 Implementación de Modelos Avanzados y Técnicas de Validación\n",
    "\n",
    "Además de los modelos tabulares baseline, implementaremos:\n",
    "\n",
    "1. **Optimización avanzada con Optuna** para los modelos tabulares XGBoost y LightGBM\n",
    "2. **Validación robusta** mediante:\n",
    "   - Hold-Out Validation (ya implementada)\n",
    "   - Cross-Validation (k=5)\n",
    "   - Bootstrapping (100 muestras)\n",
    "3. **Modelos de Deep Learning** para capturar patrones espaciales y temporales:\n",
    "   - Redes CNN para patrones espaciales\n",
    "   - Redes ConvLSTM para patrones espaciotemporales\n",
    "\n",
    "El objetivo es proporcionar una evaluación completa de diferentes enfoques de modelado para la predicción de precipitación en regiones montañosas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06416284",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06416284",
    "outputId": "a8e4c864-34e9-41b2-d5c3-e6ccaaf3699e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno configurado. Usando ruta base: ..\n",
      "Directorio para salida de modelos creado: ../models/output\n",
      "Respaldo del DataFrame guardado en: ../data/output/temp/dataframe_backup.parquet\n",
      "Respaldo del DataFrame guardado en: ../data/output/temp/dataframe_backup.parquet\n",
      "Modelo RandomForest cargado desde: ../models/output/RandomForest.pkl\n",
      "Modelo XGBoost cargado desde: ../models/output/XGBoost.pkl\n",
      "Modelo LightGBM cargado desde: ../models/output/LightGBM.pkl\n",
      "No se encontró el archivo de respaldo en: ../models/output/cnn_model.h5\n",
      "No se encontró el archivo de respaldo en: ../models/output/convlstm_model.h5\n",
      "Modelo RandomForest cargado desde: ../models/output/RandomForest.pkl\n",
      "Modelo XGBoost cargado desde: ../models/output/XGBoost.pkl\n",
      "Modelo LightGBM cargado desde: ../models/output/LightGBM.pkl\n",
      "No se encontró el archivo de respaldo en: ../models/output/cnn_model.h5\n",
      "No se encontró el archivo de respaldo en: ../models/output/convlstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Configuración del entorno (compatible con Colab y local)\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Detectar si estamos en Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')   \n",
    "    # Si estamos en Colab, clonar el repositorio\n",
    "    !git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
    "    %cd ml_precipitation_prediction\n",
    "    # Instalar dependencias necesarias\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn\n",
    "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
    "else:\n",
    "    # Si estamos en local, usar la ruta actual\n",
    "    if '/models' in os.getcwd():\n",
    "        BASE_PATH = Path('..')\n",
    "    else:\n",
    "        BASE_PATH = Path('.')\n",
    "\n",
    "print(f\"Entorno configurado. Usando ruta base: {BASE_PATH}\")\n",
    "\n",
    "# Si BASE_PATH viene como string, lo convertimos\n",
    "BASE_PATH = Path(BASE_PATH)\n",
    "\n",
    "# Ahora puedes concatenar correctamente\n",
    "model_output_dir = BASE_PATH / 'models' / 'output'\n",
    "model_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directorio para salida de modelos creado: {model_output_dir}\")\n",
    "\n",
    "# Implementación de resiliencia para interacción con Google Drive y restauración de datos\n",
    "def backup_dataframe(df, backup_path):\n",
    "    \"\"\"Guarda un DataFrame como respaldo en formato Parquet.\"\"\"\n",
    "    try:\n",
    "        df.to_parquet(backup_path, index=False)\n",
    "        print(f\"Respaldo del DataFrame guardado en: {backup_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar respaldo del DataFrame: {e}\")\n",
    "\n",
    "def restore_dataframe(backup_path):\n",
    "    \"\"\"Restaura un DataFrame desde un archivo de respaldo en formato Parquet.\"\"\"\n",
    "    try:\n",
    "        if backup_path.exists():\n",
    "            df_restored = pd.read_parquet(backup_path)\n",
    "            print(f\"DataFrame restaurado desde: {backup_path}\")\n",
    "            return df_restored\n",
    "        else:\n",
    "            print(f\"No se encontró el archivo de respaldo en: {backup_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al restaurar el DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ruta para respaldo temporal del DataFrame\n",
    "temp_dir = BASE_PATH / 'data' / 'output' / 'temp'\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "temp_file_path = temp_dir / 'dataframe_backup.parquet'\n",
    "\n",
    "# Respaldo inicial del DataFrame principal\n",
    "if 'df' in locals() and df is not None:\n",
    "    backup_dataframe(df, temp_file_path)\n",
    "\n",
    "# Modificar interacción con Google Drive para reintentos\n",
    "max_retries = 3\n",
    "retry_delay = 5  # segundos\n",
    "\n",
    "def mount_google_drive():\n",
    "    \"\"\"Intenta montar Google Drive con reintentos.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"Google Drive montado exitosamente.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error al montar Google Drive (intento {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "    print(\"No se pudo montar Google Drive después de varios intentos.\")\n",
    "    return False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not mount_google_drive():\n",
    "        print(\"Usando datos en memoria o restaurando desde respaldo local.\")\n",
    "        df = restore_dataframe(temp_file_path)\n",
    "\n",
    "# Restaurar modelos guardados en caso de fallo\n",
    "model_files = {\n",
    "    'RandomForest': model_output_dir / 'RandomForest.pkl',\n",
    "    'XGBoost': model_output_dir / 'XGBoost.pkl',\n",
    "    'LightGBM': model_output_dir / 'LightGBM.pkl'\n",
    "}\n",
    "\n",
    "def load_saved_model(model_name, model_path):\n",
    "    \"\"\"Carga un modelo guardado desde disco.\"\"\"\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "            print(f\"Modelo {model_name} cargado desde: {model_path}\")\n",
    "            return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Inicializar `modelos_base` como un diccionario vacío\n",
    "modelos_base = {}\n",
    "\n",
    "# Intentar cargar modelos guardados\n",
    "for model_name, model_path in model_files.items():\n",
    "    if model_name not in modelos_base:\n",
    "        modelos_base[model_name] = load_saved_model(model_name, model_path)\n",
    "\n",
    "# Implementación de resiliencia para modelos CNN y ConvLSTM\n",
    "\n",
    "# Respaldo y restauración de modelos CNN y ConvLSTM\n",
    "cnn_model_path = model_output_dir / 'cnn_model.h5'\n",
    "convlstm_model_path = model_output_dir / 'convlstm_model.h5'\n",
    "\n",
    "def backup_model(model, model_path):\n",
    "    \"\"\"Guarda un modelo de Keras como respaldo.\"\"\"\n",
    "    try:\n",
    "        model.save(model_path)\n",
    "        print(f\"Modelo respaldado en: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar respaldo del modelo: {e}\")\n",
    "\n",
    "def restore_model(model_path):\n",
    "    \"\"\"Restaura un modelo de Keras desde un archivo de respaldo.\"\"\"\n",
    "    try:\n",
    "        if model_path.exists():\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"Modelo restaurado desde: {model_path}\")\n",
    "            return model\n",
    "        else:\n",
    "            print(f\"No se encontró el archivo de respaldo en: {model_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al restaurar el modelo: {e}\")\n",
    "        return None\n",
    "\n",
    "# Respaldo inicial de modelos si existen\n",
    "if 'cnn_model' in locals() and cnn_model is not None:\n",
    "    backup_model(cnn_model, cnn_model_path)\n",
    "if 'convlstm_model' in locals() and convlstm_model is not None:\n",
    "    backup_model(convlstm_model, convlstm_model_path)\n",
    "\n",
    "# Restaurar modelos en caso de fallo\n",
    "if 'cnn_model' not in locals() or cnn_model is None:\n",
    "    cnn_model = restore_model(cnn_model_path)\n",
    "if 'convlstm_model' not in locals() or convlstm_model is None:\n",
    "    convlstm_model = restore_model(convlstm_model_path)\n",
    "\n",
    "# Modificar interacción con Google Drive para reintentos\n",
    "max_retries = 3\n",
    "retry_delay = 5  # segundos\n",
    "\n",
    "def mount_google_drive():\n",
    "    \"\"\"Intenta montar Google Drive con reintentos.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"Google Drive montado exitosamente.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error al montar Google Drive (intento {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "    print(\"No se pudo montar Google Drive después de varios intentos.\")\n",
    "    return False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not mount_google_drive():\n",
    "        print(\"Usando datos en memoria o restaurando desde respaldo local para modelos CNN y ConvLSTM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47fb555",
   "metadata": {
    "id": "e47fb555"
   },
   "outputs": [],
   "source": [
    "# 1. Importaciones necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import optuna\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importaciones para barras de progreso y mejora de visualización\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import time\n",
    "\n",
    "# Configurar visualización más atractiva\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313434be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow versión: 2.18.0\n",
      "No se detectó GPU. Usando CPU.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones adicionales para Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, save_model, load_model\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Conv2D, Conv3D, ConvLSTM2D, BatchNormalization, \n",
    "                                   MaxPooling2D, Flatten, Input, concatenate, Reshape, TimeDistributed, UpSampling2D)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"TensorFlow versión:\", tf.__version__)\n",
    "\n",
    "# Configurar GPU si está disponible\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(f\"GPU disponible: {physical_devices}\")\n",
    "    # Permitir crecimiento de memoria según sea necesario\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    print(\"No se detectó GPU. Usando CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26215d90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "26215d90",
    "outputId": "ccb06926-e151-453f-a306-999f15566bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando archivo en: ../data/output/complete_dataset_with_features.nc\n",
      "Intentando cargar el archivo: ../data/output/complete_dataset_with_features.nc\n",
      "Archivo cargado exitosamente con xarray\n",
      "\n",
      "Información del dataset:\n",
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\ttime = 530 ;\n",
      "\tlatitude = 62 ;\n",
      "\tlongitude = 66 ;\n",
      "\n",
      "variables:\n",
      "\tdatetime64[ns] time(time) ;\n",
      "\tfloat32 latitude(latitude) ;\n",
      "\tfloat32 longitude(longitude) ;\n",
      "\tfloat32 total_precipitation(time, latitude, longitude) ;\n",
      "\tfloat32 max_daily_precipitation(time, latitude, longitude) ;\n",
      "\tfloat32 min_daily_precipitation(time, latitude, longitude) ;\n",
      "\tfloat32 daily_precipitation_std(time, latitude, longitude) ;\n",
      "\tfloat32 month_sin(time, latitude, longitude) ;\n",
      "\tfloat32 month_cos(time, latitude, longitude) ;\n",
      "\tfloat32 doy_sin(time, latitude, longitude) ;\n",
      "\tfloat32 doy_cos(time, latitude, longitude) ;\n",
      "\tfloat64 elevation(latitude, longitude) ;\n",
      "\tfloat32 slope(latitude, longitude) ;\n",
      "\tfloat32 aspect(latitude, longitude) ;\n",
      "\n",
      "// global attributes:\n",
      "\t:description = ST-HyMOUNTAIN-Net ready dataset with CHIRPS monthly precipitation and DEM variables ;\n",
      "\t:source = CHIRPS v2.0 & DEM Boyacá ;\n",
      "\t:created_at = 2025-04-27 19:02:24 ;\n",
      "}None\n",
      "\n",
      "Variables disponibles:\n",
      "- total_precipitation: (530, 62, 66)\n",
      "- max_daily_precipitation: (530, 62, 66)\n",
      "- min_daily_precipitation: (530, 62, 66)\n",
      "- daily_precipitation_std: (530, 62, 66)\n",
      "- month_sin: (530, 62, 66)\n",
      "- month_cos: (530, 62, 66)\n",
      "- doy_sin: (530, 62, 66)\n",
      "- doy_cos: (530, 62, 66)\n",
      "- elevation: (62, 66)\n",
      "- slope: (62, 66)\n",
      "- aspect: (62, 66)\n",
      "Dataset cargado con éxito. Dimensiones: (2168760, 14)\n",
      "\n",
      "Primeras filas del DataFrame:\n",
      "Dataset cargado con éxito. Dimensiones: (2168760, 14)\n",
      "\n",
      "Primeras filas del DataFrame:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "latitude",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "longitude",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "total_precipitation",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "max_daily_precipitation",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "min_daily_precipitation",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "daily_precipitation_std",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "month_sin",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "month_cos",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "doy_sin",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "doy_cos",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "elevation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "slope",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "aspect",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e8e9d7e7-1c3a-445f-a507-801b8f8555b6",
       "rows": [
        [
         "0",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.975006",
         "47.38105",
         "24.706928",
         "0.0",
         "5.8257756",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "493.78455182073014",
         "89.53955",
         "102.0445"
        ],
        [
         "1",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.925",
         "40.750824",
         "21.819195",
         "0.0",
         "5.0190454",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "519.7501066909579",
         "89.86702",
         "73.481674"
        ],
        [
         "2",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.87501",
         "46.338623",
         "26.092327",
         "0.0",
         "5.7402234",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "248.7760453427361",
         "89.72222",
         "65.91682"
        ],
        [
         "3",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.825005",
         "48.779938",
         "29.42145",
         "0.0",
         "5.611738",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "351.4157280671193",
         "86.98613",
         "140.916"
        ],
        [
         "4",
         "1981-01-01 00:00:00",
         "4.324997",
         "-74.775",
         "38.932945",
         "18.48306",
         "0.0",
         "3.7335742",
         "0.5",
         "0.8660254",
         "0.017201575",
         "0.99985206",
         "278.2619223660964",
         "88.27329",
         "18.43994"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>max_daily_precipitation</th>\n",
       "      <th>min_daily_precipitation</th>\n",
       "      <th>daily_precipitation_std</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slope</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.975006</td>\n",
       "      <td>47.381050</td>\n",
       "      <td>24.706928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.825776</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>493.784552</td>\n",
       "      <td>89.539551</td>\n",
       "      <td>102.044502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.925003</td>\n",
       "      <td>40.750824</td>\n",
       "      <td>21.819195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.019045</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>519.750107</td>\n",
       "      <td>89.867020</td>\n",
       "      <td>73.481674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.875008</td>\n",
       "      <td>46.338623</td>\n",
       "      <td>26.092327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.740223</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>248.776045</td>\n",
       "      <td>89.722221</td>\n",
       "      <td>65.916817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.825005</td>\n",
       "      <td>48.779938</td>\n",
       "      <td>29.421450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.611738</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>351.415728</td>\n",
       "      <td>86.986130</td>\n",
       "      <td>140.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>4.324997</td>\n",
       "      <td>-74.775002</td>\n",
       "      <td>38.932945</td>\n",
       "      <td>18.483061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.733574</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>278.261922</td>\n",
       "      <td>88.273293</td>\n",
       "      <td>18.439939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  latitude  longitude  total_precipitation  \\\n",
       "0 1981-01-01  4.324997 -74.975006            47.381050   \n",
       "1 1981-01-01  4.324997 -74.925003            40.750824   \n",
       "2 1981-01-01  4.324997 -74.875008            46.338623   \n",
       "3 1981-01-01  4.324997 -74.825005            48.779938   \n",
       "4 1981-01-01  4.324997 -74.775002            38.932945   \n",
       "\n",
       "   max_daily_precipitation  min_daily_precipitation  daily_precipitation_std  \\\n",
       "0                24.706928                      0.0                 5.825776   \n",
       "1                21.819195                      0.0                 5.019045   \n",
       "2                26.092327                      0.0                 5.740223   \n",
       "3                29.421450                      0.0                 5.611738   \n",
       "4                18.483061                      0.0                 3.733574   \n",
       "\n",
       "   month_sin  month_cos   doy_sin   doy_cos   elevation      slope      aspect  \n",
       "0        0.5   0.866025  0.017202  0.999852  493.784552  89.539551  102.044502  \n",
       "1        0.5   0.866025  0.017202  0.999852  519.750107  89.867020   73.481674  \n",
       "2        0.5   0.866025  0.017202  0.999852  248.776045  89.722221   65.916817  \n",
       "3        0.5   0.866025  0.017202  0.999852  351.415728  86.986130  140.916000  \n",
       "4        0.5   0.866025  0.017202  0.999852  278.261922  88.273293   18.439939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Cargar el dataset NetCDF\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Carga un archivo NetCDF y lo convierte a pandas DataFrame\"\"\"\n",
    "    try:\n",
    "        # Cargar el archivo NetCDF con xarray\n",
    "        print(f\"Intentando cargar el archivo: {file_path}\")\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        print(\"Archivo cargado exitosamente con xarray\")\n",
    "\n",
    "        # Mostrar información del dataset cargado\n",
    "        print(\"\\nInformación del dataset:\")\n",
    "        print(ds.info())\n",
    "        print(\"\\nVariables disponibles:\")\n",
    "        for var_name in ds.data_vars:\n",
    "            print(f\"- {var_name}: {ds[var_name].shape}\")\n",
    "\n",
    "        # Convertir a DataFrame\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "        return df, ds\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el archivo NetCDF: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Ruta al dataset\n",
    "data_file = BASE_PATH / 'data' / 'output' / 'complete_dataset_with_features.nc'\n",
    "print(f\"Buscando archivo en: {data_file}\")\n",
    "\n",
    "# Cargar el dataset\n",
    "df, ds_original = load_dataset(data_file)\n",
    "\n",
    "# Verificar si se cargó correctamente\n",
    "if df is not None:\n",
    "    print(f\"Dataset cargado con éxito. Dimensiones: {df.shape}\")\n",
    "    print(\"\\nPrimeras filas del DataFrame:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No se pudo cargar el dataset. Verificar la ruta y el formato del archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f0aebbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f0aebbc",
    "outputId": "48e82987-ff47-41e8-9f40-57e53cf90cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna objetivo identificada: total_precipitation\n",
      "Filas antes de eliminar NaN: 2168760\n",
      "Filas después de eliminar NaN: 2168760\n",
      "\n",
      "Features seleccionadas (12):\n",
      "['latitude', 'longitude', 'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos', 'elevation', 'slope', 'aspect']\n",
      "\n",
      "Variable objetivo: total_precipitation\n",
      "\n",
      "Features seleccionadas (12):\n",
      "['latitude', 'longitude', 'max_daily_precipitation', 'min_daily_precipitation', 'daily_precipitation_std', 'month_sin', 'month_cos', 'doy_sin', 'doy_cos', 'elevation', 'slope', 'aspect']\n",
      "\n",
      "Variable objetivo: total_precipitation\n"
     ]
    }
   ],
   "source": [
    "# 3. Preparación de los datos\n",
    "if df is not None:\n",
    "    # Identificar la columna objetivo (precipitación)\n",
    "    target_column = 'total_precipitation'  # Ajustar si tiene otro nombre en tu dataset\n",
    "\n",
    "    # Ver si existe 'precip_target' o usar 'total_precipitation'\n",
    "    if 'total_precipitation' in df.columns:\n",
    "        target_column = 'total_precipitation'\n",
    "\n",
    "    print(f\"Columna objetivo identificada: {target_column}\")\n",
    "\n",
    "    # Separar variables predictoras y variable objetivo\n",
    "    feature_cols = [col for col in df.columns if col != target_column and not pd.isna(df[col]).all()]\n",
    "\n",
    "    # Eliminar columnas no numéricas para los modelos (como fechas o coordenadas si no se usan como features)\n",
    "    non_feature_cols = ['time', 'spatial_ref']\n",
    "    feature_cols = [col for col in feature_cols if col not in non_feature_cols]\n",
    "\n",
    "    # Eliminar filas con valores NaN\n",
    "    print(f\"Filas antes de eliminar NaN: {df.shape[0]}\")\n",
    "    df_clean = df.dropna(subset=[target_column] + feature_cols)\n",
    "    print(f\"Filas después de eliminar NaN: {df_clean.shape[0]}\")\n",
    "\n",
    "    # Separar features y target\n",
    "    X = df_clean[feature_cols]\n",
    "    y = df_clean[target_column]\n",
    "\n",
    "    print(f\"\\nFeatures seleccionadas ({len(feature_cols)}):\\n{feature_cols}\")\n",
    "    print(f\"\\nVariable objetivo: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da222af5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da222af5",
    "outputId": "579fbd57-a790-42dd-807a-e61fc1daacbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del conjunto de entrenamiento: (1735008, 12)\n",
      "Dimensiones del conjunto de prueba: (433752, 12)\n",
      "Escalador guardado en models/output/scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# 4. División del conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dimensiones del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba: {X_test.shape}\")\n",
    "\n",
    "# 5. Estandarización de variables predictoras\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Guardar el scaler para uso futuro\n",
    "with open(model_output_dir / 'scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Escalador guardado en models/output/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5ba053b",
   "metadata": {
    "id": "c5ba053b"
   },
   "outputs": [],
   "source": [
    "# 6. Funciones de evaluación y entrenamiento\n",
    "def evaluar_modelo(y_true, y_pred):\n",
    "    \"\"\"Evalúa el rendimiento de un modelo usando múltiples métricas\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "def entrenar_y_evaluar_modelo(modelo, nombre, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Entrena un modelo y evalúa su rendimiento con visualización del progreso\"\"\"\n",
    "    # Crear widget para mostrar información del proceso\n",
    "    display(HTML(f'<div style=\"background-color:#f0f8ff; padding:10px; border-radius:5px;\">' +\n",
    "                 f'<h3>🔄 Entrenando modelo: {nombre}</h3>' +\n",
    "                 f'<div id=\"status_{nombre}\">Estado: Iniciando entrenamiento...</div>' +\n",
    "                 f'</div>'))\n",
    "    \n",
    "    # Tiempo de inicio\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Entrenar el modelo con seguimiento visual según el tipo\n",
    "    if hasattr(modelo, 'fit_generator') or nombre in ['XGBoost', 'XGBoost_Optuna', 'LightGBM', 'LightGBM_Optuna']:\n",
    "        # Para modelos que soportan entrenamiento por lotes como XGBoost, LightGBM\n",
    "        print(f\"Entrenando {nombre} con visualización de progreso...\")\n",
    "        if hasattr(modelo, 'n_estimators'):\n",
    "            n_estimators = modelo.n_estimators\n",
    "            for i in tqdm(range(n_estimators), desc=f\"Entrenando {nombre}\"):\n",
    "                if i == 0:\n",
    "                    # Primera iteración, ajuste inicial\n",
    "                    if nombre.startswith('LightGBM'):\n",
    "                        # LightGBM tiene parámetro verbose\n",
    "                        temp_modelo = type(modelo)(n_estimators=1, **{k:v for k,v in modelo.get_params().items() \n",
    "                                                                 if k != 'n_estimators' and k != 'verbose'}, verbose=-1)\n",
    "                    else:\n",
    "                        temp_modelo = type(modelo)(n_estimators=1, **{k:v for k,v in modelo.get_params().items() \n",
    "                                                                if k != 'n_estimators'})\n",
    "                    temp_modelo.fit(X_train, y_train)\n",
    "                elif i == n_estimators - 1:\n",
    "                    # Última iteración, ajuste completo\n",
    "                    modelo.fit(X_train, y_train)\n",
    "                \n",
    "                # Actualizar progreso visual\n",
    "                if i % max(1, n_estimators // 10) == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    display(HTML(f'<div style=\"background-color:#f0f8ff; padding:10px; border-radius:5px;\">' +\n",
    "                                f'<h3>🔄 Entrenando modelo: {nombre}</h3>' +\n",
    "                                f'<div id=\"status_{nombre}\">Estado: Progreso {i+1}/{n_estimators} estimadores ({((i+1)/n_estimators*100):.1f}%)</div>' +\n",
    "                                f'</div>'))\n",
    "                    time.sleep(0.1)  # Pequeña pausa para actualización visual\n",
    "        else:\n",
    "            # Si no tiene n_estimators, entrenamiento directo\n",
    "            modelo.fit(X_train, y_train)\n",
    "    else:\n",
    "        # Para modelos estándar como RandomForest\n",
    "        modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Tiempo de entrenamiento\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Visualizar tiempo de entrenamiento\n",
    "    display(HTML(f'<div style=\"background-color:#e6ffe6; padding:10px; border-radius:5px;\">' +\n",
    "                f'<h3>✅ Entrenamiento completado: {nombre}</h3>' +\n",
    "                f'<div>Tiempo de entrenamiento: {training_time:.2f} segundos</div>' +\n",
    "                f'</div>'))\n",
    "    \n",
    "    print(f\"Evaluando rendimiento de {nombre}...\")\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    rmse, mae, r2 = evaluar_modelo(y_test, predicciones)\n",
    "    \n",
    "    # Visualizar métricas con estilo\n",
    "    display(HTML(f'<div style=\"background-color:#f5f5dc; padding:10px; border-radius:5px; margin-top:10px;\">' +\n",
    "                f'<h3>📊 Métricas para {nombre}</h3>' +\n",
    "                f'<table style=\"width:100%; text-align:left;\">' +\n",
    "                f'<tr><th>Métrica</th><th>Valor</th></tr>' +\n",
    "                f'<tr><td>RMSE</td><td>{rmse:.4f}</td></tr>' +\n",
    "                f'<tr><td>MAE</td><td>{mae:.4f}</td></tr>' +\n",
    "                f'<tr><td>R²</td><td>{r2:.4f}</td></tr>' +\n",
    "                f'</table></div>'))\n",
    "    \n",
    "    return modelo, (rmse, mae, r2)\n",
    "\n",
    "def guardar_modelo(modelo, nombre):\n",
    "    \"\"\"Guarda un modelo entrenado en disco\"\"\"\n",
    "    # timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # filename = f\"{nombre}_{timestamp}.pkl\"\n",
    "    filename = f\"{nombre}.pkl\"\n",
    "    with open(model_output_dir / filename, 'wb') as f:\n",
    "        pickle.dump(modelo, f)\n",
    "    \n",
    "    # Visualizar confirmación de guardado\n",
    "    display(HTML(f'<div style=\"background-color:#e6ffee; padding:10px; border-radius:5px; margin-top:10px;\">' +\n",
    "                f'<h3>💾 Modelo guardado</h3>' +\n",
    "                f'<div>Modelo <b>{nombre}</b> guardado como: {filename}</div>' +\n",
    "                f'</div>'))\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e59f9865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo RandomForest encontrado en ../models/output/RandomForest.pkl. Cargando...\n",
      "✅ RandomForest evaluado: RMSE=36.4174, MAE=24.8917, R2=0.9168\n",
      "Modelo XGBoost encontrado en ../models/output/XGBoost.pkl. Cargando...\n",
      "✅ XGBoost evaluado: RMSE=37.8542, MAE=26.3499, R2=0.9101\n",
      "Modelo LightGBM encontrado en ../models/output/LightGBM.pkl. Cargando...\n",
      "✅ RandomForest evaluado: RMSE=36.4174, MAE=24.8917, R2=0.9168\n",
      "Modelo XGBoost encontrado en ../models/output/XGBoost.pkl. Cargando...\n",
      "✅ XGBoost evaluado: RMSE=37.8542, MAE=26.3499, R2=0.9101\n",
      "Modelo LightGBM encontrado en ../models/output/LightGBM.pkl. Cargando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LightGBM evaluado: RMSE=39.0589, MAE=27.3338, R2=0.9043\n",
      "\n",
      "🔍 Comparación de modelos base sin optimización:\n",
      "\n",
      "Ordenados por RMSE (menor es mejor):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "695dee79-49a8-453a-bac6-d40d137882d3",
       "rows": [
        [
         "RandomForest",
         "36.41736289362402",
         "24.891714593345927",
         "0.9167978029821752"
        ],
        [
         "XGBoost",
         "37.85420285553673",
         "26.349937438964844",
         "0.9101028442382812"
        ],
        [
         "LightGBM",
         "39.058929036670044",
         "27.333847085632623",
         "0.9042897459778831"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>36.417363</td>\n",
       "      <td>24.891715</td>\n",
       "      <td>0.916798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>37.854203</td>\n",
       "      <td>26.349937</td>\n",
       "      <td>0.910103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>39.058929</td>\n",
       "      <td>27.333847</td>\n",
       "      <td>0.904290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RMSE        MAE        R2\n",
       "RandomForest  36.417363  24.891715  0.916798\n",
       "XGBoost       37.854203  26.349937  0.910103\n",
       "LightGBM      39.058929  27.333847  0.904290"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/c6n8lktn4qx_fwp7ksllkkhn0dhtn2/T/ipykernel_41954/2491721647.py:68: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=temp_df.index, y=temp_df['RMSE'], palette='coolwarm')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🔁 1. Importaciones necesarias\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "# ⚙️ 2. Diccionarios de almacenamiento\n",
    "resultados_base = {}\n",
    "modelos_base = {}\n",
    "modelos_guardados = {}\n",
    "\n",
    "# 📁 3. Rutas de modelos guardados\n",
    "cnn_model_path = model_output_dir / 'cnn_model.h5'\n",
    "convlstm_model_path = model_output_dir / 'convlstm_model.h5'\n",
    "\n",
    "model_paths = {\n",
    "    'RandomForest': model_output_dir / 'RandomForest.pkl',\n",
    "    'XGBoost': model_output_dir / 'XGBoost.pkl',\n",
    "    'LightGBM': model_output_dir / 'LightGBM.pkl',\n",
    "    'CNN': cnn_model_path,\n",
    "    'ConvLSTM': convlstm_model_path\n",
    "}\n",
    "\n",
    "# ✅ 4. Carga y evaluación de modelos\n",
    "for model_name, model_path in model_paths.items():\n",
    "    if model_path.exists():\n",
    "        print(f\"Modelo {model_name} encontrado en {model_path}. Cargando...\")\n",
    "        if model_name in ['RandomForest', 'XGBoost', 'LightGBM']:\n",
    "            with open(model_path, 'rb') as f:\n",
    "                modelo = pickle.load(f)\n",
    "                modelos_base[model_name] = modelo\n",
    "                y_pred = modelo.predict(X_test_scaled)\n",
    "        elif model_name == 'CNN':\n",
    "            cnn_model = tf.keras.models.load_model(model_path)\n",
    "            print(\"✅ CNN cargado.\")\n",
    "            y_pred = cnn_model.predict(X_test_spatial).squeeze()\n",
    "        elif model_name == 'ConvLSTM':\n",
    "            convlstm_model = tf.keras.models.load_model(model_path)\n",
    "            print(\"✅ ConvLSTM cargado.\")\n",
    "            y_pred = convlstm_model.predict(X_test_spatial).squeeze()\n",
    "\n",
    "        # Evaluar métricas si hay predicción\n",
    "        if 'y_pred' in locals():\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            resultados_base[model_name] = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "            print(f\"✅ {model_name} evaluado: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}\")\n",
    "            del y_pred\n",
    "\n",
    "# 📊 5. Visualización de resultados\n",
    "print(\"\\n🔍 Comparación de modelos base sin optimización:\")\n",
    "temp_df = pd.DataFrame(resultados_base, index=['RMSE', 'MAE', 'R2']).T\n",
    "\n",
    "# Mostrar tabla ordenada por RMSE\n",
    "print(\"\\nOrdenados por RMSE (menor es mejor):\")\n",
    "display(temp_df.sort_values('RMSE'))\n",
    "\n",
    "# Gráfico de comparación de RMSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=temp_df.index, y=temp_df['RMSE'], palette='coolwarm')\n",
    "plt.title('Comparación de RMSE - Modelos Base')\n",
    "plt.ylabel('RMSE (menor es mejor)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_output_dir / 'baseline_rmse_comparison_full.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:33:02,783] Using an existing study with name 'RandomForest_memory_optimized' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Ejecutando optimización para RandomForest...\n",
      "\n",
      "📊 Iniciando optimización adaptativa para RandomForest...\n",
      "Memoria RAM disponible: 2.68 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:34:17,036] Trial 71 finished with value: 43.0440408355221 and parameters: {'n_estimators': 236, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:35:50,192] Trial 72 finished with value: 41.654383989762835 and parameters: {'n_estimators': 283, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:35:50,192] Trial 72 finished with value: 41.654383989762835 and parameters: {'n_estimators': 283, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:36:53,665] Trial 73 finished with value: 51.355881691959375 and parameters: {'n_estimators': 278, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:36:53,665] Trial 73 finished with value: 51.355881691959375 and parameters: {'n_estimators': 278, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 66 with value: 41.650861342260036.\n",
      "[I 2025-04-29 16:38:23,684] Trial 74 finished with value: 41.64597096124543 and parameters: {'n_estimators': 273, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:38:23,684] Trial 74 finished with value: 41.64597096124543 and parameters: {'n_estimators': 273, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [RandomForest] Trials completados: 75/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:39:47,962] Trial 75 finished with value: 41.64772576154432 and parameters: {'n_estimators': 275, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:41:15,145] Trial 76 finished with value: 41.691880166992064 and parameters: {'n_estimators': 286, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:41:15,145] Trial 76 finished with value: 41.691880166992064 and parameters: {'n_estimators': 286, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:42:31,968] Trial 77 finished with value: 43.00608196630091 and parameters: {'n_estimators': 265, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:42:31,968] Trial 77 finished with value: 43.00608196630091 and parameters: {'n_estimators': 265, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:44:06,046] Trial 78 finished with value: 41.66513065078071 and parameters: {'n_estimators': 297, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:44:06,046] Trial 78 finished with value: 41.66513065078071 and parameters: {'n_estimators': 297, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:45:32,614] Trial 79 finished with value: 41.64772576154432 and parameters: {'n_estimators': 275, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:45:32,614] Trial 79 finished with value: 41.64772576154432 and parameters: {'n_estimators': 275, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [RandomForest] Trials completados: 80/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:46:54,227] Trial 80 finished with value: 43.04835989883482 and parameters: {'n_estimators': 282, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:48:19,357] Trial 81 finished with value: 41.69681251087568 and parameters: {'n_estimators': 270, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:48:19,357] Trial 81 finished with value: 41.69681251087568 and parameters: {'n_estimators': 270, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:49:30,819] Trial 82 finished with value: 43.030839861369635 and parameters: {'n_estimators': 250, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:49:30,819] Trial 82 finished with value: 43.030839861369635 and parameters: {'n_estimators': 250, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:50:57,558] Trial 83 finished with value: 41.68708476506717 and parameters: {'n_estimators': 292, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:50:57,558] Trial 83 finished with value: 41.68708476506717 and parameters: {'n_estimators': 292, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:52:15,295] Trial 84 finished with value: 42.975176982972094 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n",
      "[I 2025-04-29 16:52:15,295] Trial 84 finished with value: 42.975176982972094 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 74 with value: 41.64597096124543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [RandomForest] Trials completados: 85/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 16:53:36,052] Trial 85 finished with value: 41.630928646181296 and parameters: {'n_estimators': 265, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:54:56,438] Trial 86 finished with value: 41.63236035252783 and parameters: {'n_estimators': 262, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:54:56,438] Trial 86 finished with value: 41.63236035252783 and parameters: {'n_estimators': 262, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:56:17,515] Trial 87 finished with value: 41.63168439572765 and parameters: {'n_estimators': 267, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:56:17,515] Trial 87 finished with value: 41.63168439572765 and parameters: {'n_estimators': 267, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 85 with value: 41.630928646181296.\n",
      "[I 2025-04-29 16:57:36,765] Trial 88 finished with value: 41.629667633906514 and parameters: {'n_estimators': 264, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 16:57:36,765] Trial 88 finished with value: 41.629667633906514 and parameters: {'n_estimators': 264, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 16:58:53,547] Trial 89 finished with value: 41.6719194415667 and parameters: {'n_estimators': 255, 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 16:58:53,547] Trial 89 finished with value: 41.6719194415667 and parameters: {'n_estimators': 255, 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [RandomForest] Trials completados: 90/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 17:00:16,124] Trial 90 finished with value: 41.63819224368401 and parameters: {'n_estimators': 271, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:01:52,929] Trial 91 finished with value: 43.02755147184142 and parameters: {'n_estimators': 265, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:01:52,929] Trial 91 finished with value: 43.02755147184142 and parameters: {'n_estimators': 265, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:03:13,422] Trial 92 finished with value: 41.670070498415335 and parameters: {'n_estimators': 269, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:03:13,422] Trial 92 finished with value: 41.670070498415335 and parameters: {'n_estimators': 269, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True}. Best is trial 88 with value: 41.629667633906514.\n",
      "[I 2025-04-29 17:08:03,084] Trial 93 finished with value: 41.09717031410784 and parameters: {'n_estimators': 292, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:08:03,084] Trial 93 finished with value: 41.09717031410784 and parameters: {'n_estimators': 292, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:12:57,181] Trial 94 finished with value: 41.09910965056824 and parameters: {'n_estimators': 291, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:12:57,181] Trial 94 finished with value: 41.09910965056824 and parameters: {'n_estimators': 291, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [RandomForest] Trials completados: 95/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 17:17:53,290] Trial 95 finished with value: 41.09841375209928 and parameters: {'n_estimators': 294, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:22:27,136] Trial 96 finished with value: 42.666457847822166 and parameters: {'n_estimators': 288, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:22:27,136] Trial 96 finished with value: 42.666457847822166 and parameters: {'n_estimators': 288, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:27:18,780] Trial 97 finished with value: 41.09796048819834 and parameters: {'n_estimators': 293, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:27:18,780] Trial 97 finished with value: 41.09796048819834 and parameters: {'n_estimators': 293, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:31:50,234] Trial 98 finished with value: 42.66508732314287 and parameters: {'n_estimators': 291, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:31:50,234] Trial 98 finished with value: 42.66508732314287 and parameters: {'n_estimators': 291, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:36:26,891] Trial 99 finished with value: 42.66425777061779 and parameters: {'n_estimators': 294, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 17:36:26,891] Trial 99 finished with value: 42.66425777061779 and parameters: {'n_estimators': 294, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [RandomForest] Trials completados: 100/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 17:41:09,715] Trial 100 finished with value: 41.10270157234539 and parameters: {'n_estimators': 282, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 93 with value: 41.09717031410784.\n",
      "[I 2025-04-29 18:15:57,855] Using an existing study with name 'XGBoost_memory_optimized' instead of creating a new one.\n",
      "[I 2025-04-29 18:15:57,855] Using an existing study with name 'XGBoost_memory_optimized' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ RandomForest optimizado:\n",
      "RMSE: 41.0972\n",
      "MAE: 28.4235\n",
      "R²: 0.8940\n",
      "\n",
      "🚀 Ejecutando optimización para XGBoost...\n",
      "\n",
      "📊 Iniciando optimización adaptativa para XGBoost...\n",
      "Memoria RAM disponible: 2.98 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:16:04,475] Trial 60 finished with value: 39.350894779177196 and parameters: {'n_estimators': 278, 'max_depth': 4, 'learning_rate': 0.09965645419053396, 'subsample': 0.6711679030463277, 'colsample_bytree': 0.9044181459811054, 'min_child_weight': 3, 'gamma': 2.4751802377230163}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:17,690] Trial 61 finished with value: 35.75791576754806 and parameters: {'n_estimators': 189, 'max_depth': 12, 'learning_rate': 0.05560460746814403, 'subsample': 0.6157528967223698, 'colsample_bytree': 0.9706361090180385, 'min_child_weight': 2, 'gamma': 4.795362732218826}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:17,690] Trial 61 finished with value: 35.75791576754806 and parameters: {'n_estimators': 189, 'max_depth': 12, 'learning_rate': 0.05560460746814403, 'subsample': 0.6157528967223698, 'colsample_bytree': 0.9706361090180385, 'min_child_weight': 2, 'gamma': 4.795362732218826}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:31,165] Trial 62 finished with value: 35.795111943706786 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.06776939940548235, 'subsample': 0.6081970709148381, 'colsample_bytree': 0.9827617835027945, 'min_child_weight': 1, 'gamma': 4.742136855991785}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:31,165] Trial 62 finished with value: 35.795111943706786 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.06776939940548235, 'subsample': 0.6081970709148381, 'colsample_bytree': 0.9827617835027945, 'min_child_weight': 1, 'gamma': 4.742136855991785}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:46,070] Trial 63 finished with value: 35.75274348902735 and parameters: {'n_estimators': 207, 'max_depth': 12, 'learning_rate': 0.04764763125268048, 'subsample': 0.5953512532391368, 'colsample_bytree': 0.9613507776391274, 'min_child_weight': 3, 'gamma': 4.074784414355741}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:46,070] Trial 63 finished with value: 35.75274348902735 and parameters: {'n_estimators': 207, 'max_depth': 12, 'learning_rate': 0.04764763125268048, 'subsample': 0.5953512532391368, 'colsample_bytree': 0.9613507776391274, 'min_child_weight': 3, 'gamma': 4.074784414355741}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:58,667] Trial 64 finished with value: 35.80188235656664 and parameters: {'n_estimators': 185, 'max_depth': 12, 'learning_rate': 0.05965706897677661, 'subsample': 0.5821045739428595, 'colsample_bytree': 0.9328178199742988, 'min_child_weight': 3, 'gamma': 4.991950027088655}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:16:58,667] Trial 64 finished with value: 35.80188235656664 and parameters: {'n_estimators': 185, 'max_depth': 12, 'learning_rate': 0.05965706897677661, 'subsample': 0.5821045739428595, 'colsample_bytree': 0.9328178199742988, 'min_child_weight': 3, 'gamma': 4.991950027088655}. Best is trial 22 with value: 35.711163960942415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [XGBoost] Trials completados: 65/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:17:12,363] Trial 65 finished with value: 35.93389418051657 and parameters: {'n_estimators': 246, 'max_depth': 11, 'learning_rate': 0.042380034888878704, 'subsample': 0.634546770187394, 'colsample_bytree': 0.9868323406552163, 'min_child_weight': 2, 'gamma': 3.529303523512869}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:27,468] Trial 66 finished with value: 35.7568318701563 and parameters: {'n_estimators': 233, 'max_depth': 12, 'learning_rate': 0.05218237651264639, 'subsample': 0.5661149485002318, 'colsample_bytree': 0.9439404052896394, 'min_child_weight': 4, 'gamma': 4.661850070951837}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:27,468] Trial 66 finished with value: 35.7568318701563 and parameters: {'n_estimators': 233, 'max_depth': 12, 'learning_rate': 0.05218237651264639, 'subsample': 0.5661149485002318, 'colsample_bytree': 0.9439404052896394, 'min_child_weight': 4, 'gamma': 4.661850070951837}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:37,743] Trial 67 finished with value: 35.935810082549445 and parameters: {'n_estimators': 178, 'max_depth': 11, 'learning_rate': 0.0725036052194289, 'subsample': 0.665286959871946, 'colsample_bytree': 0.923743547421571, 'min_child_weight': 5, 'gamma': 4.405657774993751}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:37,743] Trial 67 finished with value: 35.935810082549445 and parameters: {'n_estimators': 178, 'max_depth': 11, 'learning_rate': 0.0725036052194289, 'subsample': 0.665286959871946, 'colsample_bytree': 0.923743547421571, 'min_child_weight': 5, 'gamma': 4.405657774993751}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:49,391] Trial 68 finished with value: 35.783349760987825 and parameters: {'n_estimators': 156, 'max_depth': 12, 'learning_rate': 0.06042582462646498, 'subsample': 0.6470507236624621, 'colsample_bytree': 0.9656870757571148, 'min_child_weight': 1, 'gamma': 4.882247254549063}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:17:49,391] Trial 68 finished with value: 35.783349760987825 and parameters: {'n_estimators': 156, 'max_depth': 12, 'learning_rate': 0.06042582462646498, 'subsample': 0.6470507236624621, 'colsample_bytree': 0.9656870757571148, 'min_child_weight': 1, 'gamma': 4.882247254549063}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:02,154] Trial 69 finished with value: 36.20294797917447 and parameters: {'n_estimators': 196, 'max_depth': 11, 'learning_rate': 0.037695739036660555, 'subsample': 0.6545199299049221, 'colsample_bytree': 0.8622852986561991, 'min_child_weight': 2, 'gamma': 3.9140976084054904}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:02,154] Trial 69 finished with value: 36.20294797917447 and parameters: {'n_estimators': 196, 'max_depth': 11, 'learning_rate': 0.037695739036660555, 'subsample': 0.6545199299049221, 'colsample_bytree': 0.8622852986561991, 'min_child_weight': 2, 'gamma': 3.9140976084054904}. Best is trial 22 with value: 35.711163960942415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [XGBoost] Trials completados: 70/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:18:08,251] Trial 70 finished with value: 36.29877006191549 and parameters: {'n_estimators': 60, 'max_depth': 12, 'learning_rate': 0.07978866991243412, 'subsample': 0.6204252253199223, 'colsample_bytree': 0.9458081925372654, 'min_child_weight': 3, 'gamma': 4.230545493841141}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:25,009] Trial 71 finished with value: 35.74243083933558 and parameters: {'n_estimators': 237, 'max_depth': 12, 'learning_rate': 0.04515644294615783, 'subsample': 0.5798589296637613, 'colsample_bytree': 0.9285770570455675, 'min_child_weight': 10, 'gamma': 4.274402251955779}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:25,009] Trial 71 finished with value: 35.74243083933558 and parameters: {'n_estimators': 237, 'max_depth': 12, 'learning_rate': 0.04515644294615783, 'subsample': 0.5798589296637613, 'colsample_bytree': 0.9285770570455675, 'min_child_weight': 10, 'gamma': 4.274402251955779}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:40,230] Trial 72 finished with value: 35.74070266724533 and parameters: {'n_estimators': 221, 'max_depth': 12, 'learning_rate': 0.043439758875546346, 'subsample': 0.5958731143843986, 'colsample_bytree': 0.9997170618607031, 'min_child_weight': 10, 'gamma': 4.466800084999603}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:40,230] Trial 72 finished with value: 35.74070266724533 and parameters: {'n_estimators': 221, 'max_depth': 12, 'learning_rate': 0.043439758875546346, 'subsample': 0.5958731143843986, 'colsample_bytree': 0.9997170618607031, 'min_child_weight': 10, 'gamma': 4.466800084999603}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:56,545] Trial 73 finished with value: 35.728982362559144 and parameters: {'n_estimators': 238, 'max_depth': 12, 'learning_rate': 0.04364595907457629, 'subsample': 0.5908223888396833, 'colsample_bytree': 0.9960436440079988, 'min_child_weight': 10, 'gamma': 3.287696253530477}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:18:56,545] Trial 73 finished with value: 35.728982362559144 and parameters: {'n_estimators': 238, 'max_depth': 12, 'learning_rate': 0.04364595907457629, 'subsample': 0.5908223888396833, 'colsample_bytree': 0.9960436440079988, 'min_child_weight': 10, 'gamma': 3.287696253530477}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:19:10,933] Trial 74 finished with value: 36.33536722165902 and parameters: {'n_estimators': 222, 'max_depth': 11, 'learning_rate': 0.02603524973787783, 'subsample': 0.594055874615617, 'colsample_bytree': 0.9975790178469592, 'min_child_weight': 9, 'gamma': 3.3362307724595763}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:19:10,933] Trial 74 finished with value: 36.33536722165902 and parameters: {'n_estimators': 222, 'max_depth': 11, 'learning_rate': 0.02603524973787783, 'subsample': 0.594055874615617, 'colsample_bytree': 0.9975790178469592, 'min_child_weight': 9, 'gamma': 3.3362307724595763}. Best is trial 22 with value: 35.711163960942415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [XGBoost] Trials completados: 75/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:19:28,279] Trial 75 finished with value: 35.73431863517636 and parameters: {'n_estimators': 248, 'max_depth': 12, 'learning_rate': 0.03550587326367754, 'subsample': 0.5853810740267053, 'colsample_bytree': 0.9848024319125552, 'min_child_weight': 10, 'gamma': 3.2196387008894387}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:19:42,961] Trial 76 finished with value: 36.00257186179985 and parameters: {'n_estimators': 252, 'max_depth': 11, 'learning_rate': 0.034998807001642256, 'subsample': 0.5675217142538795, 'colsample_bytree': 0.9851899024509025, 'min_child_weight': 9, 'gamma': 3.093088683386659}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:19:42,961] Trial 76 finished with value: 36.00257186179985 and parameters: {'n_estimators': 252, 'max_depth': 11, 'learning_rate': 0.034998807001642256, 'subsample': 0.5675217142538795, 'colsample_bytree': 0.9851899024509025, 'min_child_weight': 9, 'gamma': 3.093088683386659}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:03,057] Trial 77 finished with value: 35.78028621791527 and parameters: {'n_estimators': 260, 'max_depth': 12, 'learning_rate': 0.029333135537184613, 'subsample': 0.584998640954983, 'colsample_bytree': 0.9630554414357289, 'min_child_weight': 9, 'gamma': 3.1819780642067585}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:03,057] Trial 77 finished with value: 35.78028621791527 and parameters: {'n_estimators': 260, 'max_depth': 12, 'learning_rate': 0.029333135537184613, 'subsample': 0.584998640954983, 'colsample_bytree': 0.9630554414357289, 'min_child_weight': 9, 'gamma': 3.1819780642067585}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:17,526] Trial 78 finished with value: 35.720880773606176 and parameters: {'n_estimators': 244, 'max_depth': 12, 'learning_rate': 0.06946592839415004, 'subsample': 0.6837612973061943, 'colsample_bytree': 0.951603281558706, 'min_child_weight': 10, 'gamma': 3.6898027690721156}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:17,526] Trial 78 finished with value: 35.720880773606176 and parameters: {'n_estimators': 244, 'max_depth': 12, 'learning_rate': 0.06946592839415004, 'subsample': 0.6837612973061943, 'colsample_bytree': 0.951603281558706, 'min_child_weight': 10, 'gamma': 3.6898027690721156}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:28,340] Trial 79 finished with value: 36.10057091935147 and parameters: {'n_estimators': 228, 'max_depth': 10, 'learning_rate': 0.07113410880752633, 'subsample': 0.684907993984314, 'colsample_bytree': 0.9832355778237944, 'min_child_weight': 10, 'gamma': 3.276513093373638}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:28,340] Trial 79 finished with value: 36.10057091935147 and parameters: {'n_estimators': 228, 'max_depth': 10, 'learning_rate': 0.07113410880752633, 'subsample': 0.684907993984314, 'colsample_bytree': 0.9832355778237944, 'min_child_weight': 10, 'gamma': 3.276513093373638}. Best is trial 22 with value: 35.711163960942415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [XGBoost] Trials completados: 80/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:20:45,812] Trial 80 finished with value: 36.342193176565615 and parameters: {'n_estimators': 246, 'max_depth': 11, 'learning_rate': 0.0222884772088816, 'subsample': 0.6932643683811397, 'colsample_bytree': 0.9526654313936672, 'min_child_weight': 8, 'gamma': 3.6105962388974575}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:58,031] Trial 81 finished with value: 38.18438478240729 and parameters: {'n_estimators': 240, 'max_depth': 12, 'learning_rate': 0.2909337937359037, 'subsample': 0.5878028466351641, 'colsample_bytree': 0.9061703640467523, 'min_child_weight': 10, 'gamma': 3.0007930472949615}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:20:58,031] Trial 81 finished with value: 38.18438478240729 and parameters: {'n_estimators': 240, 'max_depth': 12, 'learning_rate': 0.2909337937359037, 'subsample': 0.5878028466351641, 'colsample_bytree': 0.9061703640467523, 'min_child_weight': 10, 'gamma': 3.0007930472949615}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:21:11,394] Trial 82 finished with value: 35.73569527786171 and parameters: {'n_estimators': 215, 'max_depth': 12, 'learning_rate': 0.06497049816178255, 'subsample': 0.6698872035595534, 'colsample_bytree': 0.940993716773699, 'min_child_weight': 10, 'gamma': 3.496097852506801}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:21:11,394] Trial 82 finished with value: 35.73569527786171 and parameters: {'n_estimators': 215, 'max_depth': 12, 'learning_rate': 0.06497049816178255, 'subsample': 0.6698872035595534, 'colsample_bytree': 0.940993716773699, 'min_child_weight': 10, 'gamma': 3.496097852506801}. Best is trial 22 with value: 35.711163960942415.\n",
      "[I 2025-04-29 18:21:27,955] Trial 83 finished with value: 35.68340538572342 and parameters: {'n_estimators': 249, 'max_depth': 12, 'learning_rate': 0.05044482284440222, 'subsample': 0.6759914585271085, 'colsample_bytree': 0.9555247021543137, 'min_child_weight': 9, 'gamma': 2.6951144283440804}. Best is trial 83 with value: 35.68340538572342.\n",
      "[I 2025-04-29 18:21:27,955] Trial 83 finished with value: 35.68340538572342 and parameters: {'n_estimators': 249, 'max_depth': 12, 'learning_rate': 0.05044482284440222, 'subsample': 0.6759914585271085, 'colsample_bytree': 0.9555247021543137, 'min_child_weight': 9, 'gamma': 2.6951144283440804}. Best is trial 83 with value: 35.68340538572342.\n",
      "[I 2025-04-29 18:21:46,148] Trial 84 finished with value: 35.69708817946063 and parameters: {'n_estimators': 264, 'max_depth': 12, 'learning_rate': 0.04958167858695335, 'subsample': 0.6760234407193454, 'colsample_bytree': 0.9778596004064802, 'min_child_weight': 9, 'gamma': 2.5286783378423427}. Best is trial 83 with value: 35.68340538572342.\n",
      "[I 2025-04-29 18:21:46,148] Trial 84 finished with value: 35.69708817946063 and parameters: {'n_estimators': 264, 'max_depth': 12, 'learning_rate': 0.04958167858695335, 'subsample': 0.6760234407193454, 'colsample_bytree': 0.9778596004064802, 'min_child_weight': 9, 'gamma': 2.5286783378423427}. Best is trial 83 with value: 35.68340538572342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [XGBoost] Trials completados: 85/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:22:05,241] Trial 85 finished with value: 35.65736947738679 and parameters: {'n_estimators': 278, 'max_depth': 12, 'learning_rate': 0.039820465006311104, 'subsample': 0.6851098826016436, 'colsample_bytree': 0.9806212460161695, 'min_child_weight': 9, 'gamma': 2.396802314871436}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:20,476] Trial 86 finished with value: 35.848257059161014 and parameters: {'n_estimators': 284, 'max_depth': 11, 'learning_rate': 0.05007009745059281, 'subsample': 0.6834848267189058, 'colsample_bytree': 0.9565882330975652, 'min_child_weight': 9, 'gamma': 2.058496403793079}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:20,476] Trial 86 finished with value: 35.848257059161014 and parameters: {'n_estimators': 284, 'max_depth': 11, 'learning_rate': 0.05007009745059281, 'subsample': 0.6834848267189058, 'colsample_bytree': 0.9565882330975652, 'min_child_weight': 9, 'gamma': 2.058496403793079}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:37,958] Trial 87 finished with value: 35.678097423239755 and parameters: {'n_estimators': 298, 'max_depth': 12, 'learning_rate': 0.05745403023060766, 'subsample': 0.6957296446891053, 'colsample_bytree': 0.9761923562099223, 'min_child_weight': 9, 'gamma': 2.4653015252914754}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:37,958] Trial 87 finished with value: 35.678097423239755 and parameters: {'n_estimators': 298, 'max_depth': 12, 'learning_rate': 0.05745403023060766, 'subsample': 0.6957296446891053, 'colsample_bytree': 0.9761923562099223, 'min_child_weight': 9, 'gamma': 2.4653015252914754}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:57,951] Trial 88 finished with value: 36.46297887069843 and parameters: {'n_estimators': 296, 'max_depth': 11, 'learning_rate': 0.016827752123288398, 'subsample': 0.675343374267482, 'colsample_bytree': 0.9740057447685834, 'min_child_weight': 9, 'gamma': 2.3538163419774913}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:22:57,951] Trial 88 finished with value: 36.46297887069843 and parameters: {'n_estimators': 296, 'max_depth': 11, 'learning_rate': 0.016827752123288398, 'subsample': 0.675343374267482, 'colsample_bytree': 0.9740057447685834, 'min_child_weight': 9, 'gamma': 2.3538163419774913}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:23:05,793] Trial 89 finished with value: 39.495589770607616 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03930649309648896, 'subsample': 0.6951847422318385, 'colsample_bytree': 0.9881318663772927, 'min_child_weight': 8, 'gamma': 2.5592011153426517}. Best is trial 85 with value: 35.65736947738679.\n",
      "[I 2025-04-29 18:23:05,793] Trial 89 finished with value: 39.495589770607616 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03930649309648896, 'subsample': 0.6951847422318385, 'colsample_bytree': 0.9881318663772927, 'min_child_weight': 8, 'gamma': 2.5592011153426517}. Best is trial 85 with value: 35.65736947738679.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [XGBoost] Trials completados: 90/30\n",
      "\n",
      "✅ XGBoost optimizado:\n",
      "RMSE: 35.6574\n",
      "MAE: 24.4894\n",
      "R²: 0.9202\n",
      "\n",
      "✅ XGBoost optimizado:\n",
      "RMSE: 35.6574\n",
      "MAE: 24.4894\n",
      "R²: 0.9202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 18:23:26,252] Using an existing study with name 'LightGBM_memory_optimized' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Ejecutando optimización para LightGBM...\n",
      "\n",
      "📊 Iniciando optimización adaptativa para LightGBM...\n",
      "Memoria RAM disponible: 2.53 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:35,991] Trial 30 finished with value: 39.346963352381465 and parameters: {'n_estimators': 264, 'max_depth': 11, 'learning_rate': 0.030730292125606733, 'subsample': 0.6388874218385346, 'colsample_bytree': 0.7249078901559086, 'min_child_samples': 75, 'reg_alpha': 0.5606647973347033, 'reg_lambda': 0.31039256966243556}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:35,991] Trial 30 finished with value: 39.346963352381465 and parameters: {'n_estimators': 264, 'max_depth': 11, 'learning_rate': 0.030730292125606733, 'subsample': 0.6388874218385346, 'colsample_bytree': 0.7249078901559086, 'min_child_samples': 75, 'reg_alpha': 0.5606647973347033, 'reg_lambda': 0.31039256966243556}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:40,629] Trial 31 finished with value: 37.793341202883745 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.21490094613315583, 'subsample': 0.611704946155858, 'colsample_bytree': 0.7840039642440151, 'min_child_samples': 100, 'reg_alpha': 0.4818963296633298, 'reg_lambda': 0.5183100958505646}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:40,629] Trial 31 finished with value: 37.793341202883745 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.21490094613315583, 'subsample': 0.611704946155858, 'colsample_bytree': 0.7840039642440151, 'min_child_samples': 100, 'reg_alpha': 0.4818963296633298, 'reg_lambda': 0.5183100958505646}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:43,902] Trial 32 finished with value: 38.03928961725169 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.2339317086540356, 'subsample': 0.5818221049056246, 'colsample_bytree': 0.8230600338772611, 'min_child_samples': 87, 'reg_alpha': 0.36727369990139574, 'reg_lambda': 0.27448497328248095}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:43,902] Trial 32 finished with value: 38.03928961725169 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.2339317086540356, 'subsample': 0.5818221049056246, 'colsample_bytree': 0.8230600338772611, 'min_child_samples': 87, 'reg_alpha': 0.36727369990139574, 'reg_lambda': 0.27448497328248095}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:49,426] Trial 33 finished with value: 37.86421096993678 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.1381126935879355, 'subsample': 0.608695743656408, 'colsample_bytree': 0.7758820089953998, 'min_child_samples': 87, 'reg_alpha': 0.5013117800345992, 'reg_lambda': 0.4169246083275006}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:49,426] Trial 33 finished with value: 37.86421096993678 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.1381126935879355, 'subsample': 0.608695743656408, 'colsample_bytree': 0.7758820089953998, 'min_child_samples': 87, 'reg_alpha': 0.5013117800345992, 'reg_lambda': 0.4169246083275006}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:53,190] Trial 34 finished with value: 37.73340463406887 and parameters: {'n_estimators': 159, 'max_depth': 8, 'learning_rate': 0.2980910093494307, 'subsample': 0.5501014280277093, 'colsample_bytree': 0.8689105872525069, 'min_child_samples': 75, 'reg_alpha': 0.3155468145928801, 'reg_lambda': 0.6528078838383202}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:53,190] Trial 34 finished with value: 37.73340463406887 and parameters: {'n_estimators': 159, 'max_depth': 8, 'learning_rate': 0.2980910093494307, 'subsample': 0.5501014280277093, 'colsample_bytree': 0.8689105872525069, 'min_child_samples': 75, 'reg_alpha': 0.3155468145928801, 'reg_lambda': 0.6528078838383202}. Best is trial 28 with value: 37.34593941374425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [LightGBM] Trials completados: 35/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:23:58,440] Trial 35 finished with value: 37.71705705316589 and parameters: {'n_estimators': 237, 'max_depth': 10, 'learning_rate': 0.18188215906458088, 'subsample': 0.5965280731754736, 'colsample_bytree': 0.7304453570550351, 'min_child_samples': 96, 'reg_alpha': 0.5795660494660648, 'reg_lambda': 0.06150172334536236}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:23:58,440] Trial 35 finished with value: 37.71705705316589 and parameters: {'n_estimators': 237, 'max_depth': 10, 'learning_rate': 0.18188215906458088, 'subsample': 0.5965280731754736, 'colsample_bytree': 0.7304453570550351, 'min_child_samples': 96, 'reg_alpha': 0.5795660494660648, 'reg_lambda': 0.06150172334536236}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:04,827] Trial 36 finished with value: 38.42329485569517 and parameters: {'n_estimators': 193, 'max_depth': 12, 'learning_rate': 0.08201683111519001, 'subsample': 0.6330518358093288, 'colsample_bytree': 0.8072100436515645, 'min_child_samples': 58, 'reg_alpha': 0.6592500368269296, 'reg_lambda': 0.5612378395588242}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:04,827] Trial 36 finished with value: 38.42329485569517 and parameters: {'n_estimators': 193, 'max_depth': 12, 'learning_rate': 0.08201683111519001, 'subsample': 0.6330518358093288, 'colsample_bytree': 0.8072100436515645, 'min_child_samples': 58, 'reg_alpha': 0.6592500368269296, 'reg_lambda': 0.5612378395588242}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:12,114] Trial 37 finished with value: 38.60008123864629 and parameters: {'n_estimators': 260, 'max_depth': 10, 'learning_rate': 0.0507933148714028, 'subsample': 0.6818604445268122, 'colsample_bytree': 0.9379188944325803, 'min_child_samples': 86, 'reg_alpha': 0.39558650642564963, 'reg_lambda': 0.2365276257207428}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:12,114] Trial 37 finished with value: 38.60008123864629 and parameters: {'n_estimators': 260, 'max_depth': 10, 'learning_rate': 0.0507933148714028, 'subsample': 0.6818604445268122, 'colsample_bytree': 0.9379188944325803, 'min_child_samples': 86, 'reg_alpha': 0.39558650642564963, 'reg_lambda': 0.2365276257207428}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:15,521] Trial 38 finished with value: 38.015780525623484 and parameters: {'n_estimators': 136, 'max_depth': 8, 'learning_rate': 0.2489885482679734, 'subsample': 0.6116685568972761, 'colsample_bytree': 0.7947059747312301, 'min_child_samples': 72, 'reg_alpha': 0.256706938969428, 'reg_lambda': 0.39683899908068127}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:15,521] Trial 38 finished with value: 38.015780525623484 and parameters: {'n_estimators': 136, 'max_depth': 8, 'learning_rate': 0.2489885482679734, 'subsample': 0.6116685568972761, 'colsample_bytree': 0.7947059747312301, 'min_child_samples': 72, 'reg_alpha': 0.256706938969428, 'reg_lambda': 0.39683899908068127}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:18,723] Trial 39 finished with value: 38.60497346459299 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.1952593962966629, 'subsample': 0.5504521701520809, 'colsample_bytree': 0.6931720150087146, 'min_child_samples': 82, 'reg_alpha': 0.7036637835943387, 'reg_lambda': 0.48284864646139214}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:18,723] Trial 39 finished with value: 38.60497346459299 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.1952593962966629, 'subsample': 0.5504521701520809, 'colsample_bytree': 0.6931720150087146, 'min_child_samples': 82, 'reg_alpha': 0.7036637835943387, 'reg_lambda': 0.48284864646139214}. Best is trial 28 with value: 37.34593941374425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [LightGBM] Trials completados: 40/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:22,769] Trial 40 finished with value: 37.406313496849414 and parameters: {'n_estimators': 212, 'max_depth': 11, 'learning_rate': 0.2564730232409371, 'subsample': 0.5827193516669354, 'colsample_bytree': 0.9956385980717999, 'min_child_samples': 94, 'reg_alpha': 0.8561476253366959, 'reg_lambda': 0.6195514196763037}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:22,769] Trial 40 finished with value: 37.406313496849414 and parameters: {'n_estimators': 212, 'max_depth': 11, 'learning_rate': 0.2564730232409371, 'subsample': 0.5827193516669354, 'colsample_bytree': 0.9956385980717999, 'min_child_samples': 94, 'reg_alpha': 0.8561476253366959, 'reg_lambda': 0.6195514196763037}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:26,311] Trial 41 finished with value: 37.53840740542601 and parameters: {'n_estimators': 176, 'max_depth': 11, 'learning_rate': 0.25392144116721577, 'subsample': 0.5880941012479235, 'colsample_bytree': 0.9981126922026227, 'min_child_samples': 95, 'reg_alpha': 0.8916418092084106, 'reg_lambda': 0.6899747107475411}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:26,311] Trial 41 finished with value: 37.53840740542601 and parameters: {'n_estimators': 176, 'max_depth': 11, 'learning_rate': 0.25392144116721577, 'subsample': 0.5880941012479235, 'colsample_bytree': 0.9981126922026227, 'min_child_samples': 95, 'reg_alpha': 0.8916418092084106, 'reg_lambda': 0.6899747107475411}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:31,141] Trial 42 finished with value: 37.65438101325667 and parameters: {'n_estimators': 212, 'max_depth': 11, 'learning_rate': 0.15682664235498858, 'subsample': 0.5822830169629756, 'colsample_bytree': 0.9957609342277367, 'min_child_samples': 93, 'reg_alpha': 0.8741516408421189, 'reg_lambda': 0.7002878332497946}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:31,141] Trial 42 finished with value: 37.65438101325667 and parameters: {'n_estimators': 212, 'max_depth': 11, 'learning_rate': 0.15682664235498858, 'subsample': 0.5822830169629756, 'colsample_bytree': 0.9957609342277367, 'min_child_samples': 93, 'reg_alpha': 0.8741516408421189, 'reg_lambda': 0.7002878332497946}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:36,556] Trial 43 finished with value: 37.61955339762543 and parameters: {'n_estimators': 183, 'max_depth': 12, 'learning_rate': 0.22236033567090766, 'subsample': 0.5774315275203007, 'colsample_bytree': 0.9627992617292189, 'min_child_samples': 96, 'reg_alpha': 0.9639498604994475, 'reg_lambda': 0.5400292943033523}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:36,556] Trial 43 finished with value: 37.61955339762543 and parameters: {'n_estimators': 183, 'max_depth': 12, 'learning_rate': 0.22236033567090766, 'subsample': 0.5774315275203007, 'colsample_bytree': 0.9627992617292189, 'min_child_samples': 96, 'reg_alpha': 0.9639498604994475, 'reg_lambda': 0.5400292943033523}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:40,724] Trial 44 finished with value: 37.57206803551958 and parameters: {'n_estimators': 184, 'max_depth': 12, 'learning_rate': 0.24144941689016675, 'subsample': 0.5535466512110425, 'colsample_bytree': 0.9609057029928285, 'min_child_samples': 96, 'reg_alpha': 0.9658374309543468, 'reg_lambda': 0.772774605551797}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:40,724] Trial 44 finished with value: 37.57206803551958 and parameters: {'n_estimators': 184, 'max_depth': 12, 'learning_rate': 0.24144941689016675, 'subsample': 0.5535466512110425, 'colsample_bytree': 0.9609057029928285, 'min_child_samples': 96, 'reg_alpha': 0.9658374309543468, 'reg_lambda': 0.772774605551797}. Best is trial 28 with value: 37.34593941374425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [LightGBM] Trials completados: 45/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:44,321] Trial 45 finished with value: 37.72344154662176 and parameters: {'n_estimators': 155, 'max_depth': 12, 'learning_rate': 0.2530776546075986, 'subsample': 0.5595842637629191, 'colsample_bytree': 0.9895543668226564, 'min_child_samples': 96, 'reg_alpha': 0.876341014048042, 'reg_lambda': 0.8899315843787003}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:44,321] Trial 45 finished with value: 37.72344154662176 and parameters: {'n_estimators': 155, 'max_depth': 12, 'learning_rate': 0.2530776546075986, 'subsample': 0.5595842637629191, 'colsample_bytree': 0.9895543668226564, 'min_child_samples': 96, 'reg_alpha': 0.876341014048042, 'reg_lambda': 0.8899315843787003}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:51,457] Trial 46 finished with value: 38.01096833450631 and parameters: {'n_estimators': 198, 'max_depth': 11, 'learning_rate': 0.11591311319145577, 'subsample': 0.5482779848156909, 'colsample_bytree': 0.9505894682740698, 'min_child_samples': 100, 'reg_alpha': 0.9258528120040186, 'reg_lambda': 0.7677445923528958}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:51,457] Trial 46 finished with value: 38.01096833450631 and parameters: {'n_estimators': 198, 'max_depth': 11, 'learning_rate': 0.11591311319145577, 'subsample': 0.5482779848156909, 'colsample_bytree': 0.9505894682740698, 'min_child_samples': 100, 'reg_alpha': 0.9258528120040186, 'reg_lambda': 0.7677445923528958}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:24:55,194] Trial 47 finished with value: 38.22070582246875 and parameters: {'n_estimators': 143, 'max_depth': 12, 'learning_rate': 0.15183422653050682, 'subsample': 0.5192089324839947, 'colsample_bytree': 0.9145942595193255, 'min_child_samples': 89, 'reg_alpha': 0.8704405798563677, 'reg_lambda': 0.8074778058983992}. Best is trial 28 with value: 37.34593941374425.\n",
      "[I 2025-04-29 18:24:55,194] Trial 47 finished with value: 38.22070582246875 and parameters: {'n_estimators': 143, 'max_depth': 12, 'learning_rate': 0.15183422653050682, 'subsample': 0.5192089324839947, 'colsample_bytree': 0.9145942595193255, 'min_child_samples': 89, 'reg_alpha': 0.8704405798563677, 'reg_lambda': 0.8074778058983992}. Best is trial 28 with value: 37.34593941374425.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:01,093] Trial 48 finished with value: 37.11077711702346 and parameters: {'n_estimators': 280, 'max_depth': 11, 'learning_rate': 0.26056382367357184, 'subsample': 0.6699101334644922, 'colsample_bytree': 0.9772010883647662, 'min_child_samples': 93, 'reg_alpha': 0.8133003553542224, 'reg_lambda': 0.7155782928888794}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:01,093] Trial 48 finished with value: 37.11077711702346 and parameters: {'n_estimators': 280, 'max_depth': 11, 'learning_rate': 0.26056382367357184, 'subsample': 0.6699101334644922, 'colsample_bytree': 0.9772010883647662, 'min_child_samples': 93, 'reg_alpha': 0.8133003553542224, 'reg_lambda': 0.7155782928888794}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:09,769] Trial 49 finished with value: 39.538676424442045 and parameters: {'n_estimators': 285, 'max_depth': 11, 'learning_rate': 0.0261891307455606, 'subsample': 0.6729100738537408, 'colsample_bytree': 0.9283598067504141, 'min_child_samples': 5, 'reg_alpha': 0.795444474477224, 'reg_lambda': 0.7033544280431728}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:09,769] Trial 49 finished with value: 39.538676424442045 and parameters: {'n_estimators': 285, 'max_depth': 11, 'learning_rate': 0.0261891307455606, 'subsample': 0.6729100738537408, 'colsample_bytree': 0.9283598067504141, 'min_child_samples': 5, 'reg_alpha': 0.795444474477224, 'reg_lambda': 0.7033544280431728}. Best is trial 48 with value: 37.11077711702346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [LightGBM] Trials completados: 50/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:16,729] Trial 50 finished with value: 37.82833306131848 and parameters: {'n_estimators': 275, 'max_depth': 11, 'learning_rate': 0.09786691390401238, 'subsample': 0.6485689141374892, 'colsample_bytree': 0.8940592932171196, 'min_child_samples': 26, 'reg_alpha': 0.8116885110866364, 'reg_lambda': 0.46400922155888225}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:16,729] Trial 50 finished with value: 37.82833306131848 and parameters: {'n_estimators': 275, 'max_depth': 11, 'learning_rate': 0.09786691390401238, 'subsample': 0.6485689141374892, 'colsample_bytree': 0.8940592932171196, 'min_child_samples': 26, 'reg_alpha': 0.8116885110866364, 'reg_lambda': 0.46400922155888225}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:22,257] Trial 51 finished with value: 37.26128108154203 and parameters: {'n_estimators': 255, 'max_depth': 11, 'learning_rate': 0.24798332552298202, 'subsample': 0.6636729066697132, 'colsample_bytree': 0.9755672122133138, 'min_child_samples': 93, 'reg_alpha': 0.9131181055691796, 'reg_lambda': 0.621329938583348}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:22,257] Trial 51 finished with value: 37.26128108154203 and parameters: {'n_estimators': 255, 'max_depth': 11, 'learning_rate': 0.24798332552298202, 'subsample': 0.6636729066697132, 'colsample_bytree': 0.9755672122133138, 'min_child_samples': 93, 'reg_alpha': 0.9131181055691796, 'reg_lambda': 0.621329938583348}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:28,378] Trial 52 finished with value: 37.218773890129945 and parameters: {'n_estimators': 257, 'max_depth': 11, 'learning_rate': 0.2561577122639253, 'subsample': 0.6659782978957755, 'colsample_bytree': 0.9847147617209204, 'min_child_samples': 91, 'reg_alpha': 0.7550822405145999, 'reg_lambda': 0.6796769065229676}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:28,378] Trial 52 finished with value: 37.218773890129945 and parameters: {'n_estimators': 257, 'max_depth': 11, 'learning_rate': 0.2561577122639253, 'subsample': 0.6659782978957755, 'colsample_bytree': 0.9847147617209204, 'min_child_samples': 91, 'reg_alpha': 0.7550822405145999, 'reg_lambda': 0.6796769065229676}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:33,089] Trial 53 finished with value: 37.43684250151292 and parameters: {'n_estimators': 254, 'max_depth': 10, 'learning_rate': 0.18469963077123455, 'subsample': 0.6647100841039998, 'colsample_bytree': 0.9787993398958806, 'min_child_samples': 90, 'reg_alpha': 0.7543131599868798, 'reg_lambda': 0.6094880396886312}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:33,089] Trial 53 finished with value: 37.43684250151292 and parameters: {'n_estimators': 254, 'max_depth': 10, 'learning_rate': 0.18469963077123455, 'subsample': 0.6647100841039998, 'colsample_bytree': 0.9787993398958806, 'min_child_samples': 90, 'reg_alpha': 0.7543131599868798, 'reg_lambda': 0.6094880396886312}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:37,649] Trial 54 finished with value: 37.406646030399614 and parameters: {'n_estimators': 257, 'max_depth': 10, 'learning_rate': 0.18657516049282813, 'subsample': 0.6997851907775049, 'colsample_bytree': 0.9749099992212265, 'min_child_samples': 90, 'reg_alpha': 0.7518624457311625, 'reg_lambda': 0.626943507027824}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:37,649] Trial 54 finished with value: 37.406646030399614 and parameters: {'n_estimators': 257, 'max_depth': 10, 'learning_rate': 0.18657516049282813, 'subsample': 0.6997851907775049, 'colsample_bytree': 0.9749099992212265, 'min_child_samples': 90, 'reg_alpha': 0.7518624457311625, 'reg_lambda': 0.626943507027824}. Best is trial 48 with value: 37.11077711702346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [LightGBM] Trials completados: 55/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:42,599] Trial 55 finished with value: 37.385937843327525 and parameters: {'n_estimators': 283, 'max_depth': 11, 'learning_rate': 0.1588812395864361, 'subsample': 0.6998177129720142, 'colsample_bytree': 0.9760117343443714, 'min_child_samples': 86, 'reg_alpha': 0.8338821359211896, 'reg_lambda': 0.7384309113212614}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:42,599] Trial 55 finished with value: 37.385937843327525 and parameters: {'n_estimators': 283, 'max_depth': 11, 'learning_rate': 0.1588812395864361, 'subsample': 0.6998177129720142, 'colsample_bytree': 0.9760117343443714, 'min_child_samples': 86, 'reg_alpha': 0.8338821359211896, 'reg_lambda': 0.7384309113212614}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:48,930] Trial 56 finished with value: 37.42007189187652 and parameters: {'n_estimators': 283, 'max_depth': 12, 'learning_rate': 0.16315640399059922, 'subsample': 0.680641902309246, 'colsample_bytree': 0.9499823073838851, 'min_child_samples': 85, 'reg_alpha': 0.9237137333041137, 'reg_lambda': 0.7381701020985204}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:48,930] Trial 56 finished with value: 37.42007189187652 and parameters: {'n_estimators': 283, 'max_depth': 12, 'learning_rate': 0.16315640399059922, 'subsample': 0.680641902309246, 'colsample_bytree': 0.9499823073838851, 'min_child_samples': 85, 'reg_alpha': 0.9237137333041137, 'reg_lambda': 0.7381701020985204}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:25:55,288] Trial 57 finished with value: 37.23618441589915 and parameters: {'n_estimators': 299, 'max_depth': 11, 'learning_rate': 0.1995390832009045, 'subsample': 0.6904311903141167, 'colsample_bytree': 0.8982404139820834, 'min_child_samples': 40, 'reg_alpha': 0.8303352316903764, 'reg_lambda': 0.8606505195068073}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:25:55,288] Trial 57 finished with value: 37.23618441589915 and parameters: {'n_estimators': 299, 'max_depth': 11, 'learning_rate': 0.1995390832009045, 'subsample': 0.6904311903141167, 'colsample_bytree': 0.8982404139820834, 'min_child_samples': 40, 'reg_alpha': 0.8303352316903764, 'reg_lambda': 0.8606505195068073}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:26:05,612] Trial 58 finished with value: 41.91892710162173 and parameters: {'n_estimators': 298, 'max_depth': 11, 'learning_rate': 0.013359706377499819, 'subsample': 0.6910386077544506, 'colsample_bytree': 0.9045364271919647, 'min_child_samples': 43, 'reg_alpha': 0.8338114959942773, 'reg_lambda': 0.9353154671756975}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:26:05,612] Trial 58 finished with value: 41.91892710162173 and parameters: {'n_estimators': 298, 'max_depth': 11, 'learning_rate': 0.013359706377499819, 'subsample': 0.6910386077544506, 'colsample_bytree': 0.9045364271919647, 'min_child_samples': 43, 'reg_alpha': 0.8338114959942773, 'reg_lambda': 0.9353154671756975}. Best is trial 48 with value: 37.11077711702346.\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-04-29 18:26:12,396] Trial 59 finished with value: 37.59809830471343 and parameters: {'n_estimators': 276, 'max_depth': 12, 'learning_rate': 0.12974199103267098, 'subsample': 0.6700170122352743, 'colsample_bytree': 0.9399309949866732, 'min_child_samples': 37, 'reg_alpha': 0.7903477861649355, 'reg_lambda': 0.8092985788621441}. Best is trial 48 with value: 37.11077711702346.\n",
      "[I 2025-04-29 18:26:12,396] Trial 59 finished with value: 37.59809830471343 and parameters: {'n_estimators': 276, 'max_depth': 12, 'learning_rate': 0.12974199103267098, 'subsample': 0.6700170122352743, 'colsample_bytree': 0.9399309949866732, 'min_child_samples': 37, 'reg_alpha': 0.7903477861649355, 'reg_lambda': 0.8092985788621441}. Best is trial 48 with value: 37.11077711702346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 [LightGBM] Trials completados: 60/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riperez/Conda/anaconda3/envs/precipitation_prediction/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ LightGBM optimizado:\n",
      "RMSE: 37.1108\n",
      "MAE: 25.8193\n",
      "R²: 0.9136\n",
      "\n",
      "📊 Comparación de modelos optimizados:\n",
      "Modelo\t\tRMSE\t\tMAE\t\tR2\n",
      "RandomForest\t41.0972\t28.4235\t0.8940\n",
      "XGBoost    \t35.6574\t24.4894\t0.9202\n",
      "LightGBM   \t37.1108\t25.8193\t0.9136\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "# ✅ Versión corregida y funcional de la optimización adaptativa con Optuna\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import warnings\n",
    "import pickle\n",
    "import optuna\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "resultados_base = {}\n",
    "model_paths = {}  # Para guardar rutas de modelos optimizados\n",
    "\n",
    "# Suprimir warnings de XGBoost innecesarios\n",
    "def suppress_specific_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\")\n",
    "    os.environ[\"XGBOOST_DISABLE_USE_LABEL_ENCODER\"] = \"1\"\n",
    "\n",
    "suppress_specific_warnings()\n",
    "\n",
    "def validate_database_path(db_path):\n",
    "    \"\"\"Valida que la base de datos SQLite tenga permisos de escritura.\"\"\"\n",
    "    try:\n",
    "        with open(db_path, 'a') as f:\n",
    "            pass\n",
    "        print(f\"✅ Base de datos validada: {db_path}\")\n",
    "    except IOError as e:\n",
    "        print(f\"❌ Error de permisos en la base de datos: {db_path}. {e}\")\n",
    "        print(\"Usando base de datos en memoria como alternativa.\")\n",
    "        return ':memory:'\n",
    "    return db_path\n",
    "\n",
    "class OptimizationProgressCallback:\n",
    "    def __init__(self, total_trials, model_name=\"Modelo\"):\n",
    "        self.total_trials = total_trials\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        completed_trials = len(study.trials)\n",
    "        if completed_trials % 5 == 0 or completed_trials == self.total_trials:\n",
    "            print(f\"📈 [{self.model_name}] Trials completados: {completed_trials}/{self.total_trials}\")\n",
    "\n",
    "def run_memory_efficient_optimization(model_type, X_train, y_train, X_test, y_test):\n",
    "    print(f\"\\n📊 Iniciando optimización adaptativa para {model_type}...\")\n",
    "\n",
    "    # Verificar si el modelo ya existe\n",
    "    model_path = model_output_dir / f\"{model_type}_optimized.pkl\"\n",
    "    if model_path.exists():\n",
    "        print(f\"✅ Modelo optimizado encontrado: {model_path}. Cargando...\")\n",
    "        with open(model_path, 'rb') as f:\n",
    "            best_model = pickle.load(f)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"\\n✅ {model_type} cargado y evaluado:\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"R²: {r2:.4f}\")\n",
    "        resultados_base[f\"{model_type}_Optuna\"] = (rmse, mae, r2)\n",
    "        model_paths[f\"{model_type}_Optuna\"] = model_path\n",
    "        return None, best_model, (rmse, mae, r2)\n",
    "\n",
    "    available_memory_gb = psutil.virtual_memory().available / (1024**3)\n",
    "    print(f\"Memoria RAM disponible: {available_memory_gb:.2f} GB\")\n",
    "\n",
    "    model_types = {\n",
    "        'RandomForest': RandomForestRegressor,\n",
    "        'XGBoost': XGBRegressor,\n",
    "        'LightGBM': LGBMRegressor\n",
    "    }\n",
    "\n",
    "    if model_type not in model_types:\n",
    "        raise ValueError(f\"Tipo de modelo no soportado: {model_type}.\")\n",
    "\n",
    "    if available_memory_gb < 2.0:\n",
    "        n_trials, max_estimators, max_depth, subsample = 10, 50, 6, 0.5\n",
    "    elif available_memory_gb < 8.0:\n",
    "        n_trials, max_estimators, max_depth, subsample = 30, 300, 12, 0.7\n",
    "    else:\n",
    "        n_trials, max_estimators, max_depth, subsample = 50, 500, 20, 0.9\n",
    "\n",
    "    def objective(trial):\n",
    "        common_params = {'random_state': 42}\n",
    "\n",
    "        if model_type == 'RandomForest':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, max_estimators),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, max_depth),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "                'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "        elif model_type == 'XGBoost':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, max_estimators),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, max_depth),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, subsample),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "                'tree_method': 'hist',\n",
    "                'n_jobs': -1,\n",
    "                'verbosity': 0\n",
    "            }\n",
    "        elif model_type == 'LightGBM':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, max_estimators),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, max_depth),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, subsample),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "                'boosting_type': 'gbdt',\n",
    "                'n_jobs': -1,\n",
    "                'verbose': -1\n",
    "            }\n",
    "\n",
    "        params.update(common_params)\n",
    "        gc.collect()\n",
    "        try:\n",
    "            model = model_types[model_type](**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            return rmse\n",
    "        except Exception as e:\n",
    "            print(f\"Error con parámetros: {params}\\n{e}\")\n",
    "            return float('inf')\n",
    "\n",
    "    db_path = validate_database_path(model_output_dir / f\"{model_type}_study.db\")\n",
    "\n",
    "    try:\n",
    "        study = optuna.create_study(\n",
    "            study_name=f\"{model_type}_memory_optimized\",\n",
    "            storage=f\"sqlite:///{db_path}\",\n",
    "            direction='minimize',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            load_if_exists=True\n",
    "        )\n",
    "    except OperationalError as e:\n",
    "        print(f\"Error al acceder a la base de datos: {e}\")\n",
    "        print(\"Asegúrate de que la base de datos no sea de solo lectura o verifica los permisos.\")\n",
    "        return None, None, None\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[OptimizationProgressCallback(n_trials, model_type)])\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params['random_state'] = 42\n",
    "    if model_type == 'XGBoost':\n",
    "        best_params['tree_method'] = 'hist'\n",
    "\n",
    "    best_model = model_types[model_type](**best_params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n✅ {model_type} optimizado:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "    resultados_base[f\"{model_type}_Optuna\"] = (rmse, mae, r2)\n",
    "\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    model_paths[f\"{model_type}_Optuna\"] = model_path\n",
    "\n",
    "    return best_params, best_model, (rmse, mae, r2)\n",
    "\n",
    "# ✅ Ejecutar optimización adaptativa para todos los modelos base\n",
    "if 'X_train_scaled' in globals() and 'y_train' in globals() and 'X_test_scaled' in globals() and 'y_test' in globals():\n",
    "    print(\"\\n🚀 Ejecutando optimización para RandomForest...\")\n",
    "    rf_params, rf_model, rf_metrics = run_memory_efficient_optimization('RandomForest', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "    print(\"\\n🚀 Ejecutando optimización para XGBoost...\")\n",
    "    xgb_params, xgb_model, xgb_metrics = run_memory_efficient_optimization('XGBoost', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "    print(\"\\n🚀 Ejecutando optimización para LightGBM...\")\n",
    "    lgb_params, lgb_model, lgb_metrics = run_memory_efficient_optimization('LightGBM', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "    # 📊 Comparación de métricas\n",
    "    print(\"\\n📊 Comparación de modelos optimizados:\")\n",
    "    print(\"Modelo\\t\\tRMSE\\t\\tMAE\\t\\tR2\")\n",
    "    print(f\"RandomForest\\t{rf_metrics[0]:.4f}\\t{rf_metrics[1]:.4f}\\t{rf_metrics[2]:.4f}\")\n",
    "    print(f\"XGBoost    \\t{xgb_metrics[0]:.4f}\\t{xgb_metrics[1]:.4f}\\t{xgb_metrics[2]:.4f}\")\n",
    "    print(f\"LightGBM   \\t{lgb_metrics[0]:.4f}\\t{lgb_metrics[1]:.4f}\\t{lgb_metrics[2]:.4f}\")\n",
    "else:\n",
    "    print(\"❌ No se encontraron las variables X_train_scaled, y_train, X_test_scaled o y_test en el entorno actual.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f81dd",
   "metadata": {},
   "source": [
    "## 🧠 Implementación de Modelos de Deep Learning\n",
    "\n",
    "A continuación implementaremos modelos basados en redes neuronales profundas para capturar patrones espaciales y temporales en los datos de precipitación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e57e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Preparando datos para modelos CNN...\n",
      "Columnas de coordenadas encontradas: ['latitude', 'longitude']\n",
      "Usando latitude y longitude como coordenadas para CNN\n",
      "Convirtiendo datos a formato espacial...\n"
     ]
    }
   ],
   "source": [
    "# Implementación de modelo CNN para predicción espacial\n",
    "import gc  # Para liberar memoria\n",
    "\n",
    "print(\"\\n🔍 Preparando datos para modelos CNN...\")\n",
    "\n",
    "# Verificar si tenemos columnas de coordenadas en nuestros datos\n",
    "coord_cols = [col for col in feature_cols if col in ['x', 'y', 'latitude', 'longitude', 'lat', 'lon']]\n",
    "\n",
    "if len(coord_cols) >= 2:\n",
    "    print(f\"Columnas de coordenadas encontradas: {coord_cols}\")\n",
    "    \n",
    "    # Mapeo de nombres de columnas comunes\n",
    "    lat_names = ['latitude', 'lat', 'y']\n",
    "    lon_names = ['longitude', 'lon', 'x']\n",
    "    \n",
    "    # Identificar columnas de latitud y longitud\n",
    "    lat_col = next((col for col in coord_cols if col in lat_names), None)\n",
    "    lon_col = next((col for col in coord_cols if col in lon_names), None)\n",
    "    \n",
    "    if lat_col and lon_col:\n",
    "        print(f\"Usando {lat_col} y {lon_col} como coordenadas para CNN\")\n",
    "        \n",
    "        # Convertir datos a formato espacial para CNN\n",
    "        def prepare_spatial_data(X_data, y_data, lat_col, lon_col):\n",
    "            \"\"\"Prepara datos espaciales para CNN\"\"\"\n",
    "            try:\n",
    "                # Extraer coordenadas únicas en orden\n",
    "                lats = sorted(X_data[lat_col].unique())\n",
    "                lons = sorted(X_data[lon_col].unique())\n",
    "                \n",
    "                # Crear diccionarios de mapeo para índices\n",
    "                lat_to_idx = {lat: idx for idx, lat in enumerate(lats)}\n",
    "                lon_to_idx = {lon: idx for idx, lon in enumerate(lons)}\n",
    "                \n",
    "                # Dimensiones de la grilla\n",
    "                grid_height = len(lats)\n",
    "                grid_width = len(lons)\n",
    "                n_features = X_data.shape[1] - 2  # Restar las dos columnas de coordenadas\n",
    "                \n",
    "                # Inicializar arrays\n",
    "                X_grid = np.zeros((len(X_data), grid_height, grid_width, n_features), dtype=np.float32)\n",
    "                y_grid = np.zeros((len(y_data), grid_height, grid_width, 1), dtype=np.float32)\n",
    "                \n",
    "                # Recorrer todos los datos y ubicarlos en la grilla\n",
    "                non_coord_cols = [col for col in X_data.columns if col != lat_col and col != lon_col]\n",
    "                \n",
    "                for idx in range(len(X_data)):\n",
    "                    lat = X_data.iloc[idx][lat_col]\n",
    "                    lon = X_data.iloc[idx][lon_col]\n",
    "                    \n",
    "                    lat_idx = lat_to_idx[lat]\n",
    "                    lon_idx = lon_to_idx[lon]\n",
    "                    \n",
    "                    # Colocar características en la grilla\n",
    "                    for i, col in enumerate(non_coord_cols):\n",
    "                        X_grid[idx, lat_idx, lon_idx, i] = X_data.iloc[idx][col]\n",
    "                    \n",
    "                    # Colocar valor objetivo\n",
    "                    y_grid[idx, lat_idx, lon_idx, 0] = y_data.iloc[idx]\n",
    "                \n",
    "                return X_grid, y_grid\n",
    "            except Exception as e:\n",
    "                print(f\"Error preparando datos espaciales: {e}\")\n",
    "                return None, None\n",
    "        \n",
    "        # Convertir datos de entrenamiento a formato espacial\n",
    "        print(\"Convirtiendo datos a formato espacial...\")\n",
    "        try:\n",
    "            X_train_df = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "            X_test_df = pd.DataFrame(X_test_scaled, columns=feature_cols)\n",
    "            \n",
    "            X_train_spatial, y_train_spatial = prepare_spatial_data(X_train_df, y_train, lat_col, lon_col)\n",
    "            X_test_spatial, y_test_spatial = prepare_spatial_data(X_test_df, y_test, lat_col, lon_col)\n",
    "            \n",
    "            if X_train_spatial is None or X_test_spatial is None:\n",
    "                raise ValueError(\"Error al preparar datos espaciales para CNN.\")\n",
    "            \n",
    "            print(f\"Datos espaciales preparados:\")\n",
    "            print(f\"X_train_spatial: {X_train_spatial.shape}\")\n",
    "            print(f\"y_train_spatial: {y_train_spatial.shape}\")\n",
    "            print(f\"X_test_spatial: {X_test_spatial.shape}\")\n",
    "            print(f\"y_test_spatial: {y_test_spatial.shape}\")\n",
    "            \n",
    "            # Liberar memoria innecesaria\n",
    "            del X_train_df, X_test_df\n",
    "            gc.collect()\n",
    "            \n",
    "            # Modelo CNN para predicción de precipitación\n",
    "            def create_cnn_model(input_shape):\n",
    "                \"\"\"Crea un modelo CNN para predicción espacial\"\"\"\n",
    "                inputs = Input(shape=input_shape)\n",
    "                x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "                x = BatchNormalization()(x)\n",
    "                x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "                x = Dropout(0.25)(x)\n",
    "                x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "                x = BatchNormalization()(x)\n",
    "                x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "                x = Dropout(0.25)(x)\n",
    "                outputs = Conv2D(1, kernel_size=(1, 1), activation='linear', padding='same')(x)\n",
    "                model = Model(inputs=inputs, outputs=outputs)\n",
    "                model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['mae'])\n",
    "                return model\n",
    "            \n",
    "            print(\"\\n🧠 Creando y entrenando modelo CNN...\")\n",
    "            input_shape = X_train_spatial.shape[1:]\n",
    "            cnn_model = create_cnn_model(input_shape)\n",
    "            cnn_model.summary()\n",
    "            \n",
    "            callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "                ModelCheckpoint(filepath=model_output_dir / 'cnn_model_best.h5', save_best_only=True, monitor='val_loss')\n",
    "            ]\n",
    "            \n",
    "            history = cnn_model.fit(\n",
    "                X_train_spatial, y_train_spatial,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            print(\"\\n📊 Evaluando modelo CNN...\")\n",
    "            cnn_metrics = cnn_model.evaluate(X_test_spatial, y_test_spatial)\n",
    "            print(f\"Loss (MSE): {cnn_metrics[0]:.4f}\")\n",
    "            print(f\"MAE: {cnn_metrics[1]:.4f}\")\n",
    "            \n",
    "            cnn_model.save(model_output_dir / 'cnn_model_final.h5')\n",
    "            print(\"Modelo CNN guardado correctamente.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error preparando datos espaciales para CNN: {e}\")\n",
    "    else:\n",
    "        print(\"No se pudieron identificar columnas de latitud y longitud.\")\n",
    "else:\n",
    "    print(\"No se encontraron suficientes columnas de coordenadas para implementar CNN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de modelo ConvLSTM para predicción espaciotemporal\n",
    "print(\"\\n🔍 Preparando datos para modelo ConvLSTM...\")\n",
    "\n",
    "# Verificar si tenemos el DataFrame disponible\n",
    "if 'df' not in locals() or df is None:\n",
    "    print(\"DataFrame no disponible, intentando recargarlo...\")\n",
    "    try:\n",
    "        # Recargar el dataset si no está disponible\n",
    "        data_file = BASE_PATH / 'data' / 'output' / 'complete_dataset_with_features.nc'\n",
    "        print(f\"Recargando archivo desde: {data_file}\")\n",
    "        df, ds_original = load_dataset(data_file)\n",
    "        \n",
    "        if df is None:\n",
    "            print(\"Error: No se pudo recargar el DataFrame. Verificar la ruta del archivo.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al recargar el DataFrame: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Verificar si tenemos las variables necesarias\n",
    "if 'feature_cols' not in locals() or 'target_column' not in locals():\n",
    "    print(\"Variables necesarias no definidas, intentando redefinirlas...\")\n",
    "    if df is not None:\n",
    "        # Identificar la columna objetivo (precipitación)\n",
    "        target_column = 'total_precipitation'  # Ajustar si tiene otro nombre en tu dataset\n",
    "        \n",
    "        # Ver si existe 'precip_target' o usar 'total_precipitation'\n",
    "        if 'total_precipitation' in df.columns:\n",
    "            target_column = 'total_precipitation'\n",
    "        \n",
    "        # Separar variables predictoras y variable objetivo\n",
    "        feature_cols = [col for col in df.columns if col != target_column and not pd.isna(df[col]).all()]\n",
    "        \n",
    "        # Eliminar columnas no numéricas para los modelos\n",
    "        non_feature_cols = ['time', 'spatial_ref']\n",
    "        feature_cols = [col for col in feature_cols if col not in non_feature_cols]\n",
    "\n",
    "# Si el DataFrame está disponible, continuar con la preparación de datos\n",
    "if df is not None:\n",
    "    # Para ConvLSTM necesitamos datos con dimensión temporal\n",
    "    time_cols = [col for col in df.columns if col in ['time', 'date', 'month', 'year', 'day']]\n",
    "\n",
    "    if len(time_cols) > 0 and len(coord_cols) >= 2:\n",
    "        print(f\"Columnas temporales encontradas: {time_cols}\")\n",
    "        time_col = time_cols[0]\n",
    "        \n",
    "        # Función para preparar datos espaciotemporales\n",
    "        def prepare_spatiotemporal_data(df, feature_cols, target_column, lat_col, lon_col, time_col, \n",
    "                                        sequence_length=3):\n",
    "            \"\"\"Prepara datos para ConvLSTM con dimensión espaciotemporal\"\"\"\n",
    "            print(\"Preparando datos espaciotemporales para ConvLSTM...\")\n",
    "            try:\n",
    "                # Asegurarnos que la columna temporal está ordenada\n",
    "                # Verificar el tipo de la columna temporal\n",
    "                time_dtype = df[time_col].dtype\n",
    "                print(f\"Tipo de dato de columna temporal: {time_dtype}\")\n",
    "                \n",
    "                if pd.api.types.is_datetime64_any_dtype(df[time_col]):\n",
    "                    # Ya es datetime, ordenamos\n",
    "                    df_sorted = df.sort_values(by=time_col)\n",
    "                else:\n",
    "                    # Intentar convertir a datetime\n",
    "                    try:\n",
    "                        df[time_col] = pd.to_datetime(df[time_col])\n",
    "                        df_sorted = df.sort_values(by=time_col)\n",
    "                    except Exception as e:\n",
    "                        print(f\"No se pudo convertir columna temporal a datetime: {e}\")\n",
    "                        # Si no podemos convertir, asumimos que ya está ordenado\n",
    "                        df_sorted = df\n",
    "                \n",
    "                # Extraer coordenadas únicas\n",
    "                lats = sorted(df_sorted[lat_col].unique())\n",
    "                lons = sorted(df_sorted[lon_col].unique())\n",
    "                time_steps = sorted(df_sorted[time_col].unique())\n",
    "                \n",
    "                print(f\"Dimensiones espaciotemporales:\")\n",
    "                print(f\"- Latitudes (filas): {len(lats)}\")\n",
    "                print(f\"- Longitudes (columnas): {len(lons)}\")\n",
    "                print(f\"- Pasos temporales: {len(time_steps)}\")\n",
    "                \n",
    "                # Crear mapeos para índices\n",
    "                lat_to_idx = {lat: idx for idx, lat in enumerate(lats)}\n",
    "                lon_to_idx = {lon: idx for idx, lon in enumerate(lons)}\n",
    "                time_to_idx = {time: idx for idx, time in enumerate(time_steps)}\n",
    "                \n",
    "                # Filtrar columnas feature eliminando coordenadas y tiempo\n",
    "                feature_cols_filtered = [col for col in feature_cols if col != lat_col and col != lon_col and col != time_col]\n",
    "                n_features = len(feature_cols_filtered)\n",
    "                \n",
    "                # Dimensiones de la grilla espaciotemporal\n",
    "                grid_height = len(lats)\n",
    "                grid_width = len(lons)\n",
    "                n_timesteps = len(time_steps)\n",
    "                \n",
    "                print(f\"Características a usar: {n_features}\")\n",
    "                \n",
    "                # Crear un DataFrame indexado para acceso rápido\n",
    "                df_indexed = df_sorted.set_index([time_col, lat_col, lon_col])\n",
    "                \n",
    "                # Crear matrices 3D para cada paso temporal\n",
    "                # Las dimensiones son: [tiempo, altura, ancho, features]\n",
    "                X_spatiotemporal = np.zeros((n_timesteps, grid_height, grid_width, n_features))\n",
    "                y_spatiotemporal = np.zeros((n_timesteps, grid_height, grid_width, 1))\n",
    "                \n",
    "                # Llenar matrices con datos disponibles\n",
    "                for t_idx, t in enumerate(time_steps):\n",
    "                    for lat_idx, lat in enumerate(lats):\n",
    "                        for lon_idx, lon in enumerate(lons):\n",
    "                            try:\n",
    "                                # Obtener datos para esta coordenada y tiempo\n",
    "                                data = df_indexed.loc[(t, lat, lon)]\n",
    "                                \n",
    "                                # Llenar características\n",
    "                                for f_idx, feat in enumerate(feature_cols_filtered):\n",
    "                                    X_spatiotemporal[t_idx, lat_idx, lon_idx, f_idx] = data[feat]\n",
    "                                \n",
    "                                # Llenar target\n",
    "                                y_spatiotemporal[t_idx, lat_idx, lon_idx, 0] = data[target_column]\n",
    "                            except KeyError:\n",
    "                                # Este punto espaciotemporal no existe en los datos\n",
    "                                pass\n",
    "                \n",
    "                # Crear secuencias para ConvLSTM\n",
    "                # Para cada paso temporal t, usaremos t-sequence_length hasta t-1 para predecir t\n",
    "                n_sequences = n_timesteps - sequence_length\n",
    "                \n",
    "                if n_sequences <= 0:\n",
    "                    print(\"No hay suficientes pasos temporales para crear secuencias. Ajustando sequence_length.\")\n",
    "                    sequence_length = max(1, n_timesteps // 2)\n",
    "                    n_sequences = n_timesteps - sequence_length\n",
    "                    print(f\"Nuevo sequence_length: {sequence_length}, n_sequences: {n_sequences}\")\n",
    "                \n",
    "                # Crear arrays para secuencias\n",
    "                X_sequences = np.zeros((n_sequences, sequence_length, grid_height, grid_width, n_features))\n",
    "                y_sequences = np.zeros((n_sequences, grid_height, grid_width, 1))\n",
    "                \n",
    "                for i in range(n_sequences):\n",
    "                    X_sequences[i] = X_spatiotemporal[i:i+sequence_length]\n",
    "                    y_sequences[i] = y_spatiotemporal[i+sequence_length]\n",
    "                \n",
    "                print(f\"Secuencias creadas:\")\n",
    "                print(f\"X_sequences: {X_sequences.shape}\")\n",
    "                print(f\"y_sequences: {y_sequences.shape}\")\n",
    "                \n",
    "                # Dividir en train/test\n",
    "                train_size = int(0.8 * n_sequences)\n",
    "                X_train = X_sequences[:train_size]\n",
    "                y_train = y_sequences[:train_size]\n",
    "                X_test = X_sequences[train_size:]\n",
    "                y_test = y_sequences[train_size:]\n",
    "                \n",
    "                return X_train, y_train, X_test, y_test\n",
    "            except Exception as e:\n",
    "                print(f\"Error preparando datos espaciotemporales: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                return None, None, None, None\n",
    "        \n",
    "        # Intentar preparar datos espaciotemporales\n",
    "        try:\n",
    "            X_train_convlstm, y_train_convlstm, X_test_convlstm, y_test_convlstm = prepare_spatiotemporal_data(\n",
    "                df, feature_cols, target_column, lat_col, lon_col, time_col, sequence_length=3\n",
    "            )\n",
    "            \n",
    "            # Si los datos se preparan correctamente, crear y entrenar modelo ConvLSTM\n",
    "            if X_train_convlstm is not None:\n",
    "                print(\"\\n🧠 Creando y entrenando modelo ConvLSTM...\")\n",
    "                \n",
    "                def create_convlstm_model(input_shape):\n",
    "                    \"\"\"Crea un modelo ConvLSTM para predicción espaciotemporal\"\"\"\n",
    "                    model = Sequential([\n",
    "                        # Capa ConvLSTM\n",
    "                        ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same',\n",
    "                                  return_sequences=True, activation='tanh',\n",
    "                                  input_shape=input_shape),\n",
    "                        BatchNormalization(),\n",
    "                        \n",
    "                        # Segunda capa ConvLSTM\n",
    "                        ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same',\n",
    "                                   return_sequences=False, activation='tanh'),\n",
    "                        BatchNormalization(),\n",
    "                        \n",
    "                        # Capa convolucional para reducir mapas de características\n",
    "                        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "                        BatchNormalization(),\n",
    "                        MaxPooling2D(pool_size=(2, 2)),\n",
    "                        \n",
    "                        # Capas finales\n",
    "                        Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "                        UpSampling2D(size=(2, 2)),  # Restaurar dimensión original\n",
    "                        Conv2D(filters=1, kernel_size=(3, 3), activation='linear', padding='same')\n",
    "                    ])\n",
    "                    \n",
    "                    # Compilar modelo\n",
    "                    model.compile(\n",
    "                        loss='mse',\n",
    "                        optimizer=Adam(learning_rate=0.001),\n",
    "                        metrics=['mae']\n",
    "                    )\n",
    "                    \n",
    "                    return model\n",
    "                \n",
    "                # Crear modelo ConvLSTM\n",
    "                input_shape = X_train_convlstm.shape[1:]  # (sequence_length, height, width, features)\n",
    "                convlstm_model = create_convlstm_model(input_shape)\n",
    "                \n",
    "                # Mostrar resumen del modelo\n",
    "                convlstm_model.summary()\n",
    "                \n",
    "                # Callbacks para entrenamiento\n",
    "                callbacks = [\n",
    "                    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "                    ModelCheckpoint(filepath=model_output_dir / 'convlstm_model_best.h5',\n",
    "                                  save_best_only=True, monitor='val_loss')\n",
    "                ]\n",
    "                \n",
    "                # Entrenar modelo\n",
    "                history = convlstm_model.fit(\n",
    "                    X_train_convlstm, y_train_convlstm,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                # Evaluar modelo\n",
    "                print(\"\\n📊 Evaluando modelo ConvLSTM...\")\n",
    "                convlstm_metrics = convlstm_model.evaluate(X_test_convlstm, y_test_convlstm)\n",
    "                print(f\"Loss (MSE): {convlstm_metrics[0]:.4f}\")\n",
    "                print(f\"MAE: {convlstm_metrics[1]:.4f}\")\n",
    "                \n",
    "                # Predecir con el modelo\n",
    "                y_pred_convlstm = convlstm_model.predict(X_test_convlstm)\n",
    "                \n",
    "                # Aplanar las predicciones para calcular métricas\n",
    "                y_test_flat = y_test_convlstm.flatten()\n",
    "                y_pred_flat = y_pred_convlstm.flatten()\n",
    "                \n",
    "                # Filtrar valores donde y_test_flat > 0 (presumiblemente donde hay datos)\n",
    "                valid_indices = y_test_flat > 0\n",
    "                y_test_valid = y_test_flat[valid_indices]\n",
    "                y_pred_valid = y_pred_flat[valid_indices]\n",
    "                \n",
    "                # Calcular métricas\n",
    "                convlstm_rmse = np.sqrt(mean_squared_error(y_test_valid, y_pred_valid))\n",
    "                convlstm_mae = mean_absolute_error(y_test_valid, y_pred_valid)\n",
    "                convlstm_r2 = r2_score(y_test_valid, y_pred_valid)\n",
    "                \n",
    "                print(f\"RMSE: {convlstm_rmse:.4f}\")\n",
    "                print(f\"MAE: {convlstm_mae:.4f}\")\n",
    "                print(f\"R²: {convlstm_r2:.4f}\")\n",
    "                \n",
    "                # Guardar modelo\n",
    "                convlstm_model.save(model_output_dir / 'convlstm_model_final.h5')\n",
    "                print(\"Modelo ConvLSTM guardado como 'convlstm_model_final.h5'\")\n",
    "                \n",
    "                # Visualizar la historia del entrenamiento\n",
    "                plt.figure(figsize=(12, 5))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.plot(history.history['loss'])\n",
    "                plt.plot(history.history['val_loss'])\n",
    "                plt.title('Pérdida del modelo ConvLSTM')\n",
    "                plt.ylabel('Pérdida')\n",
    "                plt.xlabel('Época')\n",
    "                plt.legend(['Entrenamiento', 'Validación'], loc='upper right')\n",
    "                \n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot(history.history['mae'])\n",
    "                plt.plot(history.history['val_mae'])\n",
    "                plt.title('Error absoluto medio ConvLSTM')\n",
    "                plt.ylabel('MAE')\n",
    "                plt.xlabel('Época')\n",
    "                plt.legend(['Entrenamiento', 'Validación'], loc='upper right')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(model_output_dir / 'convlstm_training_history.png')\n",
    "                plt.show()\n",
    "                \n",
    "                # Añadir resultados a nuestro diccionario de comparación\n",
    "                resultados_base['ConvLSTM'] = (convlstm_rmse, convlstm_mae, convlstm_r2)\n",
    "            else:\n",
    "                print(\"No se pudieron preparar datos para ConvLSTM.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ejecutar preparación de datos para ConvLSTM: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"No se encontraron columnas temporales o espaciales suficientes para implementar ConvLSTM.\")\n",
    "        print(\"El modelo ConvLSTM requiere al menos una columna temporal y dos columnas espaciales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87873507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar optimización adaptativa de memoria RAM para modelos base\n",
    "print(\"\\n🔍 Ejecutando optimización adaptativa de memoria RAM para Random Forest...\")\n",
    "rf_params, rf_model_opt, rf_metrics_opt = run_memory_efficient_optimization('RandomForest', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(\"\\n🔍 Ejecutando optimización adaptativa de memoria RAM para XGBoost...\")\n",
    "xgb_params, xgb_model_opt, xgb_metrics_opt = run_memory_efficient_optimization('XGBoost', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(\"\\n🔍 Ejecutando optimización adaptativa de memoria RAM para LightGBM...\")\n",
    "lgbm_params, lgbm_model_opt, lgbm_metrics_opt = run_memory_efficient_optimization('LightGBM', X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "# Resumen de parámetros óptimos encontrados\n",
    "print(\"\\n📊 Mejores parámetros encontrados para cada modelo:\")\n",
    "print(f\"\\nRandom Forest: {rf_params}\")\n",
    "print(f\"\\nXGBoost: {xgb_params}\")\n",
    "print(f\"\\nLightGBM: {lgbm_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejora de visibilidad en el entrenamiento y errores para modelos CNN y ConvLSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Visualiza la historia del entrenamiento de un modelo.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Pérdida\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_loss'], label='Validación')\n",
    "    plt.title(f'Pérdida del modelo {model_name}')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_mae'], label='Validación')\n",
    "    plt.title(f'Error absoluto medio (MAE) - {model_name}')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_model_metrics(metrics, model_name):\n",
    "    \"\"\"Muestra las métricas de evaluación de un modelo de forma visual.\"\"\"\n",
    "    rmse, mae, r2 = metrics\n",
    "    display(HTML(f'<div style=\"background-color:#f5f5dc; padding:10px; border-radius:5px; margin-top:10px;\">' +\n",
    "                 f'<h3>📊 Métricas para {model_name}</h3>' +\n",
    "                 f'<table style=\"width:100%; text-align:left;\">' +\n",
    "                 f'<tr><th>Métrica</th><th>Valor</th></tr>' +\n",
    "                 f'<tr><td>RMSE</td><td>{rmse:.4f}</td></tr>' +\n",
    "                 f'<tr><td>MAE</td><td>{mae:.4f}</td></tr>' +\n",
    "                 f'<tr><td>R²</td><td>{r2:.4f}</td></tr>' +\n",
    "                 f'</table></div>'))\n",
    "\n",
    "# Aplicar mejoras de visibilidad al modelo CNN\n",
    "if 'cnn_model' in locals() and 'history' in locals():\n",
    "    print(\"\\n📈 Visualizando historia del entrenamiento para modelo CNN...\")\n",
    "    plot_training_history(history, 'CNN')\n",
    "\n",
    "if 'cnn_metrics' in locals():\n",
    "    print(\"\\n📊 Mostrando métricas para modelo CNN...\")\n",
    "    display_model_metrics((cnn_rmse, cnn_mae, cnn_r2), 'CNN')\n",
    "\n",
    "# Aplicar mejoras de visibilidad al modelo ConvLSTM\n",
    "if 'convlstm_model' in locals() and 'history' in locals():\n",
    "    print(\"\\n📈 Visualizando historia del entrenamiento para modelo ConvLSTM...\")\n",
    "    plot_training_history(history, 'ConvLSTM')\n",
    "\n",
    "if 'convlstm_metrics' in locals():\n",
    "    print(\"\\n📊 Mostrando métricas para modelo ConvLSTM...\")\n",
    "    display_model_metrics((convlstm_rmse, convlstm_mae, convlstm_r2), 'ConvLSTM')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "precipitation_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
