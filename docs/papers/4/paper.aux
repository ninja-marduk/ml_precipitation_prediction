\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\citation{Reichstein2019}
\citation{Poveda2011}
\citation{Shi2015}
\citation{Lam2023,Chen2024GRL}
\citation{Lam2023}
\citation{Bi2023}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{Li2021FNO}
\citation{Funk2015}
\citation{LopezBermeo2022}
\citation{Shi2015}
\citation{Perez2025}
\citation{Wang2018}
\citation{Trebing2021}
\citation{Ayzel2020}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Deep Learning for Precipitation Forecasting}{2}{subsection.2.1}\protected@file@percent }
\citation{Gao2022Earthformer}
\citation{Schulz2024}
\citation{Lam2023}
\citation{Chen2024GRL}
\citation{Peng2023JGR}
\citation{Funk2015}
\citation{LopezBermeo2022,Urrea2019}
\citation{Poveda2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Graph Neural Networks in Atmospheric Science}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Precipitation Data Products for the Tropical Andes}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Materials and Methods}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data access and preprocessing pipeline}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Study area and spatial extent}{4}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Study area: Colombia with Boyac\'a Department highlighted in red (QGIS-derived). The CHIRPS precipitation grid at 0.05$^{\circ }$ resolution covers the full Boyac\'a domain (61$\times $65 = 3,965 grid cells). All experiments use this full-grid configuration.}}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:maps}{{1}{4}{Study area: Colombia with Boyac\'a Department highlighted in red (QGIS-derived). The CHIRPS precipitation grid at 0.05$^{\circ }$ resolution covers the full Boyac\'a domain (61$\times $65 = 3,965 grid cells). All experiments use this full-grid configuration}{figure.caption.1}{}}
\newlabel{fig:maps@cref}{{[figure][1][]1}{[1][4][]4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Compute environment}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.3.0.1}Software Environment}{4}{paragraph.3.3.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Feature bundles and preprocessing}{4}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Model families and architectures}{5}{subsection.3.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Model architectures used in this study. Layer stacks are shown for each model family (ConvLSTM baselines, FNO, GNN-TAT) with input shape $(\mathrm  {None}, \mathrm  {None}, 61, 65, F)$ where $F$ is the number of features (12--18 depending on bundle) and $H=12$ output on full Boyac\'a grid.}}{5}{table.caption.2}\protected@file@percent }
\newlabel{tab:model-summaries}{{1}{5}{Model architectures used in this study. Layer stacks are shown for each model family (ConvLSTM baselines, FNO, GNN-TAT) with input shape $(\mathrm {None}, \mathrm {None}, 61, 65, F)$ where $F$ is the number of features (12--18 depending on bundle) and $H=12$ output on full Boyac\'a grid}{table.caption.2}{}}
\newlabel{tab:model-summaries@cref}{{[table][1][]1}{[1][5][]5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Training protocol and metrics}{5}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Global performance}{6}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Master Model Comparison: All Architectures at H=12 Forecast Horizon}}{6}{table.caption.3}\protected@file@percent }
\newlabel{tab:master-comparison}{{2}{6}{Master Model Comparison: All Architectures at H=12 Forecast Horizon}{table.caption.3}{}}
\newlabel{tab:master-comparison@cref}{{[table][2][]2}{[1][6][]6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Architecture overview}{6}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training convergence and validation analysis}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Comprehensive benchmark analysis}{6}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces High-level data and model flow. Three architecture families are compared: ConvLSTM baselines, physics-informed FNO, and hybrid GNN-TAT. All use the same feature bundles (BASIC, KCE, PAFC) and evaluation metrics.}}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:arch}{{2}{7}{High-level data and model flow. Three architecture families are compared: ConvLSTM baselines, physics-informed FNO, and hybrid GNN-TAT. All use the same feature bundles (BASIC, KCE, PAFC) and evaluation metrics}{figure.caption.4}{}}
\newlabel{fig:arch@cref}{{[figure][2][]2}{[1][6][]7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Convergence behaviour by architecture and experiment for $H{=}12$. Cooler colors indicate lower loss. Only a subset of KCE/PAFC models remain competitive, underscoring the need for stronger regularization when adding lags and attention.}}{7}{figure.caption.5}\protected@file@percent }
\newlabel{fig:valloss}{{3}{7}{Convergence behaviour by architecture and experiment for $H{=}12$. Cooler colors indicate lower loss. Only a subset of KCE/PAFC models remain competitive, underscoring the need for stronger regularization when adding lags and attention}{figure.caption.5}{}}
\newlabel{fig:valloss@cref}{{[figure][3][]3}{[1][6][]7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Forecast horizon degradation analysis: $R^{2}$ performance from H=1 to H=12 for top models from each family (ConvLSTM, FNO, GNN-TAT). ConvLSTM variants show 6--7\% degradation, GNN-TAT shows 9--11\% degradation, while FNO exhibits inconsistent behavior across horizons. Most ConvLSTM and GNN-TAT models maintain $R^{2}>0.55$ at H=12.}}{8}{figure.caption.6}\protected@file@percent }
\newlabel{fig:benchmark-horizon}{{4}{8}{Forecast horizon degradation analysis: $R^{2}$ performance from H=1 to H=12 for top models from each family (ConvLSTM, FNO, GNN-TAT). ConvLSTM variants show 6--7\% degradation, GNN-TAT shows 9--11\% degradation, while FNO exhibits inconsistent behavior across horizons. Most ConvLSTM and GNN-TAT models maintain $R^{2}>0.55$ at H=12}{figure.caption.6}{}}
\newlabel{fig:benchmark-horizon@cref}{{[figure][4][]4}{[1][7][]8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Feature set performance heatmap: $R^{2}$ at H=12 by model and feature engineering strategy (all families: ConvLSTM, FNO, GNN-TAT). BASIC features perform best with ConvLSTM variants, PAFC improves GNN-TAT performance (particularly GCN), while FNO struggles across all feature sets due to precipitation's discontinuous nature.}}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:benchmark-features}{{5}{8}{Feature set performance heatmap: $R^{2}$ at H=12 by model and feature engineering strategy (all families: ConvLSTM, FNO, GNN-TAT). BASIC features perform best with ConvLSTM variants, PAFC improves GNN-TAT performance (particularly GCN), while FNO struggles across all feature sets due to precipitation's discontinuous nature}{figure.caption.7}{}}
\newlabel{fig:benchmark-features@cref}{{[figure][5][]5}{[1][8][]8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Multi-metric radar comparison: ConvLSTM vs FNO vs GNN-TAT across normalized metrics (higher is better). GNN-TAT achieves superior parameter efficiency and stability, ConvLSTM achieves highest peak $R^{2}$, while FNO underperforms on accuracy metrics but offers moderate parameter efficiency.}}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:benchmark-radar}{{6}{9}{Multi-metric radar comparison: ConvLSTM vs FNO vs GNN-TAT across normalized metrics (higher is better). GNN-TAT achieves superior parameter efficiency and stability, ConvLSTM achieves highest peak $R^{2}$, while FNO underperforms on accuracy metrics but offers moderate parameter efficiency}{figure.caption.8}{}}
\newlabel{fig:benchmark-radar@cref}{{[figure][6][]6}{[1][8][]9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Parameter efficiency frontier: $R^{2}$ vs model size (log scale) for all families. GNN-TAT models cluster in the efficient region ($\sim $98K parameters) with competitive $R^{2}$, ConvLSTM variants span a wide parameter range (78K--2.1M), and FNO models show poor accuracy-efficiency trade-off. The Pareto frontier indicates GNN-TAT offers the best accuracy-efficiency balance.}}{9}{figure.caption.9}\protected@file@percent }
\newlabel{fig:benchmark-efficiency}{{7}{9}{Parameter efficiency frontier: $R^{2}$ vs model size (log scale) for all families. GNN-TAT models cluster in the efficient region ($\sim $98K parameters) with competitive $R^{2}$, ConvLSTM variants span a wide parameter range (78K--2.1M), and FNO models show poor accuracy-efficiency trade-off. The Pareto frontier indicates GNN-TAT offers the best accuracy-efficiency balance}{figure.caption.9}{}}
\newlabel{fig:benchmark-efficiency@cref}{{[figure][7][]7}{[1][8][]9}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}GNN-TAT: Graph Neural Networks with Temporal Attention}{9}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Model ranking by $R^{2}$ at H=12: Top 15 model configurations across all families (ConvLSTM, FNO, GNN-TAT). ConvLSTM with BASIC features dominates the top positions, followed by GNN-TAT variants. FNO models appear in lower ranks due to underperformance on precipitation prediction. The dashed line indicates the target $R^{2}=0.6$.}}{10}{figure.caption.10}\protected@file@percent }
\newlabel{fig:benchmark-ranking}{{8}{10}{Model ranking by $R^{2}$ at H=12: Top 15 model configurations across all families (ConvLSTM, FNO, GNN-TAT). ConvLSTM with BASIC features dominates the top positions, followed by GNN-TAT variants. FNO models appear in lower ranks due to underperformance on precipitation prediction. The dashed line indicates the target $R^{2}=0.6$}{figure.caption.10}{}}
\newlabel{fig:benchmark-ranking@cref}{{[figure][8][]8}{[1][8][]10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Training dynamics comparison: Validation loss curves for representative models from each family. GNN-TAT models converge faster (fewer epochs) and achieve lower final validation loss, demonstrating training efficiency advantages.}}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:benchmark-training}{{9}{10}{Training dynamics comparison: Validation loss curves for representative models from each family. GNN-TAT models converge faster (fewer epochs) and achieve lower final validation loss, demonstrating training efficiency advantages}{figure.caption.11}{}}
\newlabel{fig:benchmark-training@cref}{{[figure][9][]9}{[1][8][]10}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Architecture Overview}{10}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Hyperparameter Configuration for All Model Families}}{11}{table.caption.12}\protected@file@percent }
\newlabel{tab:hyperparameters}{{3}{11}{Hyperparameter Configuration for All Model Families}{table.caption.12}{}}
\newlabel{tab:hyperparameters@cref}{{[table][3][]3}{[1][10][]11}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}GNN-TAT Results}{11}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Horizon Degradation Analysis}{11}{subsection.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Forecast Horizon Degradation Analysis: R$^2$ Performance from H=1 to H=12 (All Families)}}{11}{table.caption.14}\protected@file@percent }
\newlabel{tab:horizon-degradation}{{4}{11}{Forecast Horizon Degradation Analysis: R$^2$ Performance from H=1 to H=12 (All Families)}{table.caption.14}{}}
\newlabel{tab:horizon-degradation@cref}{{[table][4][]4}{[1][11][]11}{}{}{}}
\citation{Lam2023,Chen2024GRL}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces GNN-TAT model comparison on full Boyac\'a grid: (a) RMSE by model and feature set, (b) $R^{2}$ by model and feature set with ConvLSTM baseline (dashed red), (c) RMSE degradation across horizons H=1--12, (d) bias distribution by GNN variant.}}{12}{figure.caption.13}\protected@file@percent }
\newlabel{fig:v4-comparison}{{10}{12}{GNN-TAT model comparison on full Boyac\'a grid: (a) RMSE by model and feature set, (b) $R^{2}$ by model and feature set with ConvLSTM baseline (dashed red), (c) RMSE degradation across horizons H=1--12, (d) bias distribution by GNN variant}{figure.caption.13}{}}
\newlabel{fig:v4-comparison@cref}{{[figure][10][]10}{[1][11][]12}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}GNN-TAT Advantages Over ConvLSTM}{12}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{12}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Architectural Implications}{12}{subsection.6.1}\protected@file@percent }
\citation{Li2021FNO}
\citation{Roe2005}
\citation{Kratzert2019}
\citation{Wani2024}
\citation{He2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Feature Engineering Value}{13}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Horizon Degradation and Predictability Limits}{13}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Comparison with State-of-the-Art}{13}{subsection.6.4}\protected@file@percent }
\citation{Reichstein2019}
\citation{Poveda2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Statistical Significance}{14}{subsection.6.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Statistical Significance Tests: Pairwise Family Comparisons}}{14}{table.caption.15}\protected@file@percent }
\newlabel{tab:statistical-tests}{{5}{14}{Statistical Significance Tests: Pairwise Family Comparisons}{table.caption.15}{}}
\newlabel{tab:statistical-tests@cref}{{[table][5][]5}{[1][14][]14}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Limitations and Future Directions}{14}{subsection.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Next Steps: Hybrid and Ensemble Architectures}{15}{subsection.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{15}{section.7}\protected@file@percent }
\bibcite{Perez2025}{{1}{}{{}}{{}}}
\bibcite{Shi2015}{{2}{}{{}}{{}}}
\bibcite{Wang2018}{{3}{}{{}}{{}}}
\bibcite{Lam2023}{{4}{}{{}}{{}}}
\bibcite{Chen2024GRL}{{5}{}{{}}{{}}}
\bibcite{Peng2023JGR}{{6}{}{{}}{{}}}
\bibcite{Bi2023}{{7}{}{{}}{{}}}
\bibcite{Li2021FNO}{{8}{}{{}}{{}}}
\bibcite{Funk2015}{{9}{}{{}}{{}}}
\bibcite{LopezBermeo2022}{{10}{}{{}}{{}}}
\bibcite{Urrea2019}{{11}{}{{}}{{}}}
\bibcite{Rivera2018}{{12}{}{{}}{{}}}
\bibcite{Kratzert2019}{{13}{}{{}}{{}}}
\bibcite{Gao2020}{{14}{}{{}}{{}}}
\bibcite{Reichstein2019}{{15}{}{{}}{{}}}
\bibcite{Roe2005}{{16}{}{{}}{{}}}
\bibcite{Poveda2011}{{17}{}{{}}{{}}}
\bibcite{Trebing2021}{{18}{}{{}}{{}}}
\bibcite{Gao2022Earthformer}{{19}{}{{}}{{}}}
\bibcite{Schulz2024}{{20}{}{{}}{{}}}
\bibcite{Ayzel2020}{{21}{}{{}}{{}}}
\bibcite{Ravuri2021}{{22}{}{{}}{{}}}
\bibcite{Wani2024}{{23}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {8}}{17}{section.8}\protected@file@percent }
\bibcite{He2024}{{24}{}{{}}{{}}}
\bibcite{ElHafyani2024}{{25}{}{{}}{{}}}
\bibcite{Zhao2024}{{26}{}{{}}{{}}}
\bibcite{Hirpa2010}{{27}{}{{}}{{}}}
\bibcite{Liu2023}{{28}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{LastPage}{{7}{18}{}{page.18}{}}
\gdef\lastpage@lastpage{18}
\gdef\lastpage@lastpageHy{18}
\gdef \@abspage@last{18}
