{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninja-marduk/ml_precipitation_prediction/blob/feature%2Fbase-models/models/base_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "635dc005",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "635dc005",
        "outputId": "3c92f653-3cb9-4a34-ad2a-76de41a169e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'ml_precipitation_prediction' already exists and is not an empty directory.\n",
            "/content/ml_precipitation_prediction\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2025.3.1)\n",
            "Requirement already satisfied: rioxarray in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.19.0)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.4.3)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2024.12.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (4.67.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.5.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.18.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4->-r requirements.txt (line 5)) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4->-r requirements.txt (line 5)) (2025.4.26)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray->-r requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 8)) (1.1.1)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 9)) (2.1.0)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (2025.3.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask->-r requirements.txt (line 10)) (8.7.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->-r requirements.txt (line 13)) (2.21.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 15)) (0.37.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->-r requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 15)) (0.45.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask->-r requirements.txt (line 10)) (3.21.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (0.15.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask->-r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 15)) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 15)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 15)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 15)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 15)) (0.1.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.3.1)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: ace_tools_open in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.11/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (24.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.4.26)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: itables in /usr/local/lib/python3.11/dist-packages (from ace_tools_open) (2.3.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (from ace_tools_open) (7.34.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.1.0)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython->ace_tools_open) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython->ace_tools_open) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->ace_tools_open) (0.2.13)\n",
            "Entorno configurado. Usando ruta base: /content/drive/MyDrive/ml_precipitation_prediction\n"
          ]
        }
      ],
      "source": [
        "# Configuración del entorno (compatible con Colab y local)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "# Regenerar el código con las condiciones específicas\n",
        "notebook_globals = {\n",
        "    \"USE_CROSS_VALIDATION\": False,\n",
        "    \"ENABLED_MODELS\": ['CNN', 'GRU'],\n",
        "    \"ENABLED_EXPERIMENTS\": ['time+cycles', 'all_features'],\n",
        "    \"ENABLED_HORIZONS\": [3],\n",
        "}\n",
        "\n",
        "# Detectar si estamos en Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Si estamos en Colab, clonar el repositorio\n",
        "    !git clone https://github.com/ninja-marduk/ml_precipitation_prediction.git\n",
        "    %cd ml_precipitation_prediction\n",
        "    # Instalar dependencias necesarias\n",
        "    !pip install -r requirements.txt\n",
        "    !pip install xarray netCDF4 optuna matplotlib seaborn lightgbm xgboost scikit-learn ace_tools_open cartopy\n",
        "    BASE_PATH = '/content/drive/MyDrive/ml_precipitation_prediction'\n",
        "else:\n",
        "    # Si estamos en local, usar la ruta actual\n",
        "    if '/models' in os.getcwd():\n",
        "        BASE_PATH = Path('..')\n",
        "    else:\n",
        "        BASE_PATH = Path('.')\n",
        "\n",
        "print(f\"Entorno configurado. Usando ruta base: {BASE_PATH}\")\n",
        "\n",
        "# Si BASE_PATH viene como string, lo convertimos\n",
        "BASE_PATH = Path(BASE_PATH)\n",
        "\n",
        "# Ahora puedes concatenar correctamente\n",
        "data_output_dir = BASE_PATH / 'data' / 'output'\n",
        "model_output_dir = BASE_PATH / 'models' / 'output'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8ccc04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8ccc04",
        "outputId": "41d47025-2484-4910-b6a1-e99c38f3b966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Detectando dispositivo disponible...\n",
            "✅ GPU detectada: /physical_device:GPU:0\n",
            "ℹ️ Entrenamiento acelerado con GPU activado.\n",
            "📂 Configurando directorios y cargando dataset...\n",
            "✔️ Modelos en: /content/drive/MyDrive/ml_precipitation_prediction/models/output/ST_HybridWaveStack\n",
            "✔️ Curvas en: /content/drive/MyDrive/ml_precipitation_prediction/models/output/ST_HybridWaveStack/learning_curves\n",
            "✔️ Dataset cargado desde: /content/drive/MyDrive/ml_precipitation_prediction/data/output/complete_dataset_with_features_with_clusters_elevation_with_windows.nc\n",
            "✅ Variables requeridas presentes.\n",
            "\n",
            "🚀 Experimento: time+cycles\n",
            "📉 Secuencias orig.: 2101387, válidas: 2101387, eliminadas: 0 (0.00%)\n",
            "🔧 Modelo: CNN\n",
            "⏩ Ya existe. Skip.\n",
            "\n",
            "🚀 Experimento: time+cycles+elev\n",
            "📉 Secuencias orig.: 2101387, válidas: 2101387, eliminadas: 0 (0.00%)\n",
            "🔧 Modelo: CNN\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 3ms/step - loss: 0.3625 - val_loss: 0.5848\n",
            "Epoch 2/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3ms/step - loss: 0.3016 - val_loss: 2.1834\n",
            "Epoch 3/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3ms/step - loss: 0.2904 - val_loss: 1.3271\n",
            "Epoch 4/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3ms/step - loss: 0.2879 - val_loss: 3.5862\n",
            "Epoch 5/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3ms/step - loss: 0.2861 - val_loss: 5.3133\n",
            "Epoch 6/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3ms/step - loss: 0.2834 - val_loss: 4.6434\n",
            "Epoch 7/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 3ms/step - loss: 0.2842 - val_loss: 2.2013\n",
            "Epoch 8/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 3ms/step - loss: 0.2828 - val_loss: 5.0000\n",
            "Epoch 9/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 3ms/step - loss: 0.2818 - val_loss: 2.8726\n",
            "Epoch 10/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 3ms/step - loss: 0.2810 - val_loss: 2.7782\n",
            "\u001b[1m19701/19701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Modelo guardado: time_cycles_elev_CNN_NoCV.h5\n",
            "\n",
            "🚀 Experimento: time+cycles+elev+cluster\n",
            "📉 Secuencias orig.: 2101387, válidas: 2101387, eliminadas: 0 (0.00%)\n",
            "🔧 Modelo: CNN\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 3ms/step - loss: 0.3560 - val_loss: 0.5302\n",
            "Epoch 2/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 3ms/step - loss: 0.3033 - val_loss: 0.8133\n",
            "Epoch 3/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3ms/step - loss: 0.2968 - val_loss: 0.6821\n",
            "Epoch 4/50\n",
            "\u001b[1m91936/91936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3ms/step - loss: 0.2946 - val_loss: 1.3460\n",
            "Epoch 5/50\n",
            "\u001b[1m14038/91936\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 2ms/step - loss: 0.2974"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.layers import Input\n",
        "import traceback\n",
        "\n",
        "# ==== Variables de control ====\n",
        "USE_CROSS_VALIDATION = False\n",
        "ENABLED_MODELS = ['CNN'] # Primer ronda ENABLED_MODELS = ['CNN', 'GRU'], segunda ronda: ENABLED_MODELS = ['LSTM', 'BLSTM']\n",
        "ENABLED_EXPERIMENTS = ['time+cycles', 'time+cycles+elev', 'time+cycles+elev+cluster']\n",
        "ENABLED_HORIZONS = [3]\n",
        "INPUT_WINDOW = 60  # 5 años (mensual)\n",
        "OUTPUT_HORIZON = 3\n",
        "\n",
        "# ==== Configuración de entorno ====\n",
        "print(\"🔍 Detectando dispositivo disponible...\")\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "USE_GPU = bool(gpu_devices)\n",
        "if USE_GPU:\n",
        "    print(\"✅ GPU detectada:\", gpu_devices[0].name)\n",
        "    print(\"ℹ️ Entrenamiento acelerado con GPU activado.\")\n",
        "else:\n",
        "    print(\"⚠️ No se detectó GPU. Usando CPU.\")\n",
        "\n",
        "# ==== Funciones auxiliares ====\n",
        "def build_model(model_type, input_shape, output_neurons):\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, GRU, Bidirectional, Reshape\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape, dtype='float32'))\n",
        "    if model_type == 'LSTM':\n",
        "        model.add(LSTM(64))\n",
        "    elif model_type == 'GRU':\n",
        "        model.add(GRU(64))\n",
        "    elif model_type == 'BLSTM':\n",
        "        model.add(Bidirectional(LSTM(64)))\n",
        "    elif model_type == 'CNN':\n",
        "        model.add(Reshape((*input_shape, 1)))\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "    model.add(Dense(output_neurons))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return rmse, mae, mape, r2\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size=16):\n",
        "        self.x, self.y = x_set.astype(np.float32), y_set.astype(np.float32)\n",
        "        self.batch_size = batch_size\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "def to_dataset(x, y):\n",
        "    x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
        "    y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
        "    return tf.data.Dataset.from_tensor_slices((x, y)).batch(16).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ==== Directorios y Dataset ====\n",
        "print(\"📂 Configurando directorios y cargando dataset...\")\n",
        "try:\n",
        "    model_output_dir_STH = model_output_dir / 'ST_HybridWaveStack'\n",
        "    curves_dir = model_output_dir_STH / \"learning_curves\"\n",
        "    if not model_output_dir_STH.exists():\n",
        "        model_output_dir_STH.mkdir(parents=True)\n",
        "    if not curves_dir.exists():\n",
        "        curves_dir.mkdir(parents=True)\n",
        "    print(f\"✔️ Modelos en: {model_output_dir_STH}\")\n",
        "    print(f\"✔️ Curvas en: {curves_dir}\")\n",
        "\n",
        "    file_path = data_output_dir / \"complete_dataset_with_features_with_clusters_elevation_with_windows.nc\"\n",
        "    ds = xr.open_dataset(file_path)\n",
        "    print(f\"✔️ Dataset cargado desde: {file_path}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Error cargando dataset o creando carpetas: {e}\")\n",
        "\n",
        "# ==== Configuración de experimentos ====\n",
        "experiment_settings = {\n",
        "    \"time+cycles\": ['year','month',\n",
        "                    'month_sin','month_cos','doy_sin','doy_cos'],\n",
        "    \"time+cycles+lag\":  ['year','month',\n",
        "                        'month_sin','month_cos','doy_sin','doy_cos',\n",
        "                        'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "                        'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36'],\n",
        "    \"time+cycles+lag+elev\": ['year','month',\n",
        "                             'month_sin','month_cos','doy_sin','doy_cos',\n",
        "                            'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "                            'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36',\n",
        "                            'elevation','slope','aspect'],\n",
        "    \"time+cycles+elev\":   ['year','month',\n",
        "                          'month_sin','month_cos','doy_sin','doy_cos',\n",
        "                          'elevation','slope','aspect'],\n",
        "    \"time+cycles+elev+cluster\":   ['year','month',\n",
        "                                  'month_sin','month_cos','doy_sin','doy_cos',\n",
        "                                  'elevation','slope','aspect',\n",
        "                                  'cluster_elevation'],\n",
        "    \"all_features\": ['year','month',\n",
        "                     'month_sin','month_cos','doy_sin','doy_cos',\n",
        "                    'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "                    'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36',\n",
        "                    'elevation','slope','aspect',\n",
        "                     'cluster_elevation']\n",
        "}\n",
        "\n",
        "# Validación de variables\n",
        "ds_vars = set(ds.data_vars)\n",
        "for name, vars_list in experiment_settings.items():\n",
        "    missing = [v for v in vars_list if v not in ds_vars]\n",
        "    if missing:\n",
        "        raise ValueError(f\"❌ Faltan vars para '{name}': {missing}\")\n",
        "print(\"✅ Variables requeridas presentes.\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# ==== Entrenamiento modular ====\n",
        "for exp_name, variables in experiment_settings.items():\n",
        "    if exp_name not in ENABLED_EXPERIMENTS:\n",
        "        continue\n",
        "    print(f\"\\n🚀 Experimento: {exp_name}\")\n",
        "    try:\n",
        "        # Preparar datos\n",
        "        cluster_idx = variables.index('cluster_elevation') if 'cluster_elevation' in variables else None\n",
        "        subset = ds[variables].to_array().transpose('time','latitude','longitude','variable').values\n",
        "        if cluster_idx is not None:\n",
        "            cd = subset[...,cluster_idx]\n",
        "            subset[...,cluster_idx] = LabelEncoder().fit_transform(cd.ravel()).reshape(cd.shape)\n",
        "        subset = subset.astype(np.float32)\n",
        "        target = ds['total_precipitation'].values\n",
        "        samples,lat,lon,feats = subset.shape\n",
        "        X = subset.reshape(samples, lat*lon, feats)\n",
        "        y = target.reshape(samples, lat*lon)\n",
        "        mask = ~np.isnan(y)\n",
        "        X, y = X[mask], y[mask]\n",
        "\n",
        "        # Generar secuencias\n",
        "        X_seq, Y_targets = [], []\n",
        "        for i in range(len(X) - INPUT_WINDOW - OUTPUT_HORIZON):\n",
        "            X_seq.append(X[i:i + INPUT_WINDOW])\n",
        "            Y_targets.append([y[i + INPUT_WINDOW + h] for h in range(OUTPUT_HORIZON)])\n",
        "        X_seq = np.array(X_seq)\n",
        "        Y_targets = np.array(Y_targets)\n",
        "\n",
        "        # --- FILTRAR Secuencias con NaNs y reportar ---\n",
        "        def filtrar_secuencias(Xs, ys):\n",
        "            total = len(Xs)\n",
        "            valid = (~np.isnan(Xs).any(axis=(1,2))) & (~np.isnan(ys).any(axis=1))\n",
        "            kept = valid.sum()\n",
        "            lost = total - kept\n",
        "            pct = 100 * lost/total\n",
        "            print(f\"📉 Secuencias orig.: {total}, válidas: {kept}, eliminadas: {lost} ({pct:.2f}%)\")\n",
        "            return Xs[valid], ys[valid]\n",
        "\n",
        "        X_seq, Y_targets = filtrar_secuencias(X_seq, Y_targets)\n",
        "\n",
        "        if len(X_seq)==0:\n",
        "            print(f\"⚠️ No quedan secuencias válidas para '{exp_name}'. Saltando.\")\n",
        "            continue\n",
        "\n",
        "        input_shape = (X_seq.shape[1], X_seq.shape[2])\n",
        "\n",
        "        # Cross-validation\n",
        "        for model_name in ENABLED_MODELS:\n",
        "            print(f\"🔧 Modelo: {model_name}\")\n",
        "            # Partición\n",
        "            if USE_CROSS_VALIDATION:\n",
        "                splitter = KFold(n_splits=3, shuffle=False).split(X_seq)\n",
        "            else:\n",
        "                split_idx = int(len(X_seq) * 0.7)\n",
        "                splitter = [(\n",
        "                    np.arange(split_idx),\n",
        "                    np.arange(split_idx, len(X_seq))\n",
        "                )]\n",
        "\n",
        "            for h in ENABLED_HORIZONS:\n",
        "                for split_id, (tr_idx, va_idx) in enumerate(splitter, start=1):\n",
        "                    X_tr, X_va = X_seq[tr_idx], X_seq[va_idx]\n",
        "                    y_tr, y_va = Y_targets[tr_idx], Y_targets[va_idx]\n",
        "\n",
        "                    # Escalado\n",
        "                    scalerX=StandardScaler()\n",
        "                    shpX = X_tr.shape\n",
        "                    X_tr = scalerX.fit_transform(X_tr.reshape(-1,shpX[-1])).reshape(shpX)\n",
        "                    shpX2 = X_va.shape\n",
        "                    X_va = scalerX.transform(X_va.reshape(-1,shpX[-1])).reshape(shpX2)\n",
        "                    scalery=StandardScaler()\n",
        "                    y_tr = scalery.fit_transform(y_tr.reshape(-1,1)).reshape(y_tr.shape)\n",
        "                    y_va = scalery.transform(y_va.reshape(-1,1)).reshape(y_va.shape)\n",
        "\n",
        "                    # Data generators\n",
        "                    train_gen = DataGenerator(X_tr, y_tr, batch_size=16)\n",
        "                    val_gen   = DataGenerator(X_va, y_va, batch_size=16)\n",
        "\n",
        "                    # Nombre de archivo\n",
        "                    postfix = f\"_H{h}\" if USE_CROSS_VALIDATION else \"_NoCV\"\n",
        "                    model_path = model_output_dir_STH / f\"{exp_name.replace('+','_')}_{model_name}{postfix}.h5\"\n",
        "                    if model_path.exists():\n",
        "                        print(\"⏩ Ya existe. Skip.\")\n",
        "                        continue\n",
        "\n",
        "                    model = build_model(model_name, input_shape, output_neurons = OUTPUT_HORIZON)\n",
        "                    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=9, restore_best_weights=True)\n",
        "                    history = model.fit(train_gen,\n",
        "                                        validation_data=val_gen,\n",
        "                                        epochs=50,\n",
        "                                        verbose=1,\n",
        "                                        callbacks=[es])\n",
        "\n",
        "                    # Evaluación\n",
        "                    y_pred = model.predict(X_va)  # Mantiene la forma (samples, 3)\n",
        "                    y_true = y_va  # También (samples, 3)\n",
        "\n",
        "                    metrics = [evaluate(y_true[:, i], y_pred[:, i]) for i in range(OUTPUT_HORIZON)]\n",
        "\n",
        "                    results.append({\n",
        "                        'experiment': exp_name,\n",
        "                        'model': model_name,\n",
        "                        'horizon': h,\n",
        "                        'cv_enabled': USE_CROSS_VALIDATION,\n",
        "                        'RMSE': np.mean([m[0] for m in metrics]),\n",
        "                        'MAE': np.mean([m[1] for m in metrics]),\n",
        "                        'MAPE': np.mean([m[2] for m in metrics]),\n",
        "                        'R2': np.mean([m[3] for m in metrics]),\n",
        "                        'epochs': len(history.history['loss'])\n",
        "                    })\n",
        "\n",
        "                    # Curva\n",
        "                    plt.figure()\n",
        "                    plt.plot(history.history['loss'], label='Train')\n",
        "                    plt.plot(history.history['val_loss'], label='Val')\n",
        "                    plt.title(f'{exp_name} - {model_name} - {\"NoCV\" if not USE_CROSS_VALIDATION else f\"H{h}\"}')\n",
        "                    plt.xlabel('Epoch')\n",
        "                    plt.ylabel('Loss')\n",
        "                    plt.legend()\n",
        "                    fname = f\"{exp_name.replace('+','_')}_{model_name}{postfix}.png\"\n",
        "                    plt.savefig(curves_dir / fname)\n",
        "                    plt.close()\n",
        "\n",
        "                    model.save(model_path)\n",
        "                    print(f\"💾 Modelo guardado: {model_path.name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error en '{exp_name}': {e}\\n{traceback.format_exc()}\")\n",
        "\n",
        "# ==== Guardar resultados ====\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"resultados_modelos_cv_8anios_mvp.csv\", index=False)\n",
        "print(results_df.head())\n",
        "\n",
        "import ace_tools_open as tools\n",
        "tools.display_dataframe_to_user(name=\"Resultados CV MVP\", dataframe=results_df)\n",
        "print(\"✅ Proceso finalizado con éxito.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 👇 CÓDIGO COMPLETO CON LOS AJUSTES SOLICITADOS 👇\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from pathlib import Path\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import traceback\n",
        "\n",
        "# ==== Configuración de experimentos ====\n",
        "experiment_settings = {\n",
        "    \"time+cycles\": ['year','month','month_sin','month_cos','doy_sin','doy_cos'],\n",
        "    \"time+cycles+lag\": ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
        "        'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "        'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36'],\n",
        "    \"time+cycles+lag+elev\": ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
        "        'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "        'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36',\n",
        "        'elevation','slope','aspect'],\n",
        "    \"time+cycles+elev\": ['year','month','month_sin','month_cos','doy_sin','doy_cos','elevation','slope','aspect'],\n",
        "    \"time+cycles+elev+cluster\": ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
        "        'elevation','slope','aspect','cluster_elevation'],\n",
        "    \"all_features\": ['year','month','month_sin','month_cos','doy_sin','doy_cos',\n",
        "        'total_precipitation_lag1','total_precipitation_lag2','total_precipitation_lag3',\n",
        "        'total_precipitation_lag4','total_precipitation_lag12','total_precipitation_lag24','total_precipitation_lag36',\n",
        "        'elevation','slope','aspect','cluster_elevation']\n",
        "}\n",
        "target_var = 'total_precipitation'\n",
        "input_window = 60\n",
        "horizon = 3\n",
        "\n",
        "# ==== Función de evaluación ====\n",
        "def evaluate(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return rmse, mae, mape, r2\n",
        "\n",
        "def plot_map(data, title, cmap='viridis', vmin=None, vmax=None):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.set_title(title, fontsize=14)\n",
        "    mesh = plt.pcolormesh(ds_out.lon, ds_out.lat, data, cmap=cmap,\n",
        "                          shading='auto', vmin=vmin, vmax=vmax)\n",
        "    plt.colorbar(mesh, ax=ax, orientation='vertical', label=title)\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "    ax.add_feature(cfeature.LAKES, edgecolor='gray')\n",
        "    ax.add_feature(cfeature.RIVERS, edgecolor='blue')\n",
        "    ax.gridlines(draw_labels=True)\n",
        "    plt.show()\n",
        "\n",
        "# ==== Directorios y Dataset ====\n",
        "print(\"📂 Configurando directorios y cargando dataset...\")\n",
        "try:\n",
        "    model_output_dir_STH = Path(\"/content/drive/MyDrive/ml_precipitation_prediction/models/output/ST_HybridWaveStack\")\n",
        "    data_output_dir = Path(\"/content/drive/MyDrive/ml_precipitation_prediction/data/output\")\n",
        "    model_files = sorted([f for f in model_output_dir_STH.glob(\"*.h5\")])\n",
        "    print(f\"✔️ Modelos encontrados: {len(model_files)}\")\n",
        "    ds_path = data_output_dir / \"complete_dataset_with_features_with_clusters_elevation_with_windows.nc\"\n",
        "    ds = xr.open_dataset(ds_path)\n",
        "    print(f\"✔️ Dataset cargado desde: {ds_path}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Error cargando modelos o dataset: {e}\")\n",
        "\n",
        "results = []\n",
        "lat = ds.latitude.size\n",
        "lon = ds.longitude.size\n",
        "n_cells = lat * lon\n",
        "\n",
        "for model_path in model_files:\n",
        "    print(f\"🔍 Evaluando modelo: {model_path.name}\")\n",
        "    try:\n",
        "        experiment_key = next((key for key in experiment_settings if all(k in model_path.stem for k in key.replace(\"+\", \"_\").split(\"_\"))), None)\n",
        "        if experiment_key is None:\n",
        "            print(f\"⚠️ No se identificó experimento para {model_path.name}\")\n",
        "            continue\n",
        "        variables = experiment_settings[experiment_key]\n",
        "\n",
        "        subset = ds[variables].to_array().transpose('time', 'latitude', 'longitude', 'variable').values\n",
        "        target = ds[target_var].values\n",
        "\n",
        "        if 'cluster_elevation' in variables:\n",
        "            cluster_idx = variables.index('cluster_elevation')\n",
        "            encoded = LabelEncoder().fit_transform(subset[..., cluster_idx].ravel()).reshape(subset[..., cluster_idx].shape)\n",
        "            subset[..., cluster_idx] = encoded\n",
        "\n",
        "        subset = subset.astype(np.float32)\n",
        "        samples, _, _, feats = subset.shape\n",
        "        X_all = subset.reshape(samples, lat * lon, feats)\n",
        "        y_all = target.reshape(samples, lat * lon)\n",
        "\n",
        "        mask = ~np.isnan(y_all)\n",
        "        X_all = X_all[mask]\n",
        "        y_all = y_all[mask]\n",
        "\n",
        "        X_seq, Y_seq = [], []\n",
        "        for i in range(len(X_all) - input_window - horizon):\n",
        "            X_seq.append(X_all[i:i + input_window])\n",
        "            Y_seq.append([y_all[i + input_window + h] for h in range(horizon)])\n",
        "        X_seq = np.array(X_seq)\n",
        "        Y_seq = np.array(Y_seq)\n",
        "\n",
        "        split_idx = int(len(X_seq) * 0.7)\n",
        "        X_test = X_seq[split_idx:]\n",
        "        Y_test = Y_seq[split_idx:]\n",
        "\n",
        "        scaler_X = StandardScaler()\n",
        "        scaler_y = StandardScaler()\n",
        "\n",
        "        X_test_scaled = scaler_X.fit_transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "        Y_test_scaled = scaler_y.fit_transform(Y_test.reshape(-1, 1)).reshape(Y_test.shape)\n",
        "\n",
        "        model = tf.keras.models.load_model(model_path, compile=False)\n",
        "        Y_pred_scaled = model.predict(X_test_scaled, verbose=0)\n",
        "        Y_pred = scaler_y.inverse_transform(Y_pred_scaled)\n",
        "        Y_true = scaler_y.inverse_transform(Y_test_scaled)\n",
        "\n",
        "        steps = (len(Y_pred) // n_cells)\n",
        "        n_valid = steps * n_cells\n",
        "        Y_pred = Y_pred[:n_valid].reshape(steps, lat, lon, horizon)\n",
        "        Y_true = Y_true[:n_valid].reshape(steps, lat, lon, horizon)\n",
        "\n",
        "        for i in range(horizon):\n",
        "            pred_map = Y_pred[..., i].mean(axis=0)\n",
        "            true_map = Y_true[..., i].mean(axis=0)\n",
        "            mape_map = np.abs((true_map - pred_map) / (true_map + 1e-5)) * 100\n",
        "\n",
        "            # Fecha estimada del mes predicho\n",
        "            t_index = ds.time.values[input_window + i]\n",
        "            fecha = str(np.datetime_as_string(t_index, unit='M'))\n",
        "\n",
        "            ds_out = xr.Dataset({\n",
        "                \"predicted\": ((\"lat\", \"lon\"), pred_map),\n",
        "                \"observed\": ((\"lat\", \"lon\"), true_map),\n",
        "                \"mape\": ((\"lat\", \"lon\"), mape_map),\n",
        "            }, coords={\"lat\": ds.latitude.values, \"lon\": ds.longitude.values})\n",
        "            ds_out.to_netcdf(model_output_dir_STH / f\"{model_path.stem}_month{i+1}_{fecha}.nc\")\n",
        "\n",
        "            # Mapas\n",
        "            plot_map(pred_map, f\"{model_path.stem} - Predicción mes {i+1} ({fecha})\", cmap='Blues')\n",
        "            plot_map(mape_map, f\"{model_path.stem} - MAPE mes {i+1} ({fecha}) [%]\", cmap='Reds', vmin=0, vmax=100)\n",
        "\n",
        "            rmse, mae, mape, r2 = evaluate(true_map.flatten(), pred_map.flatten())\n",
        "            results.append({\n",
        "                'model': model_path.name,\n",
        "                'experiment': experiment_key,\n",
        "                'month': i + 1,\n",
        "                'fecha': fecha,\n",
        "                'RMSE': rmse,\n",
        "                'MAE': mae,\n",
        "                'MAPE (%)': mape,\n",
        "                'R2': r2\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error evaluando {model_path.name}:\\n{traceback.format_exc()}\")\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(model_output_dir_STH / \"metrics_modelos_test.csv\", index=False)\n",
        "\n",
        "import ace_tools_open as tools\n",
        "tools.display_dataframe_to_user(name=\"Resultados Test Flexible\", dataframe=df_results)\n",
        "print(\"📊 Evaluación finalizada.\")\n"
      ],
      "metadata": {
        "id": "PszSo0yXlmyd",
        "outputId": "2ceaceb8-b94a-4445-c45e-aae06cc02568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "PszSo0yXlmyd",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Configurando directorios y cargando dataset...\n",
            "✔️ Modelos encontrados: 4\n",
            "🧠 Ejemplos: ['time_cycles_CNN_NoCV.h5', 'time_cycles_GRU_NoCV.h5', 'time_cycles_elev_GRU_NoCV.h5']\n",
            "✔️ Dataset cargado desde: /content/drive/MyDrive/ml_precipitation_prediction/data/output/complete_dataset_with_features_with_clusters_elevation_with_windows.nc\n",
            "🔍 Evaluando modelo: time_cycles_CNN_NoCV.h5\n",
            "❌ Error evaluando time_cycles_CNN_NoCV.h5: Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-4a98bb5c8a13>\", line 129, in <cell line: 0>\n",
            "    y_pred_scaled = model.predict(X_test_scaled, verbose=0).flatten()\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 124, in error_handler\n",
            "    del filtered_tb\n",
            "ValueError: Exception encountered when calling Reshape.call().\n",
            "\n",
            "\u001b[1mCannot reshape a tensor with 18432 elements to shape [32,60,6,1] (11520 elements) for '{{node sequential_10_1/reshape_1/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](data, sequential_10_1/reshape_1/Reshape/shape)' with input shapes: [32,96,6], [4] and with input tensors computed as partial shapes: input[1] = [32,60,6,1].\u001b[0m\n",
            "\n",
            "Arguments received by Reshape.call():\n",
            "  • inputs=tf.Tensor(shape=(32, 96, 6), dtype=float32)\n",
            "\n",
            "🔍 Evaluando modelo: time_cycles_GRU_NoCV.h5\n",
            "❌ Error evaluando time_cycles_GRU_NoCV.h5: Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-4a98bb5c8a13>\", line 138, in <cell line: 0>\n",
            "    rmse, mae, mape, r2 = evaluate(y_true, y_pred)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-4-4a98bb5c8a13>\", line 49, in evaluate\n",
            "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 565, in mean_squared_error\n",
            "    _check_reg_targets_with_floating_dtype(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 198, in _check_reg_targets_with_floating_dtype\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "                                          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 104, in _check_reg_targets\n",
            "    check_consistent_length(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 475, in check_consistent_length\n",
            "    raise ValueError(\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [630406, 1887340]\n",
            "\n",
            "🔍 Evaluando modelo: time_cycles_elev_GRU_NoCV.h5\n",
            "❌ Error evaluando time_cycles_elev_GRU_NoCV.h5: Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-4a98bb5c8a13>\", line 138, in <cell line: 0>\n",
            "    rmse, mae, mape, r2 = evaluate(y_true, y_pred)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-4-4a98bb5c8a13>\", line 49, in evaluate\n",
            "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 565, in mean_squared_error\n",
            "    _check_reg_targets_with_floating_dtype(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 198, in _check_reg_targets_with_floating_dtype\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "                                          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 104, in _check_reg_targets\n",
            "    check_consistent_length(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 475, in check_consistent_length\n",
            "    raise ValueError(\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [630406, 1887340]\n",
            "\n",
            "🔍 Evaluando modelo: time_cycles_elev_cluster_GRU_NoCV.h5\n",
            "❌ Error evaluando time_cycles_elev_cluster_GRU_NoCV.h5: Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-4a98bb5c8a13>\", line 138, in <cell line: 0>\n",
            "    rmse, mae, mape, r2 = evaluate(y_true, y_pred)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-4-4a98bb5c8a13>\", line 49, in evaluate\n",
            "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 565, in mean_squared_error\n",
            "    _check_reg_targets_with_floating_dtype(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 198, in _check_reg_targets_with_floating_dtype\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "                                          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py\", line 104, in _check_reg_targets\n",
            "    check_consistent_length(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 475, in check_consistent_length\n",
            "    raise ValueError(\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [630406, 1887340]\n",
            "\n",
            "Resultados Test Flexible\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table id=\"itables_bc8c9107_7445_4990_a5c6_e37d8980b835\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
              "<thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead><tbody><tr>\n",
              "<td style=\"vertical-align:middle; text-align:left\">\n",
              "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
              "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
              "    <g style=\"fill:#d9d7fc\">\n",
              "        <path d=\"M100,400H500V357H100Z\" />\n",
              "        <path d=\"M100,300H400V257H100Z\" />\n",
              "        <path d=\"M0,200H400V157H0Z\" />\n",
              "        <path d=\"M100,100H500V57H100Z\" />\n",
              "        <path d=\"M100,350H500V307H100Z\" />\n",
              "        <path d=\"M100,250H400V207H100Z\" />\n",
              "        <path d=\"M0,150H400V107H0Z\" />\n",
              "        <path d=\"M100,50H500V7H100Z\" />\n",
              "    </g>\n",
              "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
              "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"0;0;400\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;300;0\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;400\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
              "            <g transform=\"translate(45 50) rotate(-45)\">\n",
              "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
              "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(450 152)\">\n",
              "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
              "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(50 352)\">\n",
              "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
              "                <polygon points=\"-35,10 0,45 35,10\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(75 250)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(425 250) rotate(180)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "        </g>\n",
              "    </g>\n",
              "</svg>\n",
              "</a>\n",
              "Loading ITables v2.3.0 from the internet...\n",
              "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
              "</tr></tbody>\n",
              "</table>\n",
              "<link href=\"https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.css\" rel=\"stylesheet\">\n",
              "<script type=\"module\">\n",
              "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.js';\n",
              "\n",
              "    document.querySelectorAll(\"#itables_bc8c9107_7445_4990_a5c6_e37d8980b835:not(.dataTable)\").forEach(table => {\n",
              "        if (!(table instanceof HTMLTableElement))\n",
              "            return;\n",
              "\n",
              "        // Define the table data\n",
              "        const data = [];\n",
              "\n",
              "        // Define the dt_args\n",
              "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n",
              "        dt_args[\"data\"] = data;\n",
              "\n",
              "        \n",
              "        new DataTable(table, dt_args);\n",
              "    });\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluación finalizada.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}